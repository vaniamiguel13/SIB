{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b35bfb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Context"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data used in this report was retrived from KAGGLE: https://www.kaggle.com/c/novozymes-enzyme-stability-prediction\n",
    "Each data example consists of a protein sequence, a pH value and thermostability index. Predicting the thermostability is fundamental in enzyme engeneering for a wide variety of applications. Employing ML techniques is of great value to achieve the latter purpose as it saves time and money."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "a3550ca3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6778f3ec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "updates = pd.read_csv(\"train_updates_20220929.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definiram-se os dados de teste e treino e, ainda, se definiu dados de treino atualizados, de modo a corrigir-se alguns dos dados de treino."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecba4e3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>47.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31385</th>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31386</th>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31388</th>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31389</th>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31390 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id                                   protein_sequence   pH  \\\n",
       "0           0  AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...  7.0   \n",
       "1           1  AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...  7.0   \n",
       "2           2  AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...  7.0   \n",
       "3           3  AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...  7.0   \n",
       "4           4  AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...  7.0   \n",
       "...       ...                                                ...  ...   \n",
       "31385   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n",
       "31386   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n",
       "31387   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n",
       "31388   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n",
       "31389   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n",
       "\n",
       "                             data_source    tm  \n",
       "0      doi.org/10.1038/s41592-020-0801-4  75.7  \n",
       "1      doi.org/10.1038/s41592-020-0801-4  50.5  \n",
       "2      doi.org/10.1038/s41592-020-0801-4  40.5  \n",
       "3      doi.org/10.1038/s41592-020-0801-4  47.2  \n",
       "4      doi.org/10.1038/s41592-020-0801-4  49.5  \n",
       "...                                  ...   ...  \n",
       "31385  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "31386  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "31387  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "31388  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "31389  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[31390 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63fc0003",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>30738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>30739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>30740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>30741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>30742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2434 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seq_id protein_sequence  pH  data_source  tm\n",
       "0         69              NaN NaN          NaN NaN\n",
       "1         70              NaN NaN          NaN NaN\n",
       "2         71              NaN NaN          NaN NaN\n",
       "3         72              NaN NaN          NaN NaN\n",
       "4         73              NaN NaN          NaN NaN\n",
       "...      ...              ...  ..          ...  ..\n",
       "2429   30738              NaN NaN          NaN NaN\n",
       "2430   30739              NaN NaN          NaN NaN\n",
       "2431   30740              NaN NaN          NaN NaN\n",
       "2432   30741              NaN NaN          NaN NaN\n",
       "2433   30742              NaN NaN          NaN NaN\n",
       "\n",
       "[2434 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0d25d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries to update (num_rows): (2434,)\n",
      "Entries to delete (shape): (2409, 5)\n",
      "Entries to change (shape): (25, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Entries to update (num_rows): {updates['pH'].shape}\")\n",
    "\n",
    "mask = updates[\"pH\"].isna()\n",
    "\n",
    "to_delete = updates.loc[mask,:]\n",
    "to_change = updates.loc[-mask,:]\n",
    "\n",
    "print(f\"Entries to delete (shape): {to_delete.shape}\")\n",
    "print(f\"Entries to change (shape): {to_change.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verificou-se o nÃºmero de dados para deletar e para modificar."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ddbdb7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# First, change rows with data arrangement errors\n",
    "train.loc[to_change.index, [\"pH\", \"tm\"]] = updates.loc[to_change.index, [\"pH\", \"tm\"]]train.loc[to_change.index, [\"pH\", \"tm\"]] = updates.loc[to_change.index, [\"pH\", \"tm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29776aa0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries (original data): 31390\n",
      "Number of entries (after cut): 28981\n"
     ]
    }
   ],
   "source": [
    "# Next, remove rows with data issues\n",
    "print(f\"Number of entries (original data): {train.shape[0]}\")\n",
    "train_cut = train.drop(to_delete.index)\n",
    "print(f\"Number of entries (after cut): {train_cut.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "ApÃ³s a realizaÃ§Ã£o das modificaÃ§Ãµes foram eliminadas 2409 entradas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a711cb73",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31385</th>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31386</th>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31388</th>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31389</th>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28981 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id                                   protein_sequence   pH  \\\n",
       "25         25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...  7.0   \n",
       "28         28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...  7.0   \n",
       "29         29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...  7.0   \n",
       "30         30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...  5.5   \n",
       "33         33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...  7.0   \n",
       "...       ...                                                ...  ...   \n",
       "31385   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n",
       "31386   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n",
       "31387   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n",
       "31388   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n",
       "31389   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n",
       "\n",
       "                             data_source    tm  \n",
       "25     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "28     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "29     doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "30     doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "33     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "...                                  ...   ...  \n",
       "31385  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "31386  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "31387  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "31388  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "31389  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[28981 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Realizou-se a verificaÃ§Ã£o das alteraÃ§Ãµes realizadas aos dados de treino e a presenÃ§a de NaNs -> verificou-se a existÃªncia de dados omissos (3494)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99e423e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows still containing NaNs: 3494\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31385</th>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31386</th>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31388</th>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31389</th>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25487 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id                                   protein_sequence   pH  \\\n",
       "25         25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...  7.0   \n",
       "28         28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...  7.0   \n",
       "29         29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...  7.0   \n",
       "30         30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...  5.5   \n",
       "33         33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...  7.0   \n",
       "...       ...                                                ...  ...   \n",
       "31385   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n",
       "31386   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n",
       "31387   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n",
       "31388   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n",
       "31389   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n",
       "\n",
       "                             data_source    tm  \n",
       "25     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "28     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "29     doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "30     doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "33     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "...                                  ...   ...  \n",
       "31385  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "31386  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "31387  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "31388  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "31389  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[25487 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are still NaNs and remove them\n",
    "idxs = train_cut[train_cut.isna().any(axis=1)].index\n",
    "print(f\"Number of rows still containing NaNs: {len(idxs)}\")\n",
    "train_cut.drop(index=idxs, inplace=True)\n",
    "train_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voltou-se a realizar a eliminaÃ§Ã£o das linhas com NaNs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e58d64",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25486</th>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25487 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id                                   protein_sequence   pH  \\\n",
       "0          25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...  7.0   \n",
       "1          28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...  7.0   \n",
       "2          29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...  7.0   \n",
       "3          30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...  5.5   \n",
       "4          33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...  7.0   \n",
       "...       ...                                                ...  ...   \n",
       "25482   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n",
       "25483   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n",
       "25484   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n",
       "25485   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n",
       "25486   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n",
       "\n",
       "                             data_source    tm  \n",
       "0      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "1      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "2      doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "3      doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "4      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "...                                  ...   ...  \n",
       "25482  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "25483  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "25484  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "25485  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "25486  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[25487 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset indexes\n",
    "train_cut.reset_index(drop=True, inplace=True)\n",
    "train_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verificaram-se os parÃ¢metros estatÃ­sticos para as colunas pH e tm. Analisando cada coluna observou-se que os valores mÃ©dios e medianos sÃ£o semelhates, que se elimanaram todos os valores omissos e que a distribuiÃ§Ã£o nas duas colunas Ã© relativamente uniforme (baixo skewness)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db4276b9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25487.000000</td>\n",
       "      <td>25487.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.903579</td>\n",
       "      <td>51.436933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.752407</td>\n",
       "      <td>12.190382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.990000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>43.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>54.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pH            tm\n",
       "count  25487.000000  25487.000000\n",
       "mean       6.903579     51.436933\n",
       "std        0.752407     12.190382\n",
       "min        1.990000      0.000000\n",
       "25%        7.000000     43.650000\n",
       "50%        7.000000     48.700000\n",
       "75%        7.000000     54.500000\n",
       "max       11.000000    130.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cut.describe().loc[:,[\"pH\",\"tm\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70624647",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b426e1e",
   "metadata": {},
   "source": [
    "Seguimos com o passo da extraÃ§Ã£o de features, com a esperanÃ§a de obter um conjunto de descritores correlacionados com a variÃ¡vel dependente (termostabilidade), capazes de a prever com algoritmos adequados.\n",
    "\n",
    "Para isto, utilizÃ¡mos funÃ§Ãµes do BioPython e ProPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e61981f2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!pip install propy3\n",
    "#!conda install propy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557ee3ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from propy.PyPro import GetProDes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e65f49",
   "metadata": {},
   "source": [
    "#### Descriptors\n",
    "\n",
    "- sequence length (1 feature) -- <b>pypro3</b> (propy.PyPro)\n",
    "- aminoacid composition (20 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- dipeptide composition (400 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- tripeptide composition (8000 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- ctd descriptors -> composition, transition, distribution (147 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- molecular weight (1 feature) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- aromaticity (1 feature) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- instability index (1 feature) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- isoelectric point (1 feature) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- secondary structure fraction -> helix, turn, sheet (3 features) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- molar extinction coefficient -> reduced, oxidized (2 features) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- geary autocorrelation descriptors (240 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- moran autocorrelation descriptors (240 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- normalized moreau-broto autocorrelation descriptors (240 features) -- <b>pypro3</b> (propy.PyPro)<br><br>\n",
    "\n",
    "- Total number of features: <b>9297</b>\n",
    "\n",
    "\n",
    "ExtraÃ­mos inicialmente o tamanho de cada sequÃªncia (**'sequence lengthÂ´**), seguido pela sua composiÃ§Ã£o de aminoÃ¡cidos individuais (**'aminoacid composition'**), e todos os dipÃ©ptidos ('dipeptide composition') e tripÃ©ptidos possÃ­veis (**'tripeptide composition'**).\n",
    "\n",
    "**'ctd descriptors'** sÃ£o um conjunto de descritores relativamente Ã s propriedades dos aminoÃ¡cidos, como hidrofobicidade, polaridade, carga, etc. Para cada propriedade, os aminoÃ¡cidos de cada proteÃ­na sÃ£o agrupadas numa de 3 grupos, sendo calculadas a composiÃ§Ã£o (percentagem de aminoÃ¡cidos), transiÃ§Ã£o (percentagem de transiÃ§Ãµes de um grupo para outro), e distribuiÃ§Ã£o (Ã­ndices de cada categoria ao longo da sequÃªncia presentes em cada quartil sÃ£o devolvidos e divididos pelo nÃºmero total dessa categoria presente na sequÃªncia).\n",
    "\n",
    "Seguem-se o peso molecular de cada proteÃ­na (**'molecular weight'**), frequÃªncia relativa de aminoÃ¡cidos aromÃ¡ticos (Phe, Trp e Tyr) (**'aromaticity'**), valor indicativo da instabilidade da proteÃ­na, onde valores altos significam proteÃ­nas mais instÃ¡veis (**'instability index'**), e o pH onde a carga global da proteÃ­na Ã© neutra (**'isoelectric point'**).\n",
    "\n",
    "**'secondary structure fraction'** refere-se Ã  fraÃ§Ã£o de aminoÃ¡cidos na sequÃªncia que costumam estar presentes em hÃ©lices, 'turns' ou folhas. **'molar extinction coefficienteÂ´** Ã© uma medida do quÃ£o forte uma espÃ©cie quÃ­mica absorve luz numa dada onda de luz (considera cisteÃ­nas e pontes dissulfito).\n",
    "\n",
    "Por fim, **'greary autocorrelation'**, **'moran autocorrelation'** e **'normalized moreau_broto autocorrelation'** sÃ£o diferentes cÃ¡lculos da distribuiÃ§Ã£o espacial de um conjunto de descritores estruturais e fisioquÃ­micos.\n",
    "\n",
    "Para extrair estes descritores, foram criadas funÃ§Ãµes auxiliares para devolver os resultados em forma de dicionÃ¡rio. Desta forma Ã© mais simples posteriormente juntar os resultados para criar um novo DataFrame do pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c4313",
   "metadata": {},
   "source": [
    "#### Compute descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d01f8c0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# sequence lenght (1 feature)\n",
    "def get_length(protein: str) -> dict:\n",
    "    return {\"SeqLength\": len(protein)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8317c0e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# aminoacid composition (20 features)\n",
    "def get_aminoacid_composition(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetAAComp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f0ad19e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# dipeptide composition (400 features)\n",
    "def get_dipeptide_composition(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetDPComp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5968555-c1ff-475f-9c1a-c00ff0785e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripeptide composition (8000 features)\n",
    "def get_tripeptide_composition(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetTPComp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f44c015-7d97-4f52-aa64-056e5e98cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctd descriptors (147 features)\n",
    "def get_ctd_descriptors(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetCTD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23203487-26a2-49f9-bca4-54cd397d4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# molecular weight (1 feature)\n",
    "def get_molecular_weight(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    return {\"MolecularWeight\": X.molecular_weight()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a54efc8f-0d80-489c-b4be-6a1baed7499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aromaticity (1 feature)\n",
    "def get_aromaticity(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    return {\"Aromaticity\": X.aromaticity()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50fa4b4d-c397-441e-843c-c8da14e6ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instability index (1 feature)\n",
    "def get_instability_index(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    return {\"InstabilityIndex\": X.instability_index()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "200c064b-585b-40d7-b8e9-cdc01e3e2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isoelectric point (1 feature)\n",
    "def get_isoelectric_point(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    return {\"IsoelectricPoint\": X.isoelectric_point()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97d38b6b-796b-4eea-8e1a-dfdd71627c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary structure fraction (3 features)\n",
    "def get_secondary_structure_fraction(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    helix, turn, sheet = X.secondary_structure_fraction()\n",
    "    return {\"HelixSSF\": helix, \"TurnSSF\": turn, \"SheetSSF\": sheet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b3da4b-cda1-4c3a-9dbb-5e9fc6ec2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# molar extinction coefficient (2 features)\n",
    "def get_molar_extinction_coefficient(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    reduced, oxidized = X.molar_extinction_coefficient()\n",
    "    return {\"ReducedMEC\": reduced, \"OxidizedMEC\": oxidized}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db2afdd6-0485-446a-becd-96cfde5cc2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geary autocorrelation descriptors (240 features)\n",
    "def get_geary_autocorrelation_descriptors(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetGearyAuto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d096e273-28de-4131-974b-9cc80054dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moran autocorrelation descriptors (240 features)\n",
    "def get_moran_autocorrelation_descriptors(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetMoranAuto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a870587-2594-4f67-9978-ae0757736821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moreau-broto autocorrelation descriptors (240 features)\n",
    "def get_moreau_broto_autocorrelation_descriptors(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetMoreauBrotoAuto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4196419-2b2d-4127-bcb6-56074c9bf253",
   "metadata": {},
   "source": [
    "#### Compute descriptors for all sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b41d8413",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_id                                   protein_sequence   pH  \\\n",
       "0      25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...  7.0   \n",
       "1      28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...  7.0   \n",
       "2      29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...  7.0   \n",
       "3      30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...  5.5   \n",
       "4      33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...  7.0   \n",
       "\n",
       "                         data_source    tm  \n",
       "0  doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "1  doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "2  doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "3  doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "4  doi.org/10.1038/s41592-020-0801-4  48.4  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5441c",
   "metadata": {},
   "source": [
    "CriÃ¡mos uma funÃ§Ã£o que junta as funÃ§Ãµes anteriores todas, de forma a criar um novo dataset, juntando os descritores do dataset original (nomeadamente o 'pH' e 'tm') com os novos descritores inferidos a partir de cada sequÃªncia do dataset ('protein_sequence').\n",
    "\n",
    "Uma vez que este processo demora bastante a correr, utilizÃ¡mos a funÃ§Ã£o 'tqdm' para visualizar o progresso da extraÃ§Ã£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba67e06b-599b-4177-a11b-22d40a9106c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53756ad5-cda8-45b0-974e-8e705480c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all descriptors (9297 features)\n",
    "def get_dataset_with_features(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    # get protein sequences from dataset and initialize an empty protein_features list\n",
    "    proteins = np.array(dataset.protein_sequence, dtype=\"str\")\n",
    "    protein_features = []\n",
    "    for protein in tqdm(proteins):\n",
    "        # compute features for each protein\n",
    "        length = get_length(protein)\n",
    "        aa_comp = get_aminoacid_composition(protein)\n",
    "        dp_comp = get_dipeptide_composition(protein)\n",
    "        tp_comp = get_tripeptide_composition(protein)\n",
    "        ctd = get_ctd_descriptors(protein)\n",
    "        mw = get_molecular_weight(protein)\n",
    "        arom = get_aromaticity(protein)\n",
    "        ii = get_instability_index(protein)\n",
    "        iso_p = get_isoelectric_point(protein)\n",
    "        ssf = get_secondary_structure_fraction(protein)\n",
    "        mec = get_molar_extinction_coefficient(protein)\n",
    "        geary = get_geary_autocorrelation_descriptors(protein)\n",
    "        moran = get_moran_autocorrelation_descriptors(protein)\n",
    "        moreau_broto = get_moreau_broto_autocorrelation_descriptors(protein)\n",
    "        # merge dictionaries and add result to protein_features\n",
    "        features = dict(length, **aa_comp, **dp_comp, **tp_comp,  **ctd, **mw, **arom, **ii, **iso_p, **ssf, **mec,\n",
    "                        **geary, **moran, **moreau_broto)\n",
    "        protein_features.append(features)\n",
    "    # return pandas DataFrame with results\n",
    "    features_df = pd.DataFrame(protein_features)\n",
    "    features_df.insert(0, \"seq_id\", dataset.seq_id)\n",
    "    return pd.concat([features_df, dataset.loc[:,[\"pH\",\"tm\"]]], axis=1) #Removeu-se, 'protein_sequence', e 'data_source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52c95307-4645-4e0a-9089-30afc091a7de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7a767a2b3341549779536df3d8ae4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>501</td>\n",
       "      <td>10.379</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.591</td>\n",
       "      <td>5.589</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.387</td>\n",
       "      <td>5.389</td>\n",
       "      <td>4.990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>313</td>\n",
       "      <td>7.987</td>\n",
       "      <td>7.668</td>\n",
       "      <td>4.473</td>\n",
       "      <td>3.834</td>\n",
       "      <td>2.236</td>\n",
       "      <td>7.029</td>\n",
       "      <td>3.834</td>\n",
       "      <td>9.904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>109</td>\n",
       "      <td>7.339</td>\n",
       "      <td>3.670</td>\n",
       "      <td>1.835</td>\n",
       "      <td>6.422</td>\n",
       "      <td>1.835</td>\n",
       "      <td>9.174</td>\n",
       "      <td>2.752</td>\n",
       "      <td>8.257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.048</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>329</td>\n",
       "      <td>7.295</td>\n",
       "      <td>3.343</td>\n",
       "      <td>6.991</td>\n",
       "      <td>7.599</td>\n",
       "      <td>0.304</td>\n",
       "      <td>6.079</td>\n",
       "      <td>3.343</td>\n",
       "      <td>8.815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.082</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>278</td>\n",
       "      <td>10.432</td>\n",
       "      <td>7.554</td>\n",
       "      <td>2.878</td>\n",
       "      <td>2.158</td>\n",
       "      <td>0.719</td>\n",
       "      <td>8.273</td>\n",
       "      <td>15.108</td>\n",
       "      <td>5.396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.049</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>31385</td>\n",
       "      <td>549</td>\n",
       "      <td>6.011</td>\n",
       "      <td>7.650</td>\n",
       "      <td>4.372</td>\n",
       "      <td>6.922</td>\n",
       "      <td>2.186</td>\n",
       "      <td>5.647</td>\n",
       "      <td>4.372</td>\n",
       "      <td>9.290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>31386</td>\n",
       "      <td>469</td>\n",
       "      <td>7.889</td>\n",
       "      <td>5.330</td>\n",
       "      <td>4.051</td>\n",
       "      <td>4.478</td>\n",
       "      <td>1.066</td>\n",
       "      <td>6.183</td>\n",
       "      <td>3.412</td>\n",
       "      <td>5.757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>31387</td>\n",
       "      <td>128</td>\n",
       "      <td>10.156</td>\n",
       "      <td>2.344</td>\n",
       "      <td>3.906</td>\n",
       "      <td>5.469</td>\n",
       "      <td>0.781</td>\n",
       "      <td>5.469</td>\n",
       "      <td>6.250</td>\n",
       "      <td>8.594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.097</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>31388</td>\n",
       "      <td>593</td>\n",
       "      <td>7.926</td>\n",
       "      <td>4.216</td>\n",
       "      <td>4.216</td>\n",
       "      <td>5.734</td>\n",
       "      <td>0.843</td>\n",
       "      <td>6.071</td>\n",
       "      <td>2.024</td>\n",
       "      <td>8.769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25486</th>\n",
       "      <td>31389</td>\n",
       "      <td>537</td>\n",
       "      <td>6.331</td>\n",
       "      <td>5.214</td>\n",
       "      <td>3.724</td>\n",
       "      <td>2.793</td>\n",
       "      <td>0.931</td>\n",
       "      <td>5.959</td>\n",
       "      <td>3.352</td>\n",
       "      <td>4.469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.065</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25487 rows Ã— 900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id  SeqLength       A      R      N      D      C      E       Q  \\\n",
       "0          25        501  10.379  4.192  4.591  5.589  0.000  6.387   5.389   \n",
       "1          28        313   7.987  7.668  4.473  3.834  2.236  7.029   3.834   \n",
       "2          29        109   7.339  3.670  1.835  6.422  1.835  9.174   2.752   \n",
       "3          30        329   7.295  3.343  6.991  7.599  0.304  6.079   3.343   \n",
       "4          33        278  10.432  7.554  2.878  2.158  0.719  8.273  15.108   \n",
       "...       ...        ...     ...    ...    ...    ...    ...    ...     ...   \n",
       "25482   31385        549   6.011  7.650  4.372  6.922  2.186  5.647   4.372   \n",
       "25483   31386        469   7.889  5.330  4.051  4.478  1.066  6.183   3.412   \n",
       "25484   31387        128  10.156  2.344  3.906  5.469  0.781  5.469   6.250   \n",
       "25485   31388        593   7.926  4.216  4.216  5.734  0.843  6.071   2.024   \n",
       "25486   31389        537   6.331  5.214  3.724  2.793  0.931  5.959   3.352   \n",
       "\n",
       "           G  ...  MoreauBrotoAuto_Mutability23  MoreauBrotoAuto_Mutability24  \\\n",
       "0      4.990  ...                        -0.058                        -0.057   \n",
       "1      9.904  ...                         0.019                         0.017   \n",
       "2      8.257  ...                         0.087                         0.079   \n",
       "3      8.815  ...                         0.074                         0.077   \n",
       "4      5.396  ...                         0.057                         0.051   \n",
       "...      ...  ...                           ...                           ...   \n",
       "25482  9.290  ...                        -0.006                        -0.004   \n",
       "25483  5.757  ...                        -0.049                        -0.048   \n",
       "25484  8.594  ...                         0.098                         0.097   \n",
       "25485  8.769  ...                         0.030                         0.029   \n",
       "25486  4.469  ...                         0.063                         0.063   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability25  MoreauBrotoAuto_Mutability26  \\\n",
       "0                            -0.058                        -0.056   \n",
       "1                             0.014                         0.017   \n",
       "2                             0.068                         0.051   \n",
       "3                             0.074                         0.073   \n",
       "4                             0.053                         0.052   \n",
       "...                             ...                           ...   \n",
       "25482                        -0.003                        -0.002   \n",
       "25483                        -0.048                        -0.048   \n",
       "25484                         0.100                         0.115   \n",
       "25485                         0.029                         0.030   \n",
       "25486                         0.064                         0.065   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability27  MoreauBrotoAuto_Mutability28  \\\n",
       "0                            -0.056                        -0.056   \n",
       "1                             0.014                         0.012   \n",
       "2                             0.065                         0.059   \n",
       "3                             0.074                         0.078   \n",
       "4                             0.050                         0.050   \n",
       "...                             ...                           ...   \n",
       "25482                        -0.003                        -0.002   \n",
       "25483                        -0.048                        -0.046   \n",
       "25484                         0.099                         0.107   \n",
       "25485                         0.030                         0.030   \n",
       "25486                         0.067                         0.064   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability29  MoreauBrotoAuto_Mutability30  \\\n",
       "0                            -0.056                        -0.057   \n",
       "1                             0.013                         0.010   \n",
       "2                             0.050                         0.048   \n",
       "3                             0.081                         0.082   \n",
       "4                             0.051                         0.049   \n",
       "...                             ...                           ...   \n",
       "25482                        -0.002                        -0.005   \n",
       "25483                        -0.044                        -0.046   \n",
       "25484                         0.102                         0.097   \n",
       "25485                         0.030                         0.031   \n",
       "25486                         0.066                         0.065   \n",
       "\n",
       "                             data_source    tm  \n",
       "0      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "1      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "2      doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "3      doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "4      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "...                                  ...   ...  \n",
       "25482  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "25483  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "25484  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "25485  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "25486  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[25487 rows x 900 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_dataset_with_features(train_cut)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daec4b2",
   "metadata": {},
   "source": [
    "Para facilitar o processo de recolha dos descritores sempre que se corre este notebook, guardou-se os resultados num ficheiro csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b920449-1c7c-4607-914d-29f7a56713df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-048cec40ba11>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# export data_train to csv\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data_train.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# export data_train to csv\n",
    "train.to_csv(\"data_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9547b",
   "metadata": {},
   "source": [
    "Todos os passos efetuados anteriormente podem ser saltados, sendo possÃ­vel correr 'de novo' o notebook a partir deste ponto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac551f0e-11e3-4c6c-a9e8-b08bae94686f",
   "metadata": {},
   "source": [
    "#### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1feacc-2b9d-4cef-82e2-a162b335ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a05c82-f719-499a-a4ff-12a4bc0360fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98521744",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14347.500000</td>\n",
       "      <td>16805.942257</td>\n",
       "      <td>450.583775</td>\n",
       "      <td>7.933964</td>\n",
       "      <td>5.422100</td>\n",
       "      <td>4.263457</td>\n",
       "      <td>5.527051</td>\n",
       "      <td>1.460943</td>\n",
       "      <td>7.105625</td>\n",
       "      <td>4.064779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021212</td>\n",
       "      <td>0.020981</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.020869</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>6.852437</td>\n",
       "      <td>49.079321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8283.965999</td>\n",
       "      <td>8351.341517</td>\n",
       "      <td>660.478906</td>\n",
       "      <td>2.826397</td>\n",
       "      <td>2.264102</td>\n",
       "      <td>1.838423</td>\n",
       "      <td>1.772346</td>\n",
       "      <td>1.322568</td>\n",
       "      <td>2.513279</td>\n",
       "      <td>1.888433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.069089</td>\n",
       "      <td>0.068423</td>\n",
       "      <td>0.068465</td>\n",
       "      <td>0.069619</td>\n",
       "      <td>0.069951</td>\n",
       "      <td>0.070658</td>\n",
       "      <td>0.070678</td>\n",
       "      <td>1.168815</td>\n",
       "      <td>14.210971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.959000</td>\n",
       "      <td>-2.066000</td>\n",
       "      <td>-1.015000</td>\n",
       "      <td>-0.362000</td>\n",
       "      <td>-0.355000</td>\n",
       "      <td>-0.366000</td>\n",
       "      <td>-0.382000</td>\n",
       "      <td>-0.399000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7173.750000</td>\n",
       "      <td>9589.750000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>5.938000</td>\n",
       "      <td>3.950750</td>\n",
       "      <td>3.061000</td>\n",
       "      <td>4.361000</td>\n",
       "      <td>0.637000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>2.932000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>41.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14347.500000</td>\n",
       "      <td>16767.500000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>7.692000</td>\n",
       "      <td>5.205000</td>\n",
       "      <td>4.110000</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>6.923000</td>\n",
       "      <td>3.823000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21521.250000</td>\n",
       "      <td>24006.250000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>9.494000</td>\n",
       "      <td>6.627000</td>\n",
       "      <td>5.263000</td>\n",
       "      <td>6.473000</td>\n",
       "      <td>1.935000</td>\n",
       "      <td>8.451000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>53.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28695.000000</td>\n",
       "      <td>31389.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>29.866000</td>\n",
       "      <td>24.540000</td>\n",
       "      <td>31.990000</td>\n",
       "      <td>20.530000</td>\n",
       "      <td>16.071000</td>\n",
       "      <td>24.658000</td>\n",
       "      <td>24.346000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 9301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        seq_id     SeqLength             A             R  \\\n",
       "count  28696.000000  28696.000000  28696.000000  28696.000000  28696.000000   \n",
       "mean   14347.500000  16805.942257    450.583775      7.933964      5.422100   \n",
       "std     8283.965999   8351.341517    660.478906      2.826397      2.264102   \n",
       "min        0.000000     25.000000      5.000000      0.000000      0.000000   \n",
       "25%     7173.750000   9589.750000    195.000000      5.938000      3.950750   \n",
       "50%    14347.500000  16767.500000    335.000000      7.692000      5.205000   \n",
       "75%    21521.250000  24006.250000    526.000000      9.494000      6.627000   \n",
       "max    28695.000000  31389.000000  32767.000000     29.866000     24.540000   \n",
       "\n",
       "                  N             D             C             E             Q  \\\n",
       "count  28696.000000  28696.000000  28696.000000  28696.000000  28696.000000   \n",
       "mean       4.263457      5.527051      1.460943      7.105625      4.064779   \n",
       "std        1.838423      1.772346      1.322568      2.513279      1.888433   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        3.061000      4.361000      0.637000      5.556000      2.932000   \n",
       "50%        4.110000      5.429000      1.220000      6.923000      3.823000   \n",
       "75%        5.263000      6.473000      1.935000      8.451000      5.000000   \n",
       "max       31.990000     20.530000     16.071000     24.658000     24.346000   \n",
       "\n",
       "       ...  MoreauBrotoAuto_Mutability23  MoreauBrotoAuto_Mutability24  \\\n",
       "count  ...                  28696.000000                  28696.000000   \n",
       "mean   ...                      0.021212                      0.020981   \n",
       "std    ...                      0.067654                      0.069089   \n",
       "min    ...                     -0.959000                     -2.066000   \n",
       "25%    ...                     -0.020000                     -0.020000   \n",
       "50%    ...                      0.019000                      0.019000   \n",
       "75%    ...                      0.062000                      0.062000   \n",
       "max    ...                      0.644000                      0.641000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability25  MoreauBrotoAuto_Mutability26  \\\n",
       "count                  28696.000000                  28696.000000   \n",
       "mean                       0.020948                      0.021123   \n",
       "std                        0.068423                      0.068465   \n",
       "min                       -1.015000                     -0.362000   \n",
       "25%                       -0.020000                     -0.021000   \n",
       "50%                        0.019000                      0.019000   \n",
       "75%                        0.062000                      0.062000   \n",
       "max                        0.638000                      0.700000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability27  MoreauBrotoAuto_Mutability28  \\\n",
       "count                  28696.000000                  28696.000000   \n",
       "mean                       0.020842                      0.021070   \n",
       "std                        0.069619                      0.069951   \n",
       "min                       -0.355000                     -0.366000   \n",
       "25%                       -0.021000                     -0.021000   \n",
       "50%                        0.019000                      0.019000   \n",
       "75%                        0.061000                      0.061000   \n",
       "max                        0.638000                      0.593000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability29  MoreauBrotoAuto_Mutability30  \\\n",
       "count                  28696.000000                  28696.000000   \n",
       "mean                       0.020869                      0.021026   \n",
       "std                        0.070658                      0.070678   \n",
       "min                       -0.382000                     -0.399000   \n",
       "25%                       -0.021000                     -0.021000   \n",
       "50%                        0.019000                      0.019000   \n",
       "75%                        0.061000                      0.061000   \n",
       "max                        0.879000                      0.855000   \n",
       "\n",
       "                 pH            tm  \n",
       "count  28696.000000  28696.000000  \n",
       "mean       6.852437     49.079321  \n",
       "std        1.168815     14.210971  \n",
       "min        1.990000     -1.000000  \n",
       "25%        7.000000     41.900000  \n",
       "50%        7.000000     48.000000  \n",
       "75%        7.000000     53.800000  \n",
       "max       64.900000    130.000000  \n",
       "\n",
       "[8 rows x 9301 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ba6ca",
   "metadata": {},
   "source": [
    "ApÃ³s observar a descriÃ§Ã£o da coluna do pH, observamos que o valor mÃ¡ximo Ã© 64.9, que nÃ£o Ã© um valor aceitÃ¡vel de pH (valor mÃ¡ximo de 14).\n",
    "\n",
    "Devido a tal discrepÃ¢ncia, procurou-se todas as ocorrÃªncias onde o valor do pH Ã© superior a 14, eliminando as respetivas linhas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "685c94cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train = train[(train[\"pH\"]<14) & (train[\"pH\"]>0)]\n",
    "#train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29adc5c",
   "metadata": {},
   "source": [
    "Observamos que foram eliminadas 7 linhas (passou de 28696 para 28689)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d320c4bc-94d8-42a0-96b5-73dca33a969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y\n",
    "X_train = train.iloc[:,2:-1] #Remove sequence id from the X dataset\n",
    "y_train = train[\"tm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee94aa7b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501</td>\n",
       "      <td>10.379</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.591</td>\n",
       "      <td>5.589</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.387</td>\n",
       "      <td>5.389</td>\n",
       "      <td>4.990</td>\n",
       "      <td>1.996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313</td>\n",
       "      <td>7.987</td>\n",
       "      <td>7.668</td>\n",
       "      <td>4.473</td>\n",
       "      <td>3.834</td>\n",
       "      <td>2.236</td>\n",
       "      <td>7.029</td>\n",
       "      <td>3.834</td>\n",
       "      <td>9.904</td>\n",
       "      <td>2.236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>7.339</td>\n",
       "      <td>3.670</td>\n",
       "      <td>1.835</td>\n",
       "      <td>6.422</td>\n",
       "      <td>1.835</td>\n",
       "      <td>9.174</td>\n",
       "      <td>2.752</td>\n",
       "      <td>8.257</td>\n",
       "      <td>1.835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.048</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>329</td>\n",
       "      <td>7.295</td>\n",
       "      <td>3.343</td>\n",
       "      <td>6.991</td>\n",
       "      <td>7.599</td>\n",
       "      <td>0.304</td>\n",
       "      <td>6.079</td>\n",
       "      <td>3.343</td>\n",
       "      <td>8.815</td>\n",
       "      <td>2.128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.082</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278</td>\n",
       "      <td>10.432</td>\n",
       "      <td>7.554</td>\n",
       "      <td>2.878</td>\n",
       "      <td>2.158</td>\n",
       "      <td>0.719</td>\n",
       "      <td>8.273</td>\n",
       "      <td>15.108</td>\n",
       "      <td>5.396</td>\n",
       "      <td>1.439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.049</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeqLength       A      R      N      D      C      E       Q      G      H  \\\n",
       "0        501  10.379  4.192  4.591  5.589  0.000  6.387   5.389  4.990  1.996   \n",
       "1        313   7.987  7.668  4.473  3.834  2.236  7.029   3.834  9.904  2.236   \n",
       "2        109   7.339  3.670  1.835  6.422  1.835  9.174   2.752  8.257  1.835   \n",
       "3        329   7.295  3.343  6.991  7.599  0.304  6.079   3.343  8.815  2.128   \n",
       "4        278  10.432  7.554  2.878  2.158  0.719  8.273  15.108  5.396  1.439   \n",
       "\n",
       "   ...  MoreauBrotoAuto_Mutability22  MoreauBrotoAuto_Mutability23  \\\n",
       "0  ...                        -0.060                        -0.058   \n",
       "1  ...                         0.020                         0.019   \n",
       "2  ...                         0.086                         0.087   \n",
       "3  ...                         0.079                         0.074   \n",
       "4  ...                         0.063                         0.057   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability24  MoreauBrotoAuto_Mutability25  \\\n",
       "0                        -0.057                        -0.058   \n",
       "1                         0.017                         0.014   \n",
       "2                         0.079                         0.068   \n",
       "3                         0.077                         0.074   \n",
       "4                         0.051                         0.053   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability26  MoreauBrotoAuto_Mutability27  \\\n",
       "0                        -0.056                        -0.056   \n",
       "1                         0.017                         0.014   \n",
       "2                         0.051                         0.065   \n",
       "3                         0.073                         0.074   \n",
       "4                         0.052                         0.050   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability28  MoreauBrotoAuto_Mutability29  \\\n",
       "0                        -0.056                        -0.056   \n",
       "1                         0.012                         0.013   \n",
       "2                         0.059                         0.050   \n",
       "3                         0.078                         0.081   \n",
       "4                         0.050                         0.051   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability30   pH  \n",
       "0                        -0.057  7.0  \n",
       "1                         0.010  7.0  \n",
       "2                         0.048  7.0  \n",
       "3                         0.082  5.5  \n",
       "4                         0.049  7.0  \n",
       "\n",
       "[5 rows x 9298 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b672ef73",
   "metadata": {},
   "source": [
    "#### Outlier treatment (dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b66ce90e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "X_train = X_train[(np.abs(stats.zscore(y_train)) < 3)]\n",
    "y_train = y_train[(np.abs(stats.zscore(y_train)) < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f28298",
   "metadata": {},
   "source": [
    "#### Standardization (MinMaxScaler and StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8617881",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501</td>\n",
       "      <td>10.379</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.591</td>\n",
       "      <td>5.589</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.387</td>\n",
       "      <td>5.389</td>\n",
       "      <td>4.990</td>\n",
       "      <td>1.996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313</td>\n",
       "      <td>7.987</td>\n",
       "      <td>7.668</td>\n",
       "      <td>4.473</td>\n",
       "      <td>3.834</td>\n",
       "      <td>2.236</td>\n",
       "      <td>7.029</td>\n",
       "      <td>3.834</td>\n",
       "      <td>9.904</td>\n",
       "      <td>2.236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>7.339</td>\n",
       "      <td>3.670</td>\n",
       "      <td>1.835</td>\n",
       "      <td>6.422</td>\n",
       "      <td>1.835</td>\n",
       "      <td>9.174</td>\n",
       "      <td>2.752</td>\n",
       "      <td>8.257</td>\n",
       "      <td>1.835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.048</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>329</td>\n",
       "      <td>7.295</td>\n",
       "      <td>3.343</td>\n",
       "      <td>6.991</td>\n",
       "      <td>7.599</td>\n",
       "      <td>0.304</td>\n",
       "      <td>6.079</td>\n",
       "      <td>3.343</td>\n",
       "      <td>8.815</td>\n",
       "      <td>2.128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.082</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278</td>\n",
       "      <td>10.432</td>\n",
       "      <td>7.554</td>\n",
       "      <td>2.878</td>\n",
       "      <td>2.158</td>\n",
       "      <td>0.719</td>\n",
       "      <td>8.273</td>\n",
       "      <td>15.108</td>\n",
       "      <td>5.396</td>\n",
       "      <td>1.439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.049</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28691</th>\n",
       "      <td>549</td>\n",
       "      <td>6.011</td>\n",
       "      <td>7.650</td>\n",
       "      <td>4.372</td>\n",
       "      <td>6.922</td>\n",
       "      <td>2.186</td>\n",
       "      <td>5.647</td>\n",
       "      <td>4.372</td>\n",
       "      <td>9.290</td>\n",
       "      <td>2.732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28692</th>\n",
       "      <td>469</td>\n",
       "      <td>7.889</td>\n",
       "      <td>5.330</td>\n",
       "      <td>4.051</td>\n",
       "      <td>4.478</td>\n",
       "      <td>1.066</td>\n",
       "      <td>6.183</td>\n",
       "      <td>3.412</td>\n",
       "      <td>5.757</td>\n",
       "      <td>4.691</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28693</th>\n",
       "      <td>128</td>\n",
       "      <td>10.156</td>\n",
       "      <td>2.344</td>\n",
       "      <td>3.906</td>\n",
       "      <td>5.469</td>\n",
       "      <td>0.781</td>\n",
       "      <td>5.469</td>\n",
       "      <td>6.250</td>\n",
       "      <td>8.594</td>\n",
       "      <td>1.562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.097</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28694</th>\n",
       "      <td>593</td>\n",
       "      <td>7.926</td>\n",
       "      <td>4.216</td>\n",
       "      <td>4.216</td>\n",
       "      <td>5.734</td>\n",
       "      <td>0.843</td>\n",
       "      <td>6.071</td>\n",
       "      <td>2.024</td>\n",
       "      <td>8.769</td>\n",
       "      <td>1.855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28695</th>\n",
       "      <td>537</td>\n",
       "      <td>6.331</td>\n",
       "      <td>5.214</td>\n",
       "      <td>3.724</td>\n",
       "      <td>2.793</td>\n",
       "      <td>0.931</td>\n",
       "      <td>5.959</td>\n",
       "      <td>3.352</td>\n",
       "      <td>4.469</td>\n",
       "      <td>3.911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.065</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28403 rows Ã— 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeqLength       A      R      N      D      C      E       Q      G  \\\n",
       "0            501  10.379  4.192  4.591  5.589  0.000  6.387   5.389  4.990   \n",
       "1            313   7.987  7.668  4.473  3.834  2.236  7.029   3.834  9.904   \n",
       "2            109   7.339  3.670  1.835  6.422  1.835  9.174   2.752  8.257   \n",
       "3            329   7.295  3.343  6.991  7.599  0.304  6.079   3.343  8.815   \n",
       "4            278  10.432  7.554  2.878  2.158  0.719  8.273  15.108  5.396   \n",
       "...          ...     ...    ...    ...    ...    ...    ...     ...    ...   \n",
       "28691        549   6.011  7.650  4.372  6.922  2.186  5.647   4.372  9.290   \n",
       "28692        469   7.889  5.330  4.051  4.478  1.066  6.183   3.412  5.757   \n",
       "28693        128  10.156  2.344  3.906  5.469  0.781  5.469   6.250  8.594   \n",
       "28694        593   7.926  4.216  4.216  5.734  0.843  6.071   2.024  8.769   \n",
       "28695        537   6.331  5.214  3.724  2.793  0.931  5.959   3.352  4.469   \n",
       "\n",
       "           H  ...  MoreauBrotoAuto_Mutability22  MoreauBrotoAuto_Mutability23  \\\n",
       "0      1.996  ...                        -0.060                        -0.058   \n",
       "1      2.236  ...                         0.020                         0.019   \n",
       "2      1.835  ...                         0.086                         0.087   \n",
       "3      2.128  ...                         0.079                         0.074   \n",
       "4      1.439  ...                         0.063                         0.057   \n",
       "...      ...  ...                           ...                           ...   \n",
       "28691  2.732  ...                        -0.005                        -0.006   \n",
       "28692  4.691  ...                        -0.047                        -0.049   \n",
       "28693  1.562  ...                         0.104                         0.098   \n",
       "28694  1.855  ...                         0.028                         0.030   \n",
       "28695  3.911  ...                         0.062                         0.063   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability24  MoreauBrotoAuto_Mutability25  \\\n",
       "0                            -0.057                        -0.058   \n",
       "1                             0.017                         0.014   \n",
       "2                             0.079                         0.068   \n",
       "3                             0.077                         0.074   \n",
       "4                             0.051                         0.053   \n",
       "...                             ...                           ...   \n",
       "28691                        -0.004                        -0.003   \n",
       "28692                        -0.048                        -0.048   \n",
       "28693                         0.097                         0.100   \n",
       "28694                         0.029                         0.029   \n",
       "28695                         0.063                         0.064   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability26  MoreauBrotoAuto_Mutability27  \\\n",
       "0                            -0.056                        -0.056   \n",
       "1                             0.017                         0.014   \n",
       "2                             0.051                         0.065   \n",
       "3                             0.073                         0.074   \n",
       "4                             0.052                         0.050   \n",
       "...                             ...                           ...   \n",
       "28691                        -0.002                        -0.003   \n",
       "28692                        -0.048                        -0.048   \n",
       "28693                         0.115                         0.099   \n",
       "28694                         0.030                         0.030   \n",
       "28695                         0.065                         0.067   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability28  MoreauBrotoAuto_Mutability29  \\\n",
       "0                            -0.056                        -0.056   \n",
       "1                             0.012                         0.013   \n",
       "2                             0.059                         0.050   \n",
       "3                             0.078                         0.081   \n",
       "4                             0.050                         0.051   \n",
       "...                             ...                           ...   \n",
       "28691                        -0.002                        -0.002   \n",
       "28692                        -0.046                        -0.044   \n",
       "28693                         0.107                         0.102   \n",
       "28694                         0.030                         0.030   \n",
       "28695                         0.064                         0.066   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability30   pH  \n",
       "0                            -0.057  7.0  \n",
       "1                             0.010  7.0  \n",
       "2                             0.048  7.0  \n",
       "3                             0.082  5.5  \n",
       "4                             0.049  7.0  \n",
       "...                             ...  ...  \n",
       "28691                        -0.005  7.0  \n",
       "28692                        -0.046  7.0  \n",
       "28693                         0.097  7.0  \n",
       "28694                         0.031  7.0  \n",
       "28695                         0.065  7.0  \n",
       "\n",
       "[28403 rows x 9298 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7aaed25",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Standardizar os valores\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Para se utilizar nos modelos de aprendizagem supervisionada\n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_arr = scaler.transform(X_train)\n",
    "X_train_sc = pd.DataFrame(data=X_train_arr, columns=X_train.columns)\n",
    "\n",
    "#Apenas para aplicar o PCA (remoÃ§Ã£o de outliers nos dados das variÃ¡veis independentes)\n",
    "X_train_sc_z = pd.DataFrame(data=preprocessing.scale(X_train), columns=X_train.columns)\n",
    "\n",
    "#O feature \"tri-peptide\" Ã© (quase) binÃ¡rio. Pode ser standardizado tambÃ©m?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7d6978b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.347519</td>\n",
       "      <td>0.170823</td>\n",
       "      <td>0.143514</td>\n",
       "      <td>0.272236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259023</td>\n",
       "      <td>0.221351</td>\n",
       "      <td>0.081911</td>\n",
       "      <td>0.136395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538762</td>\n",
       "      <td>0.562071</td>\n",
       "      <td>0.742150</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.288136</td>\n",
       "      <td>0.301108</td>\n",
       "      <td>0.323253</td>\n",
       "      <td>0.258525</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.267428</td>\n",
       "      <td>0.312469</td>\n",
       "      <td>0.139825</td>\n",
       "      <td>0.186751</td>\n",
       "      <td>0.139133</td>\n",
       "      <td>0.285060</td>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.152795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.610106</td>\n",
       "      <td>0.769487</td>\n",
       "      <td>0.622505</td>\n",
       "      <td>0.356874</td>\n",
       "      <td>0.371601</td>\n",
       "      <td>0.394161</td>\n",
       "      <td>0.313243</td>\n",
       "      <td>0.326156</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.245731</td>\n",
       "      <td>0.149552</td>\n",
       "      <td>0.057362</td>\n",
       "      <td>0.312811</td>\n",
       "      <td>0.114181</td>\n",
       "      <td>0.372050</td>\n",
       "      <td>0.113037</td>\n",
       "      <td>0.135538</td>\n",
       "      <td>0.125393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633876</td>\n",
       "      <td>0.652527</td>\n",
       "      <td>0.792390</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.422961</td>\n",
       "      <td>0.443170</td>\n",
       "      <td>0.342585</td>\n",
       "      <td>0.356459</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009890</td>\n",
       "      <td>0.244258</td>\n",
       "      <td>0.136227</td>\n",
       "      <td>0.218537</td>\n",
       "      <td>0.370141</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>0.246533</td>\n",
       "      <td>0.137312</td>\n",
       "      <td>0.144698</td>\n",
       "      <td>0.145415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629316</td>\n",
       "      <td>0.644417</td>\n",
       "      <td>0.791651</td>\n",
       "      <td>0.658802</td>\n",
       "      <td>0.409605</td>\n",
       "      <td>0.432024</td>\n",
       "      <td>0.462982</td>\n",
       "      <td>0.367169</td>\n",
       "      <td>0.383573</td>\n",
       "      <td>0.389567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.349294</td>\n",
       "      <td>0.307824</td>\n",
       "      <td>0.089966</td>\n",
       "      <td>0.105114</td>\n",
       "      <td>0.044739</td>\n",
       "      <td>0.335510</td>\n",
       "      <td>0.620554</td>\n",
       "      <td>0.088575</td>\n",
       "      <td>0.098333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618893</td>\n",
       "      <td>0.633812</td>\n",
       "      <td>0.782047</td>\n",
       "      <td>0.646098</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.407855</td>\n",
       "      <td>0.433785</td>\n",
       "      <td>0.343378</td>\n",
       "      <td>0.357257</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeqLength         A         R         N         D         C         E  \\\n",
       "0   0.015139  0.347519  0.170823  0.143514  0.272236  0.000000  0.259023   \n",
       "1   0.009401  0.267428  0.312469  0.139825  0.186751  0.139133  0.285060   \n",
       "2   0.003174  0.245731  0.149552  0.057362  0.312811  0.114181  0.372050   \n",
       "3   0.009890  0.244258  0.136227  0.218537  0.370141  0.018916  0.246533   \n",
       "4   0.008333  0.349294  0.307824  0.089966  0.105114  0.044739  0.335510   \n",
       "\n",
       "          Q         G         H  ...  MoreauBrotoAuto_Mutability22  \\\n",
       "0  0.221351  0.081911  0.136395  ...                      0.538762   \n",
       "1  0.157480  0.162574  0.152795  ...                      0.590879   \n",
       "2  0.113037  0.135538  0.125393  ...                      0.633876   \n",
       "3  0.137312  0.144698  0.145415  ...                      0.629316   \n",
       "4  0.620554  0.088575  0.098333  ...                      0.618893   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability23  MoreauBrotoAuto_Mutability24  \\\n",
       "0                      0.562071                      0.742150   \n",
       "1                      0.610106                      0.769487   \n",
       "2                      0.652527                      0.792390   \n",
       "3                      0.644417                      0.791651   \n",
       "4                      0.633812                      0.782047   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability25  MoreauBrotoAuto_Mutability26  \\\n",
       "0                      0.578947                      0.288136   \n",
       "1                      0.622505                      0.356874   \n",
       "2                      0.655172                      0.388889   \n",
       "3                      0.658802                      0.409605   \n",
       "4                      0.646098                      0.389831   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability27  MoreauBrotoAuto_Mutability28  \\\n",
       "0                      0.301108                      0.323253   \n",
       "1                      0.371601                      0.394161   \n",
       "2                      0.422961                      0.443170   \n",
       "3                      0.432024                      0.462982   \n",
       "4                      0.407855                      0.433785   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability29  MoreauBrotoAuto_Mutability30        pH  \n",
       "0                      0.258525                      0.272727  0.556049  \n",
       "1                      0.313243                      0.326156  0.556049  \n",
       "2                      0.342585                      0.356459  0.556049  \n",
       "3                      0.367169                      0.383573  0.389567  \n",
       "4                      0.343378                      0.357257  0.556049  \n",
       "\n",
       "[5 rows x 9298 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15167fa7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073179</td>\n",
       "      <td>0.884308</td>\n",
       "      <td>-0.540551</td>\n",
       "      <td>0.166229</td>\n",
       "      <td>0.028724</td>\n",
       "      <td>-1.113421</td>\n",
       "      <td>-0.280073</td>\n",
       "      <td>0.692977</td>\n",
       "      <td>-0.764141</td>\n",
       "      <td>-0.144585</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.198806</td>\n",
       "      <td>-1.178724</td>\n",
       "      <td>-1.136078</td>\n",
       "      <td>-1.161830</td>\n",
       "      <td>-1.134499</td>\n",
       "      <td>-1.111612</td>\n",
       "      <td>-1.110298</td>\n",
       "      <td>-1.095428</td>\n",
       "      <td>-1.111168</td>\n",
       "      <td>0.178177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.210196</td>\n",
       "      <td>0.031288</td>\n",
       "      <td>1.007495</td>\n",
       "      <td>0.101659</td>\n",
       "      <td>-0.964606</td>\n",
       "      <td>0.580559</td>\n",
       "      <td>-0.024101</td>\n",
       "      <td>-0.131609</td>\n",
       "      <td>1.167583</td>\n",
       "      <td>0.065466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021403</td>\n",
       "      <td>-0.038921</td>\n",
       "      <td>-0.063606</td>\n",
       "      <td>-0.107821</td>\n",
       "      <td>-0.066506</td>\n",
       "      <td>-0.104390</td>\n",
       "      <td>-0.136385</td>\n",
       "      <td>-0.117148</td>\n",
       "      <td>-0.161443</td>\n",
       "      <td>0.178177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.517688</td>\n",
       "      <td>-0.199798</td>\n",
       "      <td>-0.773025</td>\n",
       "      <td>-1.341856</td>\n",
       "      <td>0.500202</td>\n",
       "      <td>0.276763</td>\n",
       "      <td>0.831132</td>\n",
       "      <td>-0.705373</td>\n",
       "      <td>0.520137</td>\n",
       "      <td>-0.285494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949954</td>\n",
       "      <td>0.967659</td>\n",
       "      <td>0.834952</td>\n",
       "      <td>0.682685</td>\n",
       "      <td>0.430915</td>\n",
       "      <td>0.629443</td>\n",
       "      <td>0.536761</td>\n",
       "      <td>0.407436</td>\n",
       "      <td>0.377208</td>\n",
       "      <td>0.178177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.186079</td>\n",
       "      <td>-0.215489</td>\n",
       "      <td>-0.918656</td>\n",
       "      <td>1.479510</td>\n",
       "      <td>1.166384</td>\n",
       "      <td>-0.883113</td>\n",
       "      <td>-0.402876</td>\n",
       "      <td>-0.391977</td>\n",
       "      <td>0.739490</td>\n",
       "      <td>-0.029057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846931</td>\n",
       "      <td>0.775225</td>\n",
       "      <td>0.805967</td>\n",
       "      <td>0.770519</td>\n",
       "      <td>0.752776</td>\n",
       "      <td>0.758942</td>\n",
       "      <td>0.808884</td>\n",
       "      <td>0.846953</td>\n",
       "      <td>0.859158</td>\n",
       "      <td>-1.506388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.262952</td>\n",
       "      <td>0.903208</td>\n",
       "      <td>0.956725</td>\n",
       "      <td>-0.771125</td>\n",
       "      <td>-1.913223</td>\n",
       "      <td>-0.568711</td>\n",
       "      <td>0.471894</td>\n",
       "      <td>5.846773</td>\n",
       "      <td>-0.604540</td>\n",
       "      <td>-0.632079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611450</td>\n",
       "      <td>0.523580</td>\n",
       "      <td>0.429152</td>\n",
       "      <td>0.463100</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>0.413609</td>\n",
       "      <td>0.407861</td>\n",
       "      <td>0.421614</td>\n",
       "      <td>0.391383</td>\n",
       "      <td>0.178177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeqLength         A         R         N         D         C         E  \\\n",
       "0   0.073179  0.884308 -0.540551  0.166229  0.028724 -1.113421 -0.280073   \n",
       "1  -0.210196  0.031288  1.007495  0.101659 -0.964606  0.580559 -0.024101   \n",
       "2  -0.517688 -0.199798 -0.773025 -1.341856  0.500202  0.276763  0.831132   \n",
       "3  -0.186079 -0.215489 -0.918656  1.479510  1.166384 -0.883113 -0.402876   \n",
       "4  -0.262952  0.903208  0.956725 -0.771125 -1.913223 -0.568711  0.471894   \n",
       "\n",
       "          Q         G         H  ...  MoreauBrotoAuto_Mutability22  \\\n",
       "0  0.692977 -0.764141 -0.144585  ...                     -1.198806   \n",
       "1 -0.131609  1.167583  0.065466  ...                     -0.021403   \n",
       "2 -0.705373  0.520137 -0.285494  ...                      0.949954   \n",
       "3 -0.391977  0.739490 -0.029057  ...                      0.846931   \n",
       "4  5.846773 -0.604540 -0.632079  ...                      0.611450   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability23  MoreauBrotoAuto_Mutability24  \\\n",
       "0                     -1.178724                     -1.136078   \n",
       "1                     -0.038921                     -0.063606   \n",
       "2                      0.967659                      0.834952   \n",
       "3                      0.775225                      0.805967   \n",
       "4                      0.523580                      0.429152   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability25  MoreauBrotoAuto_Mutability26  \\\n",
       "0                     -1.161830                     -1.134499   \n",
       "1                     -0.107821                     -0.066506   \n",
       "2                      0.682685                      0.430915   \n",
       "3                      0.770519                      0.752776   \n",
       "4                      0.463100                      0.445545   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability27  MoreauBrotoAuto_Mutability28  \\\n",
       "0                     -1.111612                     -1.110298   \n",
       "1                     -0.104390                     -0.136385   \n",
       "2                      0.629443                      0.536761   \n",
       "3                      0.758942                      0.808884   \n",
       "4                      0.413609                      0.407861   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability29  MoreauBrotoAuto_Mutability30        pH  \n",
       "0                     -1.095428                     -1.111168  0.178177  \n",
       "1                     -0.117148                     -0.161443  0.178177  \n",
       "2                      0.407436                      0.377208  0.178177  \n",
       "3                      0.846953                      0.859158 -1.506388  \n",
       "4                      0.421614                      0.391383  0.178177  \n",
       "\n",
       "[5 rows x 9298 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc_z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f4ab1-a888-47ce-97a9-2d7322dce4ae",
   "metadata": {},
   "source": [
    "#### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801636fc-0dbf-4d69-b8ce-8973a14fdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RealPython -> https://realpython.com/python-statistics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c938784-1c8d-46fe-9a60-692392c8699a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.264490</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>0.134017</td>\n",
       "      <td>0.269764</td>\n",
       "      <td>0.091449</td>\n",
       "      <td>0.287511</td>\n",
       "      <td>0.167674</td>\n",
       "      <td>0.113819</td>\n",
       "      <td>0.147683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591827</td>\n",
       "      <td>0.611746</td>\n",
       "      <td>0.771108</td>\n",
       "      <td>0.626960</td>\n",
       "      <td>0.361154</td>\n",
       "      <td>0.378907</td>\n",
       "      <td>0.404090</td>\n",
       "      <td>0.319796</td>\n",
       "      <td>0.335239</td>\n",
       "      <td>0.538440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.093893</td>\n",
       "      <td>0.091502</td>\n",
       "      <td>0.057128</td>\n",
       "      <td>0.086060</td>\n",
       "      <td>0.082135</td>\n",
       "      <td>0.101717</td>\n",
       "      <td>0.077459</td>\n",
       "      <td>0.041758</td>\n",
       "      <td>0.078078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044265</td>\n",
       "      <td>0.042144</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>0.041326</td>\n",
       "      <td>0.064363</td>\n",
       "      <td>0.069989</td>\n",
       "      <td>0.072808</td>\n",
       "      <td>0.055934</td>\n",
       "      <td>0.056258</td>\n",
       "      <td>0.098829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.198252</td>\n",
       "      <td>0.160839</td>\n",
       "      <td>0.096186</td>\n",
       "      <td>0.213444</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>0.225322</td>\n",
       "      <td>0.121437</td>\n",
       "      <td>0.087311</td>\n",
       "      <td>0.096112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564821</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.601936</td>\n",
       "      <td>0.321092</td>\n",
       "      <td>0.336354</td>\n",
       "      <td>0.359750</td>\n",
       "      <td>0.286281</td>\n",
       "      <td>0.301435</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.256814</td>\n",
       "      <td>0.211573</td>\n",
       "      <td>0.129072</td>\n",
       "      <td>0.265075</td>\n",
       "      <td>0.075913</td>\n",
       "      <td>0.279950</td>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.108831</td>\n",
       "      <td>0.142818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.610106</td>\n",
       "      <td>0.770225</td>\n",
       "      <td>0.625529</td>\n",
       "      <td>0.358757</td>\n",
       "      <td>0.377644</td>\n",
       "      <td>0.402503</td>\n",
       "      <td>0.318002</td>\n",
       "      <td>0.334131</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.015994</td>\n",
       "      <td>0.315476</td>\n",
       "      <td>0.268786</td>\n",
       "      <td>0.165098</td>\n",
       "      <td>0.315636</td>\n",
       "      <td>0.120403</td>\n",
       "      <td>0.341451</td>\n",
       "      <td>0.206071</td>\n",
       "      <td>0.136244</td>\n",
       "      <td>0.192497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618241</td>\n",
       "      <td>0.636931</td>\n",
       "      <td>0.786110</td>\n",
       "      <td>0.651543</td>\n",
       "      <td>0.400188</td>\n",
       "      <td>0.418933</td>\n",
       "      <td>0.446298</td>\n",
       "      <td>0.351308</td>\n",
       "      <td>0.366826</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SeqLength             A             R             N             D  \\\n",
       "count  28403.000000  28403.000000  28403.000000  28403.000000  28403.000000   \n",
       "mean       0.013658      0.264490      0.220284      0.134017      0.269764   \n",
       "std        0.020250      0.093893      0.091502      0.057128      0.086060   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.005830      0.198252      0.160839      0.096186      0.213444   \n",
       "50%        0.010103      0.256814      0.211573      0.129072      0.265075   \n",
       "75%        0.015994      0.315476      0.268786      0.165098      0.315636   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                  C             E             Q             G             H  \\\n",
       "count  28403.000000  28403.000000  28403.000000  28403.000000  28403.000000   \n",
       "mean       0.091449      0.287511      0.167674      0.113819      0.147683   \n",
       "std        0.082135      0.101717      0.077459      0.041758      0.078078   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.039886      0.225322      0.121437      0.087311      0.096112   \n",
       "50%        0.075913      0.279950      0.157973      0.108831      0.142818   \n",
       "75%        0.120403      0.341451      0.206071      0.136244      0.192497   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...  MoreauBrotoAuto_Mutability22  MoreauBrotoAuto_Mutability23  \\\n",
       "count  ...                  28403.000000                  28403.000000   \n",
       "mean   ...                      0.591827                      0.611746   \n",
       "std    ...                      0.044265                      0.042144   \n",
       "min    ...                      0.000000                      0.000000   \n",
       "25%    ...                      0.564821                      0.586400   \n",
       "50%    ...                      0.590879                      0.610106   \n",
       "75%    ...                      0.618241                      0.636931   \n",
       "max    ...                      1.000000                      1.000000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability24  MoreauBrotoAuto_Mutability25  \\\n",
       "count                  28403.000000                  28403.000000   \n",
       "mean                       0.771108                      0.626960   \n",
       "std                        0.025490                      0.041326   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.755818                      0.601936   \n",
       "50%                        0.770225                      0.625529   \n",
       "75%                        0.786110                      0.651543   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability26  MoreauBrotoAuto_Mutability27  \\\n",
       "count                  28403.000000                  28403.000000   \n",
       "mean                       0.361154                      0.378907   \n",
       "std                        0.064363                      0.069989   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.321092                      0.336354   \n",
       "50%                        0.358757                      0.377644   \n",
       "75%                        0.400188                      0.418933   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability28  MoreauBrotoAuto_Mutability29  \\\n",
       "count                  28403.000000                  28403.000000   \n",
       "mean                       0.404090                      0.319796   \n",
       "std                        0.072808                      0.055934   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.359750                      0.286281   \n",
       "50%                        0.402503                      0.318002   \n",
       "75%                        0.446298                      0.351308   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability30            pH  \n",
       "count                  28403.000000  28403.000000  \n",
       "mean                       0.335239      0.538440  \n",
       "std                        0.056258      0.098829  \n",
       "min                        0.000000      0.000000  \n",
       "25%                        0.301435      0.556049  \n",
       "50%                        0.334131      0.556049  \n",
       "75%                        0.366826      0.556049  \n",
       "max                        1.000000      1.000000  \n",
       "\n",
       "[8 rows x 9298 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_stats = X_train_sc.describe()\n",
    "X_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd707a0a-c88e-41cd-98eb-3ed05bb22040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28689.000000\n",
       "mean        49.091216\n",
       "std         14.192283\n",
       "min         -1.000000\n",
       "25%         41.900000\n",
       "50%         48.000000\n",
       "75%         53.800000\n",
       "max        130.000000\n",
       "Name: tm, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_stats = y_train.describe()\n",
    "y_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb9cd537-770e-4fd6-a4d5-bc5260d731f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# violin plot (tm)\n",
    "plt.violinplot(y_train, vert=False, widths=0.5, showmeans=True)\n",
    "plt.title(\"tm violin plot\") \n",
    "plt.xlabel(\"thermostability\")\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c0fb016-55e6-450a-a837-40b97af99b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# density curve of label (tm)\n",
    "bins = 100\n",
    "plt.hist(y_train, color=\"b\", bins=bins, density=True)\n",
    "y_mean, y_std = y_stats['mean'], y_stats['std']\n",
    "plt.axvline(y_mean, color=\"r\", label=\"mu\")\n",
    "plt.axvline(y_mean-y_std*1.96, color=\"g\", label=\"mu +/- 1.96 * sigma\")\n",
    "plt.axvline(y_mean+y_std*1.96, color=\"g\")\n",
    "plt.title(f\"tm density curve ({bins} bins) - mu = {y_mean:.2f} - sigma = {y_std:.2f}\")\n",
    "plt.xlabel(\"tm values\"), plt.ylabel(\"relative frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9f7b782-9b1e-4d21-a3f6-35517cb8c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d82d2060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install outlier_utils\n",
    "\n",
    "#from outliers import smirnov_grubbs as grubbs\n",
    "\n",
    "#result = {}\n",
    "#for col in X_train.columns:\n",
    "#    result[col] = grubbs.two_sided_test_indices(np.array(X_train_sc[col]), alpha=0.05)\n",
    "\n",
    "#print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf00d4-8085-44ed-b0bf-4357309c68ee",
   "metadata": {},
   "source": [
    "#### Correlations\n",
    "(with respect to the output variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4463e4-5b90-4e8e-9ea3-9fe2f2978c95",
   "metadata": {},
   "source": [
    "<b>k best correlations</b> (given an array of correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9784d330-b01f-456a-8bcb-43482dc6685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get k best scores between features and label -> pearson, spearman, f_regression and multi_info_regression\n",
    "def get_k_best_corrs(k, scores):\n",
    "    idxs = np.argsort(scores)[-k:]\n",
    "    feats = X_train_sc.columns[idxs]\n",
    "    scores = np.sort(scores)[-k:]\n",
    "    return {f: c for f, c in zip(feats, scores)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180eeb84-00c0-4d8b-9d06-aa0f8baf24b7",
   "metadata": {},
   "source": [
    "<b>Pearson and Spearman correlations</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17fbea7d-f9d3-4d6f-a5fa-72210af8dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RealPython -> https://realpython.com/numpy-scipy-pandas-correlation-python/\n",
    "\n",
    "# Linear correlation measures the proximity of the mathematical relationship between variables or dataset features\n",
    "# to a linear function. If the relationship between the two features is closer to some linear function, then their\n",
    "# linear correlation is stronger and the absolute value of the correlation coefficient is higher.\n",
    "\n",
    "# pearson correlations with respect to tm (label) -> measures linear correlations\n",
    "def pearson_correlations(x: np.ndarray):\n",
    "    return abs(scipy.stats.pearsonr(x, y_train)[0])\n",
    "\n",
    "# Rank correlation compares the ranks or the orderings of the data related to two variables or dataset features.\n",
    "# If the orderings are similar, then the correlation is strong, positive, and high. However, if the orderings are\n",
    "# close to reversed, then the correlation is strong, negative, and low. In other words, rank correlation is concerned\n",
    "# only with the order of values, not with the particular values from the dataset.\n",
    "# Allows to capture non-linear relationships (see figure below).\n",
    "\n",
    "# spearman correlations with respect to tm (label) -> compares the ranks of data\n",
    "def spearman_correlations(x: np.ndarray):\n",
    "    return abs(scipy.stats.spearmanr(x, y_train).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17090ef6-5d4b-493c-bf42-88d8f55f2e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corrs = np.apply_along_axis(pearson_correlations, axis=0, arr=X_train_sc)\n",
    "spearman_corrs = np.apply_along_axis(spearman_correlations, axis=0, arr=X_train_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728c0206-47e4-4495-bf2f-f87c63543a2e",
   "metadata": {},
   "source": [
    "![title](corrs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95f4297a-8d6f-469a-bf42-ba4720fa5804",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'DKY': 0.15266814153133518,\n 'GQ': 0.15286365153343026,\n 'EAQ': 0.15289552301813222,\n 'AV': 0.15344493003827891,\n 'FAT': 0.15350338513524256,\n 'KKM': 0.15442712483828158,\n 'AKK': 0.15442951930601523,\n 'QT': 0.1546754948448122,\n 'KLM': 0.15506147575685586,\n 'KPN': 0.15614679682260235,\n 'SCL': 0.15649190277972555,\n 'GQR': 0.15682237066803156,\n 'RTD': 0.15697681444754621,\n 'LHK': 0.157142284572514,\n 'LVM': 0.15716188338196335,\n 'QHL': 0.1572030391749388,\n 'KL': 0.15829185569280568,\n 'YAD': 0.1584168666638824,\n 'GKM': 0.15856469543391877,\n 'SKG': 0.15859564646039082,\n 'ADG': 0.1587400200194572,\n 'HK': 0.15963941435489323,\n 'GDT': 0.16125895341758134,\n 'TK': 0.1613779793990864,\n 'GVN': 0.16198659215162237,\n 'FDK': 0.16301496580571873,\n 'KM': 0.16308080977110492,\n 'THE': 0.16358028851350914,\n 'NAD': 0.16516995458724865,\n 'YIY': 0.1653405413090765,\n 'MVN': 0.16567866339095877,\n 'CM': 0.16576213874417398,\n 'RQG': 0.16612259484366063,\n 'NNT': 0.1662320325215987,\n '_SolventAccessibilityD2025': 0.1663795203988362,\n '_HydrophobicityD1025': 0.1663795203988362,\n 'DN': 0.16662540632843809,\n 'QRT': 0.16684819108492252,\n 'KYG': 0.16790013862926198,\n 'YGR': 0.16801742648684775,\n 'TEY': 0.16825757266898983,\n 'DNA': 0.1683978989752596,\n 'CLV': 0.16842695563884486,\n 'DNG': 0.1684670971662174,\n 'YKP': 0.1684910579437615,\n 'HKE': 0.1691882522378345,\n 'FTK': 0.16965980107031012,\n 'DKG': 0.17075882008240365,\n 'HPK': 0.17160534356016785,\n 'VMT': 0.17185540368894434,\n 'TKH': 0.17251365919039408,\n 'L': 0.17294123718090823,\n 'RL': 0.17321933189239813,\n '_SolventAccessibilityC3': 0.17448767292774933,\n 'TSC': 0.17453366162784117,\n '_PolarityD3025': 0.17554693821240022,\n 'MTE': 0.17586377302911707,\n 'FFF': 0.17596995635823132,\n 'TDN': 0.17689305728505958,\n 'SED': 0.17699520786504994,\n 'ATS': 0.17755888274895162,\n 'IYA': 0.17803292169453505,\n 'HEQ': 0.17955821357569288,\n 'PNN': 0.17966024815225387,\n 'GIC': 0.18129205666928488,\n 'KMV': 0.18158145959740257,\n 'PMT': 0.1816846338038438,\n 'PL': 0.1820052510936252,\n 'KK': 0.18472441604382256,\n 'MTF': 0.1860549934617688,\n 'QTD': 0.18623045532225346,\n 'K': 0.18654800240267072,\n 'S': 0.1868199281998313,\n 'KHP': 0.18910241141519374,\n 'TKK': 0.19130538790939045,\n 'RA': 0.19236663421871336,\n 'EQH': 0.1924393292130661,\n 'LE': 0.19329383612557985,\n 'IWS': 0.19394052968248318,\n 'NTH': 0.19454212925880504,\n 'MYK': 0.1966319885685232,\n 'T': 0.19703776685959035,\n 'WSE': 0.19794258198957057,\n 'SheetSSF': 0.19894453707295545,\n 'IGM': 0.19930074750815063,\n 'ER': 0.19979457778478138,\n 'LG': 0.20135332559530894,\n 'QPM': 0.20383850084146743,\n 'R': 0.20607523845993456,\n 'GE': 0.2073068465356687,\n 'LMY': 0.20859605883048965,\n 'MAI': 0.2098502061617197,\n 'CMA': 0.2102361141843166,\n 'NIW': 0.21033923038841174,\n '_SolventAccessibilityT23': 0.21300734265585397,\n '_SolventAccessibilityC1': 0.21858633645296022,\n 'ICM': 0.21971119131894587,\n 'KGQ': 0.2205654300833148,\n 'AR': 0.24282747044304423,\n 'AL': 0.25215464973986446}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest 100 pearson correlations\n",
    "best_pearson = get_k_best_corrs(100, pearson_corrs)\n",
    "best_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82db4ff2-760a-4a02-85f7-d19e9590c16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c923da3d0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# highest correlation (pearson) -> 'AL'\n",
    "plt.plot(X_train_sc[\"AL\"], y_train, \"b.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1b795e0-80cf-46b6-bee0-e8ddf7351a26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'GQR': 0.12962660212067384,\n 'ETK': 0.13004809789779256,\n 'KRF': 0.1303176805773361,\n 'GKM': 0.1303421571404401,\n 'LVM': 0.13047556331329602,\n 'ADG': 0.13071474455829585,\n 'RQG': 0.13098661870594847,\n 'TS': 0.13121349362229823,\n 'SAN': 0.13125223264214886,\n 'NRS': 0.13182856454436126,\n 'RTD': 0.13192560905438364,\n 'GDT': 0.13196690532358818,\n 'VSI': 0.13206023662371805,\n 'HK': 0.13212793065896916,\n 'YIY': 0.13272219915855835,\n 'R': 0.13272362653837938,\n 'MVN': 0.13277013284658468,\n 'ST': 0.13342347819268413,\n 'QT': 0.13358051373961205,\n 'EFD': 0.13370615927206225,\n 'KLM': 0.13372278039552202,\n 'TLI': 0.13403988547059595,\n 'STK': 0.13420492753514432,\n 'EDN': 0.13447137015118002,\n 'KM': 0.13480177065334706,\n 'FAT': 0.13537791704118815,\n 'RA': 0.13581753888988382,\n 'DKG': 0.13605421762315262,\n 'THE': 0.1361808260910424,\n 'YKP': 0.13641926459247944,\n 'KKM': 0.1365192400190705,\n 'GQP': 0.13662112389017164,\n 'TKK': 0.13698864077372286,\n 'KPN': 0.1371519884529183,\n 'CLV': 0.13719551451934017,\n 'GVN': 0.13736638737249368,\n 'YAD': 0.13752910959770148,\n 'TKH': 0.137762298669474,\n 'CL': 0.13791529159322993,\n 'EYL': 0.13796716129289552,\n 'VMT': 0.13816296634982508,\n 'FFF': 0.13837333441667957,\n 'KS': 0.13855670461919273,\n 'KSE': 0.13877134160394788,\n 'AL': 0.1391110093285619,\n 'QHL': 0.13938019525701648,\n 'FDK': 0.13982330997119552,\n 'QRT': 0.13990960439483677,\n 'ATS': 0.14005834252985655,\n 'YGR': 0.140405157531982,\n 'EAQ': 0.14069326295569376,\n 'HPK': 0.14085186118470205,\n 'DNG': 0.14141339348675241,\n 'CM': 0.14162343384703374,\n 'LHK': 0.14217787945257798,\n 'MAI': 0.14281128629880893,\n 'IYA': 0.14292779600903768,\n 'TST': 0.14333246807570577,\n 'TSC': 0.1433801738258743,\n 'DNA': 0.14360282799887317,\n 'GQY': 0.14375475164367674,\n 'TEY': 0.14443603992833884,\n 'NAD': 0.14444000193168216,\n 'AV': 0.14460588603057814,\n 'HEQ': 0.14461027360569045,\n 'GIC': 0.14474969443092636,\n 'MTF': 0.1457508613592253,\n 'NNT': 0.14671971339381965,\n 'MTE': 0.14689412630616858,\n 'TDN': 0.14689623598732662,\n 'S': 0.14719515071510747,\n 'KK': 0.14745940241889877,\n 'PMT': 0.14747057767007035,\n 'SKG': 0.14793057796079345,\n 'FTK': 0.14831430688599637,\n 'KL': 0.15023880442959944,\n 'HKE': 0.15034994745391414,\n 'SS': 0.15221145401569905,\n 'PNN': 0.15235491351350935,\n 'DN': 0.15255612937015095,\n 'GE': 0.15283538490055804,\n 'WSE': 0.1532962307162211,\n 'IWS': 0.1535302946042737,\n 'EQH': 0.15362545050517953,\n 'AR': 0.15435658376281985,\n 'NTH': 0.1547725685316063,\n 'PKK': 0.1554762958157815,\n 'KHP': 0.1555367803206601,\n 'QTD': 0.15583484667431138,\n 'MYK': 0.15742487902922675,\n 'IGM': 0.15949995501591946,\n '_SolventAccessibilityT23': 0.16130325910679302,\n 'QPM': 0.16222914043458805,\n 'NIW': 0.1622475590563388,\n 'T': 0.16238018121382103,\n 'CMA': 0.1630329662959836,\n 'K': 0.16305691936479175,\n 'LMY': 0.16725274183361946,\n 'ICM': 0.1714719834168786,\n '_SolventAccessibilityC1': 0.17256894129742167}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest 100 spearman correlations\n",
    "best_spearman = get_k_best_corrs(100, spearman_corrs)\n",
    "best_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78ac70f2-34dd-4d54-9195-82e7504cffeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c926ce0a0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# highest correlation (spearman) -> '_SolventAccessibilityC1'\n",
    "plt.plot(X_train_sc[\"_SolventAccessibilityC1\"], y_train, \"r.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff037e-a1ee-4454-9db0-0bc2900dfc1f",
   "metadata": {},
   "source": [
    "<b>Univariate linear regression</b> (F-statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aa38703-c2da-466c-84f8-b19b05763b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From sklearn docs:\n",
    "# Univariate linear regression tests returning F-statistic and p-values.\n",
    "# f_regression is derived from r_regression (Pearson) and will rank features in the same order if all the features are\n",
    "# positively correlated with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835e0cd-017a-493f-9412-337af8decd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935851bc-306e-433e-b2d8-ac2a87835ce6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# highest 100 f-values\n",
    "f_values, _ = f_regression(X_train_sc, y_train)\n",
    "best_f_scores = get_k_best_corrs(100, f_values)\n",
    "best_f_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b9f3223-cbc7-4e03-9fab-411ad008c1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if pearson_corrs and f_values are equal\n",
    "(pearson_corrs == f_values).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31984a-accf-4f5a-bbf0-4b792427c377",
   "metadata": {},
   "source": [
    "<b>Mutual information regression</b> (MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ec47de7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# From sklearn docs:\n",
    "# Estimate mutual information for a continuous target variable.\n",
    "# Mutual information (MI) (https://en.wikipedia.org/wiki/Mutual_information) between two random variables is\n",
    "# a non-negative value, which measures the dependency between the variables. It is equal to zero if and only\n",
    "# if two random variables are independent, and higher values mean higher dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3af22040-c707-4c73-8bbd-66e961e482d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression as m_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1c5a0a6-3137-481d-825d-26a40a248962",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'_HydrophobicityD2075': 0.32902886547082577,\n '_SecondaryStrD1050': 0.3304501295378115,\n '_PolarizabilityD1050': 0.33054686774029474,\n 'H': 0.3309465925258799,\n '_SecondaryStrD1075': 0.3311222768815094,\n '_NormalizedVDWVD2075': 0.33224528918198093,\n '_ChargeD2075': 0.33235799469791427,\n 'TurnSSF': 0.3327013710268689,\n '_SecondaryStrD3050': 0.33311620298295797,\n '_SecondaryStrD2075': 0.33439838763635166,\n '_HydrophobicityD2025': 0.3344450393308298,\n '_PolarizabilityD1025': 0.33580054905334755,\n '_PolarityD3075': 0.3358156798436065,\n '_SecondaryStrD2050': 0.33686624673186305,\n '_SecondaryStrD1025': 0.33721485474885604,\n '_HydrophobicityD3075': 0.33740484394942616,\n '_SolventAccessibilityD3025': 0.3375037265858696,\n '_PolarityD2050': 0.3377859468522546,\n '_SecondaryStrD3025': 0.3380721369837483,\n '_PolarityD2075': 0.33863889442838424,\n '_PolarityD2025': 0.33874739462867076,\n '_NormalizedVDWVD3075': 0.33880768727176047,\n '_SolventAccessibilityD3050': 0.33890215147032965,\n '_NormalizedVDWVD1075': 0.3393145565007467,\n '_PolarizabilityD1075': 0.33938288605730627,\n '_NormalizedVDWVD1025': 0.3404034750094178,\n '_PolarityD3050': 0.3404611153621282,\n 'Y': 0.3404816999999216,\n '_PolarizabilityD3075': 0.3405405103403014,\n '_SolventAccessibilityD3075': 0.3406136830346531,\n '_SolventAccessibilityD2050': 0.3406327503388633,\n '_HydrophobicityD1075': 0.34064967345721975,\n '_SolventAccessibilityD2075': 0.34074321685984454,\n 'M': 0.3420869373270241,\n 'HelixSSF': 0.3422129184148224,\n '_SolventAccessibilityD1025': 0.34235507155581946,\n '_HydrophobicityD1050': 0.3425819822758376,\n '_PolarityD1050': 0.3439516911927596,\n '_SolventAccessibilityD3100': 0.3442868918438293,\n '_NormalizedVDWVD3050': 0.34514203884657224,\n '_SecondaryStrD2025': 0.34572211996066926,\n '_PolarizabilityD2025': 0.34611474781836193,\n 'Aromaticity': 0.34638659323764465,\n '_NormalizedVDWVD2025': 0.3467978132053222,\n '_PolarizabilityD3001': 0.3471738808819209,\n '_HydrophobicityD3001': 0.34719306404742767,\n '_PolarizabilityD3050': 0.3472621445423485,\n '_SecondaryStrD3075': 0.34776548315162525,\n '_NormalizedVDWVD3001': 0.34779303287796104,\n 'V': 0.3479631806321519,\n '_PolarizabilityD3025': 0.34841251929080386,\n 'G': 0.3485939174289987,\n '_PolarityD1075': 0.34873645322298774,\n '_ChargeD1001': 0.34895539490591254,\n '_SecondaryStrD1001': 0.3490386576963225,\n 'E': 0.35019348327693134,\n '_NormalizedVDWVD3025': 0.35030216824152394,\n '_PolarityD3025': 0.35096437782151035,\n '_SolventAccessibilityD3001': 0.35124413394625975,\n '_HydrophobicityD3050': 0.3522451161258431,\n '_PolarityD1001': 0.35261467937359203,\n '_HydrophobicityD1025': 0.35310389980675616,\n '_SolventAccessibilityD2025': 0.35348254341593055,\n 'T': 0.3541657520982353,\n '_SolventAccessibilityD2001': 0.35446344332156077,\n '_PolarityD3001': 0.35480791188985883,\n 'C': 0.3553292650871578,\n '_HydrophobicityD1001': 0.3568047461065449,\n '_ChargeD1075': 0.3572657153749077,\n '_ChargeD3075': 0.35738778878050237,\n '_ChargeD3050': 0.35893170961289833,\n 'L': 0.3589857198095743,\n '_HydrophobicityD3025': 0.3593163214183672,\n '_PolarizabilityD2001': 0.36030932599752585,\n '_SecondaryStrD2001': 0.36081354116108155,\n '_ChargeD1050': 0.36087832313144297,\n '_ChargeD2001': 0.36093953868916095,\n 'D': 0.3610534078021699,\n '_PolarityD1025': 0.3613991973330064,\n 'SeqLength': 0.36203385469972194,\n 'P': 0.36217435267699294,\n 'R': 0.3622266171257307,\n '_NormalizedVDWVD2001': 0.3624050334482076,\n 'A': 0.3624549058920916,\n '_ChargeD3025': 0.365045650802152,\n '_ChargeD1025': 0.36511212649082303,\n 'SheetSSF': 0.36663682443516876,\n '_SolventAccessibilityD1001': 0.36699320220513787,\n 'K': 0.36789142610185355,\n '_ChargeD3001': 0.37002209033022737,\n '_SecondaryStrD3001': 0.37293131502140753,\n 'MolecularWeight': 0.3752828458447528,\n '_PolarityD2001': 0.3785249554566139,\n '_PolarizabilityD1001': 0.37956737915830896,\n '_HydrophobicityD2001': 0.3820277982223086,\n '_NormalizedVDWVD1001': 0.3861979754761862,\n 'S': 0.39256524060559705,\n 'N': 0.40014260965557025,\n 'I': 0.4012911237467387,\n 'Q': 0.41277206504060526}"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest 100 mi's (by default, n_neighbors=3 -> explore)\n",
    "mutual_info = m_info(X_train_sc, y_train)\n",
    "best_mis = get_k_best_corrs(100, mutual_info)\n",
    "best_mis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f62968",
   "metadata": {},
   "source": [
    "#### Creating datasets with best features\n",
    "(Pearson and Spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85782239",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create new training data based on the top 100 features (for both spearman and pearson)\n",
    "\n",
    "X_train_SM = X_train_sc_z.loc[:,best_spearman.keys()]\n",
    "X_train_PS = X_train_sc_z.loc[:,best_pearson.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8b609a45",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GQR</th>\n",
       "      <th>ETK</th>\n",
       "      <th>KRF</th>\n",
       "      <th>GKM</th>\n",
       "      <th>LVM</th>\n",
       "      <th>ADG</th>\n",
       "      <th>RQG</th>\n",
       "      <th>TS</th>\n",
       "      <th>SAN</th>\n",
       "      <th>NRS</th>\n",
       "      <th>...</th>\n",
       "      <th>IGM</th>\n",
       "      <th>_SolventAccessibilityT23</th>\n",
       "      <th>QPM</th>\n",
       "      <th>NIW</th>\n",
       "      <th>T</th>\n",
       "      <th>CMA</th>\n",
       "      <th>K</th>\n",
       "      <th>LMY</th>\n",
       "      <th>ICM</th>\n",
       "      <th>_SolventAccessibilityC1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>1.817367</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>-0.921269</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>0.151038</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>0.309394</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>-0.378718</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>-0.107799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>-0.335474</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>-0.073354</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>-0.458539</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>-0.678440</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>-1.029394</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>1.151108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>-0.335474</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>-0.921269</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>-0.702369</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>-0.970259</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>0.950440</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>0.243955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>-0.335474</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>-0.126348</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>-0.214708</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>-0.065802</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>-0.589146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>-0.335474</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>1.705457</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>1.810782</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>-0.450274</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>-1.644406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GQR       ETK       KRF       GKM      LVM       ADG       RQG  \\\n",
       "0 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803  1.817367 -0.300111   \n",
       "1 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803 -0.335474 -0.300111   \n",
       "2 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803 -0.335474 -0.300111   \n",
       "3 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803 -0.335474 -0.300111   \n",
       "4 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803 -0.335474 -0.300111   \n",
       "\n",
       "         TS       SAN       NRS  ...       IGM  _SolventAccessibilityT23  \\\n",
       "0 -0.921269 -0.315313 -0.279966  ... -0.248737                  0.151038   \n",
       "1 -0.073354 -0.315313 -0.279966  ... -0.248737                 -0.458539   \n",
       "2 -0.921269 -0.315313 -0.279966  ... -0.248737                 -0.702369   \n",
       "3 -0.126348 -0.315313 -0.279966  ... -0.248737                 -0.214708   \n",
       "4  0.032636 -0.315313 -0.279966  ... -0.248737                  1.705457   \n",
       "\n",
       "        QPM       NIW         T       CMA         K       LMY       ICM  \\\n",
       "0 -0.218189 -0.192412  0.309394 -0.193642 -0.378718 -0.226035 -0.185827   \n",
       "1 -0.218189 -0.192412 -0.678440 -0.193642 -1.029394 -0.226035 -0.185827   \n",
       "2 -0.218189 -0.192412 -0.970259 -0.193642  0.950440 -0.226035 -0.185827   \n",
       "3 -0.218189 -0.192412 -0.065802 -0.193642  0.366500 -0.226035 -0.185827   \n",
       "4 -0.218189 -0.192412  1.810782 -0.193642 -0.450274 -0.226035 -0.185827   \n",
       "\n",
       "   _SolventAccessibilityC1  \n",
       "0                -0.107799  \n",
       "1                 1.151108  \n",
       "2                 0.243955  \n",
       "3                -0.589146  \n",
       "4                -1.644406  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_SM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "112f982a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DKY</th>\n",
       "      <th>GQ</th>\n",
       "      <th>EAQ</th>\n",
       "      <th>AV</th>\n",
       "      <th>FAT</th>\n",
       "      <th>KKM</th>\n",
       "      <th>AKK</th>\n",
       "      <th>QT</th>\n",
       "      <th>KLM</th>\n",
       "      <th>KPN</th>\n",
       "      <th>...</th>\n",
       "      <th>LMY</th>\n",
       "      <th>MAI</th>\n",
       "      <th>CMA</th>\n",
       "      <th>NIW</th>\n",
       "      <th>_SolventAccessibilityT23</th>\n",
       "      <th>_SolventAccessibilityC1</th>\n",
       "      <th>ICM</th>\n",
       "      <th>KGQ</th>\n",
       "      <th>AR</th>\n",
       "      <th>AL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.235935</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>0.824652</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.760302</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>0.161105</td>\n",
       "      <td>-0.117881</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>1.140561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.743002</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.989898</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>0.337159</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.445497</td>\n",
       "      <td>1.130644</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>3.146741</td>\n",
       "      <td>-1.184397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.680907</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.989898</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>2.429193</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.688137</td>\n",
       "      <td>0.230972</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.815957</td>\n",
       "      <td>0.166985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.680907</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.445533</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.760302</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.202856</td>\n",
       "      <td>-0.595258</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.815957</td>\n",
       "      <td>0.588383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.680907</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.336660</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>4.178271</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>1.707939</td>\n",
       "      <td>-1.641816</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.072951</td>\n",
       "      <td>-1.184397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DKY        GQ       EAQ        AV       FAT       KKM       AKK  \\\n",
       "0 -0.267463 -0.235935 -0.346617  0.824652 -0.283886 -0.269837 -0.391064   \n",
       "1 -0.267463  0.743002 -0.346617 -0.989898 -0.283886 -0.269837 -0.391064   \n",
       "2 -0.267463 -0.680907 -0.346617 -0.989898 -0.283886 -0.269837 -0.391064   \n",
       "3 -0.267463 -0.680907 -0.346617 -0.445533 -0.283886 -0.269837 -0.391064   \n",
       "4 -0.267463 -0.680907 -0.346617 -0.336660 -0.283886 -0.269837 -0.391064   \n",
       "\n",
       "         QT       KLM       KPN  ...       LMY       MAI       CMA       NIW  \\\n",
       "0 -0.760302 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "1  0.337159 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "2  2.429193 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "3 -0.760302 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "4  4.178271 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "\n",
       "   _SolventAccessibilityT23  _SolventAccessibilityC1       ICM       KGQ  \\\n",
       "0                  0.161105                -0.117881 -0.184867 -0.257779   \n",
       "1                 -0.445497                 1.130644 -0.184867 -0.257779   \n",
       "2                 -0.688137                 0.230972 -0.184867 -0.257779   \n",
       "3                 -0.202856                -0.595258 -0.184867 -0.257779   \n",
       "4                  1.707939                -1.641816 -0.184867 -0.257779   \n",
       "\n",
       "         AR        AL  \n",
       "0  0.009605  1.140561  \n",
       "1  3.146741 -1.184397  \n",
       "2 -0.815957  0.166985  \n",
       "3 -0.815957  0.588383  \n",
       "4 -0.072951 -1.184397  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_PS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99dae9f",
   "metadata": {},
   "source": [
    "#### Correlations\n",
    "(pairs of variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd19bd",
   "metadata": {},
   "source": [
    "Um problema que pode ocorrer nos dados Ã© a multicolinearidade, quando se observa correlaÃ§Ãµes elevadas entre variÃ¡veis independentes. Isto pode fazer com que os resultados obtidos de anÃ¡lises de machine leraning, como na aplicaÃ§Ã£o de regressÃµes lineares, nÃ£o sejam fidedÃ­gnos. **(explicar?)** Desta forma, deve-se remover uma das variÃ¡veis altamente correlacionadas, de preferÃªncia a que estÃ¡ menos correlacionada com a variÃ¡vel alvo.\n",
    "\n",
    "Desta forma, criou-se uma funÃ§Ã£o para averiguar a possibilidade de multicolinearidade (usando as correlaÃ§Ãµes de pearson e spearman) e devolvendo os pares de variÃ¡veis com correlaÃ§Ãµes elevadas. Na generalidade, considera-se uma correlaÃ§Ã£o elevada quando se obtÃ©m um valor absoluto igual ou superior a 0.8.\n",
    "\n",
    "ApÃ³s ser analisado uma correlaÃ§Ã£o elevada, compara-se cada variÃ¡vel independente com a dependente, de forma a averiguar qual Ã© a que estÃ¡ menos correlacionada e, portanto, deve ser removida. A funÃ§Ã£o devolve, assim, os pares de variÃ¡veis altamente correlacionados, e ainda qual a variÃ¡vel desse par que deverÃ¡ ser removida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eb437c5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to determine the independent variables that are highly correlated with one another\n",
    "# (they result in less reliable statistical inference)\n",
    "\n",
    "def _check_xy_corr(y_data:pd.DataFrame, var1:str, var2:str):\n",
    "    \"\"\"\n",
    "    Returns the name of the variable worse correlated to y\n",
    "    \"\"\"\n",
    "    corr1 = y_data.loc[var1,:]\n",
    "    corr2 = y_data.loc[var2,:]\n",
    "\n",
    "    if corr1 < corr2:\n",
    "        return var1\n",
    "    else:\n",
    "        return var2\n",
    "\n",
    "\n",
    "def multicolinearity(x_data:pd.DataFrame, y_data:pd.DataFrame, perc:float=0.8, method=\"pearson\") -> list:\n",
    "    \"\"\"\n",
    "    Selects pair os variables with collinearity above a given threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    :param x_data: Dataframe with independent variables\n",
    "    :param y_var: Indicates column index or name of the dependent variable. If non-existent, define this parameter as None.\n",
    "    :param perc: Collinearity percentage threshold\n",
    "    :param method: Method to determine correlation between variables ('pearson', 'kendall', 'spearman')\n",
    "    \"\"\"\n",
    "\n",
    "    corr = x_data.corr(method=method.lower())\n",
    "    result = []\n",
    "    check = 1\n",
    "    for l in corr:\n",
    "        for ix,val in enumerate(corr[l][check:]):\n",
    "            if val>=perc:\n",
    "                var1, var2 = (l, corr.index[ix])\n",
    "                if y_data:\n",
    "                    least_corr = _check_xy_corr(y_data, var1, var2)\n",
    "                    result.append(((var1, var2), least_corr))\n",
    "                else:\n",
    "                    result.append((var1, var2))\n",
    "            check += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2a98576",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "multicol_sm = multicolinearity(X_train_SM, y_train, perc=0.8, method=\"spearman\")\n",
    "\n",
    "for elem in multicol_sm:\n",
    "    print(elem)\n",
    "#Multicollinearity non-existent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbd813d7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "multicol_ps = multicolinearity(X_train_PS, y_train, perc=0.8, method=\"pearson\")\n",
    "\n",
    "for elem in multicol_ps:\n",
    "    print(elem)\n",
    "#Multicollinearity non-existent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0f01b",
   "metadata": {},
   "source": [
    "Em nenhum dos casos (considerando os 100 descritores mais relevantes pelo mÃ©todo de spearman e pearson) se observou multicolinearidade.\n",
    "\n",
    "Caso tivesse sido observado, utilizarÃ­amos o seguinte bloco de cÃ³digo para remover as variÃ¡veis menos correlacionadas com a variÃ¡vel dependente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2ab6349",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Eliminate variables with multicollinearity\n",
    "\n",
    "#pairs, least_corr = list(zip(*multicol))\n",
    "#least_corr = set(least_corr)\n",
    "\n",
    "#for elem in least_corr:\n",
    "#    del X_train[elem]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7d27c",
   "metadata": {},
   "source": [
    "# Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d616fbdc",
   "metadata": {},
   "source": [
    "Passando para a anÃ¡lise dos dados, comeÃ§amos aplicar algoritmos de aprendizagem nÃ£o-supervisionada, ou seja, que nÃ£o tem em conta a variÃ¡vel dependente. Retiram inferÃªncias apenas a partir dos descritores, podendo ser aplicados para reduzir a dimensionalidade do dataset, e atÃ© mesmo agrupar os dados de acordo com a sua proximidade.\n",
    "\n",
    "Os algoritmos de aprendizagem nÃ£o-supervivionada, como o PCA, sÃ£o sensÃ­veis Ã s escalas dos valores e outliers. Uma vez que jÃ¡ se efetuou a standardizaÃ§Ã£o dos dados, nÃ£o Ã© necessÃ¡rio efetuar esse passo novamente. Relativamente aos outliers, procuraram-se as linhas que contÃªm apenas valores inferiores a 3, ou seja, que contÃªm valores inferiores a 3 vezes o desvio padrÃ£o (considerando-se outlier). Desta forma, sÃ£o removidas as linhas que nÃ£o satisfazem esta condiÃ§Ã£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "737e0521",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28403, 100)\n",
      "(5948, 100)\n",
      "(5948,)\n",
      "\n",
      "(28403, 100)\n",
      "(6477, 100)\n",
      "(6477,)\n"
     ]
    }
   ],
   "source": [
    "#Removing outliers\n",
    "\n",
    "\n",
    "\n",
    "X_train_PS_clean = X_train_PS[(np.abs(X_train_PS) < 3).all(axis=1)]\n",
    "X_train_PS_clean.index = range(len(X_train_PS_clean))\n",
    "X_train_SM_clean = X_train_SM[(np.abs(X_train_SM) < 3).all(axis=1)]\n",
    "X_train_SM_clean.index = range(len(X_train_SM_clean))\n",
    "\n",
    "y_train_PS = y_train.loc[list((np.abs(X_train_PS) < 3).all(axis=1))]\n",
    "y_train_PS.index = range(len(y_train_PS))\n",
    "y_train_SM = y_train.loc[list((np.abs(X_train_SM) < 3).all(axis=1))]\n",
    "y_train_SM.index = range(len(y_train_SM))\n",
    "\n",
    "print(X_train_PS.shape)\n",
    "print(X_train_PS_clean.shape)\n",
    "print(y_train_PS.shape)\n",
    "print()\n",
    "print(X_train_SM.shape)\n",
    "print(X_train_SM_clean.shape)\n",
    "print(y_train_SM.shape)\n",
    "#df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236e9d10",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DKY</th>\n",
       "      <th>GQ</th>\n",
       "      <th>EAQ</th>\n",
       "      <th>AV</th>\n",
       "      <th>FAT</th>\n",
       "      <th>KKM</th>\n",
       "      <th>AKK</th>\n",
       "      <th>QT</th>\n",
       "      <th>KLM</th>\n",
       "      <th>KPN</th>\n",
       "      <th>...</th>\n",
       "      <th>LMY</th>\n",
       "      <th>MAI</th>\n",
       "      <th>CMA</th>\n",
       "      <th>NIW</th>\n",
       "      <th>_SolventAccessibilityT23</th>\n",
       "      <th>_SolventAccessibilityC1</th>\n",
       "      <th>ICM</th>\n",
       "      <th>KGQ</th>\n",
       "      <th>AR</th>\n",
       "      <th>AL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.431522</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.082623</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>0.954480</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>0.464406</td>\n",
       "      <td>-0.521816</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>0.215995</td>\n",
       "      <td>0.254170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.720753</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>0.389160</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.314459</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.384836</td>\n",
       "      <td>0.084086</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.299981</td>\n",
       "      <td>0.094330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.146941</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.554406</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>0.062793</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>0.858697</td>\n",
       "      <td>-0.852308</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.320620</td>\n",
       "      <td>-0.835654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.680907</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.391097</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.760302</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.263516</td>\n",
       "      <td>0.561464</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>0.546220</td>\n",
       "      <td>0.239639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.387025</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.554406</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.760302</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.172526</td>\n",
       "      <td>-0.319848</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>0.174717</td>\n",
       "      <td>-0.138166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DKY        GQ       EAQ        AV       FAT       KKM       AKK  \\\n",
       "15 -0.267463  0.431522 -0.346617 -0.082623 -0.283886 -0.269837 -0.391064   \n",
       "16 -0.267463  0.720753 -0.346617  0.389160 -0.283886 -0.269837 -0.391064   \n",
       "19 -0.267463 -0.146941 -0.346617 -0.554406 -0.283886 -0.269837 -0.391064   \n",
       "29 -0.267463 -0.680907 -0.346617 -0.391097 -0.283886 -0.269837 -0.391064   \n",
       "31 -0.267463  0.387025 -0.346617 -0.554406 -0.283886 -0.269837 -0.391064   \n",
       "\n",
       "          QT       KLM       KPN  ...       LMY       MAI       CMA       NIW  \\\n",
       "15  0.954480 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "16 -0.314459 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "19  0.062793 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "29 -0.760302 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "31 -0.760302 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "\n",
       "    _SolventAccessibilityT23  _SolventAccessibilityC1       ICM       KGQ  \\\n",
       "15                  0.464406                -0.521816 -0.184867 -0.257779   \n",
       "16                 -0.384836                 0.084086 -0.184867 -0.257779   \n",
       "19                  0.858697                -0.852308 -0.184867 -0.257779   \n",
       "29                 -0.263516                 0.561464 -0.184867 -0.257779   \n",
       "31                 -0.172526                -0.319848 -0.184867 -0.257779   \n",
       "\n",
       "          AR        AL  \n",
       "15  0.215995  0.254170  \n",
       "16 -0.299981  0.094330  \n",
       "19 -0.320620 -0.835654  \n",
       "29  0.546220  0.239639  \n",
       "31  0.174717 -0.138166  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_PS_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2300a55",
   "metadata": {},
   "source": [
    "Foi possÃ­vel remover 22222 amostras do dataset do pearson, e 21726 amostras do dataset do spearman. As novas variÃ¡veis criadas tÃªm valores mais homogÃªnios que vÃ£o permitir uma prestaÃ§Ã£o mais fidedÃ­gna dos algoritmos de aprendizagem nÃ£o-supervisionada. Vamos analisar o efeito de 2 algoritmos: **PCA** e **tSNE**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d52c2",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675964e6",
   "metadata": {},
   "source": [
    "ComeÃ§amos com o algorÃ­tmo do PCA (Principal Components Analysis). Este algoritmo tem o objetivo de reduzir a dimensionalidade, ao encontrar uma nova forma de representar os dados que explique o mÃ¡ximo da variÃ¢ncia possÃ­vel. Desta forma, Ã© geralmente possÃ­vel eliminar informaÃ§Ã£o que nÃ£o contribui muito para a variabilidade dos dados, fornecendo dados menos ruidosos aos eventuais algoritmos de aprendizagem aplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d818e4e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_SM = PCA()\n",
    "pca_SM.fit(X_train_SM_clean)\n",
    "x_reduced_SM = pca_SM.transform(X_train_SM_clean)\n",
    "\n",
    "pca_PS = PCA()\n",
    "pca_PS.fit(X_train_PS_clean)\n",
    "x_reduced_PS = pca_PS.transform(X_train_PS_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5936e78c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.58349946e+01 1.19868417e+01 7.69860902e+00 5.78776121e+00\n",
      " 4.55715104e+00 3.61589294e+00 3.09353735e+00 2.80958183e+00\n",
      " 2.66072014e+00 2.34178112e+00 2.09030455e+00 1.95181483e+00\n",
      " 1.92950259e+00 1.77384607e+00 1.70977808e+00 1.68653116e+00\n",
      " 1.57966308e+00 1.48635047e+00 1.36186695e+00 1.30986550e+00\n",
      " 1.25323662e+00 1.10317744e+00 1.07231966e+00 1.00774743e+00\n",
      " 9.86784333e-01 9.46418059e-01 9.26852830e-01 8.92194457e-01\n",
      " 8.77838259e-01 8.48371205e-01 8.46325056e-01 8.29659537e-01\n",
      " 8.01798273e-01 7.94884979e-01 7.80413081e-01 7.67277296e-01\n",
      " 7.44147847e-01 7.16520115e-01 7.05616514e-01 6.92158194e-01\n",
      " 6.65515813e-01 5.57787611e-01 5.55566651e-01 5.27902376e-01\n",
      " 5.06248142e-01 4.82487518e-01 4.39759189e-01 4.06054190e-01\n",
      " 4.02015064e-01 3.83264184e-01 2.13263837e-01 3.12417291e-30\n",
      " 1.00606850e-30 9.32823811e-31 6.77004404e-31 4.91479842e-31\n",
      " 4.90945494e-31 3.03792203e-31 2.53950748e-31 2.40682866e-31\n",
      " 1.30506360e-31 9.62562489e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.30633775e-32 4.79376546e-32 2.81308248e-32 1.09771841e-32]\n",
      "\n",
      "Spearman:\n",
      "NÃºmero total de PCs: 100\n",
      "NÃºmero de PCs necessÃ¡rios para explicar 95% da variÃ¢ncia: 41\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pca_SM.explained_variance_ratio_*100)\n",
    "\n",
    "print()\n",
    "print(\"Spearman:\")\n",
    "print(f\"NÃºmero total de PCs: {pca_SM.n_components_}\")\n",
    "print(f\"NÃºmero de PCs necessÃ¡rios para explicar 95% da variÃ¢ncia: \\\n",
    "{sum(pca_SM.explained_variance_ratio_.cumsum() < 0.95) + 1}\")\n",
    "\n",
    "plt.bar(range(4), pca_SM.explained_variance_ratio_[:4]*100)\n",
    "plt.xticks(range(4), ['PC'+str(i) for i in range(1,5)])\n",
    "plt.title(\"VariÃ¢ncia explicada por PC\")\n",
    "plt.ylabel(\"Percentagem\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c65706fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.37852940e+01 1.16982816e+01 9.24791356e+00 6.62364218e+00\n",
      " 5.17924856e+00 4.23030726e+00 3.15678657e+00 2.96802570e+00\n",
      " 2.75196204e+00 2.59458985e+00 2.07394720e+00 2.06367677e+00\n",
      " 1.93450496e+00 1.87517368e+00 1.78896947e+00 1.67624857e+00\n",
      " 1.56575690e+00 1.53979298e+00 1.48090454e+00 1.44162142e+00\n",
      " 1.34480829e+00 1.20400829e+00 1.12530345e+00 1.09938136e+00\n",
      " 9.86151953e-01 9.26902232e-01 8.61259244e-01 8.56166813e-01\n",
      " 8.48130658e-01 8.13589295e-01 7.91618237e-01 7.36713830e-01\n",
      " 7.26963634e-01 7.06370113e-01 6.50835634e-01 6.21134742e-01\n",
      " 5.93519139e-01 5.72303308e-01 5.35604244e-01 5.14758114e-01\n",
      " 5.03816602e-01 4.96057283e-01 4.45902545e-01 4.34321668e-01\n",
      " 4.02778364e-01 3.97518502e-01 3.81252062e-01 2.98513360e-01\n",
      " 2.56083975e-01 1.91585319e-01 2.71890802e-30 7.99448038e-31\n",
      " 6.01647897e-31 4.84908893e-31 4.28612401e-31 4.08482469e-31\n",
      " 3.30915483e-31 2.52591868e-31 1.93035826e-31 1.55499273e-31\n",
      " 9.69289533e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.14515070e-32\n",
      " 5.33539671e-32 2.50275243e-32 2.33903103e-32 1.77107162e-33]\n",
      "\n",
      "Pearson:\n",
      "NÃºmero total de PCs: 100\n",
      "NÃºmero de PCs necessÃ¡rios para explicar 95% da variÃ¢ncia: 38\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pca_PS.explained_variance_ratio_*100)\n",
    "\n",
    "print()\n",
    "print(\"Pearson:\")\n",
    "print(f\"NÃºmero total de PCs: {pca_PS.n_components_}\")\n",
    "print(f\"NÃºmero de PCs necessÃ¡rios para explicar 95% da variÃ¢ncia: \\\n",
    "{sum(pca_PS.explained_variance_ratio_.cumsum() < 0.95) + 1}\")\n",
    "\n",
    "plt.bar(range(4), pca_PS.explained_variance_ratio_[:4]*100)\n",
    "plt.xticks(range(4), ['PC'+str(i) for i in range(1,5)])\n",
    "plt.title(\"VariÃ¢ncia explicada por PC\")\n",
    "plt.ylabel(\"Percentagem\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829cd64",
   "metadata": {},
   "source": [
    "Os resultados demonstram que, para os 100 melhores features selecionados pelo mÃ©todo de spearman, Ã© possÃ­vel utilizar apenas 41 componentes para explicar 95% da variÃ¢ncia, e para os 100 features selecionados pelo mÃ©todo de spearman, Ã© possÃ­vel utilizar apenas 38 componentes.\n",
    "\n",
    "*NOTA: ao utilizar os dados isentos de outliers (valores standardizados superiores a 3), obtivemos resultados muito insatisfatÃ³rios na aprendizagem supervisionada, pelo que decidimos nÃ£o utilizar estes dados, nem os reduzidos pelo PCA.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95d947",
   "metadata": {},
   "source": [
    "#### t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e64ee4",
   "metadata": {},
   "source": [
    "tSNE ('t-distributed Stochastic Neighbor Embedding') aplica um mÃ©todo de reduÃ§Ã£o de dimensionalidade semelhante ao PCA, mas tem como principal foco a visualizaÃ§Ã£o dos dados transformados. Neste caso, Ã© necessÃ¡rio definir em quantos grupos deverÃ£o ser separados os dados. Como a variÃ¡vel dependente se trata de de valores contÃ­nuos, nÃ£o Ã© Ã³bvio o nÃºmero de grupos que se deverÃ¡ separar os dados. Desta forma, optou-se por separÃ¡-los em 3 grupos baseados na variÃ¡vel dependente:\n",
    "\n",
    "- os que estÃ£o prÃ³ximos da mÃ©dia;\n",
    "- os que estÃ£o acima de um desvio-padrÃ£o da mÃ©dia;\n",
    "- os que estÃ£o abaixo de um desvio-padrÃ£o da mÃ©dia.\n",
    "\n",
    "Apesar deste algoritmo nÃ£o ser tÃ£o sensÃ­vel a outliers como no caso do PCA, vamos efetuar a anÃ¡lise sem outliers para visualizar melhor os grÃ¡ficos resultantes. Ã‰, contudo, um algoritmo com elevado peso computacional, pelo que pode demorar bastante tempo a correr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d4b8295",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mean = y_train.mean()\n",
    "std = y_train.std()\n",
    "\n",
    "ub = mean+std\n",
    "lb = mean-std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0c13e48",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, n_iter=1000)\n",
    "\n",
    "points_sm = tsne.fit_transform(X_train_SM_clean)\n",
    "points_ps = tsne.fit_transform(X_train_PS_clean)\n",
    "\n",
    "group1_sm = y_train_SM.index[y_train_SM > ub]\n",
    "group2_sm = y_train_SM.index[(y_train_SM <= ub) & (y_train_SM > lb)]\n",
    "group3_sm = y_train_SM.index[y_train_SM <= lb]\n",
    "\n",
    "group1_ps = y_train_PS.index[y_train_PS > ub]\n",
    "group2_ps = y_train_PS.index[(y_train_PS <= ub) & (y_train_PS > lb)]\n",
    "group3_ps = y_train_PS.index[y_train_PS <= lb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a59d6d71",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEICAYAAAC6fYRZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxU1dnHv2cme4CEEJAtFFTcgAiCivuCQmsQrFasVgsu0NpaqVYqvKUSFJUWi8KrtSoIWG0lWkQ0r0WLK1pUEBpEXCqLLGENCZCFZGae9487M5nl3lnvZCbJ/X4+Icyde889M5n53XOf85zfo0QECwsLC4u2iS3ZHbCwsLCwSByWyFtYWFi0YSyRt7CwsGjDWCJvYWFh0YaxRN7CwsKiDWOJvIWFhUUbxhJ5izaPUqqrUuorpVRWsvuSLJRSxymlNiulMpPdF4uWxRJ5i4SilNqmlLosYNutSqkvlVJHlFJ7lVLlSqmO7ucWK6VEKXWWz/4nKqXE5/G7SqkGpdRRn5/XQnRjKrBIRBrcxw9QSr2plDqklKpWSq1TSl1h7itPLURkL/AOMCnZfbFoWSyRt2hRlFIXAQ8B14tIR+BUoCxgtypgVpim7hCRDj4/VxqcLxMYDzzvs/k14C3gOKAbcCdwOOoXEwdKo6W/fy8AP2vhc1okGUvkLRKGUuqvQB/gNfdo+7fAmcC/RWQ9gIhUicgSETnic+gSoNh9QYiXs4FqEdnp7lMh0A94RkQa3T8fishq9/MXK6V2KqX+Ryl1wH0n8hOf15SplHpEKfWd+y7kL0qpbPdznZVSryul9rvvEl5XSvX2OfZdpdSDSqkPgTrgePddyy+UUt+472weUEqdoJT6t1LqsFKqTCmVEUX7DyilPnS39ab79Xr42H3O75nwvlq0EiyRt0gYInIT8B1wpXu0/Uc0oRmllJqplDrPIEZchzbaf9CEbgwCvvJ5fBD4L/C8UuoqpdRxOsd0BwqBXmh3AU8rpU52P/cH4CRgMHCie5/73M/ZgEXA99AubvXA4wFt34QWMukIbHdv+z4wFBgO/BZ4GvgJUAQMBK6Pov0bgJvR7lAygHs8T4iIw/3aT9d5zRZtFEvkLVoUEfkAuBo4AygHDiql5iql7AG7PgX0UUr9wKCp+e54uufnAYP98gHvXYJoZk2XANuAPwGVSqn3lVL9A477vYgcE5H33P0cp5RSwETgLvcdyBG0i9GP3W0fFJF/iEid+7kHgcC7kcUisklEHCLS5N72BxE5LCKbgM+BN0Vki4jUAG8AQ6Jof5GIfC0i9WhhsMEBzx9xvycW7YS0ZHfAov0hIm8Ab7hj0pcAL6GNtp/y2eeYW7gfoHkk68udIrIggtMdQhs1+55/J3AHgFKqCG3k/BxwjucYEan1OWQ70BPoCuQA6zS9B0ABdndbOcCjaCPzzu7nOyql7CLidD/eodPHvT7/r9d53D2K9vf4HFsHdAg4V0egWqcPFm0UayRvkWgMbU5FxCUiq4C30cISgSwC8oAfxnH+CrTwilEfdgBPBJy/s1Iq1+dxH2A3cABNdAeISL77J09EPEL6G+Bk4GwR6QRc6N6ufNqKx/Y1kvYNUUqloYWY/hNHHyxaGZbIWySavcDxngdKqbFKqR+7JxGVO1XyImBN4IHuGHIpcG8c5/8EyFdK9XKfv7N7PuBEpZTNPTF5i875ZyqlMpRSFwCjgZdExAU8AzyqlOrmbq+XUmqU+5iOaBeBaqVUATAjjn7rEW/7ZwHbRGR72D0t2gyWyFskmoeB6e64+T1o4ZOJwDdoaYvPA3NE5AWD4/8OVOpsfzwgT36d3sEi0ggsBm50b2oE+gL/cp//c+AYMMHnsD3ufu5GSzv8uYh86X7uXrTJyzVKqcPudjyTso8B2Wgj/jXAPw1eU6zE2/5PgL+Y3CeLFEdZRUMs2jpKqa7AB8AQ94RkqH0vBp4Xkd6h9mttuO883kN7DxqS3R+LlsOaeLVo84jIfuCUZPcjmYjIPrSFZxbtDCtcY2FhYdGGscI1FhYWFm0YayRvYWFh0YZJqZh8YWGh9O3bN9ndsLCwsGhVrFu37oCIdNV7LqVEvm/fvqxduzbZ3bCwsLBoVSilDNc+WOEaCwsLizaMJfIWFhYWbRhL5C0sLCzaMCkVk7ewsEhNmpqa2LlzJw0N1mLZZJKVlUXv3r1JT0+P+BhL5C0sLMKyc+dOOnbsSN++ffGxWbZoQUSEgwcPsnPnTvr16xfxcZbIW1gkgfI5PZjXOZ89aXa6O5xMPlRNyRQ9H7bUoKGhwRL4JKOUokuXLuzfvz+q40yJySul7lJKbVJKfa6U+rtSKkspVaCUestdu/ItpVTn8C1ZWLRhKsrg0YGUz+lBaWEBlelpiFJUpqdRWlhA+Zweye5hSCyBTz6x/A3iHsm7fbrvBE4TkXqlVBlaObTTgFUiMlspNRWYSny+4BYWrZeKMnjtTmiqZ17vnjTY/MdXDTYb8zrnU2J0/ONnw4Evmx8XngJ3fJyw7lq0HczKrkkDst2VZ3LQfLjHAkvczy8BrjLpXBYWrY9V90OT5nK8Jy2wnC0htwcJPGiPHz/bzB5aJIHHHnuMuro63ecWL17MHXfcEfc54hZ5EdkFPAJ8h1bcoUZE3gSOE5FK9z6VaNXjg1BKTVJKrVVKrY021mRh0Wqo2en9b3eHU3cXo+1BAu+zvXxLOSP/dj7FiwcycsGplD8xULtrSDLL1+/ivNlv029qOefNfpvl63fF3eahQ4dM6FnimTBhAu+++25E+4YSebOIW+TdsfaxQD+0Yse5SqkbQx/VjIg8LSLDRGRY16661gsWFq2fvOYaJJMPVZPlcvk9neVyMflQtTY6L81r/nmgu2GTswrymfr+vVQ21TTH9nOE8n9NSarQL1+/i2nLNrKruh4BdlXXM23ZxriFftiwYdxwww28/fbbhHPPvfjii7nrrru48MILOfXUU/n000+5+uqr6d+/P9OnT/fu9/zzz3PWWWcxePBgfvazn+F0ahfa22+/nWHDhjFgwABmzGiusti3b19mzJjBGWecwaBBg/jyS4MLcAC1tbWUlJRw+umnM3DgQJYuXcr8+fPZvXs3l1xyCZdccgkAixYt4qSTTuKiiy7iww8/jPYt0sWMcM1lwFYR2S8iTcAy4Fxgr1KqB4D79z4TzmVh0ToZcR+kZwNQUltH6YEqejQ5UCL0aHJQeqCKkuw+waN2p34hq/LcHJZ26ggBE3ENNhvzOuVo4aEkMWflV9Q3+d+V1Dc5mbPyq7ja/frrr7nhhht4/PHHOe2003jooYfYvXu34f4ZGRm8//77/PznP2fs2LE88cQTfP755yxevJiDBw+yefNmli5dyocffsiGDRuw2+288IJWhfLBBx9k7dq1VFRU8N5771FRUeFtt7CwkM8++4zbb7+dRx55JKK+//Of/6Rnz5785z//4fPPP+f73/8+d955Jz179uSdd97hnXfeobKykhkzZvDhhx/y1ltv8cUXX8T1fnkwQ+S/A4YrpXKUNvU7AtgMrADGu/cZD7xqwrksLFonxePgyvmQVwQoStK68OZZM6mY8Dlv3raZkm5nGodldJjXOT9I4D3sSbNDzY7mu4GH+5j0IiJjd7X+hcloe6TY7XZGjx7NsmXLeP/999myZQt9+vThk08+0d1/zJgxAAwaNIgBAwbQo0cPMjMzOf7449mxYwerVq1i3bp1nHnmmQwePJhVq1axZcsWAMrKyjjjjDMYMmQImzZt8hPcq6++GoChQ4eybds2AFauXMngwYMZPHgwK1as4LbbbmPw4MGcffbZ3j7861//4t577+WDDz4gLy8vqL8ff/wxF198MV27diUjI4PrrrsurvfLQ9zZNSLysVLqZeAzwAGsB54GOgBlSqlb0S4E18Z7LguLVssjp1AuNVpufOfeWm78yl9TUjwOloyBre9F1ZzhJC06sf1jNZrQT/sulp5HTc/8bHbpCHrP/Oy4266pqWHp0qUsWrSI9PR0Fi5cSHFxse6+mZmZANhsNu//PY8dDgciwvjx43n44Yf9jtu6dSuPPPIIn376KZ07d2bChAl+K309bdntdhwOBwCjRo1i1KhRgBaTnzBhAhdffLH3mJNOOol169bxf//3f0ybNo2RI0dy3333BfU5EWmqpmTXiMgMETlFRAaKyE0ickxEDorICBHp7/5dZca5LCxaHW6B/33XLn658b/vWkD5nJ4RC/ysgnxO71vEoL5FGEakRbTYfiDHamLufrRMGXUy2en+F6HsdDtTRp0cV7s33ngjZ5xxBlu2bOG5557j/fffZ/z48WRlZcXU3ogRI3j55ZfZt0+LJFdVVbF9+3YOHz5Mbm4ueXl57N27lzfeeCOufgPs3r2bnJwcbrzxRu655x4+++wzADp27MiRI0cAOPvss3n33Xc5ePAgTU1NvPTSS3GfF6wVrxYWiedoJbP79KIpYJTWpBSzu+RTUlure1h5bo53VWyWS6i3Kf8QjUjQ4+sOH6GkNrHZGuG4akgvQIvN766up2d+NlNGnezdHivjxo1j8eLFpKWZI1unnXYas2bNYuTIkbhcLtLT03niiScYPnw4Q4YMYcCAARx//PGcd955cZ9r48aNTJkyBZvNRnp6Ok8++SQAkyZN4gc/+AE9evTgnXfeobS0lHPOOYcePXpwxhlneCeC4yGlarwOGzZMrKIhFm2O0jwG9S3Sj6GLsHHbjqDN5bk5lBYWBC2a0jteAZ2cLpSCGput2SYhUOxLYx/Nb968mVNPPTXm4y3MQ+9voZRaJyLD9Pa3RvIWqcPrd8O6xSBOUHYYOgFGz012rxKO74jdI9DzOueHF3g3D+8/6HdB8NgkAM1Cnxk80WfRPrBE3iJ5PNzHOFYsTli7UPt/GxD6PKeLGp3J0mwRXYFuiHACzga6FwSvTUJtnSbwLTTpapF6WEVDLJJDKIH3Ze1CbYTfmhl2K9OqDpEWsAAqzeUiwyW6Ah3RF1OEaw8fCW2TUFpjCXw7xxJ5i6RQntbEyN49Ke5bxMjePSnPzTHeubUL/ei5lJx6PbMCFkDNOlDFYbv+V9AF2sRqGKZXVUdvk2DRrrBE3qLFKV9yib7VbiihX7e4xfqXEEbPpSS7D2/u3E3Fth28uXM3JbV1xkKs3Jk0IYTe8+WdXFOnb5MQ39ojizaCJfIWLUr5kkv4H9lvGEM2RNrAqFRnRauej40fSqFEgsXeHaqhQw9KjlQH2yQcdVHyq80mvwCL1ogl8hYtRvmSSyh17cMVajm+ESrEc60YXx+bUKP26w4fweYWe5s7H356VTUcrfS2471LqDxIyUUzW+olWETI8uXLDf1otm3bxsCBAxNyXkvkLVqMeU17QqYFGoUuBKjJ6ZuYTqUAJbV1vHnbZnqEiK1Pr6rmP9t2sHHbDv6zbYcm8EY4j8Grv0yu5bC7Chal+dpvE/rSWqyGjQgl8onEEnmLFiPUSN1rtauDAnKPbjXFkzypFJ4Scvvk9O7GFsTR4myEN5JUiM1TBatmByDa79fujFvoW5PV8NSpUznttNMoLi7mnnvu4aOPPmLFihVMmTKFwYMH8+2337Ju3TpOP/10zjnnHJ544om43ptQWCJv0TJUlBmO1G0imtVuiOX4dlxxW9UmnTs+DhL613JzGJl1mOLFA3nYsRcFWthGhHynM+z7EpL6JNlF+VTB8tJUH7f9cWuxGq6qquKVV15h06ZNVFRUMH36dM4991zGjBnDnDlz2LBhAyeccAI333wz8+fP59///ndc70s4LJG3SDzukZ1RsYyH9h8MK2RObHFb1aYEF/4GbBkAvJ6bw/0+WUY1aXbqbTZvZk3IBVGZedDvohbqdJT4VMGKaHuEpLLVsC+dOnUiKyuL2267jWXLlpGTE5w1VlNTQ3V1NRddpP0Nb7rpprjem1BYK14tEo97ZFfSpD0MXMLvK/Ceu/BAH64XnJeaYlWbVCrKYNlE78P5YawL/Fat+uLrQRPKpji7IJ7exk5eb3eoRmd7nKSy1fDevXsZNmwYCxYs4JNPPmHVqlW8+OKLPP7447z99tt+5xCRhNgK62GJvEXi8RnBldTWGY7aReA552UA/MT+NnZcOLHxgvNSZquJPBynVW3SCQhXVIbKJnITNI8ROHofv0K7eCz/Bbiamrfb0uEHf4i1p/Ex4j4tBu8bsknP1rbHwY033si///1vrr32Wp577jn69+8fXzdHjGDs2LHcdddddOvWjaqqKo4cOaJrNezrDa/HypUrvf8/evQodXV1XHHFFQwfPpwTTzwR8LcVzs/PJy8vj9WrV3P++ed7w0SJwBJ5i8RjNLLzoU4ymNp0Gytc5wMww3ELoE269szP5mETrGqTTgzhCr95jH4XaaIeSPE47feq+7Vz5PXWBNWzvaVJUH9ai9XwkSNHGDt2LA0NDYgIjz76KAA//vGPmThxIvPnz+fll19m0aJF3HLLLeTk5HgLjiQCU6yGlVL5wAJgIFrG2y3AV8BSoC+wDRgnIiFzoCyr4TaKJ9vCd2RnS4fMjlB/iD0U8lDjtV6B99ArP5sPp17awp1NII8O9LvYGdoPu8lyuSg9cIiSKcaTiy2FZTWcOkRrNWzWxOs84J8icgpwOlqN16nAKhHpD6xyP7ZojwTUNyWvCK76M9y7FUqrWTP2Pd6y+4chzKgklHIEhCsMv3ze4t6pIfAWrZu473uUUp2AC4EJACLSCDQqpcYCF7t3WwK8CyQpcdci6RSPM7xdT1QloZTD8/qX/xJcjVx7+AhLO3UMru5U72L67e3HkmD3wa85JM3zCZ2dTno6nZBTCPlFSexZ28CM4NbxwH5gkVLqdGAdMBk4TkQqAUSkUinVTe9gpdQkYBJAnz4tW1W+LfHpzAsY5qrw27ZbOtPr/m3ex1/PGUH/o83hsCaVRgbO5Mdw0YS+zYm6Hj4Xu+kAT57GS9k2XGgj+2vrXUy/veVXRSaLQIEHOGTXJpt71h3QNlhCHxdxx+SVUsOANcB5IvKxUmoecBj4lYjk++x3SEQ6h2rLisnHhkfgA8O7Is1C7xF4wxBwerYWUkmi0FukLmbH5HdXb+WQI/JFXrm2DPoWxJdN01ZIRvm/ncBOEfnY/fhltPj7XqVUD/covgewz4RzWeigJ/CgRQF6os11hxR4aF6R2AZFfvryjfz94x04RbArxfVnFzHrqkHJ7la7JVqBB6h1NbKt6htL6GMg7olXEdkD7FBKeWbJRgBfACuA8e5t44FX4z2XRYKJc0ViKjJ9+UaeX/MdTvcdq1OE59d8x/TlG5Pcs/ZLtALvodbVaHJP2gdm5cn/CnhBKZUBbAFuRruAlCmlbgW+A6416Vzthk9XPMWgddPIpDlX+gPXAKZkzeTj310ecTtlz/4psjffhBWJieDb0oEcL82ph1tUESeUfh7RsX//WD8//+8f72DWVYMYsXQE+xrcN5kidHM4WLWzUlst+oM/tMk7m2RSfaSVm8zFwfLlyznppJM47bTTgp7btm0bo0eP5vPPI/tcR4MpKZQiskFEholIsYhcJSKHROSgiIwQkf7u30lyS2qdfLriKc5Y91uylNNbJEgpuMC2iTkNMzj7wbe8+661FRtakbuAq7Y/FDpUg9tOIM4ViYnAI/C+78HxsoNvS8N7b1fO6Mt/M65na+YNbM28gQ8zfuF9ziniL/AASrEvLY0RvXto5l7JtuttxZRvKWfkyyMpXlLMyJdHUr6lHOqq2Ndgrl1wY2MjtbW1praZKCyrYQs/ij6bg90gzn6BbRN7jzTfuublZOi24RKoJ4sM5Qh5LhGoVxkpOWr1CLwvHqHXY3zZkwxYcAHFiwdybZ8cLvxeL07vV8Soop6s79DoFXqbwl/gfRrf51lR6WwM65x47gvnMmjJIO1n8UAGLR7IrKfM8U9vrZRvKaf0o1IqaysRhMraSko/KqX8q5doisOvJdfW/DnfvHkzv/nNbzj55JP5+uuvg/a1rIabsWwNUpRusl9b0x8BRpOqCsilIfgJN57R/2GVS15p8hbdLF+/y5Qc+fFlT7Kh9ils6U4EzdXRQ2V6Gr/vWsADVEGVdgGMiBDzFIMWDkPsx5rfe/d/lmYKvD9NS5FMwQtnopn32TwanP6fuwZnA/O+/juP9z4vJqHPtWXQNbMnixYtYuHChYgIN998MxUVFXTs2FH3GI/V8Lx58xg7dizr1q2joKCAE044gbvuuot9+/Z5rYbT09P5xS9+wQsvvMBPf/pTHnzwQQoKCnA6nYwYMYKKigqvEZrHavjPf/4zjzzyCAsWLPA7r8dq+Msvv0QpRXV1Nfn5+YwZM4bRo0fzox/9CIDi4mL+93//l4suuogpU6ZE/Z5EiiXyKco+1ZXu7E/4efod+xv9u+XyVvhdTWf5+l2UrtjEfEcpq22bIBOoB5aDLAeHUlF9QL84vAhXunEtWIfNxv2FBeAOHIqEdBXQMJinKJ7xT6TfMf3jlWJph2ymt9FspXDsqd2jv72him5OJ7vT7EiEI5heHXuRn6llYnfq1Ini4mIWLFjAKacYFGDxQc9qGPBaDa9evdprNQxQX19Pt27acp6ysjKefvppHA4HlZWVfPHFF16R97UaXrZsWdB5fa2GS0pKGD16dNA+elbDb7zxRkTvSbRY4ZoUZccZU3DqjDZFtMnX4zrqh2hi4Zt9LR/TXL5+F9OWbWS+o5QLbJv8Yu6enzQRT/0MP0S0yddAjqWFz9qotymuy39Ma6epo+a0FNi454T2DMN5isPHIigsHsaUra3SPbe7/vacbuQL9HQ4sfv8UY3kPlPEK/AAL7/8Mr169eKHP/wh999/P9u3bw/Zj0ithjds2MCGDRv46quvKC0t9VoNr1q1ioqKCkpKSiKyGh48eDC33XYbaWlpfPLJJ1xzzTUsX76c73//+0F9a0mrYUvkU5Qzx/yMz4b+kQaxe3XHI/CB2TXfdBimK4TfdBiGK9KYTwszZ+VX1Dc5vQKvh0fsj4nN7z3YooqoUp2RGXnen09nXmBYeSqw0fWFWgim9tvf4Qq8iLhPek5Rbxj7hOFIfIxtNSroChF4rrZZfDwck8+YTJY9y29blj2LyUPvgrwi8l0uTmlqYkBjIwMaGzmtsZHcgGIyuS4XJzb5r4QdOXIkS5cuZfXq1eTl5TF27Fguu+wy3cIdkTBixAhefvll9u3T5maqqqrYvn27rtVwOFauXMmGDRtYsGABR48epaamhiuuuILHHnuMDRs2AMZWw4BlNdxeOXPMz2DMz/y2XQh8HLDfSVNWBVkWfNNhGCdNWcW/509g+MFXdFfDfuAakJiOR8Du6nrG2FaH3U8pyMTFzPRfUzp9JgBVOit8h7kquL2qIw91zQtZiAP8Pdo9F5LAkx6xK+NQS0UZs9MXcJmzkCN2u3HMR5xQmmdsEdwK8Cwk+8uV3XHsrKEgN51enYMrHflScnwJoMXm99TuoXtudyafMdm7HdDucqRZ2Ps6dJID7Pp3q126dGHy5MlMnjyZTz75BLs9toupZTWcBCxbg8Tw7/kTOPvgK35j+g9cA/hp0+8A6N8tl/1dfo3TJx/fjp0N4zckrE/nzX6bpXUT6W07ENH+LgHbmbdCn+HIPybq6qoIlHfIYX7nfK0gh4H49mhy8PV/tdqcHU6ZatjW5xMMFkz9oZ+3fuqg7/UOvlKIYBdhw3afSdtWJPR/e/ICFqcf8FbvGnkwl9MveJrj+hwftG+HzDSO79oh+pPUVcGRSi2DSdndgu+jRcqmuZXmJKm6VQqTLKthixTmnDsXY5tZg5pZw8i8V+l37G8hBR7AiZPBSwaHbvj1u2FmgTZanVmgPY6QKaNOpqeKTOBBS3lk7UJ49ZchJ0tHn3o9b+7cTQ+j0I0IQw5ok6nnnRCDgFSU+RXI3rh9pxZf9vkJEngwLtGXYvztyQt4NKvKW3e2Mj2Npd3q6WSr1t3/6DEHW/Yfjf5EOQVw3ADoOQR6FEN+n+aRuz3DEngTscI17Yy37r44aNugJfqCGCj8frx+tya6HsTZ/Hj03LD9uGpIL46+mkkHjoXd179TYZa2u8995+a/M7OwwD90I8KPDh/ltvotzM76Cepob4blp9OAI6imbJoyqCerkzfvFXRl196HlqSiLP4KTD5tLO7dgwabvyw02GwctQsdsnYhYkccnRBnc8jm6LHQ6zAiIqfAEvUEYY3kLWJj3eLotuuQLfqCHUsEUURb+QvA6LmMPvV6ZhyookeTA+UuwvHQ/ipm1NTSSx3QJk1rdrB2dyVZkuY3sZumstkw/hP9E4Xy9/nhX6LveDx4Km7V7AD36+G1O6NbiBXQhlHdWUHcGSFObOmHsGftwpYR+Z2YhTnEEl63RvIWsWE0Yo1iJGtTxh9Yl7hDNJGi4MwZHzQ/7jOc0Z89x+jaMIu8mupZu32LFh6IZBRsVK82u0A7dv3z+qGZwALcZrDqfv+SihC9m2hAGzY0K4xAdtTvoOBIARkdM7ypf8p2DFvGAVyNhRyqa6SzwcprC3MQEQ4ePEhWVlb4nX2wRN4CO3bd0IydEFkLRqGJKNIGRdlQEiwpYrNhG3ozrH2W4ER2g+7kBeTNr7ofXE36O+vhGQVDaIEccV9wvVoPFWXa5OqSMf5Cn6BJV6nZoZsga7Rdl4ALlp7AAzzz3TNMZCJF2UWogNZdTYc5uFPRPS868bGInqysLHr3js5I0BJ5CzaM38DgJYOjy64ZOsE/Ju+7PUJsQ29G1i70kwxxb2f0XOgzHFbdj9TspJpc8uWowaSrCl60FIttcsAoeOLLV7Lm6Fbv08M79OOZH72mPXjjXr8JWOqrmi8SLZRF48RGmo4sO8XG6+t3GVtDeGPwwXckPRxOKtODZeGI8whztwbPtYjA0S9no4Cts0uCnrdIPpbIWwBEny7pmVxdt1gb0Su7JvARTLr6tqEC2lC+bRSPY7nzPKa89B/eSfsVnW1GWRwSPPo2CquEw31x8Aq8z1VlzdGtTHz5Sq4qHMy8wiz22Ivo7nAy+VA1JbV1LV54xSYu3eWiNlzMWfmVvsh7YvB6dyLA5EPVTC8swBFmrUEgPfMNJqotko4l8haxM3pudPsrEyUAACAASURBVKIeQxtzVn5Fk0tCp1sGhmogdFglFG6vmkCBB0Ap1hzdyoYjW2lwO1VWpqdRWqhlhZTU1mkXidfvju/iFyFG/ka7pZDd1QavWy+O70NJbR0iMK1rF+0CEiJfVQSctSeg0FJiLVITK7vGIqUZevgtVmfcaRhjdhn54BePg9NviC5TJz07Ik/9hoAZ4QabjXmdmz1WWLuweb7Ck1pqtIZgyRhtnYHnZ8mYyPr6+t0cx4Gg11cnGfzRMc54ZB3B3c0VtXVs3L6DExob/fL/A3+ctSfQsGMiPxnep30UYW+lmDaSV0rZgbXALhEZrZQqAJYCfYFtwDgRMbdigEWb5tMVTzE7fQE5Sj/V0iXwvPNyfmoUHvnmTWPHAR9xFNyj4isfijnU0myVYHBVWbfYO8fgzWlPz4UDAX7kW9/ThH7IjcH57+AXS1fef9yxccnkd45bect+EQ/rjawrytwHRJbVtHz33hD7KS7Ins+U62KzhbZoOcwM10wGNgOd3I+nAqtEZLZSaqr78b0mns+ijVP02RxdgReBXVLIHx3j6HTWDd7tgb70qxt2hswyec55GTMct5CdbufhqwdxVXGzWA3v0C84ZCNCuoiuH3pYczRx+oePQoyoZet7NG39kAwc3n1dy36GzZ5muBhMKcimiXWdLuf145Zywoob4NWAcNGq+9ETeM8Fb5cURrwKuSGnOx/ee2lE+1okF1PCNUqp3kAJ4OuePxZY4v7/EuAqM85l0X7oJvp++oLigsb5dDrrBmZdNQhoti7eVV2PALuq69ktXQzbVgp+av8XEzp8ogl8wGj0uLSHyK8t9AtPDK+v54EDVWQFOCZmuVxMPqS/7N+PSOcHhGaBd2PDFXa1b5py8eHA1zlh+4v64SKDjCNBqytwfuN8dkth2O65BLLqK6n7wyntugJWa8GskfxjwG8B3xItx4lIJYCIVCqluukdqJSaBEwC6NOnj0ndsWgLGE0s7lOFbD1/lRYC2aCNVp1cTn3TT/32+0PTOP6QsZBsA+sEpaDUMY/lTOK82W977wD6dsnmw2+rGGM7h3npf9YN+czrnO818PJm1yQbZQ+9Etkg48hX2P/oGBccIrOlc8yeS0ZjtZbi6n4/cuorkWUTUeufbzXma75c9OwdHLT5L1zrm3EZr9/waJJ6lBjiHskrpUYD+0RkXSzHi8jT7iLgw7p27RpvdyxaMcvX7+K82W/Tb2o5581+m60F5weV6auXDFSXE4ImN692/ZOZac/67bvCdT5TG28NuUBLkKA7gC5bV7AuY5KhwJfU1vHmzt1UbNvBmzt3p4bAgxaWCbUSuf9IAnMuHfYs/uS6zvt4het8pjbdxi4p1Ko35RXBVX/mUvsidklh0CpkBdo8QhTmdKnAkGeuocr2XlChmu2N/2L03+5KdvdMxYxwzXnAGKXUNuBF4FKl1PPAXqVUDwD3b52qyRbtnooyeHQgUprPmcsvZOjhtxC0rJrTD5b7iYoL2N33ao6r+jSoGaXgJ/a3g7av7XR5WE+Z+qZmYRxjW83s9AV0sRktvIqWEI0Y+KVHfV5lZ2+X4exZuyJ0NtHahQTG5NOG/ISLrvkl+dnp3m0fZF3Cp1e9jyqthrs+h+Jx2l1OqHh9FJ5FyWbm23/Fkf61/p9GwfbGt1g279Q2E4qKO1wjItOAaQBKqYuBe0TkRqXUHGA8MNv9+9V4z2WRosTqhFhRhuPVX5HmbEABvdQBZqcvgCb4bVpZ0KSrDTih+kPD0apdZ/XnJad0heJLYdlE/T4EiKLeeWMmnCvl2Ce036/8PHr3Sh+vnU9XPMXAddPJVo0RF3/3sukVrho9N2yGTM/8bHbXFdLbSOhb2n0zDv6x9ZnQyqcUD3eykfbWPYyBVl+nN5F58rOBy5VS3wCXux9btDE+XfEUjct+7ueE6Hzl9ohGQXVv3Eeas8FvW45q5LdpZfQyEBOp2YFL6X9snTof5+fXfEfZs38y7IMzQBSj8bgPh7icoZ13lk3UDM10/HvC0n+kV3yKPpujCXws1Fdpf6uKMq0Yiidf/w/9/P6GU0adzGP82PhOoRWVOnTZw2dyN9hsPJ6Xq2st3dowVeRF5F0RGe3+/0ERGSEi/d2/q8Idb9G6WL5+Fyesu5+MAHMzuzg49to9hsd9uuIp9pSeSHZdpe7zPdVBQ6MsBL529tStafuRy79azhjbatZlTOLa7cZf1PVn/JHs9GaBiiS7JFKUimBgvfU9sKWH2yuYtQs1MX50IMcZZCFFiiybqF1wArx4ZNlEHKWFUFHGVUN6cf4Pf8Enqlhf6KPwLEo2NmfniPbbk2aPzQMpxbBWvFqExh0zpzRf++0zupuz8is6o+8nk9FUo7vdE1rozn7D2PNu6WL4wVQKTlS79RwHOF41L94JG1tXNhykM+yz3/KF7Tq2Zt7A55m3sMo1OCY/+7hwxREeisWfJwCjC5EC0mjCtWySV+jPLv0AdabPZLayw7BbE2LbkCiu6TeREC7XXro7nF6bi9aMVeNVDzOq7bQGHu4Dx3zEODMPpn3nXVS0oO4OTlG7/EUyPRuunE/Z2h2cu+3PWgEOgxqpvx+ymr9/vAOnCHaluDXvU35b/xhpyjg8UScZTG26zTCzxdO20Tk9C5xWZ9wZsn6soC9uDrHhwEaWMqHaUUDfIplQNepXIs8ZEdkFcO/W8PulMj7f62Wde/BApzQcvmrv82ZluVz8vuoIYy5/pFV890PVeLVEPhA9lz63sLWGP3bEzCwECfZbP2bvyODGBSxTdwcLvJujtk7YnA0hJygPSUeGHHvK+9gzsjY6RkSLqb/gvJQZjlv4LHMSBUr/LiGUeHmE/ib7v6IrOuLDUckiQzmCFiRFgpFI70E/5z8QF+ASW8gLYdK4+pnW+x0I872e+fZfKd/6vzTY6+jucPLzWrj6kpmt5vVaIh8Njw5kYlY9a7KbDZ6G19fz9J7mUeEOex/63LcxGb2LjcA7k4LjDQtLCzC58RcxjaQ9NEoaU5om8arrfO+2cCNrD56RPMDc9L8Yil2oPjjExh4pMDxfuP6LwJouP+Qc51rNUgBQUYzECdi3XjJo7FBEXu234Rsg+EJh5ujeFFpZeAbQQo16oa28Ii1NNEpmvv1X/rH1GVz2Q9icnbmm30RmXHqTCR2NjVAib8XkA7jNI/A+KyTWZGczqXuhd1OR8zu+u39QsrsaGXp1QA0EHrRd5qb/JaSghRL/g64O3BMg8BB51oonu2aF63xecF5qGB9XyrgWrF256KUO4AhxbCiUgpMOvEVZ3s2Qno0tgmO8xwbs6wKqVS6djkYm8J42jB4LsdXANZVQrpqpitEEagwTqzPf/isvbX8USTukfQ7TDvHyd39g0OKBDFo8kEsWnBq+kRakXfvJXz73Xb7ZV+t93L9bLnsKsvV9xH1G9h6hT3kqyqLOwVYK3WpDkR5bL1msCBB40LJWDHOsA+ipDgIwwrYhppiyx53RLlDvspOlnFG3U6COctn2uaCi9KMPwAZ0l0PmxMZLazh+ajlX2laHvNNqEdY+27pG80ZFZGKYWP3H1mdQaQGhTp8/xoE0O8OeHcDaWzZF3XYiaLcj+UCBB4Iet2o8I/gWXqTSSx1gS+YNrM64kzG21d7tf3SMo078V3gGWhZ48BiLhRv9RzIiz1LNr788N4eRvXtS3LeIkb17Up6bE/JYo8yhZNIzP1v3ItryJPt2IkpG3KfF4H2JsH5AIGHz7JXimE0x6/UJUbedCNqtyLcpQdcjTAWgRKGUZmDV23aAuelP8m3mT9iaeQNz0//CWld/droKcYlip6uQvzovCxJ+T9GLmWnPmhKH9oTYynNzKC0soDI9DVHKW9EpnNCbgWkj7pkFPHfcUr+8fosIKR6nTbLmFYHHkyfGZIqI8uyV4qUDKZApSDsP1+hxVn09n2QHhGzcNrOtCakJ7aUeVVvuQVu0YpXmk56WhosLbJu8KY4e1rlO4rdpZfRUB9ktXfijYxxDbV/zU/u/TA1HzOucT0NA3VJPRadYDcZMTVGM6IROTtj+Iu922wYHW/C8emTkJrkDMVA8zpRsmWv6TeSl7Y+ibMHZab6kSn5UuxT5j2acx9bM5hn1D1wD+GnT75iZ9iw/3XOASd0Lg7JrntnbHDoQgVpbBzq0aK8jZ/n6XZwpXQytAWLBDDFTCm60r/IT+RWu81nR6B9+eDQB8ebmyk2RbY+EZMXEjzu4JqHti37quD+jH0toH1KZGZfeBG9rsXmxu1cJ67xRqRImaXci/9GM8ziHz/3+JhfYNvFc+oOca9uMUvgJOmgf+tdzc5hf0OwhPqGpkBtITeas/IqhTTq+4DFippjZwsRyx9hWJ+TL0d3hpDI9+OMetqJTCpLolMqwf+9ht2q/Hx2YGgsGk7B4ccalNzEDLWVy2LMDOBaYgiXCtYW6GY0tTrsT+UCBB+1v817XXfyqUy9caFfgaw8fYXqVVu2nvEMOMwsLvLf7lelpPGqvgicv4IbbP2jZFxABu6vr2cX50BQ61zwV+W1aWUJGyJMPVVPq8zeEKCo6pRhJz5nvMzy4lOFrd2r/b2mhD1zkFGdfrlx0OdtUs6dSX+nBaze/FfKYtbdsYtbrE3jpwNpm/SgcxvTRi6M+fyJod4uhZEZekIjMKshnaaeOQVfi69xCP7J3T91RYI8mB2/etjmh/Y2FwTPfpLpeixduybwh5pWficC3Pqtelkgi+1uem5OaFZ1aE3lF2m+9dERl1xw1W3JkH+Uip8GLBuD0+Z7bRdhws5bq6BX4AB3o06Qon5jaix9DLYZqdyN5PcoCBR5AKco6dWR6VXVC4rmJxPNSxthW48Km1QdNEZSC3uoAj6Q/De55K23i9QC7pZBD0oEuBnYG8VJSWxeTqMc68RzLeaI5R4tP/HpSDg29+d2hr5Yc2UexyMkr8D5vmtO9fcPNm4IFHkApvksXypdcQsn4d0zseMuRKnMDLca/GRhsU2uwr6CN/ozitqkaz62ua/J6xaRCqEbvZjFDOXgofSGPpD9Nb9sBb9plnqpL/opOHVpCTKM9hyg0P5mWoqneWOD19m0JL3ajxUw62wMFHgCl/Eb2uijFvKY9MXYw+bQ7kT935odeoff8GKIU8zrnc+eharJc/mKZ5XIxock873Ez6ZmfbW6FowSRyzEyAtweU+GiFEhSV5aGwAaRi24yqNlB+ZZyRr48kuIlxYx8eSTlW8rNPYdJi5yKFw8M+Xyq3rVHQtzhGqVUEfAc0B0tNfRpEZmnlCoAlgJ9gW3AOBEJX5KlBTh35oeAlmo4bdlG0jAucLEnzc7oU6/n8I5PWZx+wD+7JgUnXUGr4tNruXnpk/FiJJKpKp6JpMVDLEmkPDeH0vfupcE9yVJZW0npR6UAlBxfYs5JPOGgENk11y44hy/Tjhi3oVTz3bzBH0jvrv2iZ+/goO19PPlOXVwX8t4tj8f8UhJF3BOv7iLdPUTkM6VUR2AdcBUwAagSkdlKqalAZxG5N1RbyXChXL5+F39afznVdv0rdapOroakogxZNjH5WRgx0p6EsC1zQZ9eut+rHrk9ePNHbyb8/Hc8fQnvZbjtneOZ7HA/7pHbg8lnTKbk+BK3wL8XtFsX10V+Qj9rzSzKvipD3JeRbHs2M86dYd5Fzk2LWg0rpV4FHnf/XCwile4LwbsicnKoY5NlNbxsThH3d80Lis2luVxMq2pi3G++bvE+xYVBxkFrEc96l51M5TQ9y6Y8N4fZXTpT7U6jzHO6mFZ1yMqwiYBIM5M8+1V6whs6HziFomJ8RUL76xX4UJapYFh9pofDqf8aRLju8FFe6tQBl86xIorPJ2ivbdaaWSz9amnI04Oib8YIXr/h0QhelTEtJvJKqb7A+8BA4DsRyfd57pCIBJk+KKUmAZMA+vTpM3T79u2m9Scals0p4tEuHf0E4M5qR+sTeNBK9aW4gZSRaDSJQrAHxerNON/vu3ahSedCPutAVbsUeqNFVYHbPb4/gWsMSgPeN7399GiJkXzx4oFIjCMam4j3PdAT8lAXCM9AyqZsiIh3BB8KEeibcVlcQt8iKZRKqQ7AP4Bfi8hhFeEbLCJPA0+DNpI3qz/RcvWUHVydrJObjZGtaooQKAYeszCXwCW1TjqoY6afc17n/CCBB3BE4F8z8bjQNhdtnUh9f/T202PyGZNN72MgMQuJiFfYDdsIoW2ep1wSeQKBUrCtcVXE+0eLKdk1Sql0NIF/QUSWuTfvdYdpPHH7fWacyyIC9DIOUggj0fjfgnxyMV/gIXR2RKjnvAIfUERm4nHRZVYlOi00puZD5Q77EOk6kYgyUJw5psejTSOp8Uxh4OJBDFw8iEHPXGZqy3GLvNKG7AuBzSLiW0VgBTDe/f/xwKvxnssiQvxsVVOPUKKRqO9YqDUNoZ5bE+hICkFFZCIhkdohEpvVgd6dDRDUWKTrRMKtG8l0CVMOHEJK85AZeUhpHq6ZnVOnylSsf6SwudiRndrzI+l7TRV6M0by5wE3AZcqpTa4f64AZgOXK6W+AS53P7aIkRufHOQtLzZo8UBufbK/5tthRPE4bVn31c+k3Kg+GYvLJh+qJl3ni5jWSv1rfIlVm9KR4IWBOlo12WCdSOD7prefRwB7NDm4b38VP63b6y2RqACbuJAElBPMM6pIkwDynC5TFxx5hN4s4u6biKwWESUixSIy2P3zfyJyUERGiEh/9+8qMzrcHrnxyUH8J1v8LvefZGdy64f/E1rowTuqN7wzT8IsSKSiYSYltXU8sP8g+U6nV3jyHM52O+kKwfVooVl8fSmpraP0QBU9mhwot2AHTroa7Td7/0E2btvByh27GVOnX6hHAaxbbNKr0hjXcRTpgUKfoA+7UpqhYUztt8AX0PKuaQV4Bd4XpfgkO0tbBBKJP0gIf9qWDkV6xKGlzcJi8a4ZXl8fHLKJsohMazBGC9fHSN87o/3Cfr5MLlN557Vz4aW7ebVmJfvTFF0dQpH9VNbKf1E2c89VY7N5HWuDjA590cu/b4HVLJbIt3YiqTa/6n5TVp16PpNmfCxjNQtraZ7ZeyCu7BqjTCIgZV5/SvRRmW8bcOe1c7kzYNugZ88GzH1Nee670ulV1bzUqaOxHaDny+YevfdoVFSq45D0vcFrr5qOM61/lsi3diKpNh/JhSASFImvWJGCxJMumYiyg2aT7D4KoIZOSPh5AMRWZ/rH96hSlOfm8IOjdfQ63JfvOm0PPXhSCkR4c5JmXzzomcv8YvCq6Tg2TvyXaf2zRL4VcHq9Cg7ZiHBWfQOMeCh8AyblzSvvP+2XaFfNtgab6mT2UQS29P0xJ4yeG35nE7A5OyNp5lpoedZa/OBoHZMueIoFmx9x570LivCxUDMFXY9250IZDx5HvUFLBnH6c6czaMmgxDjrBfD87Rs5vV41p2qJcFb9MRae91Bk8fgwefOpaO2bSpTn5jCyd08G9S1iatcumh+LewK8Js3O9MICynNzdI9tDTbVZvRRL0uneZPSSgbaM/z2aSSNtUP/yAk3PxV5Z+Pkmn4TEVe63zYzPv+VaXZO71fE9P98n6POSj6fUMHnE1Kj0Ei7qwwVK+Vbypm+ejoO0V9uP7z7cJ4Z1YLe3tFSUQZv3IvUV/kNxp0qnXqXLSGrTNsCES/Vb3Lw5s7dER2vZwmQTKLpo0ct9MamLp98/aDBa+EpcOFvWrwWqx4z3/4r/9j6DC77IWzOzuTYjqNWbdY1JYsFESi0D+Ddm15k+DPF1Ka7gtrObbKxZqJ5/j0talAWD6ks8ucvGkRNmPuelBd60C167PrHRF0zsNZiaJZIjEo/BqJEqNimHxJrC9k1gLa4zuPT/srPo8+IufqZ5BX7DsGABRdgSzc3fVcE70jeK/RuzBZ4sMr/xc/jZ1PTIfyM45o9ayjfUp66y7ZB+5IFfNF2vzyN3ip4cvEQHShQ9aant7UmIo1LhwpttIZMorB9LK1p/n9FGSLO6KdnIk33bWFUmoHAhxnlRFoW0mxBjxYrJh8JB76MeNd5n81LYEcSwyPO66gT/3hpnWRwv2M8DJ0QlS9KRBW3WhGRxKXbwqrZsFSUaXNSfzuf4s/uZ1TvnobzEIaYleVlMuLI192e53QZfpBF4No+v01kt0zDEnmT2VPb+mpBdjjzeqY23cZRyfIKdCaN3JLzIfVrnzeMv+rh68HRFgi1VL89rZot/+B+Sj8qpbKpBlHKm0sfldBHku6bBIZ1uiF4MtaVzgkdf4VyFugeY3N2ZsalN1FoH6A76VxoH5Co7kaNJfIm0z23e7K7EDWzrhrE9d0ryaXBK9B2BYMaN5Ct4wrpEBurXQMMhb6l8WS/FPctYmQsI8wQhFqqv3HbDlbv2NXmBR5gXqaTBmeD3zZPLn0kCGhpvA/11OodPDowvCVHC7Fk3O0MzZ2IqykfEXA15TM0dyJLxt2un43jSueaflpt3XdvetEr9J4fz6RrqmBNvEbC42dzVcYhvs3ICDlEzbJnUXpuaWrH5I2YWRBx7D3SWCTArIJ87ypAG5rHh2cJuBm0huyVtkBx3yLdIhyhJpwjIj0XrnwsJWP1HgKzca7pN5EZl96U7G75YWXXmMHjZzOoQ61BuTDo0aG5/mOrpDTP9CZnFeQHe3m4fV+2p2eYkm1ilP1ilNJoYZxJYzTPKAKjTjyJSldD0HOe9zmuDCJ7Box9IqWFPtWxsmvM4I6PGb5yImv2rAl6aniP1E+drHjwIgY1bvA+3pgxmOLfvde8g7KbnkXzkp5Zk8eL3b09Xp+UVF5Rmui7mFiIyadGweSqako7ZQTdMU0+VB2/942zMWUzb9oCVkw+Cp4Z9QzDuw/329YacuM9Au87KTqocQMVD17UvFMCvEPCGjW5iSa2G0iqrij13MW43G+4SymWdurIrILYXmd5bg4X9OnFoL5FDOpbxPlFvWKaewjlUxOKkkP7DO2GY23TjxTNvGkLWCP5KEl1QdfDI/C+eITei8c7ZO1C085rI4TQBxDryHvyoWrdmHwyUhp9QxYCuncxL3XqGPVovjw3h//p2sWvqLTHTgGiuwMKd+cT5IYLKFsGuBoNc+lNuZtK0cybtkDCR/JKqe8rpb5SSv1XKTU10edrk1SUadkIic5KGD0XMx3IdAspGMwBxTryjrSgRaLxhCwq09O0CUqDWenIyzs383BBZz+B9+AIGC3PKsjndPdI//S+Rbp3DeHufAJX9tdndANXU8j+mXI3VbNDm/z3VIhqqc98OyChI3mllB14Aq38307gU6XUChH5IpHnTXXqHupPduM+r21vfUY3cv7nm+AdH+4Dx2r8t9XsgNfcLtmJiGGa5FgJeEesvnHps+rr2ZCVZerIOxVWlOqFLPSIZVRVYzc+yjNaDpzkduEuYAF+dw7R3PkoBdmN+2iy55DuNH5/I24z3LyPOLU7yYP/hZ2fQJO7MEuiP/NtnESHa84C/isiWwCUUi8CY4H2J/JLxsDW9xDA6xrsHjVlH9uHlOY1j6H7XQS7NwQLvIemes07BCL60G/MGBwUshGBRmUnszTf3yyq/0hY+yxEtc7VmOlV1UHhidbg5RItEYUmRLS7GxPxjJaNJrkDw0PRVuVSgD2EwEfcZnoupGVCfQRVQLe+F7ytqd6anI2RRIt8L8B3WLgTONt3B6XUJGASQJ8+fRLcnSThFnjQ92QPuhPX+5AHIs6IRzfFv3svKLvGpSAT96jKM1L6bg2s/ytmCTzo23+kwsjbbLo7nPpGZu7wVDzZNfkul2ZvrNO2Z7RsFAbS2x7t+68iKBQTts2mWu0nHnQmZ5ev38WclV+xu7qenvnZTBl1MlcN6RXfedoYiY7J6300/BRERJ4WkWEiMqxr164J7k6SiES0Y8EzuomA4t+9h5pZo/3kFxEkGU31sG6Rls5mIm3F3iAcRsXJPatj/7NtR8zpk1MPHiJdZ27jusNHvMJq9EU25QseZYnIJrt5K479CJicXb5+F9OWbWRXdT0C7KquZ9qyjSxfvysx52+lJHokvxMo8nncG7BWqLgxJWwRS+qZ0TESy7SgBSS2OHkkbV97+IjuwjMzwkPRXKfrc3qQc6/b0C+KVdQeBHDZMrAj/hO+6dnNNsdu5qz8ivqm5vbH2FbzmO3PqFeBV31fgF1LEW6h6lOpRqJF/lOgv1KqH7AL+DFwQ4LP2SowrXhyLKlnJk6uWjSTyDCUb9uewcG0rl28gq83yd3Si68EyKmv1MR96ISoBN4T1lOA3dXoX0o4uwB+8IegsOTDtdO5IHOT3/n16iJ4J3ShXQp9QkVeRBxKqTuAlYAdeFZENoU5rO3R76KgkI0pxZN1RjcRMeI+LQbvyV7wtOVobNfe8WaQ6EnlUIMDvUnulsSrr76iGumxgfNUvg8c9QTx+NlcYP/Sb7+wdxxrF0Kf4e1u8tbyrmkpArxhojJ88hRsCKzq1H8kfPNmbOXUAtsqOF537sDXjCxWAWsvFaZawiyt3Xr15BXBXZ9r/68og2UTY2pGULgQbAJOZWP798a1aI3ZRGF51xhw6YJT2e+T+tbV4eTt2za3yLmNsjGCFpD087Ee8K3qVFHmPxqPNpc4sELUTH3fbKXgiCuTdzqk8UBh5/jDS20YU+7OwpDKXj0JpWaHtiiqZieo2KeTFaIlHShIw8Xx217k20W0CaE3ol1615S/+3sGLRqgCbyPocv+NDuXLjg1MSctPMXvoVE2hiclTsSd/jZ+hX57q+73D7dAVNk2QYQI0+SqRqblnxCzP0l7GMUDVLaAALekV0/x93p7vXIG9S2i+HvJtB5Q7nkkMTWkqBR8b3vbXk3b7kS+/N3fU7r1FbDZdBeP7E/UiOiOj71CL8AVtXXM2G+8HN8zCWWIUYZMrEZPyvh175YuhoWO96TZk17yL5FFQ6LpgxFmCnC4wYFZFH+vd7M9g/tHvaaf4wAAIABJREFUlEqi0Cfuw2Vv41ll7S5cM2/LKzTYkzS0vONjoFm8R7t/ZEae/mg31OfaKEMmVqOnoRN0J8uaRPGODKG7YxN7DMJLnr57hL4lR+6mZSnFcf55nfO1UbyBGbuZApzIVE1fdP13lEqg1CYPp7K1aSFsdyP5Pan4io1EMZRYjrhPy4jxJdZsm9fvhnWLEbTrikesG12KB9MnM8K+nl9HMIJMRm1XU2xuY8TXlCzUCzdbgEtq63hz524qtu3gzZ27rTmROBCB7d9r29k2bfkC5uVAaT+6iOaZ0b1IPzsBABG6JsGHXNz/BHrLSKiQjWfS1DdDJprsGg+v3+0dwXvP5f5POsJNvfbQfdsBStwr0lPNcyaZE5GRmJL1SLKvfWvB8x3wfPZaYqwgwJa+P27Tk67QDkT+H3/szVO9O7InrYjuDicX1tXxascO/l9On2DyJXV1mteMe8Jz/kt382rNSvanKbo6hLF5o7jzWnMXVNhKa3B5UizdH3RR2vaQBGbIxMK6xYZPeSal9qmudGd/SnrORJylFAPhUkbDXUiS5WtvBkok2BNfBJWgiRc9T6fgnezaquy83tBYG5nZWZhztnWBhzaeJz9z7vd5vfOOoLzlsUeO8lrHDtTpxRdE6Oh08lFaf+bnnMhfj64MOv6mDuYLfdIIU9tVBNYO/SMD100nWzX6bU+FrJlE5aZH0q5Rzjoi9EiRO5148E6+ulEiVGxPUgWn9Gy4cr5/CnGMufJ+hBtItRLabZ78h52202Dzf4kNNhvv5+ToCzyAUhyx27nq2JccafqWhvTgeO+rNSu5M5Edb0nCeHw7lY0zbV/hUo3eW2pRBsvHk0CiJiKNYv1Tu3ZhXud8Lqyr0z5DAVc7sxc/JZNIBL1FLvZ5RcGhSM//l/0ciPGurUOPuLvWGmjTIh9zvFYpvs3IMLx73J+WIgpnBgZZNaB9gWs79CNv7cLmGfpwqZ2eY2mZuCokxjPG8DOiFJXpabpmYPkuF1MPHmoTAh8JniBAoNCba+2gmle6BhJqcWA4MvPgni9j7FPrIhVzTUwj3oUjXR36oSyj7a2S0XNh2K2g7H7ZNQ5sbOn7Y/LqtsXUbKwCnyrRw7CfEZ30wmyXtBuBB78Uei+BZRA9Ka0xr12INCW4eJwWzskrApT2++pntHDM1c8Eb5/2XWz9aYW06ZH8eYe/pxuT/1nVEWZ2yw+b8zs2b5RuTH5s3qgE9ThJjJ4Lo+f6CXMacAJA6Yst1o1UifODfkm7cLR5a4EIiNXawTO48AsDRpsSbJSIYEaCQiumTY/kZ9z9TwY2NOK7JHNgQyPX/HYnP6x1Gg8bRTi+sZFffb7Qb1Vqt6Y2NukaCYYrYZVmAWvmqVJE4KG5QLgtiluLRFgLtDZiCpEqO2rYrdiuCRhx+060WsRMmx7Jz3ryNNZmZ/qpx9rsTGY9eRozf7mZlQsHUGsnKLZqF2H5rr0oBaPr6hhdV6dVrlcZ5NxmjsDPevI0lmY3X2MV8MPD9Qzo8AvG3fIbU85hCkYx+2G3aA6YcaaxpTIltXVM69pF/0mdCdfWmi5pJlGltGYXwL1b/bdZom46bXok/1K2vj/NS25xXXPrJnJVbz/vlVzVm/XbduodRraYUxrPK/ABviDLOmXzguMpyp79kynniZqKMs3przRf+11R5hezB7Tfw27Vtsfqk9OKMBqd57j9hvR8h9ozUXnr1B8K3vb63Zojamle88/MAm27RUy0iZH85XPf5Zt9zUWC+3fL5a27L46ouPGa8f8Mel5mhM4dj5elehcfAKXYkpFBxeG/MI4WHs2Hsi52x+yDCFdhStlafUlBvdh8lsvFfZao6xJVSmvgpKrP6ms/PEVI/vMiNNXFvrq7nRLXSF4pNUcp9aVSqkIp9YpSKt/nuWlKqf8qpb5SSiVspvLyue/yK8f1nHTiPXQ65V5OOvEefuW4nsvnvpvY4saJQilWdMps+fPGYl0cblLsh0/5x1jj8AE3m0idKz2xeWvUHjkltXWs3LGbd7ccYOWOEN46gZ+fEKuvAWiqBaR5AFLRti2CzSLeb91bwEARKQa+BqYBKKVOQ6vnOgD4PvBnpUJ42cbBrxzX80BX/5StB7oW8CvH9Vxb7wqeXBXRtoegXmXoHUa9yjC59/qYkUW4fP0uzpv9Nv2mlnPe7LfDV7CPxbq4eFxIi2K+W6PlOJdWa79TZFQfbZpfNIZgqWB73OIoO3u7DPf7zigFWcrJl9JL//M87NbgkXg0PvHx1E5oZ8Ql8iLypog43A/XAJ77r7HAiyJyTES2Av8FzornXEY8XqCfsvV4QT7Tb/+C6+pdWoaECDYRrqt3Mf32L0K2mVO63yv0np96lUFO6f5EvATTWb5+F9OWbWRXdT0C7KquZ9qyjaGF3igfOVye8g//YjxCX7vQP5aamOt81CTKudL0HPHWwtAJyMFvgyKQOaqRjhzj142/CM5Th+bYuyfmHu3nox3MCZmBmTH5W4Cl7v/3QhN9Dzvd24JQSk0CJgH06dMn6pMaVePxbJ9++xdMj7pVggTd3K9p6FzBrDhXBM1Z+RX1Tf6jovomJ3NWfsVVQ3T/DMbFvcOFZLzLyw18RNYthtFz+XTFU5wmaeSIM+mpkolyrmyJ8n8ph3sSvtunC3U/1j3VQdZ2uhzuethraR30WfHE3AtPgQNRrEKNtXZCOyPsSF4p9S+l1Oc6P2N99vkd4ABe8GzSaUpXuUTkaREZJiLDunbtGstraHVcd8p1hjEZ5XJR2u/quNrfXa2/tNtoO6C/YjDSPOVQ+4iTT1c8xZB195LLMb8CI8kiUSX02lv9VQc2lvfSEgT2Kf3v7m7pwpRRJzdPqoYKyRz8RrtoREKstRPaIWFH8iJyWajnlVLj0QocjZBmS8udQJHPbr2BNlxKPjqmD9fuLV76cikuH7Xv4XAyuaaOkpsfiKv9nvnZ7NIR9J752Tp7+xDPykAjozNl57TPfk+a8lf1ZI7mjTJm4s1zT6TtcSpiFxe1r0zGtWIVx+EKWrFcJxl81PcXjBvSC1YsDt+gOLUsrrXPYjQK8tRZsFkLpSImrnCNUur7wL3ARSLiez+6AvibUmou0BPoD3wSz7mMsIFuqmTq5HHoM334dKa/9Tg4dUbXD/eJyFtj7NOnsiWjeZR4fKOTVydtZsqok5m2bKNfyCY73a6NqBKF0aKpoRPIMbiVDxSFlrI1SJRzpa4VgggX1rXRUA1wg3oL7/VbNRf/2Ku6smPoFMaN+Zn2XCSTqp6YvEFqrgjU2jrQYUaYJAILP+KNyT8OZAJvKe3buUZEfi4im5RSZcAXaGGcX4qYWGLdhytqFa/nBqvFFbUptEZej4oyfYEHOBbe49or8D6ve0uGnbFPn8qrkzYDWmx+d3U9PfOzmTLqZON4vBl48uj1RmGhyhvmFTV/oRP8JzPXHTGYkto61mdm+DtUKsWrHTsw5FhjROdKdB896F1Qo3UO1V3q4f6n+9UP0d13pB3G0hrQBgpgOD+krpxPB2v0HjVxibyInBjiuQeBB+NpPxIe/uVGeGIQ/5cruNBG8FfUKm17KhNn+legwAPuxVTaaOiqIb0SK+qGBAi8gY2xhoL+I4PLDyaAlir4/X5OTtDfJZLJ1/LcHB4u6EyNvXmhXEsXJTf1/fcspPOIcghLa5Rde94zUDCrtKUF0MYrQ6U0pfmEzIgPU7Fm0OKB+kMpETZOMPDfTjQzC3RHay5A6YRm9hUO57iqT6PLj44RoypOPZocvLnTvOmi4r5FftWUvIhw3eEjTK8KjvvrVaFKZB9bzO0zr8jfC96TXSPOYGG3iIt2WxkqpQllCZCZWFuFhGEg1grdmw7k4LfEXNUnSloq88Vo8hWltDAO+Al9eW4O/9O1C64QqmtWH8Udj2mxSe/Az7eRPYZFQkn1+cm2y4j7tDSwQOzZEU26Ht+oY5Usom1PFkaLWQxuWLrJgYgXwMS7kjTStMl4b2z1DLq8KMVLbqGH5hF8KIHX62M8pPhMlUUCsEQ+WRhVsvn9nogOf3XS5mahd/94smuShmfiLIA6laW7vTGSyTjMWUkaiTuiGWEMj9eN0dXCtwd6i6cCaQ0WxqkT8LXQwwrXhOHchadxxN78RezodPHRraFtESImzoo1SRV0PTy34r5x1y79yT7wZZCAOgUylUO3mcAsDzNWkkaSNhko8KEyXUI9V1Jbp4VgdPrh+yrChWGUSELN0MzK5DG8LkZwl7Z8/S5vFliHk6eC73oKpdg4PsUTKFoBlsiHwCvwPt/+I3Yb5y48zTyhD+D3i37BR8732J+m6OoQzrVfxAM3/zkh50oIvnFX9ypHG3iVQEQb2eeoBkNx2OUqpLftgPdxqHi6Jy87khF4NAW/Q2XjAGEzda49fOT/2zvz+Kjqc/+/n5kkECIEAsFESCtS9bYFr4ILWtFr3VpjFb2I0tevFfeqLVFbFTU0weVVilUbeu+1uCD2Xrdoi3LNtaL9eXlZVwQt4K6gAgZZQhZDtpl57h/nzGSWM0tmJ3zfr9e8MvOdM+d8850zz/me53m+n8ex2Pd57R2Bl1H992F9Tgeq8IpOYlrBJxR4u7OTbRTlzs6PX2Opq8/LcL+BDxuvyQ99l/VT60xmTQoYd00Mwg08ACJ0uF146kahdaV46kbx2uI5aTne/Ieu4q+sYnuhCxVhe6GLv7KK+Q9dlfrOnQqCZBoH6VgRKJG+mL7hB4r+H3u0X/Ezmk9asbJZDptQxcnjK1Prq43f9z+vfHTUu4dEBM5qW1o5v70jVBwvLLsmpv+eNK+UFdh5TiMFZ/8BSqsyJtJmHSuosEwMQjSWwg089BfVMbLCKWFm8klyRlVF4PZ22q7lvLYYjp27LKV9vupdRXdh5A/v1b5VKe03VkGQ1Z/tpmrtnYzVHWyXcjZPuZ6j/KsUUyWavz2OH/6GwicY2teLR1248TG3pZUF5ZErSYONwvaCAk4eX8nftjQn3d14qYwQ28US/l5tS2uIUbccERJ45p8xh+fHQ/p98QL2ugnLRbht2aSE/ocBEZ4yGYeYWkrB+GWFzWw+KYyRT4ag4B9YP9ajdj2T8m53FDjPb8Pbg/2Y4atZj3vw23S4+3+ow71eXm13OxYEaV/+Syb5uimWXmuVIjsoXVPLakiPoY+hZ8OBx8Mm54vXsK5mEHDhw6vwgz1dyM6WgP9YwXHWt70gtdM5kUCof3adlEaNEupzpt+FlPGVrkUl1sXeXmBUUVVJs8N4JX33kIRgWDSNJUeMrHDSGHdNDIZ7HYqOBBF8e+t2CLM9sPg4Tnvg2xy2bBKnPfBtHlh8XMzjlXucjxXc7vdjTm1/gZeL5vJy1zkc9fQJrF6xpN/AB9WO7XC7OW6E8w93uK/dMvBBFEsvVWvvjNnPhInmk506By5cARNODHsj8iLnFihAQwp3ZIp4s1j/7HpAdUyDiBU3GEhhkqQYUWXdvbVtBpSaluj/w4DTVQeiWBrE9acfSnGhPeYqjinBgTYjK5w0xsjH4NVL3us39FGMvd8weMOG8oHFx7FkeFtI2t+S4W0xDf1x7hMdf3jHufuNYf2KdznVu4qFhQ8w3rUTl8A42ck/r7m538AHYxv6yQPILx+rO+NukxCxioCDZejr26zU0dIqcp2MF3UWG1b2z6kkYN2OPC8JuPODkLu5wP/gCS1rCCSeruoqtL67azck5UqZccQ4fnPuZMaNLObrDxf2G/qgx/rPtxhZ4RQx7po4+LNoTnvg21Fv0VVh9eizOTaovXHYbrpdodt3u1w0DtvNpWH7+E3DGbxUsoltBW5KfUqRx0eHOzK75um3t9La1Udd0Z8YFjYDL4qSjgiEaKHU2i6mk7720KVFjJavIzbfLmOoiL63gRFvlWN4vCABxno8lmsmLBNjbIqBymgSxE5pjMGZOlmTCUgzgf/hyEsCujKnjT8gsXTVwhL40e9T9pOHaixVW38CbqWt1sXf6NakhDHyCfLTjkIaRnqjapCHB13jLaO//f5/5slCr+XkKQXE+ipa3W6G+nzMbvsGN9X8T8hn71j1CGO+9RQnFYyiwjMixG97e1liWREel4vflI3i+d1WzZeFhQ+EXDC6tIjNU69Pn5GPh1MB8Xgf+aqVk785ge3e/gvU2OL9+dv7qekeOeXSn7BnDw2jRnJT+WhnX7mrCLy9jvvbq4z/kZfAmmXx5R+yYXRTXD9iCMUIlA2AZxdVsrgsMjimCrIgVFAs2sy/ss/DCVrEE4XemBagss/Dykv7Fzs1bWzixlXzEVdfoM0/ywSYVz46cYtif+eiyhVtP+ZfWx9irO5ku4xJb3ZNIsQTagPLkA7fP74i4YJRUYqF+8dlYOe6U7aN08y+WwsYGutOKlMUlkBfZ+r7ETfUWedRrPN25dELjPHNU4xAWZqYtmco1Z1fRqgp7pIyxoRtO2vPKJYMb4swELP2jOIPI9rjGuTwGVXD2oYQAw9hec0DmTLa2yqwpPRRrr7mEwAq7EdWiSXUBoALZvy7ZVwePsvKyPnLZaF1Qv3ZOo4GHst37HOebcci0ZW2Q8STm1l7Ogw8WBlQC8pg6hxqCiuo922PvGP1FBsDv5diAq8DYEz9JnZJWUhsaJeUMaZ+U8S2l859lSs6SkOCc+dvL+al4rscl7uHEx4E3NbprGmzrcCdfG6ziLMsbjZxFGqz+1RaBecuCTXwTqg3+nu4oxp4xTmhw0+iypVOKpv5SYxO2sW0q0cfQb1rbMh5W7+rneptG7O3iM6QVtIykxeRXwF3AuWqVmqGiNwEXIKlJTtXVZ9Px7FyTbhBD5/BB/NS8V189Il1G9wOfASwu4XSf3IuWehnqM/HSZ0TQtoqSipo7oxc6BMrb3uvINECEVGNeDy83F42kidHDA8UlTnPXnnqxUWBhH4TwcY6VzVbM5YzP+ZQK8smFmuWUV3XYoVAYyyic5zVB+XhUzreKgjz9n+GxiwmnGhlVe3jNG1somFtA9s6t1FRUkHNlBqqD6rOyLFStgwiUgWcCnwR1PYd4ALgu1g1Xl8UkUMyVQIwX2h6ajYL2/9Bq/9WtxDGH+zjil09zG9ZHNjulHZl5Qgiq2hgFfM+qXNCRNC1ZkoNdatupMflvCpyQD75fCODgbbby0aGaMj4IKDrfvOu1piT20wV/I5FRjVldn0cCLAmtBrZKSgebfXpukZY/rP+z7dtdq4EtWmVdVe2Dxv6po1N1L9aT7e3G4DmzmbqX60HyIihT4e75h7gBkKjWmcDj6tqj6puAj4Bjk7DsfKWpqdmc8vX62kNW4zUVuBmUXkxt5VZM6AFBUv57a4vmRWua9LnZv2cDay89P0IAw/Wlx+emx2ct31+e0d8MXQH34TkUeA9EzwZLhIGAV33LzXWfRiO+fCZVIWE2HGAlFGvlc5a1xJdITK4PdoqU6f2/74m8QpfSd+VDQ4a1jYEDLyfbm83DWsbMnK8lGbyInIWsFVV/yGhP6RxwOtBr7fYbU77uBy4HOAb3/hGKt3JKk/Wz+IcfQE3Pry4WPjNSrzuKD8cl7BobDFnDLmFn7ZsQgTmt7Qyv6UVVdh44AVMvGxJ3GOeWVDGmVucg5S1La0c0dMbfUbvsKBLVFn35S5rFpbvQbUJJ6KbVg246EU0t5gPWOSZFZFCGh5AHYhyZTrIVgUrps5B33owZDwVkOBVytGC4vbq08vuPZjXi4dYbePKKNRR3Jbhi+BgIGp8LUp7qsSdyYvIiyKyweFxNnAL4LQUzem36DhlVNX7VPVIVT2yvLx8YL3PEU/Wz2KmPk+B+BCBAvH1u2iiIcLLpR7uGD0yvJlvfp5gMCvOqr/qzj0s3LGLgnBlQ1sBcf3nW1j/2ebAY93nW/pvv20al97F1rqJ+OpK2Vo3kcaldyXWtwzzWltZUgtio30rLmCF73jm9V3KFt8YfCp0MsTxzE21KtVASLSCVarUei7iT55T8KgLVfCoiz95TqHWc1H/Rk5BcXv1acDAB9219rlc3FQ+OqPjMxioKHHOYYvWnipxjbyqnqKqk8IfwEZgAvAPEfkMGA+sFZEKrJl7VdBuxgPpq0ScY87RF5Jzf4eVf/Pjjpb6F85hs6C4LOYm1Z17uD3MxbBwxy7HAtIB7NvvxqV3cebnCxkn/XIJMz+/NW1SysmyesUSjtm1PKkxP8/JjaXKjHbL17zCdzzH9y5mYs8jlIgnwsY3lQxjfvnokGX+81MxZHG+v2R1cRLm2esAeOyNzdR5LuZbPf/FhJ5H+VbPf1HnuZjH3giauTtVL7M1agIGPgwVie9aitAs2reomVLDUHdotbSh7qHUTKnJyPGSdteo6npgrP+1beiPVNWdIrICeFRE7sYKvB4MvJliX/MGJzGyUq+PtgRuqZ3MuVdciX8RP/xthAxAyi4G+/b7e5//R4RcgkvgmF3LYd0ZOXPpVK29E1eSMWX/xS04u2Zmewc7tv04ZLsDRhZDd+RseeHoUfSFGbM+ERaOHpWcW6KrJebbiVSwSok1y+DMu/FGicVEtCcRFI/mWlKF20aP5M+6Ed+ySVamU2cvtVd/NKD97+34g6t7TXaNE6r6rog0Au8BHuDqwZRZ48VFQZi5vqllN7VjyvDEcduEv6sKnx84i4mJHjwo5VDbtvCljuZF7+Gc7HqHcWIJi4Un7YSX0wuxWUHiT5U4C5O5hJzpeT/99lbO0h0pVaCO0HVXmOA7PvC6uNDN9acfCisipZGjueHiuudSYKAVrAZ0QbD/P7eIo6F3pyFDK5pr6Y7RI0MC4T7giZIi+PdD9klDnymjHk7azlRVPdCfI2+/vkNVJ6rqoar6XLqOkw8sl1MjPABnfL2H63b0UNnnCVXSC0aVU7uG4sH2g+Kygq4XxQ+6hvDF6zzr2cXp4yv54YRiHjnwPd7Yr4eDeh+lpu+qgI95i28MNX1XcVDPo0ywHzV9V7FVx6Bht98AzbGy/nOg5+2XVd6t+6V1vz1SyLiRxQgwbmQxvzl3siWSFadcXb6RVIFzO3tm9jFVjm9Haw/n6K4ux2wuUY3qWoqa6VRiVQFrrz8ArSsNPNrrD0ioL4bY7KUraHLLefWNEdk1y+VUfnJDIz9ZUAbqpalkGLeOKSN4TnVS0WR+N+exwOsCCMzgQzIVgGldPdx/5ceRB3/2Op59/zEWhOVSLywv5W65EjnlNc5//lS+bO2itLjQ0j3b0xeYua0ZcSqrT/95kPJfP6988ypmfn6rs2sky3req1cs4ag1i3jXtdO6IKWRIvp4Zd73I99wKEReKoW0EalLU+pNMI6SQWLKLvQJ9DrIHtgXsttnTAYs37xXFbcIs4+pCrTH49K+6Qgv80Zxf2C2UNUxu8Z/txEr06m9/gCGa2fINWC4dtJefwAj6gdNOC8nGIGydONghMEKnl3bXcaPr3w54iMhmQp+VJ0N/YIyThu3f3QRqSBRs2R4bfEcjtm1PNTQFxYnVRQiWVavWMKkNbURBU3SSn2ooBzrGtnz3K8Z2tVsFW8SUHHx3Hd/QG3HuhA3XIHPx+15kCp42IFVjrIUosq6Kb+GL14PuWAxdU7cuquOhK9ktVckv7Z4DtPiBMQTKanoUuWdTZujZv6Gi/8ZIjECZdnkzLtZvO05xxnWssKd/NjhI46ZCiIhM/sA6s1oLvWxc5dZQdZ4MgMZpGrtnZk18OELgdY14nnmFwzzL1CxvwpRH2ds+B+omEhDQVfmSvMlSVTZBXdxf8A0GaMeTAxpg2PnLoNbm2KKv8UtqajKeR0Dk5o2DAxj5DNARhe0iDujmiqX3DuRN4uLYRQwajxHd3XxYJYDrmNTDLTGJdz3/rdbKQhbgehHgOqvPqN66pzYcgDxKK2Ko7Y5cBxlF6SQmu/Vp+8gsaQNIK66Z8xzXpVpXV3UtnfmuCbY4MaoUGaAjC5omTqHuVFyqa/cnZr0bMDABy1webO4mEvuTTj3Jy1sF+dFcf6FO76ULILD1SNeUDlYDsBfrjD8biCaTICfazdYn/U/4m2fANWdXdQPP4zKkkoEobKkkvrjb0tv1kYsaYOgRXTRGBErdiHCB0OGQF9X1BKvHVIygM4anDBGPgPM6RvjaITn9Dlnr0zr6nE8w6d19URufObdnPnt2dSFLXi6eWcH51z/ReT2AyBg4IOxDT0LygILaTLN5inX06VFIW1dWsTbUxfyzIz3uLXwGnb59kty9qeWcFbw/xIvqBxukA+bBef8MXSR0Dl/jL7Qyak91Yzi0io49z6qZz7GypkrWXfhOlbOXJn+tLxoY1M6PqGMq3gZmf5UVBdCh5SEJKZ1SIkJuqYBE3jNEI/eO51lhTsDftw5fWMcg65+Es6uySCTl02Kqnuz/jPb1RBciDuDrF6xhKq1d8auWLWuMbR4yEAIqobk98k7uWwUkET/53WN8MzVkeUAxQVTLwrdh52FlTThgeNM4VSD1x+IT2DsowWHA9jnlg9wZet/GoTECrwaIz9IGOhFxYmEjHywccwH6ktjvNcW/30/UbJrXOHGOR7rGi1FRqeqTcEXi2evc5binXAibHkzTt1bgfrMyR1HECW7JubY2pw2/oCYtQ5KPV7+vnkrqtA1ZCzDbs7uxGawYLJrBjmP3jude4a20O2yvs7mwgLucbfAvdMHZOiP7uqKdNnYwbH+13vZwmWJXMUaaA/msFkMCwswJxX7PWyWpavuhC0pADjm5AdSHANGNUqg9siLk+lZ8qSg9+8UHPZT4PNxU8tuwDrlinu3p9RNgzPGyGeRpQ+dy1LfB7S5rRN+pM/HDbta+dHpv08pRXFZ4c6AgfcTK2UzGg9e+Wl/8NVmWlcX938VJHeQhoBhVpk6x3nGnMnVrYkU5ADLoDvdJQQb1WevS0+ue44I1uJpLnDjwlr8VOmUipo/ToVBhTHyWWLpQ+fyBz7EE5RS1up2c3N5GTxfw48gaUOfzpQkqtx1AAAM40lEQVTNB6/81HoSzZ2Qd0v//WbDqZ3YM+ZMkejdQyJEuxDkA1II2ufwhgtKxwXuRMK1eMK1lPr3l4lOGkx2TZZ43Pu+s3iZCHVjyhJKR4tGRlI2z7zb8iH7DZO4sxZ0HRD1u4k8jV12u01w+mNdS+b/h2gXwry7QKZI3U7L0AcjhdbYX7sh5ked0iW7isY6b2xICTOTzxKxZtV9IikJgM3pG8M97pYIGYVoKZsJk8+zyGCCDXo+kIu7h1xR56xcGgsB9gwZa/ng7Wm9CbpmDmPks0S0VaoBUhAA+/GVL0MasmvSydI7J/H4KG+gPxfsdnPx9bFnd4OKveUCmUn2q4Svmx3bh/3qg5AmU0sqcxh3TZb4RUtr7ELbcUr7xeLpuyawrHAnzQVuBGgucLOscCd/XpRd5Ug/S++cxL1jNEQC955ymL70OzQ9NTsnfTLkgF99YBn6YPartNoNWcPM5LPEmKGnM7H3VT4tKopIUZza5U066Pr0XRO4o2xYwFXjD0H65YdZNJ5/vSG7WvCPj/JGZPsgQqvbzbyv1/P2w8dSe+FrWe2TIUcYg55zUp7Ji8gvRORDEXlXRBYFtd8kIp/Y752e6nH2do6du4wbu4/rL7ZgPw7vEZZdmbw88H+UDo2q8tftcrGkLLKmbKaJmdUjwhPaQdP/zs9ehwyGfZiUZvIichJwNnCYqvaIyFi7/TvABcB3sWq8vigihwymEoDJcOzcZRyb5n3GS5NMi/LlAIkbfxChYeNyqv/ltux1ymDYR0l1Jn8lsFBVewBU1b9k7WzgcVXtUdVNwCfA0Skey+BAvDTJtChfDpALdrsjBNrC2WaiQQZDVkj1p3YIMF1E3hCRVSJylN0+Dghek73FbotARC4XkbdE5K0dO3ak2J19j6vauqMa1KE+H1e0dGS5R3Dx9Ruo29FCqccbNdhckfvqeQbDPkFcIy8iL4rIBofH2VjunlHANOB6oFFEBOe1a46/dlW9T1WPVNUjy8uddcQN0Znxy03c0rInUEDcZfv6K/s8zNvRlvWgq5/qPXv4++atnN/eEWHoh/p81Bx0Tk76ZTDsa8T1yavqKdHeE5Ergb+oJWX5poj4gDFYM/fgsu/jASMMnSFm/HITM3LdiTDEroRU29LKET29NIwa2V8+71szjT/eYMgSqbprnga+DyAihwBFwE5gBXCBiAwRkQnAwcCbKR7LsDdx8q8t3XEs7ZKVW75k3dadrDx6gTHwBkMWSTVPfimwVEQ2AL3Ahfas/l0RaQTeAzzA1ft6Zs0+hz/vP4cFwQ0GgykaYjDkHU0bm2hY28C2zm1UlFRQM6Um/WX9DIMKUzTEYNhLaNrYRP2r9XTbpQibO5upf7UewBh6Q1KYbGWDIY9oWNsQMPB+ur3dNKxtyFGPDHs7xsgbDImyrhHumQT1I62/6xrTfohtndsc25s7m2na2JT24xkGP8YnbzAkwrpG+O+5oQW2C4vhR4vTGkw+7anTaO50kOcNY4gM4a2fmt+KwSKWT97M5A2GRPjbraEGHqzXKVT0cqJmSg1D3UPjbtejPUx+eDLTH59uZviGmJjAq8GQANq2mTvKRvLkiOH4sGZH57V3UNuyOd5HB8TTHz8d4ZOPRWtPK/NfsRQ9TWDW4ISZyRsMcVi9Ygm3lY3kiRHD8YmACD4RnhgxnNvLRlo++jT45y97/jJe3/b6gD/X5+szgVlDVIxP3mCIg6e+lKkHVlkGPgyXKv/4bDO43DDjjyn55yc/PDmVbkawcPpCM7vfRzA+eYMhBdzaX3ErnEC7z5t2/3yqzHt5nvHXG4xP3pB9mp6aTUPbO2xzu6nweqkpPZzqmY/lulvREWs25GToQ2ZJbblR/IxFw9oGM5vfxzEzeUNWaXpqNvUd62gusIt8FxRQ37Eu7wt8n+cgmYyq1e6nNLXC6dMqpqX0eSei5d0b9h2MkTdklYa2dyJq0na7XDS0vZOjHsVH9qvklpZWzm/vCOj1u1Q5v72D2pZWayOX2xJgS4H7T78/Db0NpaKkIu37NOxdGHeNIatsczvXnG12u5m8bFLgdaVXqZl4bn7IEv/qA+R3/0RtS3O/UQ+mqATO/H1aFkWNHDKS1h6HYyRJzZSatO3LsHdijLwhq1R4vTQXOJx2YZkrzQVC/aa/AOSNoc8G846ex/xX5tPn60vL/ow/3mDcNYasUlN6eNwi3366XS4aNi7PcI/yi+qDqrnte+m5qC2cvjAt+zHs3Rgjb8gq1TMfo374YVR6PIjt347Ftn3wDK0+qJrzDz1/QJ9ZOH0hlSWVCEJlSaXJkTcESMldIyKHA38EhmJVgLpKVd+037sJuATwAnNV9fkU+2oYJFTPfAy/+Qn2wztRkdikf9BRO60WgCc+fCLQVuQqotfXG7Gt36Abo25wIlWf/CJggao+JyJn2K//RUS+A1wAfBc4AHhRRA4xJQANA0KVmoPOyXUvckbttNqAsfdjqkYZBkqqRl6BEfbzUuBL+/nZwOOq2gNsEpFPgKOB11I8nmGQcVBvLxuLiiICr6hyYm95fgRd8wgzYzcMlFQ9ntcAd4rIZuB3wE12+zggWJ5vi90WgYhcLiJvichbO3bsSLE7hr2NZy7/iIN6ey3fvD8H3edjhp7Av13+Uq67ZzDs9cSdyYvIi4DTiopbgJOBa1X1zyIyC3gQOAWIVHKyZv2Rjar3AfeBJVCWYL8Ng4hnLv8o110wGAYtcY28qp4S7T0R+RPgX23xJPCA/XwLUBW06Xj6XTkGg8FgyBKpumu+BE60n38f+Nh+vgK4QESGiMgE4GDgzRSPZTAYDIYBkmrg9TKgQUQKgG7gcgBVfVdEGoH3sFIrrzaZNQaDwZB9UjLyqvp3YGqU9+4A7khl/waDwWBIjX1wPaHBYDDsO+RV+T8R2QF8nut+hDEG2JnrTgwA09/MYvqbWUx/k+Obqlru9EZeGfl8RETeilY7MR8x/c0spr+ZxfQ3/Rh3jcFgMAxijJE3GAyGQYwx8vG5L9cdGCCmv5nF9DezmP6mGeOTNxgMhkGMmckbDAbDIMYYeYPBYBjEGCMfBRF5QkTesR+ficg7dvuBItIV9N4f86Cv9SKyNahPZwS9d5OIfCIiH4rI6bnspx8RuVNEPhCRdSKyXERG2u15N7Z+ROQH9hh+IiLzct2fcESkSkReEpH3ReRdEamx26OeG7nG/l2tt/v1lt1WJiIviMjH9t9Rue4ngIgcGjSG74hIu4hck8/j68f45BNARO4C2lT1VhE5EHhWVWPXrcsiIlIPfK2qvwtr/w7wGFbBlgOAF4GcV+gSkdOA/6+qHhH5LYCq3piPYwsgIm7gI+BULIXV1cBsVX0vpx0LQkQqgUpVXSsiw4E1wAxgFg7nRj4gIp8BR6rqzqC2RUCLqi60L6ajVPXGXPXRCft82AocA1xEno6vHzOTj4OICNYP5bFc9yUJAhW6VHUT4K/QlVNUdaWqeuyXr2NJUeczRwOfqOpGVe0FHsca27xBVZtVda39vAN4nyiFevKcs4GH7ecPY12o8o2TgU9VNd9W5ztijHx8pgNfqerHQW0TRORtEVklItNz1bEwfm67P5YG3eImXKErh1wMPBf0Oh/Hdm8YxwD2HdERwBt2k9O5kQ8osFJE1ojI5Xbb/qraDNaFCxibs95F5wJCJ335Or7APm7kReRFEdng8Aiepc0m9AttBr6hqkcA1wGPisgIMkycvt4LTAQOt/t3l/9jDrvKin8ukbEVkVuwpKgfsZtyMrYJkLNxHCgish/wZ+AaVW0n+rmRD3xPVacAPwSuFpETct2heIhIEXAWVpEkyO/xBVLXk9+riVX1CkAsnfxzCZJTtouT99jP14jIp8AhwFsZ7GrcvvoRkfuBZ+2XOavQlcDYXgicCZysdmAoV2ObAHtFpTMRKcQy8I+o6l8AVPWroPeDz42co6pf2n+3i8hyLLfYVyJSqarNdpxhe047GckPgbX+cc3n8fWzT8/kE+AU4ANV3eJvEJFyO/CCiByEVfVqY4765+9TZdDLc4AN9vO8rNAlIj8AbgTOUtU9Qe15N7Y2q4GDRWSCPZO7AGts8wY7dvQg8L6q3h3UHu3cyCkiUmIHiBGREuA0rL6tAC60N7sQeCY3PYxKyJ19vo5vMPv0TD4Bwn1vACcAt4qIB/ACP1PVlqz3LJRFInI4lgvhM+AKyOsKXf8GDAFesGwTr6vqz8jPscXOAvo58DzgBpaq6rs57lY43wN+AqwXO90XuBmY7XRu5AH7A8vt778AeFRV/yoiq4FGEbkE+AI4L4d9DEFEhmFlWAWPoeNvL58wKZQGg8EwiDHuGoPBYBjEGCNvMBgMgxhj5A0Gg2EQY4y8wWAwDGKMkTcYDIZBjDHyBoPBMIgxRt5gMBgGMf8HSQS4eEQnTxkAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for group, lab in zip((group1_sm, group2_sm, group3_sm), (\"> mean+std\", \"> mean-std\", \"< mean-std\")):\n",
    "    plt.plot(points_sm[group,0], points_sm[group,1], \"o\", label=lab)\n",
    "plt.title(\"tSNE (Spearman)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66f2f54c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for group, lab in zip((group1_ps, group2_ps, group3_ps), (\"> mean+std\", \"> mean-std\", \"< mean-std\")):\n",
    "    plt.plot(points_ps[group,0], points_ps[group,1], \"o\", label=lab)\n",
    "plt.title(\"tSNE (Pearson)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d187c7e",
   "metadata": {},
   "source": [
    "Os resultados demonstram que nÃ£o Ã© possÃ­vel separar de forma clara os pontos com base nos grupos definidos."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KMeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k=3\n",
    "kmeans_sm = KMeans(n_clusters=k, max_iter=1000)\n",
    "kmeans_ps = KMeans(n_clusters=k, max_iter=1000)\n",
    "\n",
    "#Using the TSNE fitted points for the KMeans analysis\n",
    "kmeans_sm.fit(points_sm)\n",
    "kmeans_ps.fit(points_ps)\n",
    "\n",
    "\n",
    "labels_sm = kmeans_sm.labels_\n",
    "labels_ps = kmeans_ps.labels_\n",
    "\n",
    "centroids_sm = kmeans_ps.cluster_centers_\n",
    "centroids_ps = kmeans_sm.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "tm        10.0  12.0  15.0  16.6  17.2  20.0  21.7  22.0  22.5  23.0  ...  \\\nclusters                                                              ...   \n0            0     0     1     0     0     2     0     0     0     3  ...   \n1            1     0     1     0     1     6     3     3     2     0  ...   \n2            2     3     0     1     0     0     0     1     0     0  ...   \n\ntm        90.3  90.4  90.7  90.8  91.0  91.1  91.2  91.4  91.5  91.6  \nclusters                                                              \n0            0     0     0     0     0     0     0     0     0     1  \n1            0     0     0     0     0     0     0     0     0     0  \n2            2     1     2     1     2     1     1     1     1     0  \n\n[3 rows x 598 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>tm</th>\n      <th>10.0</th>\n      <th>12.0</th>\n      <th>15.0</th>\n      <th>16.6</th>\n      <th>17.2</th>\n      <th>20.0</th>\n      <th>21.7</th>\n      <th>22.0</th>\n      <th>22.5</th>\n      <th>23.0</th>\n      <th>...</th>\n      <th>90.3</th>\n      <th>90.4</th>\n      <th>90.7</th>\n      <th>90.8</th>\n      <th>91.0</th>\n      <th>91.1</th>\n      <th>91.2</th>\n      <th>91.4</th>\n      <th>91.5</th>\n      <th>91.6</th>\n    </tr>\n    <tr>\n      <th>clusters</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 598 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(labels_ps, y_train_PS, rownames=['clusters'] )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "tm        10.0  12.0  15.0  16.6  20.0  21.7  22.0  22.5  23.1  23.5  ...  \\\nclusters                                                              ...   \n0            2     3     0     1     1     3     1     2     1     1  ...   \n1            1     0     0     0     0     0     0     0     0     0  ...   \n2            0     0     1     0     7     0     3     0     0     0  ...   \n\ntm        90.6  90.7  90.8  91.0  91.1  91.2  91.3  91.4  91.5  91.6  \nclusters                                                              \n0            0     0     0     1     0     0     0     0     0     0  \n1            0     0     0     0     0     1     0     0     0     0  \n2            1     2     2     2     1     0     1     2     1     1  \n\n[3 rows x 609 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>tm</th>\n      <th>10.0</th>\n      <th>12.0</th>\n      <th>15.0</th>\n      <th>16.6</th>\n      <th>20.0</th>\n      <th>21.7</th>\n      <th>22.0</th>\n      <th>22.5</th>\n      <th>23.1</th>\n      <th>23.5</th>\n      <th>...</th>\n      <th>90.6</th>\n      <th>90.7</th>\n      <th>90.8</th>\n      <th>91.0</th>\n      <th>91.1</th>\n      <th>91.2</th>\n      <th>91.3</th>\n      <th>91.4</th>\n      <th>91.5</th>\n      <th>91.6</th>\n    </tr>\n    <tr>\n      <th>clusters</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 609 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(labels_sm, y_train_SM, rownames=['clusters'] )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    # select only data observations with cluster label == i\n",
    "    ds = points_sm[list(np.where(labels_sm==i)[0]),:]\n",
    "    #print(ds)\n",
    "\n",
    "    # plot the data observations (only 2 first colums)\n",
    "    plt.plot(points_sm[:,0], points_sm[:,1])\n",
    "    #plt.plot(ds[\"_SolventAccessibilityT23\"],ds[\"_SolventAccessibilityC1\"],'o')\n",
    "    # plot the centroids\n",
    "    lines = plt.plot(centroids_sm[i,0],centroids_sm[i,1],'kx')\n",
    "    # make the centroid x's bigger\n",
    "    plt.setp(lines,ms=10.0)    # x size\n",
    "    plt.setp(lines,mew=2.0)    # line thickness\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "[1517,\n 1705,\n 3009,\n 3218,\n 3219,\n 3220,\n 3221,\n 3231,\n 3232,\n 3233,\n 3234,\n 3237,\n 3238,\n 3239,\n 3245,\n 3246,\n 3247,\n 3248,\n 3249,\n 3262,\n 3263,\n 3264,\n 3265,\n 3266,\n 3267,\n 3275,\n 3276,\n 3277,\n 3278,\n 3296,\n 3297,\n 3298,\n 3299,\n 3300,\n 3301,\n 3302,\n 3303,\n 3304,\n 3305,\n 3306,\n 3307,\n 3308,\n 3309,\n 3310,\n 3311,\n 3312,\n 3313,\n 3314,\n 3315,\n 3316,\n 3317,\n 3318,\n 3319,\n 3320,\n 3321,\n 3322,\n 3323,\n 3324,\n 3325,\n 3326,\n 3327,\n 3328,\n 3329,\n 3330,\n 3331,\n 3332,\n 3333,\n 3334,\n 3335,\n 3336,\n 3337,\n 3338,\n 3339,\n 3340,\n 3341,\n 3342,\n 3343,\n 3344,\n 3345,\n 3346,\n 3347,\n 3348,\n 3349,\n 3350,\n 3351,\n 3352,\n 3353,\n 3354,\n 3355,\n 3356,\n 3357,\n 3358,\n 3359,\n 3360,\n 3361,\n 3362,\n 3363,\n 3364,\n 3365,\n 3366,\n 3367,\n 3368,\n 3369,\n 3370,\n 3371,\n 3372,\n 3373,\n 3374,\n 3375,\n 3376,\n 3377,\n 3378,\n 3379,\n 3380,\n 3381,\n 3382,\n 3383,\n 3384,\n 3385,\n 3386,\n 3387,\n 3388,\n 3389,\n 3390,\n 3391,\n 3392,\n 3393,\n 3394,\n 3395,\n 3396,\n 3397,\n 3398,\n 3399,\n 3400,\n 3401,\n 3402,\n 3403,\n 3404,\n 3405,\n 3406,\n 3407,\n 3408,\n 3409,\n 3410,\n 3411,\n 3412,\n 3413,\n 3414,\n 3415,\n 3416,\n 3417,\n 3418,\n 3419,\n 3420,\n 3421,\n 3422,\n 3423,\n 3424,\n 3425,\n 3426,\n 3427,\n 3428,\n 3429,\n 3430,\n 3431,\n 3432,\n 3433,\n 3434,\n 3435,\n 3436,\n 3437,\n 3438,\n 3439,\n 3440,\n 3441,\n 3442,\n 3443,\n 3444,\n 3445,\n 3446,\n 3447,\n 3448,\n 3449,\n 3450,\n 3451,\n 3452,\n 3453,\n 3454,\n 3455,\n 3456,\n 3457,\n 3458,\n 3459,\n 3460,\n 3461,\n 3462,\n 3463,\n 3464,\n 3465,\n 3466,\n 3467,\n 3468,\n 3469,\n 3470,\n 3471,\n 3472,\n 3473,\n 3474,\n 3475,\n 3476,\n 3477,\n 3478,\n 3479,\n 3480,\n 3481,\n 3482,\n 3483,\n 3484,\n 3485,\n 3486,\n 3487,\n 3488,\n 3489,\n 3490,\n 3491,\n 3492,\n 3493,\n 3494,\n 3495,\n 3496,\n 3497,\n 3498,\n 3499,\n 3500,\n 3501,\n 3502,\n 3503,\n 3504,\n 3505,\n 3506,\n 3507,\n 3508,\n 3509,\n 3510,\n 3511,\n 3512,\n 3513,\n 3514,\n 3515,\n 3516,\n 3517,\n 3518,\n 3519,\n 3520,\n 3521,\n 3522,\n 3523,\n 3524,\n 3525,\n 3526,\n 3527,\n 3528,\n 3529,\n 3530,\n 3531,\n 3532,\n 3533,\n 3534,\n 3535,\n 3536,\n 3537,\n 3538,\n 3539,\n 3540,\n 3541,\n 3542,\n 3543,\n 3544,\n 3545,\n 3546,\n 3547,\n 3548,\n 3549,\n 3550,\n 3551,\n 3552,\n 3553,\n 3554,\n 3555,\n 3556,\n 3557,\n 3558,\n 3559,\n 3560,\n 3561,\n 3562,\n 3563,\n 3564,\n 3565,\n 3566,\n 3567,\n 3568,\n 3569,\n 3570,\n 3571,\n 3572,\n 3573,\n 3574,\n 3575,\n 3576,\n 3577,\n 3578,\n 3579,\n 3580,\n 3581,\n 3582,\n 3583,\n 3584,\n 3585,\n 3586,\n 3587,\n 3588,\n 3589,\n 3590,\n 3591,\n 3592,\n 3593,\n 3594,\n 3595,\n 3596,\n 3597,\n 3598,\n 3599,\n 3600,\n 3601,\n 3602,\n 3603,\n 3604,\n 3605,\n 3606,\n 3607,\n 3608,\n 3609,\n 3610,\n 3611,\n 3612,\n 3613,\n 3614,\n 3615,\n 3616,\n 3617,\n 3618,\n 3619,\n 3620,\n 3621,\n 3622,\n 3623,\n 3624,\n 3625,\n 3626,\n 3627,\n 3628,\n 3629,\n 3630,\n 3631,\n 3632,\n 3633,\n 3634,\n 3635,\n 3636,\n 3637,\n 3638,\n 3639,\n 3640,\n 3641,\n 3642,\n 3643,\n 3644,\n 3645,\n 3646,\n 3647,\n 3648,\n 3649,\n 3650,\n 3651,\n 3652,\n 3653,\n 3654,\n 3655,\n 3656,\n 3657,\n 3658,\n 3659,\n 3660,\n 3661,\n 3662,\n 3663,\n 3664,\n 3665,\n 3666,\n 3667,\n 3668,\n 3669,\n 3670,\n 3671,\n 3672,\n 3673,\n 3674,\n 3675,\n 3676,\n 3677,\n 3678,\n 3679,\n 3680,\n 3681,\n 3682,\n 3683,\n 3684,\n 3685,\n 3686,\n 3687,\n 3688,\n 3689,\n 3690,\n 3691,\n 3692,\n 3693,\n 3694,\n 3695,\n 3696,\n 3697,\n 3698,\n 3699,\n 3700,\n 3701,\n 3702,\n 3703,\n 3704,\n 3705,\n 3706,\n 3707,\n 3708,\n 3709,\n 3710,\n 3711,\n 3712,\n 3713,\n 3714,\n 3715,\n 3716,\n 3717,\n 3718,\n 3719,\n 3720,\n 3721,\n 3722,\n 3723,\n 3724,\n 3725,\n 3726,\n 3727,\n 3728,\n 3729,\n 3730,\n 3731,\n 3732,\n 3733,\n 3734,\n 3735,\n 3736,\n 3737,\n 3738,\n 3739,\n 3740,\n 3741,\n 3742,\n 3743,\n 3744,\n 3745,\n 3746,\n 3747,\n 3748,\n 3749,\n 3750,\n 3751,\n 3752,\n 3753,\n 3754,\n 3755,\n 3756,\n 3757,\n 3758,\n 3759,\n 3760,\n 3761,\n 3762,\n 3763,\n 3764,\n 3765,\n 3766,\n 3767,\n 3768,\n 3769,\n 3770,\n 3771,\n 3772,\n 3773,\n 3774,\n 3775,\n 3776,\n 3777,\n 3778,\n 3779,\n 3780,\n 3781,\n 3782,\n 3783,\n 3784,\n 3785,\n 3786,\n 3787,\n 3788,\n 3789,\n 3790,\n 3791,\n 3792,\n 3793,\n 3794,\n 3795,\n 3796,\n 3797,\n 3798,\n 3799,\n 3800,\n 3801,\n 3802,\n 3803,\n 3804,\n 3805,\n 3806,\n 3807,\n 3808,\n 3809,\n 3810,\n 3811,\n 3812,\n 3813,\n 3814,\n 3815,\n 3816,\n 3817,\n 3818,\n 3819,\n 3820,\n 3821,\n 3822,\n 3823,\n 3824,\n 3825,\n 3826,\n 3827,\n 3828,\n 3829,\n 3830,\n 3831,\n 3832,\n 3833,\n 3834,\n 3835,\n 3836,\n 3837,\n 3838,\n 3839,\n 3840,\n 3841,\n 3842,\n 3843,\n 3844,\n 3845,\n 3846,\n 3847,\n 3848,\n 3849,\n 3850,\n 3851,\n 3852,\n 3853,\n 3854,\n 3855,\n 3856,\n 3857,\n 3858,\n 3859,\n 3860,\n 3861,\n 3862,\n 3863,\n 3864,\n 3865,\n 3866,\n 3867,\n 3868,\n 3869,\n 3870,\n 3871,\n 3872,\n 3873,\n 3874,\n 3875,\n 3876,\n 3877,\n 3878,\n 3879,\n 3880,\n 3881,\n 3882,\n 3883,\n 3884,\n 3885,\n 3886,\n 3887,\n 3888,\n 3889,\n 3890,\n 3891,\n 3892,\n 3893,\n 3894,\n 3895,\n 3896,\n 3897,\n 3898,\n 3899,\n 3900,\n 3901,\n 3902,\n 3903,\n 3904,\n 3905,\n 3906,\n 3907,\n 3908,\n 3909,\n 3910,\n 3911,\n 3912,\n 3913,\n 3914,\n 3915,\n 3916,\n 3917,\n 3918,\n 3919,\n 3920,\n 3921,\n 3922,\n 3923,\n 3924,\n 3925,\n 3926,\n 3927,\n 3928,\n 3929,\n 3930,\n 3931,\n 3932,\n 3933,\n 3934,\n 3935,\n 3936,\n 3937,\n 3938,\n 3939,\n 3940,\n 3941,\n 3942,\n 3943,\n 3944,\n 3945,\n 3946,\n 3947,\n 3948,\n 3949,\n 3950,\n 3951,\n 3952,\n 3953,\n 3954,\n 3955,\n 3956,\n 3957,\n 3958,\n 3959,\n 3960,\n 3961,\n 3962,\n 3963,\n 3964,\n 3965,\n 3966,\n 3967,\n 3968,\n 3969,\n 3970,\n 3971,\n 3972,\n 3973,\n 3974,\n 3975,\n 3976,\n 3977,\n 3978,\n 3979,\n 3980,\n 3981,\n 3982,\n 3983,\n 3984,\n 3985,\n 3986,\n 3987,\n 3988,\n 3989,\n 3990,\n 3991,\n 3992,\n 3993,\n 3994,\n 3995,\n 3996,\n 3997,\n 3998,\n 3999,\n 4000,\n 4001,\n 4002,\n 4003,\n 4004,\n 4005,\n 4006,\n 4007,\n 4008,\n 4009,\n 4010,\n 4011,\n 4012,\n 4013,\n 4014,\n 4015,\n 4016,\n 4017,\n 4018,\n 4019,\n 4020,\n 4021,\n 4022,\n 4023,\n 4024,\n 4025,\n 4056,\n 4057,\n 4058,\n 4059,\n 4060,\n 4061,\n 4062,\n 4072,\n 4073,\n 4074,\n 4119,\n 4120,\n 4121,\n 4122,\n 4359,\n 4360,\n 4361,\n 4373,\n 4374,\n 4375,\n 4376,\n 4377,\n 4378,\n 4385,\n 4386,\n 4387,\n 4388,\n 4402,\n 4403,\n 4407,\n 4408,\n 4409,\n 5079,\n 5218,\n 5316,\n 6167]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.where(labels_sm==i)[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    # select only data observations with cluster label == i\n",
    "    ds = X_train_PS_clean.iloc[list(np.where(labels_ps==i)[0])]\n",
    "    # plot the data observations (only 2 first colums)\n",
    "    plt.plot(ds[\"_SolventAccessibilityT23\"],ds[\"_SolventAccessibilityC1\"],'o')\n",
    "    # plot the centroids\n",
    "    lines = plt.plot(centroids_ps[i,0],centroids_ps[i,1],'kx')\n",
    "    # make the centroid x's bigger\n",
    "    plt.setp(lines,ms=10.0)    # x size\n",
    "    plt.setp(lines,mew=2.0)    #grossura da linha\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "5725a1ab-4187-4b44-9100-e4dd166f0d8e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33b782-54c4-40c5-8bcb-1551754bb2a6",
   "metadata": {},
   "source": [
    "Por fim, aplicÃ¡mos algoritmos de aprendizagem supervisionada de modo a conseguirmos fazer previsÃµes acerca da variÃ¡vel de output (<b>tm</b>) a partir de sequÃªncias de aminoÃ¡cidos cujo valor de termostabilidade Ã© desconhecido. Para isso, utilizÃ¡mos sete algoritmos distintos implementados na biblioteca <b>sklearn</b>.\n",
    "\n",
    "- <b>LinearRegression</b> (LR)\n",
    "- <b>KNeighborsRegressor</b> (KNR)\n",
    "- <b>RandomForestRegressor</b> (RFR)\n",
    "- <b>SVR</b> -> Support Vector Regressor\n",
    "- <b>MLPRegressor</b> (MLPR) -> Multi Layer Perceptron Regressor\n",
    "- <b>AdaBoostRegressor</b> (ADA)\n",
    "- <b>HistGradientBoostingRegressor</b> (HGBR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc515b9c-8d8f-4772-9153-b700e8454baa",
   "metadata": {},
   "source": [
    "### Get best combination dataset-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2ff20ec-333d-426f-a9fb-7531c1658800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor as ADA\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor as HGBR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNR\n",
    "from sklearn.neural_network import MLPRegressor as MLPR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ee745-d87f-495d-a580-4b902a5e4c2f",
   "metadata": {},
   "source": [
    "ComeÃ§Ã¡mos por determinar, a partir de cada um dos mÃ©todos de seleÃ§Ã£o de features referidos anteriormente (<b>Pearson</b>, <b>Spearman</b>, <b>ANOVA f-values</b> e <b>informaÃ§Ã£o mÃºtua</b>), qual a melhor combinaÃ§Ã£o <b>modelo / nÃºmero de features selecionadas</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62077a11-790f-431f-8422-b78393b31403",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_NUMS = [200, 400, 600, 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd667d78-a525-4f69-9a23-adf08ba73cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_corr_models(model, method, corrs, cv=5, num_feats=DEFAULT_NUMS):\n",
    "    print(f\"Getting results for {model.__class__.__name__} using {method} to select features...\\n\")\n",
    "    for k in num_feats:\n",
    "        # get best corrs and cross-validate\n",
    "        best_scores = get_k_best_corrs(k, corrs) # Get best features\n",
    "        result = cross_validate(estimator=model,\n",
    "                                X=X_train_sc.loc[:, best_scores.keys()],\n",
    "                                y=y_train,\n",
    "                                cv=KFold(n_splits=cv, shuffle=True),\n",
    "                                return_train_score=True)\n",
    "        # print results\n",
    "        mean_train = np.sum(result[\"train_score\"]) / cv\n",
    "        mean_test = np.sum(result[\"test_score\"]) / cv\n",
    "        print(f\"Results for {k} best features\")\n",
    "        print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "        print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab4536-e6b1-422f-b881-8e9f5b8b87e9",
   "metadata": {},
   "source": [
    "<b>Pearson</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "edf92216",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.31830325 0.31392415 0.31633945 0.31182916 0.3066358 ] -> mean_train = 0.3134\n",
      "Test scores: [0.27919092 0.29974493 0.29115746 0.30118958 0.33140716] -> mean_test = 0.3005\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.39371228 0.38799135 0.39360352 0.39383614 0.39987173] -> mean_train = 0.3938\n",
      "Test scores: [0.38300769 0.35232374 0.37767527 0.37743098 0.35830092] -> mean_test = 0.3697\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.42371335 0.4146264  0.42294396 0.42536268 0.42076352] -> mean_train = 0.4215\n",
      "Test scores: [0.37103912 0.37512818 0.38437575 0.3865769  0.40484428] -> mean_test = 0.3844\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.43373677 0.43318539 0.43969612 0.43861505 0.43600294] -> mean_train = 0.4362\n",
      "Test scores: [0.41054996 0.3655078  0.38919964 0.39444717 0.36578661] -> mean_test = 0.3851\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for RandomForestRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.86762202 0.86455812 0.86756847 0.8654831  0.86635326] -> mean_train = 0.8663\n",
      "Test scores: [0.46893692 0.47474253 0.47183767 0.47635708 0.46603657] -> mean_test = 0.4716\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.86865287 0.8708922  0.86909876 0.86407208 0.87073908] -> mean_train = 0.8687\n",
      "Test scores: [0.48321788 0.4651082  0.48409388 0.51644364 0.45168042] -> mean_test = 0.4801\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.86692848 0.86931937 0.86943738 0.86686052 0.87293123] -> mean_train = 0.8691\n",
      "Test scores: [0.4851075  0.48528567 0.49189294 0.52378137 0.46479614] -> mean_test = 0.4902\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.86701671 0.86933204 0.87158342 0.86787022 0.87067643] -> mean_train = 0.8693\n",
      "Test scores: [0.50926646 0.47984863 0.4709283  0.48995825 0.4742135 ] -> mean_test = 0.4848\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for SVR using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.27768877 0.28164607 0.27543778 0.28223729 0.27169098] -> mean_train = 0.2777\n",
      "Test scores: [0.27372642 0.26373777 0.28260736 0.2527845  0.28642668] -> mean_test = 0.2719\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.26833298 0.26359706 0.26154189 0.26092158 0.27139692] -> mean_train = 0.2652\n",
      "Test scores: [0.25027263 0.26140355 0.27630936 0.2633784  0.24690274] -> mean_test = 0.2597\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.25604641 0.2557586  0.2542764  0.26941398 0.26639608] -> mean_train = 0.2604\n",
      "Test scores: [0.26574554 0.25771847 0.27268954 0.23138731 0.24560992] -> mean_test = 0.2546\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.25269249 0.25810787 0.25484969 0.25800937 0.26009149] -> mean_train = 0.2568\n",
      "Test scores: [0.25179683 0.25459869 0.26067716 0.24756907 0.23981551] -> mean_test = 0.2509\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for MLPRegressor using Pearson correlation to select features...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 200 best features\n",
      "Train scores: [0.52105186 0.51666136 0.51690926 0.52675541 0.52715188] -> mean_train = 0.5217\n",
      "Test scores: [0.43688842 0.45549741 0.42600597 0.45694164 0.44466639] -> mean_test = 0.4440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 400 best features\n",
      "Train scores: [0.46204741 0.49887642 0.4694671  0.45133553 0.50712451] -> mean_train = 0.4778\n",
      "Test scores: [0.42765406 0.46299803 0.43444477 0.43355555 0.45313489] -> mean_test = 0.4424\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 600 best features\n",
      "Train scores: [0.50828932 0.48730197 0.53997773 0.52672009 0.51295359] -> mean_train = 0.5150\n",
      "Test scores: [0.48259759 0.42385795 0.48960782 0.47330764 0.47066749] -> mean_test = 0.4680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 800 best features\n",
      "Train scores: [0.55768337 0.53201379 0.57710713 0.54583701 0.53376656] -> mean_train = 0.5493\n",
      "Test scores: [0.50072421 0.44872076 0.47927216 0.48096196 0.48445523] -> mean_test = 0.4788\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for AdaBoostRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.30878064 0.31747994 0.2821283  0.33309379 0.30994882] -> mean_train = 0.3103\n",
      "Test scores: [0.31653165 0.28572524 0.27650359 0.31991506 0.28990877] -> mean_test = 0.2977\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.31737068 0.33604038 0.30093692 0.30342464 0.29648123] -> mean_train = 0.3109\n",
      "Test scores: [0.3274757  0.33384534 0.29182668 0.27977979 0.28082602] -> mean_test = 0.3028\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.31718018 0.28876691 0.30003358 0.29836457 0.32519596] -> mean_train = 0.3059\n",
      "Test scores: [0.29306934 0.26952092 0.28428521 0.30487058 0.31365367] -> mean_test = 0.2931\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.28814453 0.30092214 0.32320997 0.28723039 0.34017101] -> mean_train = 0.3079\n",
      "Test scores: [0.26270269 0.30130176 0.30585807 0.27255919 0.32357272] -> mean_test = 0.2932\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.61760073 0.61823471 0.62163874 0.62513078 0.62371354] -> mean_train = 0.6213\n",
      "Test scores: [0.52983723 0.53351532 0.51879814 0.49154409 0.50710966] -> mean_test = 0.5162\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.65205709 0.64711572 0.64902128 0.65037379 0.65255898] -> mean_train = 0.6502\n",
      "Test scores: [0.52083674 0.54288122 0.55053516 0.52329081 0.5269    ] -> mean_test = 0.5329\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.6641068  0.66170629 0.66909358 0.64717522 0.66185312] -> mean_train = 0.6608\n",
      "Test scores: [0.5458077  0.55594568 0.51133182 0.54347462 0.54799937] -> mean_test = 0.5409\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.66427657 0.66246132 0.65999607 0.66341141 0.67036066] -> mean_train = 0.6641\n",
      "Test scores: [0.54249578 0.54910128 0.52700264 0.54868719 0.52947596] -> mean_test = 0.5394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, Model in enumerate([LR, RFR, SVR, MLPR, ADA, HGBR]):\n",
    "    test_corr_models(model=Model(), method=\"Pearson correlation\", corrs=pearson_corrs)\n",
    "    if i < 5:\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ae4c5-0eeb-46ef-940a-4b06c9f39f43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(BEFORE UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.27011736 0.28650022 0.22313226 0.26490225 0.26940456] -> mean_train = 0.2628\n",
    "Test scores: [0.14711361 0.10705096 0.27218331 0.20173697 0.18240789] -> mean_test = 0.1821\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.41665499 0.39386691 0.3850985  0.39537238 0.41242381] -> mean_train = 0.4007\n",
    "Test scores: [0.08573871 0.2893108  0.33210872 0.30932031 0.1514813 ] -> mean_test = 0.2336\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.44620921 0.43236111 0.43381858 0.43981191 0.4531923 ] -> mean_train = 0.4411\n",
    "Test scores: [0.06293847 0.27328139 0.33204977 0.30332439 0.17662368] -> mean_test = 0.2296\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.47941186 0.45920366 0.44087096 0.46595271 0.46848766] -> mean_train = 0.4628\n",
    "Test scores: [0.08041124 0.27869326 0.287661   0.29106935 0.1168009 ] -> mean_test = 0.2109\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.81861813 0.84025213 0.85172038 0.81723961 0.82355589] -> mean_train = 0.8303\n",
    "Test scores: [0.22094994 0.23278113 0.25640221 0.31260307 0.2571411 ] -> mean_test = 0.2560\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.84739424 0.86756812 0.87518231 0.84538561 0.85187832] -> mean_train = 0.8575\n",
    "Test scores: [0.23421498 0.35857337 0.24336712 0.36769986 0.31232961] -> mean_test = 0.3032\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.84771979 0.86827125 0.87595901 0.8461804  0.85253105] -> mean_train = 0.8581\n",
    "Test scores: [0.22143367 0.32069786 0.19008172 0.38143426 0.31148471] -> mean_test = 0.2850\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.87676433 0.90002164 0.89224492 0.87385361 0.87793775] -> mean_train = 0.8842\n",
    "Test scores: [0.27083525 0.33920909 0.20056345 0.38527337 0.27747011] -> mean_test = 0.2947\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.21789023 0.24789051 0.1688259  0.1946165  0.24299579] -> mean_train = 0.2144\n",
    "Test scores: [0.0217743  0.0393838  0.06749173 0.11066504 0.1454537 ] -> mean_test = 0.0770\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.32242365 0.32898748 0.27168506 0.28805197 0.30137941] -> mean_train = 0.3025\n",
    "Test scores: [0.12702293 0.20443145 0.13614342 0.22957511 0.14922126] -> mean_test = 0.1693\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.29640638 0.31946727 0.28776308 0.29008702 0.32292222] -> mean_train = 0.3033\n",
    "Test scores: [0.09409807 0.17705651 0.13124845 0.21650374 0.18319332] -> mean_test = 0.1604\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.30405968 0.21448556 0.23909915 0.28300452 0.30514278] -> mean_train = 0.2692\n",
    "Test scores: [0.07639932 0.08501833 0.0728567  0.18245674 0.12884878] -> mean_test = 0.1091\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.31371592 0.31834536 0.3022404  0.31092042 0.31666435] -> mean_train = 0.3124\n",
    "Test scores: [0.21283891 0.16427215 0.07069547 0.25263497 0.24485791] -> mean_test = 0.1891\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.28378963 0.26807723 0.24905719 0.26710835 0.28725249] -> mean_train = 0.2711\n",
    "Test scores: [0.18274096 0.15177209 0.24838459 0.22915948 0.18186443] -> mean_test = 0.1988\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.27629772 0.25743841 0.23863574 0.26184484 0.27565766] -> mean_train = 0.2620\n",
    "Test scores: [0.17035563 0.15027543 0.22394396 0.19866285 0.16760289] -> mean_test = 0.1822\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.26972242 0.25406078 0.23311293 0.25886046 0.27116362] -> mean_train = 0.2574\n",
    "Test scores: [0.16767649 0.14030832 0.19821048 0.1878921  0.1576652 ] -> mean_test = 0.1704\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.45202777 0.43871447 0.45321541 0.45765465 0.45912327] -> mean_train = 0.4521\n",
    "Test scores: [ 0.2031334   0.16033084 -0.08987277  0.2116972   0.15462226] -> mean_test = 0.1280\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.47475198 0.4923954  0.50451639 0.50400392 0.47938821] -> mean_train = 0.4910\n",
    "Test scores: [0.23719782 0.36519414 0.2931955  0.35681098 0.23217787] -> mean_test = 0.2969\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.55805531 0.56752787 0.54657214 0.52045875 0.54403841] -> mean_train = 0.5473\n",
    "Test scores: [0.14783581 0.36859843 0.27241315 0.3401092  0.34026483] -> mean_test = 0.2938\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.60004007 0.60734283 0.6379186  0.53613144 0.58864283] -> mean_train = 0.5940\n",
    "Test scores: [0.18884443 0.32031392 0.36322389 0.28063518 0.31413352] -> mean_test = 0.2934\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(Z-scores)\n",
    "\n",
    "Getting results for LinearRegression using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.67160102 0.6689632  0.68186929 0.66149608 0.67386646] -> mean_train = 0.6716\n",
    "Test scores: [-1.07791337 -0.18159527 -0.02480662 -0.27529876 -1.04734993] -> mean_test = -0.5214\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.67160102 0.6689632  0.68186929 0.66149608 0.67386646] -> mean_train = 0.6716\n",
    "Test scores: [-1.07791337 -0.18159527 -0.02480662 -0.27529876 -1.04734993] -> mean_test = -0.5214\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.67160102 0.6689632  0.68186929 0.66149608 0.67386646] -> mean_train = 0.6716\n",
    "Test scores: [-1.07791337 -0.18159527 -0.02480662 -0.27529876 -1.04734993] -> mean_test = -0.5214\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.80727911 0.83041557 0.84220175 0.80666646 0.81338696] -> mean_train = 0.8200\n",
    "Test scores: [0.1891794  0.18649405 0.18417251 0.27658475 0.22553633] -> mean_test = 0.2124\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.84161805 0.86398035 0.86833273 0.84003347 0.84644822] -> mean_train = 0.8521\n",
    "Test scores: [0.19887344 0.31872482 0.23552122 0.35482832 0.28120151] -> mean_test = 0.2778\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.84235855 0.86518026 0.86934521 0.8409079  0.84660065] -> mean_train = 0.8529\n",
    "Test scores: [0.18125953 0.29988959 0.12022268 0.3604441  0.2963378 ] -> mean_test = 0.2516\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.24087864 0.23950204 0.16925286 0.19086963 0.25147329] -> mean_train = 0.2184\n",
    "Test scores: [0.08491198 0.0297712  0.16957604 0.10801696 0.14612454] -> mean_test = 0.1077\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.29832073 0.31678918 0.27567914 0.30577065 0.30121334] -> mean_train = 0.2996\n",
    "Test scores: [0.0998887  0.18089942 0.15771938 0.25511451 0.15684757] -> mean_test = 0.1701\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.34946497 0.26841796 0.33437571 0.29196208 0.33172762] -> mean_train = 0.3152\n",
    "Test scores: [0.1768113  0.12819227 0.15462779 0.20862672 0.19958328] -> mean_test = 0.1736\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.3470447  0.34487087 0.35734174 0.34269595 0.35251758] -> mean_train = 0.3489\n",
    "Test scores: [0.18790998 0.14018134 0.10888095 0.225853   0.22270535] -> mean_test = 0.1771\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.40986956 0.39526794 0.41410988 0.39641576 0.41763621] -> mean_train = 0.4067\n",
    "Test scores: [0.206643   0.18902751 0.11136261 0.27958821 0.22978204] -> mean_test = 0.2033\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.42662508 0.4044915  0.4269925  0.40696331 0.42792255] -> mean_train = 0.4186\n",
    "Test scores: [0.20535089 0.19830048 0.1409307  0.28567528 0.23900059] -> mean_test = 0.2139\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.53202    0.52313445 0.57137021 0.53976422 0.54659028] -> mean_train = 0.5426\n",
    "Test scores: [-0.05543219  0.1250431   0.2640586   0.1859917   0.05506732] -> mean_test = 0.1149\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.78213761 0.78802413 0.82398603 0.7461426  0.77420503] -> mean_train = 0.7829\n",
    "Test scores: [-0.17832807  0.17922449 -0.82818129  0.17095727 -0.17155348] -> mean_test = -0.1656\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.65240063 0.81298679 0.85650392 0.80202072 0.81944741] -> mean_train = 0.7887\n",
    "Test scores: [-0.3428903   0.13659494 -6.15435645  0.14391498 -0.25913343] -> mean_test = -1.2952\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6784a-af1b-4d05-8eef-846d2b503d79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.31830325 0.31392415 0.31633945 0.31182916 0.3066358 ] -> mean_train = 0.3134\n",
    "Test scores: [0.27919092 0.29974493 0.29115746 0.30118958 0.33140716] -> mean_test = 0.3005\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.39371228 0.38799135 0.39360352 0.39383614 0.39987173] -> mean_train = 0.3938\n",
    "Test scores: [0.38300769 0.35232374 0.37767527 0.37743098 0.35830092] -> mean_test = 0.3697\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.42371335 0.4146264  0.42294396 0.42536268 0.42076352] -> mean_train = 0.4215\n",
    "Test scores: [0.37103912 0.37512818 0.38437575 0.3865769  0.40484428] -> mean_test = 0.3844\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.43373677 0.43318539 0.43969612 0.43861505 0.43600294] -> mean_train = 0.4362\n",
    "Test scores: [0.41054996 0.3655078  0.38919964 0.39444717 0.36578661] -> mean_test = 0.3851\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.86762202 0.86455812 0.86756847 0.8654831  0.86635326] -> mean_train = 0.8663\n",
    "Test scores: [0.46893692 0.47474253 0.47183767 0.47635708 0.46603657] -> mean_test = 0.4716\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.86865287 0.8708922  0.86909876 0.86407208 0.87073908] -> mean_train = 0.8687\n",
    "Test scores: [0.48321788 0.4651082  0.48409388 0.51644364 0.45168042] -> mean_test = 0.4801\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.86692848 0.86931937 0.86943738 0.86686052 0.87293123] -> mean_train = 0.8691\n",
    "Test scores: [0.4851075  0.48528567 0.49189294 0.52378137 0.46479614] -> mean_test = 0.4902\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.86701671 0.86933204 0.87158342 0.86787022 0.87067643] -> mean_train = 0.8693\n",
    "Test scores: [0.50926646 0.47984863 0.4709283  0.48995825 0.4742135 ] -> mean_test = 0.4848\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.27768877 0.28164607 0.27543778 0.28223729 0.27169098] -> mean_train = 0.2777\n",
    "Test scores: [0.27372642 0.26373777 0.28260736 0.2527845  0.28642668] -> mean_test = 0.2719\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.26833298 0.26359706 0.26154189 0.26092158 0.27139692] -> mean_train = 0.2652\n",
    "Test scores: [0.25027263 0.26140355 0.27630936 0.2633784  0.24690274] -> mean_test = 0.2597\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.25604641 0.2557586  0.2542764  0.26941398 0.26639608] -> mean_train = 0.2604\n",
    "Test scores: [0.26574554 0.25771847 0.27268954 0.23138731 0.24560992] -> mean_test = 0.2546\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.25269249 0.25810787 0.25484969 0.25800937 0.26009149] -> mean_train = 0.2568\n",
    "Test scores: [0.25179683 0.25459869 0.26067716 0.24756907 0.23981551] -> mean_test = 0.2509\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.52105186 0.51666136 0.51690926 0.52675541 0.52715188] -> mean_train = 0.5217\n",
    "Test scores: [0.43688842 0.45549741 0.42600597 0.45694164 0.44466639] -> mean_test = 0.4440\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.46204741 0.49887642 0.4694671  0.45133553 0.50712451] -> mean_train = 0.4778\n",
    "Test scores: [0.42765406 0.46299803 0.43444477 0.43355555 0.45313489] -> mean_test = 0.4424\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.50828932 0.48730197 0.53997773 0.52672009 0.51295359] -> mean_train = 0.5150\n",
    "Test scores: [0.48259759 0.42385795 0.48960782 0.47330764 0.47066749] -> mean_test = 0.4680\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.55768337 0.53201379 0.57710713 0.54583701 0.53376656] -> mean_train = 0.5493\n",
    "Test scores: [0.50072421 0.44872076 0.47927216 0.48096196 0.48445523] -> mean_test = 0.4788\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.30878064 0.31747994 0.2821283  0.33309379 0.30994882] -> mean_train = 0.3103\n",
    "Test scores: [0.31653165 0.28572524 0.27650359 0.31991506 0.28990877] -> mean_test = 0.2977\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.31737068 0.33604038 0.30093692 0.30342464 0.29648123] -> mean_train = 0.3109\n",
    "Test scores: [0.3274757  0.33384534 0.29182668 0.27977979 0.28082602] -> mean_test = 0.3028\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.31718018 0.28876691 0.30003358 0.29836457 0.32519596] -> mean_train = 0.3059\n",
    "Test scores: [0.29306934 0.26952092 0.28428521 0.30487058 0.31365367] -> mean_test = 0.2931\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.28814453 0.30092214 0.32320997 0.28723039 0.34017101] -> mean_train = 0.3079\n",
    "Test scores: [0.26270269 0.30130176 0.30585807 0.27255919 0.32357272] -> mean_test = 0.2932\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.61760073 0.61823471 0.62163874 0.62513078 0.62371354] -> mean_train = 0.6213\n",
    "Test scores: [0.52983723 0.53351532 0.51879814 0.49154409 0.50710966] -> mean_test = 0.5162\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.65205709 0.64711572 0.64902128 0.65037379 0.65255898] -> mean_train = 0.6502\n",
    "Test scores: [0.52083674 0.54288122 0.55053516 0.52329081 0.5269    ] -> mean_test = 0.5329\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.6641068  0.66170629 0.66909358 0.64717522 0.66185312] -> mean_train = 0.6608\n",
    "Test scores: [0.5458077  0.55594568 0.51133182 0.54347462 0.54799937] -> mean_test = 0.5409\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.66427657 0.66246132 0.65999607 0.66341141 0.67036066] -> mean_train = 0.6641\n",
    "Test scores: [0.54249578 0.54910128 0.52700264 0.54868719 0.52947596] -> mean_test = 0.5394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32293ce6-597d-40f9-a8b4-d9bcbf06671f",
   "metadata": {},
   "source": [
    "<b>Pearson</b> (further testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25586e2a-f437-4ee5-be32-ecd60fa5a41c",
   "metadata": {},
   "source": [
    "Novos testes para um novo modelo (<b>KNeighborsRegressor</b>) e para uma gama de features distinta da anterior (para os modelos <b>SVR</b>, <b>MLPRegressor</b> e <b>HistGradientBoostingRegressor</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "042156fd-b2f6-4b19-b465-da540458166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for KNeighborsRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.58503702 0.58997743 0.59379933 0.58816645 0.58779664] -> mean_train = 0.5890\n",
      "Test scores: [0.3928789  0.36819901 0.36770372 0.38222477 0.39573199] -> mean_test = 0.3813\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.61136161 0.60893551 0.60805813 0.61107387 0.60937698] -> mean_train = 0.6098\n",
      "Test scores: [0.41522946 0.427479   0.40978524 0.41295209 0.41445057] -> mean_test = 0.4160\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.61533186 0.61624814 0.61941333 0.6153637  0.62533147] -> mean_train = 0.6183\n",
      "Test scores: [0.43304784 0.4479805  0.43914913 0.43093723 0.39303128] -> mean_test = 0.4288\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.6232438  0.6171689  0.62247578 0.61839789 0.62404356] -> mean_train = 0.6211\n",
      "Test scores: [0.41433254 0.43647186 0.4307311  0.4435146  0.42248312] -> mean_test = 0.4295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=KNR(), method=\"Pearson correlation\", corrs=pearson_corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d328182-3745-4e7c-be32-260198b7c5ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for KNeighborsRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.58503702 0.58997743 0.59379933 0.58816645 0.58779664] -> mean_train = 0.5890\n",
    "Test scores: [0.3928789  0.36819901 0.36770372 0.38222477 0.39573199] -> mean_test = 0.3813\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.61136161 0.60893551 0.60805813 0.61107387 0.60937698] -> mean_train = 0.6098\n",
    "Test scores: [0.41522946 0.427479   0.40978524 0.41295209 0.41445057] -> mean_test = 0.4160\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.61533186 0.61624814 0.61941333 0.6153637  0.62533147] -> mean_train = 0.6183\n",
    "Test scores: [0.43304784 0.4479805  0.43914913 0.43093723 0.39303128] -> mean_test = 0.4288\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.6232438  0.6171689  0.62247578 0.61839789 0.62404356] -> mean_train = 0.6211\n",
    "Test scores: [0.41433254 0.43647186 0.4307311  0.4435146  0.42248312] -> mean_test = 0.4295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e70e8d9-f390-421a-af19-b18bc6c407de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for SVR using Pearson correlation to select features...\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.25385633 0.24365601 0.24720895 0.2442057  0.25017659] -> mean_train = 0.2478\n",
      "Test scores: [0.22252446 0.23985421 0.24987935 0.2456937  0.24385969] -> mean_test = 0.2404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=SVR(), method=\"Pearson correlation\", corrs=pearson_corrs, num_feats=[2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595ca00-3bd1-4027-ba34-a5b690d244d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for SVR using Pearson correlation to select features...\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.25385633 0.24365601 0.24720895 0.2442057  0.25017659] -> mean_train = 0.2478\n",
    "Test scores: [0.22252446 0.23985421 0.24987935 0.2456937  0.24385969] -> mean_test = 0.2404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37b20309-bb1a-4a43-9a3d-4fff5ec4a8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for MLPRegressor using Pearson correlation to select features...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1000 best features\n",
      "Train scores: [0.56490654 0.55768887 0.55608917 0.55828499 0.52461717] -> mean_train = 0.5523\n",
      "Test scores: [0.46331716 0.46617747 0.48015719 0.49865836 0.47098379] -> mean_test = 0.4759\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1200 best features\n",
      "Train scores: [0.60046975 0.62332129 0.58112659 0.60393118 0.58597108] -> mean_train = 0.5990\n",
      "Test scores: [0.46578919 0.49174316 0.497005   0.47763045 0.49677766] -> mean_test = 0.4858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=MLPR(), method=\"Pearson correlation\", corrs=pearson_corrs, num_feats=[1000, 1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dbcdbc-0d48-4125-8b3a-eb0695cbbfb7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for MLPRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.56490654 0.55768887 0.55608917 0.55828499 0.52461717] -> mean_train = 0.5523\n",
    "Test scores: [0.46331716 0.46617747 0.48015719 0.49865836 0.47098379] -> mean_test = 0.4759\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.60046975 0.62332129 0.58112659 0.60393118 0.58597108] -> mean_train = 0.5990\n",
    "Test scores: [0.46578919 0.49174316 0.497005   0.47763045 0.49677766] -> mean_test = 0.4858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d32bc681-3c20-4137-9bba-4b133540f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for HistGradientBoostingRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.66663238 0.66909042 0.66829338 0.64459554 0.64295293] -> mean_train = 0.6583\n",
      "Test scores: [0.5530253  0.53940209 0.53295276 0.53978152 0.52986614] -> mean_test = 0.5390\n",
      "\n",
      "Results for 900 best features\n",
      "Train scores: [0.65743789 0.66979245 0.66498664 0.6695574  0.66648605] -> mean_train = 0.6657\n",
      "Test scores: [0.52125799 0.53635422 0.54399451 0.55205156 0.55057303] -> mean_test = 0.5408\n",
      "\n",
      "Results for 1000 best features\n",
      "Train scores: [0.66787554 0.67396278 0.67286435 0.66773249 0.66925989] -> mean_train = 0.6703\n",
      "Test scores: [0.54568328 0.52206459 0.53540264 0.55007844 0.54338797] -> mean_test = 0.5393\n",
      "\n",
      "Results for 1100 best features\n",
      "Train scores: [0.69352346 0.6948638  0.68931223 0.69610607 0.68214437] -> mean_train = 0.6912\n",
      "Test scores: [0.57321944 0.57223914 0.59692036 0.55132183 0.55748441] -> mean_test = 0.5702\n",
      "\n",
      "Results for 1200 best features\n",
      "Train scores: [0.69206243 0.69502702 0.69416212 0.69338847 0.6969137 ] -> mean_train = 0.6943\n",
      "Test scores: [0.57839476 0.57089618 0.58192688 0.57475982 0.55218899] -> mean_test = 0.5716\n",
      "\n",
      "Results for 1300 best features\n",
      "Train scores: [0.69576919 0.69370551 0.69591981 0.69425998 0.67655226] -> mean_train = 0.6912\n",
      "Test scores: [0.5726625  0.57750318 0.56965538 0.57275846 0.56328342] -> mean_test = 0.5712\n",
      "\n",
      "Results for 1400 best features\n",
      "Train scores: [0.6912309  0.69517008 0.69510343 0.69311147 0.68308284] -> mean_train = 0.6915\n",
      "Test scores: [0.5802304  0.56588862 0.56999854 0.57888254 0.54718202] -> mean_test = 0.5684\n",
      "\n",
      "Results for 1500 best features\n",
      "Train scores: [0.69648327 0.69624902 0.69995392 0.69291142 0.68118336] -> mean_train = 0.6934\n",
      "Test scores: [0.56878518 0.56883332 0.55616613 0.59378321 0.58255785] -> mean_test = 0.5740\n",
      "\n",
      "Results for 1600 best features\n",
      "Train scores: [0.69645181 0.65683526 0.70009776 0.69207575 0.69738217] -> mean_train = 0.6886\n",
      "Test scores: [0.55683351 0.57472355 0.55793864 0.58730223 0.57331733] -> mean_test = 0.5700\n",
      "\n",
      "Results for 1700 best features\n",
      "Train scores: [0.68402266 0.67682186 0.69298539 0.69737798 0.69693916] -> mean_train = 0.6896\n",
      "Test scores: [0.59166452 0.55001258 0.57317637 0.55063248 0.56945549] -> mean_test = 0.5670\n",
      "\n",
      "Results for 1800 best features\n",
      "Train scores: [0.69636665 0.69543724 0.6926872  0.69620411 0.69621706] -> mean_train = 0.6954\n",
      "Test scores: [0.56216641 0.57699126 0.56875645 0.57260295 0.5738527 ] -> mean_test = 0.5709\n",
      "\n",
      "Results for 1900 best features\n",
      "Train scores: [0.69199944 0.69749367 0.69985996 0.69853    0.69549178] -> mean_train = 0.6967\n",
      "Test scores: [0.5899744  0.56577578 0.5450411  0.5664836  0.57838029] -> mean_test = 0.5691\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.69645712 0.67113174 0.69395222 0.69647604 0.6989796 ] -> mean_train = 0.6914\n",
      "Test scores: [0.57832126 0.58382683 0.57307968 0.57548771 0.5519819 ] -> mean_test = 0.5725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=HGBR(), method=\"Pearson correlation\", corrs=pearson_corrs, num_feats=range(800, 2001, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875ef8c-bff5-49db-bf40-1082b60c5830",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.66663238 0.66909042 0.66829338 0.64459554 0.64295293] -> mean_train = 0.6583\n",
    "Test scores: [0.5530253  0.53940209 0.53295276 0.53978152 0.52986614] -> mean_test = 0.5390\n",
    "\n",
    "Results for 900 best features\n",
    "Train scores: [0.65743789 0.66979245 0.66498664 0.6695574  0.66648605] -> mean_train = 0.6657\n",
    "Test scores: [0.52125799 0.53635422 0.54399451 0.55205156 0.55057303] -> mean_test = 0.5408\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.66787554 0.67396278 0.67286435 0.66773249 0.66925989] -> mean_train = 0.6703\n",
    "Test scores: [0.54568328 0.52206459 0.53540264 0.55007844 0.54338797] -> mean_test = 0.5393\n",
    "\n",
    "Results for 1100 best features\n",
    "Train scores: [0.69352346 0.6948638  0.68931223 0.69610607 0.68214437] -> mean_train = 0.6912\n",
    "Test scores: [0.57321944 0.57223914 0.59692036 0.55132183 0.55748441] -> mean_test = 0.5702\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.69206243 0.69502702 0.69416212 0.69338847 0.6969137 ] -> mean_train = 0.6943\n",
    "Test scores: [0.57839476 0.57089618 0.58192688 0.57475982 0.55218899] -> mean_test = 0.5716\n",
    "\n",
    "Results for 1300 best features\n",
    "Train scores: [0.69576919 0.69370551 0.69591981 0.69425998 0.67655226] -> mean_train = 0.6912\n",
    "Test scores: [0.5726625  0.57750318 0.56965538 0.57275846 0.56328342] -> mean_test = 0.5712\n",
    "\n",
    "Results for 1400 best features\n",
    "Train scores: [0.6912309  0.69517008 0.69510343 0.69311147 0.68308284] -> mean_train = 0.6915\n",
    "Test scores: [0.5802304  0.56588862 0.56999854 0.57888254 0.54718202] -> mean_test = 0.5684\n",
    "\n",
    "Results for 1500 best features\n",
    "Train scores: [0.69648327 0.69624902 0.69995392 0.69291142 0.68118336] -> mean_train = 0.6934\n",
    "Test scores: [0.56878518 0.56883332 0.55616613 0.59378321 0.58255785] -> mean_test = 0.5740\n",
    "\n",
    "Results for 1600 best features\n",
    "Train scores: [0.69645181 0.65683526 0.70009776 0.69207575 0.69738217] -> mean_train = 0.6886\n",
    "Test scores: [0.55683351 0.57472355 0.55793864 0.58730223 0.57331733] -> mean_test = 0.5700\n",
    "\n",
    "Results for 1700 best features\n",
    "Train scores: [0.68402266 0.67682186 0.69298539 0.69737798 0.69693916] -> mean_train = 0.6896\n",
    "Test scores: [0.59166452 0.55001258 0.57317637 0.55063248 0.56945549] -> mean_test = 0.5670\n",
    "\n",
    "Results for 1800 best features\n",
    "Train scores: [0.69636665 0.69543724 0.6926872  0.69620411 0.69621706] -> mean_train = 0.6954\n",
    "Test scores: [0.56216641 0.57699126 0.56875645 0.57260295 0.5738527 ] -> mean_test = 0.5709\n",
    "\n",
    "Results for 1900 best features\n",
    "Train scores: [0.69199944 0.69749367 0.69985996 0.69853    0.69549178] -> mean_train = 0.6967\n",
    "Test scores: [0.5899744  0.56577578 0.5450411  0.5664836  0.57838029] -> mean_test = 0.5691\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.69645712 0.67113174 0.69395222 0.69647604 0.6989796 ] -> mean_train = 0.6914\n",
    "Test scores: [0.57832126 0.58382683 0.57307968 0.57548771 0.5519819 ] -> mean_test = 0.5725"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6297b9a-6268-4433-b3af-6d56498ce72d",
   "metadata": {},
   "source": [
    "Para este mÃ©todo de seleÃ§Ã£o de features (<b>correlaÃ§Ã£o de Pearson</b>) obtivemos um score mÃ¡ximo de <b>0.5740</b> para a combinaÃ§Ã£o <b>HistGradientBoostingRegressor / 1500 features</b>. No entanto, selecionÃ¡mos a combinaÃ§Ã£o <b>HistGradientBoostingRegressor / 1200 features </b> por se encontrar numa regiÃ£o mais estÃ¡vel no espaÃ§o de procura do nÃºmero de features Ã³timo. Neste caso, o score obtido foi <b>0.5716</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aba4df-9491-439c-a2f9-185237f4cac4",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca67e625-89da-4e16-a524-be56c7afb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings -> MLPR related\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0042a47-91d1-4508-9b9b-bd500b38bb57",
   "metadata": {},
   "source": [
    "<b>Spearman</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1d76400-cfd1-471f-bee0-c1a2df54e35e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.30276032 0.30999642 0.29627182 0.30485768 0.30062867] -> mean_train = 0.3029\n",
      "Test scores: [0.29231614 0.26266536 0.31845467 0.28441096 0.30099507] -> mean_test = 0.2918\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.38744808 0.38428109 0.3826784  0.33979449 0.38501327] -> mean_train = 0.3758\n",
      "Test scores: [0.3538583  0.36657723 0.33417186 0.30842076 0.36367539] -> mean_test = 0.3453\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.41855357 0.41669686 0.41262532 0.41615306 0.42218293] -> mean_train = 0.4172\n",
      "Test scores: [0.37755745 0.38235578 0.39904554 0.39122124 0.34962146] -> mean_test = 0.3800\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.43666678 0.42842225 0.43421242 0.43776558 0.43959521] -> mean_train = 0.4353\n",
      "Test scores: [0.39523955 0.38230352 0.37197668 0.39334337 0.39326577] -> mean_test = 0.3872\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for KNeighborsRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.58144722 0.56791155 0.57262067 0.57422373 0.57555677] -> mean_train = 0.5744\n",
      "Test scores: [0.34116207 0.38116106 0.36167522 0.36244282 0.34761941] -> mean_test = 0.3588\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.60354152 0.60200782 0.6085737  0.60455412 0.59745753] -> mean_train = 0.6032\n",
      "Test scores: [0.41038186 0.41923013 0.36877787 0.39774969 0.43388593] -> mean_test = 0.4060\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.61668517 0.61529299 0.61350762 0.61218549 0.62025389] -> mean_train = 0.6156\n",
      "Test scores: [0.40996733 0.42958298 0.45250813 0.42477277 0.39997428] -> mean_test = 0.4234\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.60642041 0.60735275 0.61471306 0.60815288 0.61213709] -> mean_train = 0.6098\n",
      "Test scores: [0.42858132 0.42051792 0.41496123 0.4170616  0.42208561] -> mean_test = 0.4206\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for RandomForestRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.86286666 0.86327227 0.86515871 0.86526029 0.86058221] -> mean_train = 0.8634\n",
      "Test scores: [0.45806815 0.45428154 0.43739402 0.44168913 0.47137121] -> mean_test = 0.4526\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.86659924 0.86960868 0.8664068  0.87180788 0.86824758] -> mean_train = 0.8685\n",
      "Test scores: [0.50130257 0.48736882 0.50682832 0.46481167 0.47564835] -> mean_test = 0.4872\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.87154669 0.86740715 0.8687975  0.86999956 0.86789773] -> mean_train = 0.8691\n",
      "Test scores: [0.47269618 0.49320745 0.49477457 0.49530748 0.48645884] -> mean_test = 0.4885\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.86992188 0.86863113 0.86980674 0.86922954 0.86885264] -> mean_train = 0.8693\n",
      "Test scores: [0.47346002 0.48232316 0.49540531 0.48162644 0.48545635] -> mean_test = 0.4837\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for SVR using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.27542999 0.2723476  0.27631393 0.2772708  0.28241463] -> mean_train = 0.2768\n",
      "Test scores: [0.28283144 0.28564874 0.25955313 0.26985495 0.2524273 ] -> mean_test = 0.2701\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.25050722 0.24563219 0.24316983 0.24466171 0.25483817] -> mean_train = 0.2478\n",
      "Test scores: [0.22647406 0.24715775 0.24966636 0.2546818  0.23105567] -> mean_test = 0.2418\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.24899087 0.24717708 0.24506422 0.24771682 0.24762889] -> mean_train = 0.2473\n",
      "Test scores: [0.24235095 0.22966731 0.26202853 0.2312249  0.24195584] -> mean_test = 0.2414\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.24881949 0.26274852 0.25277209 0.25090909 0.25622489] -> mean_train = 0.2543\n",
      "Test scores: [0.26830012 0.2200019  0.24973791 0.26164309 0.24226996] -> mean_test = 0.2484\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for MLPRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.55277466 0.55306357 0.54210614 0.47871056 0.58166296] -> mean_train = 0.5417\n",
      "Test scores: [0.43527307 0.42055891 0.43856691 0.32758635 0.40498687] -> mean_test = 0.4054\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.52406768 0.53170162 0.55011785 0.52939447 0.50005963] -> mean_train = 0.5271\n",
      "Test scores: [0.47915438 0.47292983 0.48500241 0.46352347 0.45960753] -> mean_test = 0.4720\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.5295686  0.48546583 0.52897515 0.53093441 0.51876645] -> mean_train = 0.5187\n",
      "Test scores: [0.46535184 0.44473846 0.46850541 0.4922603  0.44927276] -> mean_test = 0.4640\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.53871824 0.55747297 0.56545089 0.51894987 0.56946029] -> mean_train = 0.5500\n",
      "Test scores: [0.47679662 0.48825781 0.4961454  0.43920372 0.47527757] -> mean_test = 0.4751\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for AdaBoostRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.27077418 0.28118372 0.28132986 0.27185248 0.28699682] -> mean_train = 0.2784\n",
      "Test scores: [0.29456676 0.27699162 0.2566113  0.24467112 0.27629458] -> mean_test = 0.2698\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.30250501 0.29647762 0.32411476 0.34112609 0.29839447] -> mean_train = 0.3125\n",
      "Test scores: [0.29654511 0.28648838 0.30943204 0.32816846 0.28505545] -> mean_test = 0.3011\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.27707697 0.29286917 0.29149421 0.27581087 0.30896063] -> mean_train = 0.2892\n",
      "Test scores: [0.27402579 0.28327587 0.25670492 0.27295977 0.29208173] -> mean_test = 0.2758\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.29183765 0.2888603  0.30779433 0.28695369 0.31408741] -> mean_train = 0.2979\n",
      "Test scores: [0.25761796 0.29439967 0.29200319 0.28608114 0.30552038] -> mean_test = 0.2871\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.60516408 0.5987729  0.60463261 0.60686439 0.60086074] -> mean_train = 0.6033\n",
      "Test scores: [0.49752306 0.51061865 0.49868967 0.50033296 0.52337996] -> mean_test = 0.5061\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.65131722 0.64860272 0.64927219 0.65068186 0.6526421 ] -> mean_train = 0.6505\n",
      "Test scores: [0.53977152 0.53134494 0.54185351 0.54044321 0.52402806] -> mean_test = 0.5355\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.66156741 0.65808232 0.6616351  0.65506371 0.6288157 ] -> mean_train = 0.6530\n",
      "Test scores: [0.53542535 0.54794698 0.51950571 0.53169638 0.55002214] -> mean_test = 0.5369\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.66139306 0.64139385 0.65894965 0.66316064 0.66545993] -> mean_train = 0.6581\n",
      "Test scores: [0.53807847 0.52731971 0.5485689  0.54767644 0.52776092] -> mean_test = 0.5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, Model in enumerate([LR, KNR, RFR, SVR, MLPR, ADA, HGBR]):\n",
    "    test_corr_models(model=Model(), method=\"Spearman correlation\", corrs=spearman_corrs)\n",
    "    if i < 6:\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda8abca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(BEFORE UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.24921425 0.27093374 0.19917184 0.24836267 0.25260701] -> mean_train = 0.2441\n",
    "Test scores: [0.12833164 0.08071247 0.30922312 0.16954245 0.07740915] -> mean_test = 0.1530\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.4025985  0.38290001 0.36831767 0.39148884 0.40252618] -> mean_train = 0.3896\n",
    "Test scores: [ 0.11624326  0.23527244  0.35650679  0.27089772 -0.14652723] -> mean_test = 0.1665\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.44845567 0.43248325 0.4326496  0.44199982 0.45568573] -> mean_train = 0.4423\n",
    "Test scores: [0.16300762 0.30164229 0.31059724 0.31290982 0.07484427] -> mean_test = 0.2326\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.48010521 0.45825764 0.46333424 0.45450236 0.47633618] -> mean_train = 0.4665\n",
    "Test scores: [0.10893423 0.28829533 0.29607386 0.27848742 0.10913831] -> mean_test = 0.2162\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.79790694 0.81899067 0.83845994 0.79660533 0.8045238 ] -> mean_train = 0.8113\n",
    "Test scores: [ 0.18483478  0.15368858 -0.25720172  0.2958112   0.21631886] -> mean_test = 0.1187\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.8474152  0.86798361 0.87595374 0.84598044 0.85213325] -> mean_train = 0.8579\n",
    "Test scores: [0.22281325 0.31339996 0.18994458 0.37560868 0.32661866] -> mean_test = 0.2857\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.8477982  0.86835485 0.87645327 0.84625799 0.85241732] -> mean_train = 0.8583\n",
    "Test scores: [0.24889581 0.34326805 0.16376661 0.37541566 0.31084247] -> mean_test = 0.2884\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.84772302 0.86877618 0.87635444 0.84619647 0.85224971] -> mean_train = 0.8583\n",
    "Test scores: [0.25188013 0.34737981 0.19047434 0.37756621 0.29847012] -> mean_test = 0.2932\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.24821102 0.25230277 0.21134905 0.21002211 0.23393682] -> mean_train = 0.2312\n",
    "Test scores: [0.1175337  0.03529187 0.08088012 0.16061473 0.14581597] -> mean_test = 0.1080\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.29865158 0.31315385 0.25569119 0.33387219 0.32322424] -> mean_train = 0.3049\n",
    "Test scores: [0.07679387 0.17580784 0.10835713 0.28114289 0.21491714] -> mean_test = 0.1714\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.3076953  0.3517414  0.32845105 0.34109796 0.31832754] -> mean_train = 0.3295\n",
    "Test scores: [0.08846429 0.20249093 0.13341789 0.27885762 0.17941891] -> mean_test = 0.1765\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.31154677 0.30782744 0.27839546 0.29130889 0.32315659] -> mean_train = 0.3024\n",
    "Test scores: [0.11880103 0.18370943 0.11145375 0.21734129 0.174815  ] -> mean_test = 0.1612\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.30884939 0.32273583 0.30089287 0.3053253  0.31058927] -> mean_train = 0.3097\n",
    "Test scores: [0.21621466 0.12125812 0.1112789  0.25380752 0.23638237] -> mean_test = 0.1878\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.26754801 0.25625888 0.22697208 0.25103663 0.26315251] -> mean_train = 0.2530\n",
    "Test scores: [0.1723757  0.13718039 0.25440779 0.20893442 0.17647675] -> mean_test = 0.1899\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.27200646 0.25702211 0.23535592 0.25894348 0.27205739] -> mean_train = 0.2591\n",
    "Test scores: [0.18259951 0.14574259 0.21460884 0.20840586 0.16562045] -> mean_test = 0.1834\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.27213732 0.25572714 0.23750669 0.25962499 0.27161214] -> mean_train = 0.2593\n",
    "Test scores: [0.17233394 0.13768511 0.17746137 0.19825448 0.15705791] -> mean_test = 0.1686\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.46308    0.43662746 0.44424994 0.43677552 0.44358956] -> mean_train = 0.4449\n",
    "Test scores: [ 0.03581221  0.13530282 -0.8988539   0.23407946  0.05936877] -> mean_test = -0.0869\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.52548503 0.5186544  0.55516421 0.52769569 0.44315011] -> mean_train = 0.5140\n",
    "Test scores: [0.25086634 0.37064945 0.35341974 0.34305033 0.11683819] -> mean_test = 0.2870\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.56269636 0.57803714 0.55488283 0.5593286  0.52405762] -> mean_train = 0.5558\n",
    "Test scores: [0.15751221 0.37946022 0.29111232 0.37348009 0.30562286] -> mean_test = 0.3014\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.59737034 0.55466742 0.59562882 0.5875031  0.53883696] -> mean_train = 0.5748\n",
    "Test scores: [0.19248025 0.32994159 0.20769372 0.32922724 0.26530933] -> mean_test = 0.2649"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d660ab4b-464a-42da-8dde-5336b6df14f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.30276032 0.30999642 0.29627182 0.30485768 0.30062867] -> mean_train = 0.3029\n",
    "Test scores: [0.29231614 0.26266536 0.31845467 0.28441096 0.30099507] -> mean_test = 0.2918\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.38744808 0.38428109 0.3826784  0.33979449 0.38501327] -> mean_train = 0.3758\n",
    "Test scores: [0.3538583  0.36657723 0.33417186 0.30842076 0.36367539] -> mean_test = 0.3453\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.41855357 0.41669686 0.41262532 0.41615306 0.42218293] -> mean_train = 0.4172\n",
    "Test scores: [0.37755745 0.38235578 0.39904554 0.39122124 0.34962146] -> mean_test = 0.3800\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.43666678 0.42842225 0.43421242 0.43776558 0.43959521] -> mean_train = 0.4353\n",
    "Test scores: [0.39523955 0.38230352 0.37197668 0.39334337 0.39326577] -> mean_test = 0.3872\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for KNeighborsRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.58144722 0.56791155 0.57262067 0.57422373 0.57555677] -> mean_train = 0.5744\n",
    "Test scores: [0.34116207 0.38116106 0.36167522 0.36244282 0.34761941] -> mean_test = 0.3588\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.60354152 0.60200782 0.6085737  0.60455412 0.59745753] -> mean_train = 0.6032\n",
    "Test scores: [0.41038186 0.41923013 0.36877787 0.39774969 0.43388593] -> mean_test = 0.4060\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.61668517 0.61529299 0.61350762 0.61218549 0.62025389] -> mean_train = 0.6156\n",
    "Test scores: [0.40996733 0.42958298 0.45250813 0.42477277 0.39997428] -> mean_test = 0.4234\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.60642041 0.60735275 0.61471306 0.60815288 0.61213709] -> mean_train = 0.6098\n",
    "Test scores: [0.42858132 0.42051792 0.41496123 0.4170616  0.42208561] -> mean_test = 0.4206\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.86286666 0.86327227 0.86515871 0.86526029 0.86058221] -> mean_train = 0.8634\n",
    "Test scores: [0.45806815 0.45428154 0.43739402 0.44168913 0.47137121] -> mean_test = 0.4526\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.86659924 0.86960868 0.8664068  0.87180788 0.86824758] -> mean_train = 0.8685\n",
    "Test scores: [0.50130257 0.48736882 0.50682832 0.46481167 0.47564835] -> mean_test = 0.4872\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.87154669 0.86740715 0.8687975  0.86999956 0.86789773] -> mean_train = 0.8691\n",
    "Test scores: [0.47269618 0.49320745 0.49477457 0.49530748 0.48645884] -> mean_test = 0.4885\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.86992188 0.86863113 0.86980674 0.86922954 0.86885264] -> mean_train = 0.8693\n",
    "Test scores: [0.47346002 0.48232316 0.49540531 0.48162644 0.48545635] -> mean_test = 0.4837\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.27542999 0.2723476  0.27631393 0.2772708  0.28241463] -> mean_train = 0.2768\n",
    "Test scores: [0.28283144 0.28564874 0.25955313 0.26985495 0.2524273 ] -> mean_test = 0.2701\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.25050722 0.24563219 0.24316983 0.24466171 0.25483817] -> mean_train = 0.2478\n",
    "Test scores: [0.22647406 0.24715775 0.24966636 0.2546818  0.23105567] -> mean_test = 0.2418\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.24899087 0.24717708 0.24506422 0.24771682 0.24762889] -> mean_train = 0.2473\n",
    "Test scores: [0.24235095 0.22966731 0.26202853 0.2312249  0.24195584] -> mean_test = 0.2414\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.24881949 0.26274852 0.25277209 0.25090909 0.25622489] -> mean_train = 0.2543\n",
    "Test scores: [0.26830012 0.2200019  0.24973791 0.26164309 0.24226996] -> mean_test = 0.2484\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.55277466 0.55306357 0.54210614 0.47871056 0.58166296] -> mean_train = 0.5417\n",
    "Test scores: [0.43527307 0.42055891 0.43856691 0.32758635 0.40498687] -> mean_test = 0.4054\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.52406768 0.53170162 0.55011785 0.52939447 0.50005963] -> mean_train = 0.5271\n",
    "Test scores: [0.47915438 0.47292983 0.48500241 0.46352347 0.45960753] -> mean_test = 0.4720\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.5295686  0.48546583 0.52897515 0.53093441 0.51876645] -> mean_train = 0.5187\n",
    "Test scores: [0.46535184 0.44473846 0.46850541 0.4922603  0.44927276] -> mean_test = 0.4640\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.53871824 0.55747297 0.56545089 0.51894987 0.56946029] -> mean_train = 0.5500\n",
    "Test scores: [0.47679662 0.48825781 0.4961454  0.43920372 0.47527757] -> mean_test = 0.4751\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.27077418 0.28118372 0.28132986 0.27185248 0.28699682] -> mean_train = 0.2784\n",
    "Test scores: [0.29456676 0.27699162 0.2566113  0.24467112 0.27629458] -> mean_test = 0.2698\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.30250501 0.29647762 0.32411476 0.34112609 0.29839447] -> mean_train = 0.3125\n",
    "Test scores: [0.29654511 0.28648838 0.30943204 0.32816846 0.28505545] -> mean_test = 0.3011\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.27707697 0.29286917 0.29149421 0.27581087 0.30896063] -> mean_train = 0.2892\n",
    "Test scores: [0.27402579 0.28327587 0.25670492 0.27295977 0.29208173] -> mean_test = 0.2758\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.29183765 0.2888603  0.30779433 0.28695369 0.31408741] -> mean_train = 0.2979\n",
    "Test scores: [0.25761796 0.29439967 0.29200319 0.28608114 0.30552038] -> mean_test = 0.2871\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.60516408 0.5987729  0.60463261 0.60686439 0.60086074] -> mean_train = 0.6033\n",
    "Test scores: [0.49752306 0.51061865 0.49868967 0.50033296 0.52337996] -> mean_test = 0.5061\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.65131722 0.64860272 0.64927219 0.65068186 0.6526421 ] -> mean_train = 0.6505\n",
    "Test scores: [0.53977152 0.53134494 0.54185351 0.54044321 0.52402806] -> mean_test = 0.5355\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.66156741 0.65808232 0.6616351  0.65506371 0.6288157 ] -> mean_train = 0.6530\n",
    "Test scores: [0.53542535 0.54794698 0.51950571 0.53169638 0.55002214] -> mean_test = 0.5369\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.66139306 0.64139385 0.65894965 0.66316064 0.66545993] -> mean_train = 0.6581\n",
    "Test scores: [0.53807847 0.52731971 0.5485689  0.54767644 0.52776092] -> mean_test = 0.5379"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffe67f-bbe5-47c2-ac2a-fb8ead3b8127",
   "metadata": {},
   "source": [
    "<b>Spearman</b> (further testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb8a42-bbf8-48ce-ba85-155fe0cab687",
   "metadata": {},
   "source": [
    "Novos testes para uma gama de features distinta da anterior. Testes efetuados para o melhor modelo - <b>HistGradientBoostingRegressor</b> - e para o modelo <b>LinearRegression</b> (progresÃ£o de scores promissora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48f496d9-e076-4fcc-b1a1-8c73ff2b59b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using Spearman correlation to select features...\n",
      "\n",
      "Results for 900 best features\n",
      "Train scores: [0.44845659 0.44690669 0.45188674 0.44772917 0.4460683 ] -> mean_train = 0.4482\n",
      "Test scores: [0.37239857 0.40371682 0.36711783 0.40791929 0.41591596] -> mean_test = 0.3934\n",
      "\n",
      "Results for 1000 best features\n",
      "Train scores: [0.44677465 0.45609028 0.45454997 0.46056612 0.44835278] -> mean_train = 0.4533\n",
      "Test scores: [0.38473902 0.39825773 0.40052927 0.38249102 0.41902439] -> mean_test = 0.3970\n",
      "\n",
      "Results for 1100 best features\n",
      "Train scores: [0.45673772 0.46337917 0.45801098 0.45532306 0.46020887] -> mean_train = 0.4587\n",
      "Test scores: [0.39463812 0.37497419 0.41201434 0.42376544 0.39754653] -> mean_test = 0.4006\n",
      "\n",
      "Results for 1200 best features\n",
      "Train scores: [0.46731002 0.46380396 0.47062831 0.46190505 0.46045568] -> mean_train = 0.4648\n",
      "Test scores: [0.39199155 0.39522075 0.38187573 0.42181252 0.41388638] -> mean_test = 0.4010\n",
      "\n",
      "Results for 1300 best features\n",
      "Train scores: [0.47142267 0.46782679 0.46742981 0.46838148 0.46693459] -> mean_train = 0.4684\n",
      "Test scores: [0.39921763 0.38336105 0.41378528 0.40241595 0.41758455] -> mean_test = 0.4033\n",
      "\n",
      "Results for 1400 best features\n",
      "Train scores: [0.46847459 0.47484548 0.47232039 0.47313792 0.47524504] -> mean_train = 0.4728\n",
      "Test scores: [0.43056256 0.3855252  0.4116635  0.39009259 0.39527261] -> mean_test = 0.4026\n",
      "\n",
      "Results for 1500 best features\n",
      "Train scores: [0.47858775 0.47802305 0.46858288 0.47044577 0.47881881] -> mean_train = 0.4749\n",
      "Test scores: [0.38243632 0.3995922  0.42093709 0.40010573 0.37637554] -> mean_test = 0.3959\n",
      "\n",
      "Results for 1600 best features\n",
      "Train scores: [0.4858436  0.47689532 0.47976781 0.48110309 0.48202328] -> mean_train = 0.4811\n",
      "Test scores: [0.35896603 0.42488088 0.35953264 0.40529942 0.4013409 ] -> mean_test = 0.3900\n",
      "\n",
      "Results for 1700 best features\n",
      "Train scores: [0.48145071 0.48511768 0.48920228 0.48001406 0.48410548] -> mean_train = 0.4840\n",
      "Test scores: [0.41967937 0.39818969 0.39131978 0.41330345 0.3542309 ] -> mean_test = 0.3953\n",
      "\n",
      "Results for 1800 best features\n",
      "Train scores: [0.48788269 0.48986427 0.48178563 0.48823181 0.49033944] -> mean_train = 0.4876\n",
      "Test scores: [0.41527967 0.39016132 0.41973562 0.40783465 0.34565396] -> mean_test = 0.3957\n",
      "\n",
      "Results for 1900 best features\n",
      "Train scores: [0.49636614 0.48962182 0.49556593 0.48604723 0.49170334] -> mean_train = 0.4919\n",
      "Test scores: [0.36662858 0.36986296 0.39454486 0.43095738 0.4014067 ] -> mean_test = 0.3927\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.49159278 0.49793264 0.49522585 0.49662057 0.49429215] -> mean_train = 0.4951\n",
      "Test scores: [0.40642492 0.35235637 0.40593204 0.38819664 0.41421353] -> mean_test = 0.3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=LR(), method=\"Spearman correlation\", corrs=spearman_corrs, num_feats=range(900, 2001, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee720e6-318a-4b32-aa69-aac307918ad5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Spearman correlation to select features...\n",
    "\n",
    "Results for 900 best features\n",
    "Train scores: [0.44845659 0.44690669 0.45188674 0.44772917 0.4460683 ] -> mean_train = 0.4482\n",
    "Test scores: [0.37239857 0.40371682 0.36711783 0.40791929 0.41591596] -> mean_test = 0.3934\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.44677465 0.45609028 0.45454997 0.46056612 0.44835278] -> mean_train = 0.4533\n",
    "Test scores: [0.38473902 0.39825773 0.40052927 0.38249102 0.41902439] -> mean_test = 0.3970\n",
    "\n",
    "Results for 1100 best features\n",
    "Train scores: [0.45673772 0.46337917 0.45801098 0.45532306 0.46020887] -> mean_train = 0.4587\n",
    "Test scores: [0.39463812 0.37497419 0.41201434 0.42376544 0.39754653] -> mean_test = 0.4006\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.46731002 0.46380396 0.47062831 0.46190505 0.46045568] -> mean_train = 0.4648\n",
    "Test scores: [0.39199155 0.39522075 0.38187573 0.42181252 0.41388638] -> mean_test = 0.4010\n",
    "\n",
    "Results for 1300 best features\n",
    "Train scores: [0.47142267 0.46782679 0.46742981 0.46838148 0.46693459] -> mean_train = 0.4684\n",
    "Test scores: [0.39921763 0.38336105 0.41378528 0.40241595 0.41758455] -> mean_test = 0.4033\n",
    "\n",
    "Results for 1400 best features\n",
    "Train scores: [0.46847459 0.47484548 0.47232039 0.47313792 0.47524504] -> mean_train = 0.4728\n",
    "Test scores: [0.43056256 0.3855252  0.4116635  0.39009259 0.39527261] -> mean_test = 0.4026\n",
    "\n",
    "Results for 1500 best features\n",
    "Train scores: [0.47858775 0.47802305 0.46858288 0.47044577 0.47881881] -> mean_train = 0.4749\n",
    "Test scores: [0.38243632 0.3995922  0.42093709 0.40010573 0.37637554] -> mean_test = 0.3959\n",
    "\n",
    "Results for 1600 best features\n",
    "Train scores: [0.4858436  0.47689532 0.47976781 0.48110309 0.48202328] -> mean_train = 0.4811\n",
    "Test scores: [0.35896603 0.42488088 0.35953264 0.40529942 0.4013409 ] -> mean_test = 0.3900\n",
    "\n",
    "Results for 1700 best features\n",
    "Train scores: [0.48145071 0.48511768 0.48920228 0.48001406 0.48410548] -> mean_train = 0.4840\n",
    "Test scores: [0.41967937 0.39818969 0.39131978 0.41330345 0.3542309 ] -> mean_test = 0.3953\n",
    "\n",
    "Results for 1800 best features\n",
    "Train scores: [0.48788269 0.48986427 0.48178563 0.48823181 0.49033944] -> mean_train = 0.4876\n",
    "Test scores: [0.41527967 0.39016132 0.41973562 0.40783465 0.34565396] -> mean_test = 0.3957\n",
    "\n",
    "Results for 1900 best features\n",
    "Train scores: [0.49636614 0.48962182 0.49556593 0.48604723 0.49170334] -> mean_train = 0.4919\n",
    "Test scores: [0.36662858 0.36986296 0.39454486 0.43095738 0.4014067 ] -> mean_test = 0.3927\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.49159278 0.49793264 0.49522585 0.49662057 0.49429215] -> mean_train = 0.4951\n",
    "Test scores: [0.40642492 0.35235637 0.40593204 0.38819664 0.41421353] -> mean_test = 0.3934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96da6235-a27a-4703-9856-6484fd416aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for HistGradientBoostingRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 900 best features\n",
      "Train scores: [0.66640621 0.66761633 0.66318797 0.66438972 0.66299885] -> mean_train = 0.6649\n",
      "Test scores: [0.5385035  0.53013342 0.53696804 0.54630403 0.53912704] -> mean_test = 0.5382\n",
      "\n",
      "Results for 1000 best features\n",
      "Train scores: [0.66843968 0.66608647 0.66707098 0.67020146 0.65024564] -> mean_train = 0.6644\n",
      "Test scores: [0.54170773 0.53339188 0.55513566 0.52840985 0.54995223] -> mean_test = 0.5417\n",
      "\n",
      "Results for 1100 best features\n",
      "Train scores: [0.66817317 0.65897502 0.66969823 0.66850961 0.66736228] -> mean_train = 0.6665\n",
      "Test scores: [0.54798365 0.54820868 0.54489859 0.53689083 0.53303332] -> mean_test = 0.5422\n",
      "\n",
      "Results for 1200 best features\n",
      "Train scores: [0.66697576 0.67070654 0.67109184 0.67369563 0.66743542] -> mean_train = 0.6700\n",
      "Test scores: [0.56181496 0.53415526 0.54248205 0.5224809  0.55233844] -> mean_test = 0.5427\n",
      "\n",
      "Results for 1300 best features\n",
      "Train scores: [0.67069024 0.67527102 0.66286378 0.66742903 0.67396175] -> mean_train = 0.6700\n",
      "Test scores: [0.54450774 0.52375611 0.56018647 0.55024704 0.53476782] -> mean_test = 0.5427\n",
      "\n",
      "Results for 1400 best features\n",
      "Train scores: [0.67654191 0.66878745 0.66998537 0.67230986 0.66403637] -> mean_train = 0.6703\n",
      "Test scores: [0.52383477 0.54404493 0.55101852 0.53449349 0.54573617] -> mean_test = 0.5398\n",
      "\n",
      "Results for 1500 best features\n",
      "Train scores: [0.67044806 0.67563318 0.67118479 0.66868364 0.66982355] -> mean_train = 0.6712\n",
      "Test scores: [0.55567347 0.53332231 0.54208241 0.54953324 0.54846705] -> mean_test = 0.5458\n",
      "\n",
      "Results for 1600 best features\n",
      "Train scores: [0.67593141 0.67537575 0.67382011 0.64675993 0.67344937] -> mean_train = 0.6691\n",
      "Test scores: [0.53136766 0.53740612 0.55298813 0.5473727  0.54057805] -> mean_test = 0.5419\n",
      "\n",
      "Results for 1700 best features\n",
      "Train scores: [0.67209529 0.67042095 0.67559447 0.66762051 0.66367423] -> mean_train = 0.6699\n",
      "Test scores: [0.55008033 0.54208193 0.532531   0.54504007 0.52712765] -> mean_test = 0.5394\n",
      "\n",
      "Results for 1800 best features\n",
      "Train scores: [0.66989339 0.62961343 0.67362719 0.65298226 0.67519948] -> mean_train = 0.6603\n",
      "Test scores: [0.53343463 0.54984739 0.54449213 0.54810165 0.52855286] -> mean_test = 0.5409\n",
      "\n",
      "Results for 1900 best features\n",
      "Train scores: [0.6755778  0.66552389 0.67168683 0.67462481 0.65582312] -> mean_train = 0.6686\n",
      "Test scores: [0.53451847 0.53947979 0.54446444 0.53571897 0.54730343] -> mean_test = 0.5403\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.67643412 0.67331554 0.67335111 0.67241284 0.67489739] -> mean_train = 0.6741\n",
      "Test scores: [0.53448304 0.55207278 0.54070753 0.53314925 0.54743649] -> mean_test = 0.5416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=HGBR(), method=\"Spearman correlation\", corrs=spearman_corrs, num_feats=range(900, 2001, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8edb9-0ad6-4c62-a8a0-7894a6dbc83e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 900 best features\n",
    "Train scores: [0.66640621 0.66761633 0.66318797 0.66438972 0.66299885] -> mean_train = 0.6649\n",
    "Test scores: [0.5385035  0.53013342 0.53696804 0.54630403 0.53912704] -> mean_test = 0.5382\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.66843968 0.66608647 0.66707098 0.67020146 0.65024564] -> mean_train = 0.6644\n",
    "Test scores: [0.54170773 0.53339188 0.55513566 0.52840985 0.54995223] -> mean_test = 0.5417\n",
    "\n",
    "Results for 1100 best features\n",
    "Train scores: [0.66817317 0.65897502 0.66969823 0.66850961 0.66736228] -> mean_train = 0.6665\n",
    "Test scores: [0.54798365 0.54820868 0.54489859 0.53689083 0.53303332] -> mean_test = 0.5422\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.66697576 0.67070654 0.67109184 0.67369563 0.66743542] -> mean_train = 0.6700\n",
    "Test scores: [0.56181496 0.53415526 0.54248205 0.5224809  0.55233844] -> mean_test = 0.5427\n",
    "\n",
    "Results for 1300 best features\n",
    "Train scores: [0.67069024 0.67527102 0.66286378 0.66742903 0.67396175] -> mean_train = 0.6700\n",
    "Test scores: [0.54450774 0.52375611 0.56018647 0.55024704 0.53476782] -> mean_test = 0.5427\n",
    "\n",
    "Results for 1400 best features\n",
    "Train scores: [0.67654191 0.66878745 0.66998537 0.67230986 0.66403637] -> mean_train = 0.6703\n",
    "Test scores: [0.52383477 0.54404493 0.55101852 0.53449349 0.54573617] -> mean_test = 0.5398\n",
    "\n",
    "Results for 1500 best features\n",
    "Train scores: [0.67044806 0.67563318 0.67118479 0.66868364 0.66982355] -> mean_train = 0.6712\n",
    "Test scores: [0.55567347 0.53332231 0.54208241 0.54953324 0.54846705] -> mean_test = 0.5458\n",
    "\n",
    "Results for 1600 best features\n",
    "Train scores: [0.67593141 0.67537575 0.67382011 0.64675993 0.67344937] -> mean_train = 0.6691\n",
    "Test scores: [0.53136766 0.53740612 0.55298813 0.5473727  0.54057805] -> mean_test = 0.5419\n",
    "\n",
    "Results for 1700 best features\n",
    "Train scores: [0.67209529 0.67042095 0.67559447 0.66762051 0.66367423] -> mean_train = 0.6699\n",
    "Test scores: [0.55008033 0.54208193 0.532531   0.54504007 0.52712765] -> mean_test = 0.5394\n",
    "\n",
    "Results for 1800 best features\n",
    "Train scores: [0.66989339 0.62961343 0.67362719 0.65298226 0.67519948] -> mean_train = 0.6603\n",
    "Test scores: [0.53343463 0.54984739 0.54449213 0.54810165 0.52855286] -> mean_test = 0.5409\n",
    "\n",
    "Results for 1900 best features\n",
    "Train scores: [0.6755778  0.66552389 0.67168683 0.67462481 0.65582312] -> mean_train = 0.6686\n",
    "Test scores: [0.53451847 0.53947979 0.54446444 0.53571897 0.54730343] -> mean_test = 0.5403\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.67643412 0.67331554 0.67335111 0.67241284 0.67489739] -> mean_train = 0.6741\n",
    "Test scores: [0.53448304 0.55207278 0.54070753 0.53314925 0.54743649] -> mean_test = 0.5416"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e968f-c580-45da-8aaa-52d8f7ad7d38",
   "metadata": {},
   "source": [
    "AtravÃ©s deste mÃ©todo de seleÃ§Ã£o de features (<b>correlaÃ§Ã£o de Spearman</b>) obtivemos um score mÃ¡ximo de <b>0.5458</b> para a combinaÃ§Ã£o <b>HistGradientBoostingRegressor / 1500 features</b>. No entanto, mais uma vez, selecionÃ¡mos a combinaÃ§Ã£o <b>HistGradientBoostingRegressor / 1200 features </b> por se encontrar numa regiÃ£o mais estÃ¡vel no espaÃ§o de procura do nÃºmero de features Ã³timo. Neste caso, o score obtido foi <b>0.5427</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84aa4a-59ef-4964-b1ec-5b63ff0069c8",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe710b8-4e41-460a-adf9-b0ed082bcedc",
   "metadata": {},
   "source": [
    "<b>Univariate linear regression</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e31188f-10eb-4487-b50c-92d23e3d0d8c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.31373502 0.31453924 0.30417023 0.31123685 0.31630096] -> mean_train = 0.3120\n",
      "Test scores: [0.28783469 0.29779471 0.30135783 0.31145979 0.29140639] -> mean_test = 0.2980\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.39764482 0.39875594 0.39529086 0.39313225 0.39097182] -> mean_train = 0.3952\n",
      "Test scores: [0.36595936 0.36158467 0.37670695 0.37031297 0.38661595] -> mean_test = 0.3722\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.42097787 0.42265563 0.42186017 0.42585712 0.42528314] -> mean_train = 0.4233\n",
      "Test scores: [0.40439878 0.40036036 0.40637312 0.38183613 0.30668828] -> mean_test = 0.3799\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.43038356 0.43612914 0.43978573 0.44180339 0.43237401] -> mean_train = 0.4361\n",
      "Test scores: [0.38657825 0.40212593 0.34410856 0.37866801 0.42163509] -> mean_test = 0.3866\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for KNeighborsRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.58418731 0.58761806 0.58538494 0.59134022 0.59104524] -> mean_train = 0.5879\n",
      "Test scores: [0.39551114 0.38906299 0.40408989 0.37811526 0.35545967] -> mean_test = 0.3844\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.60920937 0.61170261 0.6108256  0.61009618 0.61126893] -> mean_train = 0.6106\n",
      "Test scores: [0.42115555 0.41674847 0.40392014 0.41160636 0.40854717] -> mean_test = 0.4124\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.60560376 0.62121132 0.61906993 0.62097345 0.62114381] -> mean_train = 0.6176\n",
      "Test scores: [0.47479312 0.426869   0.42171527 0.41947493 0.39440085] -> mean_test = 0.4275\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.61991044 0.62148301 0.62284772 0.62001424 0.61840822] -> mean_train = 0.6205\n",
      "Test scores: [0.42825631 0.42061052 0.4388823  0.41319129 0.44369429] -> mean_test = 0.4289\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for RandomForestRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.8655547  0.86781916 0.86922104 0.865152   0.86404984] -> mean_train = 0.8664\n",
      "Test scores: [0.46708494 0.4685512  0.45384547 0.47275276 0.47673177] -> mean_test = 0.4678\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.86970501 0.86995028 0.86384063 0.86740251 0.87094993] -> mean_train = 0.8684\n",
      "Test scores: [0.47498573 0.48671501 0.51024889 0.47597489 0.45133407] -> mean_test = 0.4799\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.86849813 0.87306993 0.86734382 0.86760202 0.86648112] -> mean_train = 0.8686\n",
      "Test scores: [0.49520044 0.4626488  0.5081917  0.49469975 0.50113926] -> mean_test = 0.4924\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.86669763 0.86905955 0.873318   0.8691455  0.86850394] -> mean_train = 0.8693\n",
      "Test scores: [0.49135522 0.47788815 0.47668487 0.47902245 0.50758556] -> mean_test = 0.4865\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for SVR using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.27740995 0.27944163 0.28039117 0.27269153 0.27814691] -> mean_train = 0.2776\n",
      "Test scores: [0.26537281 0.27334189 0.26638405 0.28994056 0.26355078] -> mean_test = 0.2717\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.26640452 0.26723274 0.26763332 0.26570439 0.25921702] -> mean_train = 0.2652\n",
      "Test scores: [0.25655023 0.2491282  0.26175801 0.2637441  0.26534464] -> mean_test = 0.2593\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.2633362  0.25717587 0.26141754 0.26372821 0.25696623] -> mean_train = 0.2605\n",
      "Test scores: [0.24922436 0.2637499  0.25923562 0.24439915 0.25890932] -> mean_test = 0.2551\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.25483685 0.25661253 0.25750852 0.2579038  0.25711309] -> mean_train = 0.2568\n",
      "Test scores: [0.25750941 0.24639282 0.25115945 0.24799389 0.25132416] -> mean_test = 0.2509\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for MLPRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.54430174 0.49224234 0.49570655 0.52271968 0.52896249] -> mean_train = 0.5168\n",
      "Test scores: [0.45825457 0.39281788 0.4275423  0.41115331 0.44533216] -> mean_test = 0.4270\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.44218338 0.47154214 0.46907953 0.50640186 0.52612966] -> mean_train = 0.4831\n",
      "Test scores: [0.41794719 0.40787312 0.46285865 0.4551712  0.4717947 ] -> mean_test = 0.4431\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.50729017 0.50026381 0.48247831 0.52337791 0.53190939] -> mean_train = 0.5091\n",
      "Test scores: [0.43744918 0.46668748 0.46659086 0.46733173 0.47559299] -> mean_test = 0.4627\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.51564951 0.533168   0.5462754  0.51449448 0.52771785] -> mean_train = 0.5275\n",
      "Test scores: [0.46981089 0.48904764 0.47320711 0.4360045  0.47072816] -> mean_test = 0.4678\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for AdaBoostRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.31135141 0.29206503 0.25498672 0.32811158 0.31501928] -> mean_train = 0.3003\n",
      "Test scores: [0.31578124 0.265545   0.26295658 0.30517282 0.30600072] -> mean_test = 0.2911\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.3124823  0.28744464 0.28341977 0.27703655 0.28536512] -> mean_train = 0.2891\n",
      "Test scores: [0.30490637 0.26035061 0.23991877 0.27369385 0.30046343] -> mean_test = 0.2759\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.29051633 0.30135369 0.29399859 0.28739016 0.30473563] -> mean_train = 0.2956\n",
      "Test scores: [0.25262018 0.27319283 0.31489678 0.29137544 0.28354113] -> mean_test = 0.2831\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.31043962 0.31909498 0.29958588 0.31864839 0.28153108] -> mean_train = 0.3059\n",
      "Test scores: [0.32475499 0.30761267 0.28309899 0.29929982 0.25241269] -> mean_test = 0.2934\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.62287758 0.61627686 0.6203058  0.61895197 0.6068761 ] -> mean_train = 0.6171\n",
      "Test scores: [0.51206187 0.52476304 0.52843164 0.53115901 0.49411325] -> mean_test = 0.5181\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.64348381 0.65269333 0.65288184 0.64936361 0.65076979] -> mean_train = 0.6498\n",
      "Test scores: [0.55823305 0.50265354 0.52208418 0.53948546 0.52743806] -> mean_test = 0.5300\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.65881413 0.66029417 0.64909058 0.6650785  0.66054107] -> mean_train = 0.6588\n",
      "Test scores: [0.54466073 0.52675804 0.53552745 0.53019041 0.5483749 ] -> mean_test = 0.5371\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.65846428 0.67083182 0.66793144 0.63553435 0.66818127] -> mean_train = 0.6602\n",
      "Test scores: [0.55374652 0.52408791 0.53612751 0.54250362 0.53651148] -> mean_test = 0.5386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, Model in enumerate([LR, KNR, RFR, SVR, MLPR, ADA, HGBR]):\n",
    "    test_corr_models(model=Model(), method=\"univariate linear regression\", corrs=f_values)\n",
    "    if i < 6:\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f394470-0615-4d7a-b801-b3778df0a5c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.31373502 0.31453924 0.30417023 0.31123685 0.31630096] -> mean_train = 0.3120\n",
    "Test scores: [0.28783469 0.29779471 0.30135783 0.31145979 0.29140639] -> mean_test = 0.2980\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.39764482 0.39875594 0.39529086 0.39313225 0.39097182] -> mean_train = 0.3952\n",
    "Test scores: [0.36595936 0.36158467 0.37670695 0.37031297 0.38661595] -> mean_test = 0.3722\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.42097787 0.42265563 0.42186017 0.42585712 0.42528314] -> mean_train = 0.4233\n",
    "Test scores: [0.40439878 0.40036036 0.40637312 0.38183613 0.30668828] -> mean_test = 0.3799\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.43038356 0.43612914 0.43978573 0.44180339 0.43237401] -> mean_train = 0.4361\n",
    "Test scores: [0.38657825 0.40212593 0.34410856 0.37866801 0.42163509] -> mean_test = 0.3866\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for KNeighborsRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.58418731 0.58761806 0.58538494 0.59134022 0.59104524] -> mean_train = 0.5879\n",
    "Test scores: [0.39551114 0.38906299 0.40408989 0.37811526 0.35545967] -> mean_test = 0.3844\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.60920937 0.61170261 0.6108256  0.61009618 0.61126893] -> mean_train = 0.6106\n",
    "Test scores: [0.42115555 0.41674847 0.40392014 0.41160636 0.40854717] -> mean_test = 0.4124\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.60560376 0.62121132 0.61906993 0.62097345 0.62114381] -> mean_train = 0.6176\n",
    "Test scores: [0.47479312 0.426869   0.42171527 0.41947493 0.39440085] -> mean_test = 0.4275\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.61991044 0.62148301 0.62284772 0.62001424 0.61840822] -> mean_train = 0.6205\n",
    "Test scores: [0.42825631 0.42061052 0.4388823  0.41319129 0.44369429] -> mean_test = 0.4289\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.8655547  0.86781916 0.86922104 0.865152   0.86404984] -> mean_train = 0.8664\n",
    "Test scores: [0.46708494 0.4685512  0.45384547 0.47275276 0.47673177] -> mean_test = 0.4678\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.86970501 0.86995028 0.86384063 0.86740251 0.87094993] -> mean_train = 0.8684\n",
    "Test scores: [0.47498573 0.48671501 0.51024889 0.47597489 0.45133407] -> mean_test = 0.4799\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.86849813 0.87306993 0.86734382 0.86760202 0.86648112] -> mean_train = 0.8686\n",
    "Test scores: [0.49520044 0.4626488  0.5081917  0.49469975 0.50113926] -> mean_test = 0.4924\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.86669763 0.86905955 0.873318   0.8691455  0.86850394] -> mean_train = 0.8693\n",
    "Test scores: [0.49135522 0.47788815 0.47668487 0.47902245 0.50758556] -> mean_test = 0.4865\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.27740995 0.27944163 0.28039117 0.27269153 0.27814691] -> mean_train = 0.2776\n",
    "Test scores: [0.26537281 0.27334189 0.26638405 0.28994056 0.26355078] -> mean_test = 0.2717\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.26640452 0.26723274 0.26763332 0.26570439 0.25921702] -> mean_train = 0.2652\n",
    "Test scores: [0.25655023 0.2491282  0.26175801 0.2637441  0.26534464] -> mean_test = 0.2593\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.2633362  0.25717587 0.26141754 0.26372821 0.25696623] -> mean_train = 0.2605\n",
    "Test scores: [0.24922436 0.2637499  0.25923562 0.24439915 0.25890932] -> mean_test = 0.2551\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.25483685 0.25661253 0.25750852 0.2579038  0.25711309] -> mean_train = 0.2568\n",
    "Test scores: [0.25750941 0.24639282 0.25115945 0.24799389 0.25132416] -> mean_test = 0.2509\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.54430174 0.49224234 0.49570655 0.52271968 0.52896249] -> mean_train = 0.5168\n",
    "Test scores: [0.45825457 0.39281788 0.4275423  0.41115331 0.44533216] -> mean_test = 0.4270\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.44218338 0.47154214 0.46907953 0.50640186 0.52612966] -> mean_train = 0.4831\n",
    "Test scores: [0.41794719 0.40787312 0.46285865 0.4551712  0.4717947 ] -> mean_test = 0.4431\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.50729017 0.50026381 0.48247831 0.52337791 0.53190939] -> mean_train = 0.5091\n",
    "Test scores: [0.43744918 0.46668748 0.46659086 0.46733173 0.47559299] -> mean_test = 0.4627\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.51564951 0.533168   0.5462754  0.51449448 0.52771785] -> mean_train = 0.5275\n",
    "Test scores: [0.46981089 0.48904764 0.47320711 0.4360045  0.47072816] -> mean_test = 0.4678\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.31135141 0.29206503 0.25498672 0.32811158 0.31501928] -> mean_train = 0.3003\n",
    "Test scores: [0.31578124 0.265545   0.26295658 0.30517282 0.30600072] -> mean_test = 0.2911\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.3124823  0.28744464 0.28341977 0.27703655 0.28536512] -> mean_train = 0.2891\n",
    "Test scores: [0.30490637 0.26035061 0.23991877 0.27369385 0.30046343] -> mean_test = 0.2759\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.29051633 0.30135369 0.29399859 0.28739016 0.30473563] -> mean_train = 0.2956\n",
    "Test scores: [0.25262018 0.27319283 0.31489678 0.29137544 0.28354113] -> mean_test = 0.2831\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.31043962 0.31909498 0.29958588 0.31864839 0.28153108] -> mean_train = 0.3059\n",
    "Test scores: [0.32475499 0.30761267 0.28309899 0.29929982 0.25241269] -> mean_test = 0.2934\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.62287758 0.61627686 0.6203058  0.61895197 0.6068761 ] -> mean_train = 0.6171\n",
    "Test scores: [0.51206187 0.52476304 0.52843164 0.53115901 0.49411325] -> mean_test = 0.5181\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.64348381 0.65269333 0.65288184 0.64936361 0.65076979] -> mean_train = 0.6498\n",
    "Test scores: [0.55823305 0.50265354 0.52208418 0.53948546 0.52743806] -> mean_test = 0.5300\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.65881413 0.66029417 0.64909058 0.6650785  0.66054107] -> mean_train = 0.6588\n",
    "Test scores: [0.54466073 0.52675804 0.53552745 0.53019041 0.5483749 ] -> mean_test = 0.5371\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.65846428 0.67083182 0.66793144 0.63553435 0.66818127] -> mean_train = 0.6602\n",
    "Test scores: [0.55374652 0.52408791 0.53612751 0.54250362 0.53651148] -> mean_test = 0.5386"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881ee85-ead7-4da9-84b2-ffc358724079",
   "metadata": {},
   "source": [
    "<b>Univariate linear regression</b> (further testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c62b4-843f-4ca3-be17-034b4ee0ec31",
   "metadata": {},
   "source": [
    "Novos testes para uma gama de features distinta da anterior (apenas para o melhor modelo - <b>HistGradientBoostingRegressor</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38cb59ae-0a16-4f3e-9090-5e1809a5219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for HistGradientBoostingRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 900 best features\n",
      "Train scores: [0.66688224 0.6693543  0.64699053 0.65804901 0.65496276] -> mean_train = 0.6592\n",
      "Test scores: [0.54599391 0.53878915 0.53546626 0.55122983 0.52327278] -> mean_test = 0.5390\n",
      "\n",
      "Results for 1000 best features\n",
      "Train scores: [0.6694098  0.66224539 0.66859652 0.66918313 0.67199177] -> mean_train = 0.6683\n",
      "Test scores: [0.54907084 0.55617924 0.53640704 0.54427348 0.51604045] -> mean_test = 0.5404\n",
      "\n",
      "Results for 1100 best features\n",
      "Train scores: [0.69247604 0.69628291 0.6926902  0.69139486 0.69126861] -> mean_train = 0.6928\n",
      "Test scores: [0.5784869  0.56210165 0.56201292 0.5760861  0.57289338] -> mean_test = 0.5703\n",
      "\n",
      "Results for 1200 best features\n",
      "Train scores: [0.69627107 0.69432081 0.69199877 0.69308179 0.69435136] -> mean_train = 0.6940\n",
      "Test scores: [0.56833448 0.57382256 0.57845046 0.56835063 0.5636445 ] -> mean_test = 0.5705\n",
      "\n",
      "Results for 1300 best features\n",
      "Train scores: [0.69475934 0.69202208 0.6960469  0.69555998 0.69639005] -> mean_train = 0.6950\n",
      "Test scores: [0.56968746 0.58672153 0.55414568 0.57689586 0.56750432] -> mean_test = 0.5710\n",
      "\n",
      "Results for 1400 best features\n",
      "Train scores: [0.69881584 0.69692072 0.69314296 0.69586188 0.69289755] -> mean_train = 0.6955\n",
      "Test scores: [0.55043044 0.5779404  0.57557886 0.5731831  0.57545229] -> mean_test = 0.5705\n",
      "\n",
      "Results for 1500 best features\n",
      "Train scores: [0.68757758 0.69831251 0.69299613 0.69575932 0.69099983] -> mean_train = 0.6931\n",
      "Test scores: [0.55513583 0.55758307 0.58213375 0.56612144 0.5801901 ] -> mean_test = 0.5682\n",
      "\n",
      "Results for 1600 best features\n",
      "Train scores: [0.69680396 0.67875579 0.68808888 0.6935068  0.7016316 ] -> mean_train = 0.6918\n",
      "Test scores: [0.57010867 0.58887448 0.55656807 0.57979911 0.54721794] -> mean_test = 0.5685\n",
      "\n",
      "Results for 1700 best features\n",
      "Train scores: [0.68721915 0.6983206  0.70068564 0.69672682 0.70210271] -> mean_train = 0.6970\n",
      "Test scores: [0.60723235 0.56101476 0.56193151 0.57444668 0.55663242] -> mean_test = 0.5723\n",
      "\n",
      "Results for 1800 best features\n",
      "Train scores: [0.68656108 0.69824925 0.69583443 0.67644838 0.6988139 ] -> mean_train = 0.6912\n",
      "Test scores: [0.57885629 0.56883871 0.58091668 0.57711449 0.55996856] -> mean_test = 0.5731\n",
      "\n",
      "Results for 1900 best features\n",
      "Train scores: [0.69954738 0.69798781 0.69430744 0.69749429 0.6929716 ] -> mean_train = 0.6965\n",
      "Test scores: [0.57454464 0.55854714 0.57742535 0.5581389  0.58210644] -> mean_test = 0.5702\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.69979395 0.69530248 0.70005613 0.69404283 0.6946719 ] -> mean_train = 0.6968\n",
      "Test scores: [0.56435615 0.56315425 0.56291767 0.57217159 0.57758536] -> mean_test = 0.5680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=HGBR(), method=\"univariate linear regression\", corrs=f_values, num_feats=range(900, 2001, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f6720-77e7-483d-ac3d-46d6b4555fe2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 900 best features\n",
    "Train scores: [0.66688224 0.6693543  0.64699053 0.65804901 0.65496276] -> mean_train = 0.6592\n",
    "Test scores: [0.54599391 0.53878915 0.53546626 0.55122983 0.52327278] -> mean_test = 0.5390\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.6694098  0.66224539 0.66859652 0.66918313 0.67199177] -> mean_train = 0.6683\n",
    "Test scores: [0.54907084 0.55617924 0.53640704 0.54427348 0.51604045] -> mean_test = 0.5404\n",
    "\n",
    "Results for 1100 best features\n",
    "Train scores: [0.69247604 0.69628291 0.6926902  0.69139486 0.69126861] -> mean_train = 0.6928\n",
    "Test scores: [0.5784869  0.56210165 0.56201292 0.5760861  0.57289338] -> mean_test = 0.5703\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.69627107 0.69432081 0.69199877 0.69308179 0.69435136] -> mean_train = 0.6940\n",
    "Test scores: [0.56833448 0.57382256 0.57845046 0.56835063 0.5636445 ] -> mean_test = 0.5705\n",
    "\n",
    "Results for 1300 best features\n",
    "Train scores: [0.69475934 0.69202208 0.6960469  0.69555998 0.69639005] -> mean_train = 0.6950\n",
    "Test scores: [0.56968746 0.58672153 0.55414568 0.57689586 0.56750432] -> mean_test = 0.5710\n",
    "\n",
    "Results for 1400 best features\n",
    "Train scores: [0.69881584 0.69692072 0.69314296 0.69586188 0.69289755] -> mean_train = 0.6955\n",
    "Test scores: [0.55043044 0.5779404  0.57557886 0.5731831  0.57545229] -> mean_test = 0.5705\n",
    "\n",
    "Results for 1500 best features\n",
    "Train scores: [0.68757758 0.69831251 0.69299613 0.69575932 0.69099983] -> mean_train = 0.6931\n",
    "Test scores: [0.55513583 0.55758307 0.58213375 0.56612144 0.5801901 ] -> mean_test = 0.5682\n",
    "\n",
    "Results for 1600 best features\n",
    "Train scores: [0.69680396 0.67875579 0.68808888 0.6935068  0.7016316 ] -> mean_train = 0.6918\n",
    "Test scores: [0.57010867 0.58887448 0.55656807 0.57979911 0.54721794] -> mean_test = 0.5685\n",
    "\n",
    "Results for 1700 best features\n",
    "Train scores: [0.68721915 0.6983206  0.70068564 0.69672682 0.70210271] -> mean_train = 0.6970\n",
    "Test scores: [0.60723235 0.56101476 0.56193151 0.57444668 0.55663242] -> mean_test = 0.5723\n",
    "\n",
    "Results for 1800 best features\n",
    "Train scores: [0.68656108 0.69824925 0.69583443 0.67644838 0.6988139 ] -> mean_train = 0.6912\n",
    "Test scores: [0.57885629 0.56883871 0.58091668 0.57711449 0.55996856] -> mean_test = 0.5731\n",
    "\n",
    "Results for 1900 best features\n",
    "Train scores: [0.69954738 0.69798781 0.69430744 0.69749429 0.6929716 ] -> mean_train = 0.6965\n",
    "Test scores: [0.57454464 0.55854714 0.57742535 0.5581389  0.58210644] -> mean_test = 0.5702\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.69979395 0.69530248 0.70005613 0.69404283 0.6946719 ] -> mean_train = 0.6968\n",
    "Test scores: [0.56435615 0.56315425 0.56291767 0.57217159 0.57758536] -> mean_test = 0.5680"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c676af-3da6-4f61-a5ee-9b0524960631",
   "metadata": {},
   "source": [
    "Utilizando os <b>ANOVA f-values</b> como mÃ©todo de seleÃ§Ã£o de features obtivemos um score mÃ¡ximo de <b>0.5731</b> para a combinaÃ§Ã£o <b>HistGradientBoostingRegressor / 1800 features</b>. Todavia, tal como havia acontecido nos casos anteriores, selecionÃ¡mos a combinaÃ§Ã£o <b>HistGradientBoostingRegressor / 1300 features </b> por se encontrar numa regiÃ£o mais estÃ¡vel no espaÃ§o de procura do nÃºmero de features Ã³timo. Neste caso, o score obtido foi <b>0.5710</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212759d7-d4a7-41cd-a8a1-87a3c1ce4479",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc819be-5e0c-4259-b4f9-a9def391667b",
   "metadata": {},
   "source": [
    "<b>Mutual information regression</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bf73db1-01af-41de-a9f2-481dd3aa1e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.29933053 0.30549307 0.30197076 0.30446767 0.29626695] -> mean_train = 0.3015\n",
      "Test scores: [0.2959669  0.2691783  0.28315959 0.27444436 0.30818651] -> mean_test = 0.2862\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.39009861 0.39224099 0.39230819 0.3884802  0.38664143] -> mean_train = 0.3900\n",
      "Test scores: [0.34586822 0.34771363 0.35038695 0.36931395 0.37310897] -> mean_test = 0.3573\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.4271809  0.42857239 0.42821025 0.4340767  0.42882269] -> mean_train = 0.4294\n",
      "Test scores: [0.39660344 0.23434375 0.38580482 0.36781109 0.39394364] -> mean_test = 0.3557\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.45024162 0.44818107 0.44927905 0.44205742 0.45097461] -> mean_train = 0.4481\n",
      "Test scores: [0.38582873 0.3408515  0.34684105 0.4190393  0.38900584] -> mean_test = 0.3763\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for KNeighborsRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.66938194 0.6692286  0.67205625 0.67092688 0.67394699] -> mean_train = 0.6711\n",
      "Test scores: [0.49851846 0.50919087 0.50141949 0.50967624 0.48322933] -> mean_test = 0.5004\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.6649939  0.66388582 0.6675673  0.66380483 0.66774893] -> mean_train = 0.6656\n",
      "Test scores: [0.49177363 0.49484785 0.48735343 0.48916829 0.48379032] -> mean_test = 0.4894\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.66257682 0.65881848 0.65683579 0.65848209 0.6576441 ] -> mean_train = 0.6589\n",
      "Test scores: [0.48440107 0.44303405 0.47002927 0.48236651 0.50191799] -> mean_test = 0.4763\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.64859161 0.65853628 0.65476492 0.64637203 0.64708879] -> mean_train = 0.6511\n",
      "Test scores: [0.46616296 0.43867683 0.46643825 0.4858647  0.48901911] -> mean_test = 0.4692\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for RandomForestRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.89444151 0.89337992 0.89547431 0.89845373 0.89603736] -> mean_train = 0.8956\n",
      "Test scores: [0.53502458 0.55360583 0.54909641 0.53530799 0.54899091] -> mean_test = 0.5444\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.89585105 0.8940862  0.89247588 0.89726787 0.89673408] -> mean_train = 0.8953\n",
      "Test scores: [0.54289553 0.55422491 0.54656744 0.5286691  0.53471027] -> mean_test = 0.5414\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.89460238 0.89840983 0.89471388 0.89379372 0.89348131] -> mean_train = 0.8950\n",
      "Test scores: [0.53805615 0.49215636 0.53282304 0.54405425 0.55358532] -> mean_test = 0.5321\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.89466953 0.89382278 0.89359465 0.89711647 0.89608051] -> mean_train = 0.8951\n",
      "Test scores: [0.50978071 0.53141708 0.53141627 0.51194323 0.53676421] -> mean_test = 0.5243\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for SVR using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.21831226 0.22384925 0.22468885 0.22106031 0.23286098] -> mean_train = 0.2242\n",
      "Test scores: [0.22227113 0.22504403 0.22066862 0.22561754 0.20318227] -> mean_test = 0.2194\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.27662049 0.27005039 0.27946139 0.27833096 0.28038266] -> mean_train = 0.2770\n",
      "Test scores: [0.26810613 0.28251338 0.26700299 0.26206192 0.27327793] -> mean_test = 0.2706\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.26095284 0.2599437  0.2742461  0.27089909 0.26437299] -> mean_train = 0.2661\n",
      "Test scores: [0.2656998  0.27016543 0.24706366 0.24770026 0.26133609] -> mean_test = 0.2584\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.25518322 0.26270685 0.25606052 0.25377655 0.25957403] -> mean_train = 0.2575\n",
      "Test scores: [0.24989192 0.23992727 0.24558835 0.26371241 0.25509985] -> mean_test = 0.2508\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for MLPRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.4987827  0.52403325 0.48887852 0.49507846 0.49171286] -> mean_train = 0.4997\n",
      "Test scores: [0.46916664 0.47291492 0.50145108 0.4597296  0.47345257] -> mean_test = 0.4753\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.53748188 0.52034604 0.48873221 0.49153429 0.51736356] -> mean_train = 0.5111\n",
      "Test scores: [0.47288314 0.49475383 0.43479143 0.46580252 0.48696947] -> mean_test = 0.4710\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.52394406 0.50311842 0.51250483 0.48896357 0.50551634] -> mean_train = 0.5068\n",
      "Test scores: [0.48286718 0.48485679 0.46718476 0.44797404 0.46836286] -> mean_test = 0.4702\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.49514453 0.49211496 0.49850836 0.49249767 0.48718663] -> mean_train = 0.4931\n",
      "Test scores: [0.44881383 0.46495059 0.46009689 0.46278661 0.4584256 ] -> mean_test = 0.4590\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for AdaBoostRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.30779509 0.27707164 0.29471665 0.32587769 0.31276764] -> mean_train = 0.3036\n",
      "Test scores: [0.29247165 0.2671752  0.29446766 0.31134919 0.29826194] -> mean_test = 0.2927\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.28359559 0.32371424 0.31099812 0.29702389 0.28263655] -> mean_train = 0.2996\n",
      "Test scores: [0.29590716 0.29494945 0.29787745 0.27476386 0.28179445] -> mean_test = 0.2891\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.27976414 0.32424724 0.31334374 0.28116491 0.3159436 ] -> mean_train = 0.3029\n",
      "Test scores: [0.27701969 0.29591232 0.31300413 0.27438443 0.30041012] -> mean_test = 0.2921\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.29247856 0.29151977 0.29933653 0.28316984 0.2901339 ] -> mean_train = 0.2913\n",
      "Test scores: [0.25972989 0.27607238 0.293455   0.2808207  0.28542952] -> mean_test = 0.2791\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.68981372 0.69006714 0.6844912  0.69081417 0.69452469] -> mean_train = 0.6899\n",
      "Test scores: [0.58052739 0.57938755 0.60418372 0.58680193 0.57019993] -> mean_test = 0.5842\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.69877871 0.69744662 0.69532888 0.70010964 0.69522936] -> mean_train = 0.6974\n",
      "Test scores: [0.58736675 0.58846537 0.60117214 0.56251592 0.58267537] -> mean_test = 0.5844\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.69906142 0.70169151 0.70439615 0.69289322 0.70444951] -> mean_train = 0.7005\n",
      "Test scores: [0.59873747 0.59653477 0.56286187 0.58374117 0.57587304] -> mean_test = 0.5835\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.70322891 0.69916378 0.70634854 0.70964569 0.70509382] -> mean_train = 0.7047\n",
      "Test scores: [0.58508506 0.60112711 0.57402897 0.56497576 0.5867018 ] -> mean_test = 0.5824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, Model in enumerate([LR, KNR, RFR, SVR, MLPR, ADA, HGBR]):\n",
    "    test_corr_models(model=Model(), method=\"mutual information regression\", corrs=mutual_info)\n",
    "    if i < 6:\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0f8a3-6be2-4da7-8ad5-047f1e0d89f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.29933053 0.30549307 0.30197076 0.30446767 0.29626695] -> mean_train = 0.3015\n",
    "Test scores: [0.2959669  0.2691783  0.28315959 0.27444436 0.30818651] -> mean_test = 0.2862\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.39009861 0.39224099 0.39230819 0.3884802  0.38664143] -> mean_train = 0.3900\n",
    "Test scores: [0.34586822 0.34771363 0.35038695 0.36931395 0.37310897] -> mean_test = 0.3573\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.4271809  0.42857239 0.42821025 0.4340767  0.42882269] -> mean_train = 0.4294\n",
    "Test scores: [0.39660344 0.23434375 0.38580482 0.36781109 0.39394364] -> mean_test = 0.3557\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.45024162 0.44818107 0.44927905 0.44205742 0.45097461] -> mean_train = 0.4481\n",
    "Test scores: [0.38582873 0.3408515  0.34684105 0.4190393  0.38900584] -> mean_test = 0.3763\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for KNeighborsRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.66938194 0.6692286  0.67205625 0.67092688 0.67394699] -> mean_train = 0.6711\n",
    "Test scores: [0.49851846 0.50919087 0.50141949 0.50967624 0.48322933] -> mean_test = 0.5004\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.6649939  0.66388582 0.6675673  0.66380483 0.66774893] -> mean_train = 0.6656\n",
    "Test scores: [0.49177363 0.49484785 0.48735343 0.48916829 0.48379032] -> mean_test = 0.4894\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.66257682 0.65881848 0.65683579 0.65848209 0.6576441 ] -> mean_train = 0.6589\n",
    "Test scores: [0.48440107 0.44303405 0.47002927 0.48236651 0.50191799] -> mean_test = 0.4763\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.64859161 0.65853628 0.65476492 0.64637203 0.64708879] -> mean_train = 0.6511\n",
    "Test scores: [0.46616296 0.43867683 0.46643825 0.4858647  0.48901911] -> mean_test = 0.4692\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.89444151 0.89337992 0.89547431 0.89845373 0.89603736] -> mean_train = 0.8956\n",
    "Test scores: [0.53502458 0.55360583 0.54909641 0.53530799 0.54899091] -> mean_test = 0.5444\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.89585105 0.8940862  0.89247588 0.89726787 0.89673408] -> mean_train = 0.8953\n",
    "Test scores: [0.54289553 0.55422491 0.54656744 0.5286691  0.53471027] -> mean_test = 0.5414\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.89460238 0.89840983 0.89471388 0.89379372 0.89348131] -> mean_train = 0.8950\n",
    "Test scores: [0.53805615 0.49215636 0.53282304 0.54405425 0.55358532] -> mean_test = 0.5321\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.89466953 0.89382278 0.89359465 0.89711647 0.89608051] -> mean_train = 0.8951\n",
    "Test scores: [0.50978071 0.53141708 0.53141627 0.51194323 0.53676421] -> mean_test = 0.5243\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.21831226 0.22384925 0.22468885 0.22106031 0.23286098] -> mean_train = 0.2242\n",
    "Test scores: [0.22227113 0.22504403 0.22066862 0.22561754 0.20318227] -> mean_test = 0.2194\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.27662049 0.27005039 0.27946139 0.27833096 0.28038266] -> mean_train = 0.2770\n",
    "Test scores: [0.26810613 0.28251338 0.26700299 0.26206192 0.27327793] -> mean_test = 0.2706\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.26095284 0.2599437  0.2742461  0.27089909 0.26437299] -> mean_train = 0.2661\n",
    "Test scores: [0.2656998  0.27016543 0.24706366 0.24770026 0.26133609] -> mean_test = 0.2584\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.25518322 0.26270685 0.25606052 0.25377655 0.25957403] -> mean_train = 0.2575\n",
    "Test scores: [0.24989192 0.23992727 0.24558835 0.26371241 0.25509985] -> mean_test = 0.2508\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.4987827  0.52403325 0.48887852 0.49507846 0.49171286] -> mean_train = 0.4997\n",
    "Test scores: [0.46916664 0.47291492 0.50145108 0.4597296  0.47345257] -> mean_test = 0.4753\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.53748188 0.52034604 0.48873221 0.49153429 0.51736356] -> mean_train = 0.5111\n",
    "Test scores: [0.47288314 0.49475383 0.43479143 0.46580252 0.48696947] -> mean_test = 0.4710\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.52394406 0.50311842 0.51250483 0.48896357 0.50551634] -> mean_train = 0.5068\n",
    "Test scores: [0.48286718 0.48485679 0.46718476 0.44797404 0.46836286] -> mean_test = 0.4702\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.49514453 0.49211496 0.49850836 0.49249767 0.48718663] -> mean_train = 0.4931\n",
    "Test scores: [0.44881383 0.46495059 0.46009689 0.46278661 0.4584256 ] -> mean_test = 0.4590\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.30779509 0.27707164 0.29471665 0.32587769 0.31276764] -> mean_train = 0.3036\n",
    "Test scores: [0.29247165 0.2671752  0.29446766 0.31134919 0.29826194] -> mean_test = 0.2927\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.28359559 0.32371424 0.31099812 0.29702389 0.28263655] -> mean_train = 0.2996\n",
    "Test scores: [0.29590716 0.29494945 0.29787745 0.27476386 0.28179445] -> mean_test = 0.2891\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.27976414 0.32424724 0.31334374 0.28116491 0.3159436 ] -> mean_train = 0.3029\n",
    "Test scores: [0.27701969 0.29591232 0.31300413 0.27438443 0.30041012] -> mean_test = 0.2921\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.29247856 0.29151977 0.29933653 0.28316984 0.2901339 ] -> mean_train = 0.2913\n",
    "Test scores: [0.25972989 0.27607238 0.293455   0.2808207  0.28542952] -> mean_test = 0.2791\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.68981372 0.69006714 0.6844912  0.69081417 0.69452469] -> mean_train = 0.6899\n",
    "Test scores: [0.58052739 0.57938755 0.60418372 0.58680193 0.57019993] -> mean_test = 0.5842\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.69877871 0.69744662 0.69532888 0.70010964 0.69522936] -> mean_train = 0.6974\n",
    "Test scores: [0.58736675 0.58846537 0.60117214 0.56251592 0.58267537] -> mean_test = 0.5844\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.69906142 0.70169151 0.70439615 0.69289322 0.70444951] -> mean_train = 0.7005\n",
    "Test scores: [0.59873747 0.59653477 0.56286187 0.58374117 0.57587304] -> mean_test = 0.5835\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.70322891 0.69916378 0.70634854 0.70964569 0.70509382] -> mean_train = 0.7047\n",
    "Test scores: [0.58508506 0.60112711 0.57402897 0.56497576 0.5867018 ] -> mean_test = 0.5824"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681809a3-2831-4d4d-801b-490e0c0a5270",
   "metadata": {},
   "source": [
    "<b>Mutual information regression</b> (further testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe62b40-9818-40c4-91eb-e2c04c6a03cd",
   "metadata": {},
   "source": [
    "Obtivemos os melhores scores utilizando o modelo <b>HistGradientBoosting</b> e um nÃºmero de features entre <b>200</b> e <b>400</b>. EntÃ£o, efetuÃ¡mos novas validaÃ§Ãµes cruzadas do modelo tendo em conta nÃºmeros de features pertecentes a esta gama de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "29e30cd4-e1ae-4515-9304-a42f364e75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for HistGradientBoostingRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 100 best features\n",
      "Train scores: [0.64638056 0.647755   0.65273351 0.64679615 0.64730562] -> mean_train = 0.6482\n",
      "Test scores: [0.56075003 0.54913101 0.52380878 0.56463768 0.54638954] -> mean_test = 0.5489\n",
      "\n",
      "Results for 150 best features\n",
      "Train scores: [0.68533162 0.68011919 0.68446605 0.68878994 0.68179735] -> mean_train = 0.6841\n",
      "Test scores: [0.59444313 0.58825639 0.5846732  0.56242807 0.61195944] -> mean_test = 0.5884\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.69143393 0.68617854 0.68891249 0.689917   0.69075993] -> mean_train = 0.6894\n",
      "Test scores: [0.58727969 0.59127946 0.58798012 0.58635699 0.58367   ] -> mean_test = 0.5873\n",
      "\n",
      "Results for 250 best features\n",
      "Train scores: [0.68964904 0.69257095 0.69232035 0.69044551 0.69519141] -> mean_train = 0.6920\n",
      "Test scores: [0.5855083  0.5921357  0.58939877 0.59280559 0.57684508] -> mean_test = 0.5873\n",
      "\n",
      "Results for 300 best features\n",
      "Train scores: [0.69317032 0.69305788 0.6969709  0.69497039 0.69406247] -> mean_train = 0.6944\n",
      "Test scores: [0.59697292 0.58954455 0.57880944 0.58565545 0.58374544] -> mean_test = 0.5869\n",
      "\n",
      "Results for 350 best features\n",
      "Train scores: [0.69772839 0.69377324 0.70152373 0.69195493 0.69701042] -> mean_train = 0.6964\n",
      "Test scores: [0.58113254 0.60130415 0.57293537 0.5932389  0.58947037] -> mean_test = 0.5876\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.69333979 0.6969914  0.69768763 0.699293   0.70044102] -> mean_train = 0.6976\n",
      "Test scores: [0.60967112 0.58794547 0.58419745 0.58313238 0.56278805] -> mean_test = 0.5855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=HGBR(), method=\"mutual information regression\", corrs=mutual_info, num_feats=range(100, 401, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d608a49-6cbd-4050-8e4a-9aa923a2decf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.64638056 0.647755   0.65273351 0.64679615 0.64730562] -> mean_train = 0.6482\n",
    "Test scores: [0.56075003 0.54913101 0.52380878 0.56463768 0.54638954] -> mean_test = 0.5489\n",
    "\n",
    "Results for 150 best features\n",
    "Train scores: [0.68533162 0.68011919 0.68446605 0.68878994 0.68179735] -> mean_train = 0.6841\n",
    "Test scores: [0.59444313 0.58825639 0.5846732  0.56242807 0.61195944] -> mean_test = 0.5884\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.69143393 0.68617854 0.68891249 0.689917   0.69075993] -> mean_train = 0.6894\n",
    "Test scores: [0.58727969 0.59127946 0.58798012 0.58635699 0.58367   ] -> mean_test = 0.5873\n",
    "\n",
    "Results for 250 best features\n",
    "Train scores: [0.68964904 0.69257095 0.69232035 0.69044551 0.69519141] -> mean_train = 0.6920\n",
    "Test scores: [0.5855083  0.5921357  0.58939877 0.59280559 0.57684508] -> mean_test = 0.5873\n",
    "\n",
    "Results for 300 best features\n",
    "Train scores: [0.69317032 0.69305788 0.6969709  0.69497039 0.69406247] -> mean_train = 0.6944\n",
    "Test scores: [0.59697292 0.58954455 0.57880944 0.58565545 0.58374544] -> mean_test = 0.5869\n",
    "\n",
    "Results for 350 best features\n",
    "Train scores: [0.69772839 0.69377324 0.70152373 0.69195493 0.69701042] -> mean_train = 0.6964\n",
    "Test scores: [0.58113254 0.60130415 0.57293537 0.5932389  0.58947037] -> mean_test = 0.5876\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.69333979 0.6969914  0.69768763 0.699293   0.70044102] -> mean_train = 0.6976\n",
    "Test scores: [0.60967112 0.58794547 0.58419745 0.58313238 0.56278805] -> mean_test = 0.5855"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d8280-8048-4111-8095-0e9eea5d85d7",
   "metadata": {},
   "source": [
    "Utilizando a <b>informaÃ§Ã£o mÃºtua</b> como mÃ©todo de seleÃ§Ã£o de features obtivemos um score mÃ¡ximo de <b>0.5884</b> para a combinaÃ§Ã£o <b>HistGradientBoostingRegressor / 150 features</b>. No entanto, tal como se sucedeu em todos os casos anteriores, selecionÃ¡mos a combinaÃ§Ã£o <b>HistGradientBoostingRegressor / 200 features </b> por se encontrar numa regiÃ£o mais estÃ¡vel no espaÃ§o de procura do nÃºmero de features Ã³timo. Neste caso, o score obtido foi <b>0.5873</b>, o melhor resultado atÃ© ao momento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b442145-4863-4def-a02f-9b21e9e779e8",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ed228-585d-49d0-9a08-a1ff5b767044",
   "metadata": {},
   "source": [
    "<b>SelectFromModel</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b858e-b3c2-46a2-8bc9-491e59e5ecf9",
   "metadata": {},
   "source": [
    "De seguida, de modo a testar outro mÃ©todo de seleÃ§Ã£o de features, utilizÃ¡mos a classe <b>SelectFromModel</b> do <b>sklearn</b>. A seleÃ§Ã£o de features Ã© realizada tendo por base o modelo <b>RandomForestRegressor</b> jÃ¡ que, a par do modelo <b>LinearRegression</b>, Ã© o Ãºnico que apresenta o atributo <b>feature_importances_</b> (<b>coef_</b> no caso do modelo <b>LinearRegression</b>), necessÃ¡rio para a definiÃ§Ã£o de quais features manter e eliminar. As features selecionadas sÃ£o depois partilhadas na definiÃ§Ã£o do dataset que alimenta os restantes modelos de machine learning (<b>LR</b>, <b>KNR</b>, <b>SVR</b>, <b>MLPR</b>, <b>ADA</b>, <b>HGBR</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b0d066a-b075-48f2-b362-32e56bcbe079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8171c51",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cv_select_from_model(models: list, cv=5):\n",
    "    \"\"\"\n",
    "    Cross-validates models using features outputed by sklearn's SelectFromModel using a Random Forest\n",
    "    Regressor as estimator. Returns the computed feature mask for further use.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models: list\n",
    "        A list object containing uninitialized sklearn models\n",
    "    cv: int (default=5)\n",
    "        Number of folds used in cross-validation\n",
    "    \"\"\"\n",
    "    # select best features according to RFR feature importances\n",
    "    # features whose absolute importance value is greater or equal to the mean importance are kept\n",
    "    selector = SelectFromModel(estimator=RFR())\n",
    "    selector.fit(X_train_sc, y_train)\n",
    "    feature_mask = selector.get_support()\n",
    "    # new dataframe containing the features selected by SelectFromModel\n",
    "    X_train_new = X_train_sc.iloc[:, feature_mask]\n",
    "    # iterate through models and cross-validate\n",
    "    for Model in models:\n",
    "        InitModel = Model()\n",
    "        print(f\"Getting results for {InitModel.__class__.__name__} using 'SelectFromModel' to select features...\\n\")\n",
    "        # cross-validate\n",
    "        result = cross_validate(estimator=InitModel,\n",
    "                                X=X_train_new,\n",
    "                                y=y_train,\n",
    "                                cv=KFold(n_splits=cv, shuffle=True),\n",
    "                                return_train_score=True)\n",
    "        # print cross-validation results\n",
    "        mean_train = np.sum(result[\"train_score\"]) / cv\n",
    "        mean_test = np.sum(result[\"test_score\"]) / cv\n",
    "        print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "        print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")\n",
    "    return feature_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f6d1fc3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.47917286 0.4787124  0.47911779 0.47851584 0.47531577] -> mean_train = 0.4782\n",
      "Test scores: [0.3846648  0.41275611 0.3885643  0.38054965 0.4225524 ] -> mean_test = 0.3978\n",
      "\n",
      "Getting results for KNeighborsRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.64117131 0.64691899 0.65368522 0.64261927 0.65363452] -> mean_train = 0.6476\n",
      "Test scores: [0.48092228 0.4558046  0.45069206 0.48195009 0.43438383] -> mean_test = 0.4608\n",
      "\n",
      "Getting results for RandomForestRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.89198975 0.8930869  0.89418728 0.89629146 0.89215876] -> mean_train = 0.8935\n",
      "Test scores: [0.53534368 0.5273811  0.49640657 0.51720304 0.52155594] -> mean_test = 0.5196\n",
      "\n",
      "Getting results for SVR using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.2441218  0.23882408 0.2410639  0.24465293 0.24739255] -> mean_train = 0.2432\n",
      "Test scores: [0.23128662 0.24998816 0.24070777 0.22920134 0.23454579] -> mean_test = 0.2371\n",
      "\n",
      "Getting results for MLPRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.42067463 0.42944524 0.51796859 0.41438029 0.42415684] -> mean_train = 0.4413\n",
      "Test scores: [0.40686397 0.38491727 0.48272257 0.40023052 0.36919241] -> mean_test = 0.4088\n",
      "\n",
      "Getting results for AdaBoostRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.28959696 0.30083703 0.29143091 0.2909287  0.28061531] -> mean_train = 0.2907\n",
      "Test scores: [0.25596531 0.29722519 0.29148558 0.27467346 0.2703121 ] -> mean_test = 0.2779\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.68981507 0.69744861 0.70596076 0.71203651 0.70741611] -> mean_train = 0.7025\n",
      "Test scores: [0.58028429 0.57268925 0.57793106 0.56851494 0.57161777] -> mean_test = 0.5742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_mask = cv_select_from_model(models=[LR, KNR, RFR, SVR, MLPR, ADA, HGBR])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96970d-bbab-4d24-8956-519423c2a053",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Getting results for LinearRegression using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.47917286 0.4787124  0.47911779 0.47851584 0.47531577] -> mean_train = 0.4782\n",
    "Test scores: [0.3846648  0.41275611 0.3885643  0.38054965 0.4225524 ] -> mean_test = 0.3978\n",
    "\n",
    "Getting results for KNeighborsRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.64117131 0.64691899 0.65368522 0.64261927 0.65363452] -> mean_train = 0.6476\n",
    "Test scores: [0.48092228 0.4558046  0.45069206 0.48195009 0.43438383] -> mean_test = 0.4608\n",
    "\n",
    "Getting results for RandomForestRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.89198975 0.8930869  0.89418728 0.89629146 0.89215876] -> mean_train = 0.8935\n",
    "Test scores: [0.53534368 0.5273811  0.49640657 0.51720304 0.52155594] -> mean_test = 0.5196\n",
    "\n",
    "Getting results for SVR using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.2441218  0.23882408 0.2410639  0.24465293 0.24739255] -> mean_train = 0.2432\n",
    "Test scores: [0.23128662 0.24998816 0.24070777 0.22920134 0.23454579] -> mean_test = 0.2371\n",
    "\n",
    "Getting results for MLPRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.42067463 0.42944524 0.51796859 0.41438029 0.42415684] -> mean_train = 0.4413\n",
    "Test scores: [0.40686397 0.38491727 0.48272257 0.40023052 0.36919241] -> mean_test = 0.4088\n",
    "\n",
    "Getting results for AdaBoostRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.28959696 0.30083703 0.29143091 0.2909287  0.28061531] -> mean_train = 0.2907\n",
    "Test scores: [0.25596531 0.29722519 0.29148558 0.27467346 0.2703121 ] -> mean_test = 0.2779\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.68981507 0.69744861 0.70596076 0.71203651 0.70741611] -> mean_train = 0.7025\n",
    "Test scores: [0.58028429 0.57268925 0.57793106 0.56851494 0.57161777] -> mean_test = 0.5742"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cb32b-2944-4f19-af17-6474856d60ce",
   "metadata": {},
   "source": [
    "Os resultados sugerem que o melhor modelo Ã© o <b>HistGradientBoostingRegressor</b> com um score de <b>0.5742</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa6aa4-461c-4552-8179-4b77aaded534",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8a5a8-9432-4e62-b43a-0935fcf819f3",
   "metadata": {},
   "source": [
    "<b>Pearson + Spearman + mutual information</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na tentativa de melhorar ligeiramente o nosso melhor modelo (combinaÃ§Ã£o <b>HistGradientBoostingRegressor</b> / <b>200 features</b> utilizando a <b>informaÃ§Ã£o mÃºtua</b> como mÃ©todo de seleÃ§Ã£o de features), decidimos combinar as melhores features selecionadas a partir de cada mÃ©todo de seleÃ§Ã£o (com exceÃ§Ã£o dos <b>ANOVA f-values</b>). Para isso, definimos um lower bound de <b>150</b> features e um upper bound de <b>350</b> features, selecionÃ¡mos as melhores features tendo em conta cada mÃ©todo de seleÃ§Ã£o e combinÃ¡mo-las atravÃ©s da disjunÃ§Ã£o dos nomes associados Ã s mesma. Finalmente, efetuÃ¡mos novas validaÃ§Ãµes cruzadas 5-fold a partir dos datasets resultantes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating HistGradientBoostingRegressor using 305 (150 comb) features...\n",
      "Train scores: [0.68301761 0.69117031 0.68361854 0.69151876 0.68589539] -> mean_train = 0.6870\n",
      "Test scores: [0.60715197 0.56753502 0.59320281 0.57107169 0.5921822 ] -> mean_test = 0.5862\n",
      "\n",
      "Cross-validating HistGradientBoostingRegressor using 404 (200 comb) features...\n",
      "Train scores: [0.6932829  0.68857836 0.69084999 0.69144631 0.6913527 ] -> mean_train = 0.6911\n",
      "Test scores: [0.58061507 0.58997917 0.59100267 0.5860717  0.58747708] -> mean_test = 0.5870\n",
      "\n",
      "Cross-validating HistGradientBoostingRegressor using 498 (250 comb) features...\n",
      "Train scores: [0.69726495 0.69041586 0.69251149 0.69384081 0.69802487] -> mean_train = 0.6944\n",
      "Test scores: [0.57633606 0.60185842 0.59790227 0.58521013 0.57564917] -> mean_test = 0.5874\n",
      "\n",
      "Cross-validating HistGradientBoostingRegressor using 588 (300 comb) features...\n",
      "Train scores: [0.69776227 0.69850622 0.69715715 0.69354673 0.6991712 ] -> mean_train = 0.6972\n",
      "Test scores: [0.58759311 0.57259427 0.57885996 0.60668513 0.58010628] -> mean_test = 0.5852\n",
      "\n",
      "Cross-validating HistGradientBoostingRegressor using 678 (350 comb) features...\n",
      "Train scores: [0.69871638 0.69956833 0.69968343 0.69848404 0.70071811] -> mean_train = 0.6994\n",
      "Test scores: [0.58591725 0.5735554  0.58815685 0.59272155 0.57522353] -> mean_test = 0.5831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num in [150, 200, 250, 300, 350]:\n",
    "    best_pearson = list(get_k_best_corrs(num, pearson_corrs).keys())\n",
    "    best_spearman = list(get_k_best_corrs(num, spearman_corrs).keys())\n",
    "    best_mutual_info = list(get_k_best_corrs(num, mutual_info).keys())\n",
    "    best_feats = list(set(best_pearson + best_spearman + best_mutual_info))\n",
    "    print(f\"Cross-validating HistGradientBoostingRegressor using {len(best_feats)} ({num} comb) features...\")\n",
    "    x_train_psmi = X_train_sc[best_feats]\n",
    "    result = cross_validate(estimator=HGBR(),\n",
    "                            X=x_train_psmi,\n",
    "                            y=y_train,\n",
    "                            cv=KFold(n_splits=5, shuffle=True),\n",
    "                            return_train_score=True)\n",
    "    mean_train = np.sum(result[\"train_score\"]) / 5\n",
    "    mean_test = np.sum(result[\"test_score\"]) / 5\n",
    "    print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "    print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 305 (150 comb) features...\n",
    "Train scores: [0.68301761 0.69117031 0.68361854 0.69151876 0.68589539] -> mean_train = 0.6870\n",
    "Test scores: [0.60715197 0.56753502 0.59320281 0.57107169 0.5921822 ] -> mean_test = 0.5862\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 404 (200 comb) features...\n",
    "Train scores: [0.6932829  0.68857836 0.69084999 0.69144631 0.6913527 ] -> mean_train = 0.6911\n",
    "Test scores: [0.58061507 0.58997917 0.59100267 0.5860717  0.58747708] -> mean_test = 0.5870\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 498 (250 comb) features...\n",
    "Train scores: [0.69726495 0.69041586 0.69251149 0.69384081 0.69802487] -> mean_train = 0.6944\n",
    "Test scores: [0.57633606 0.60185842 0.59790227 0.58521013 0.57564917] -> mean_test = 0.5874\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 588 (300 comb) features...\n",
    "Train scores: [0.69776227 0.69850622 0.69715715 0.69354673 0.6991712 ] -> mean_train = 0.6972\n",
    "Test scores: [0.58759311 0.57259427 0.57885996 0.60668513 0.58010628] -> mean_test = 0.5852\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 678 (350 comb) features...\n",
    "Train scores: [0.69871638 0.69956833 0.69968343 0.69848404 0.70071811] -> mean_train = 0.6994\n",
    "Test scores: [0.58591725 0.5735554  0.58815685 0.59272155 0.57522353] -> mean_test = 0.5831"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Os resultados sugerem que o nÃºmero Ã³timo de features (tendo em consideraÃ§Ã£o o espaÃ§o de procura estabelecido) Ã© <b>250</b> para cada mÃ©todo de seleÃ§Ã£o. ApÃ³s disjunÃ§Ã£o dos nomes das features resultantes da seleÃ§Ã£o por cada um dos mÃ©todos, obtivemos um total de <b>498</b> features e um score mÃ©dio de teste na validaÃ§Ã£o cruzada 5-fold de <b>0.5874</b>."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "58d8963c",
   "metadata": {},
   "source": [
    "### Optimize hyperparameters of the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# best number of features considering the combination of methods (from {200, 250, 300, 350, 400})\n",
    "best_k = 250\n",
    "best_pearson = list(get_k_best_corrs(best_k, pearson_corrs).keys())\n",
    "best_spearman = list(get_k_best_corrs(best_k, spearman_corrs).keys())\n",
    "best_mutual_info = list(get_k_best_corrs(best_k, mutual_info).keys())\n",
    "\n",
    "best_features_psmi = list(set(best_pearson + best_spearman + best_mutual_info))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tendo em consideraÃ§Ã£o os melhores modelos para cada mÃ©todo de seleÃ§Ã£o de features (<b>Pearson</b>, <b>Spearman</b>, <b>ANOVA f-values</b>, <b>informaÃ§Ã£o mÃºtua</b>, <b>SelectFromModel</b> e combinaÃ§Ã£o <b>Pearson + Spearman + informaÃ§Ã£o mÃºtua</b>), procedemos Ã  otimizaÃ§Ã£o dos seus hiperparÃ¢metros. Invariavelmente, o melhor modelo foi o <b>HistGradientBoostingRegressor</b>. Consequentemente, apenas definimos um espaÃ§o de procura para a otimizaÃ§Ã£o de hiperparÃ¢metros para este modelo. ConsiderÃ¡mos os seguintes hiperparÃ¢metros: <b>learning_rate</b>, <b>max_iter</b>, <b>max_leaf_nodes</b>, <b>min_samples_leaf</b> e <b>warm_start</b>. De modo a efetuar a procura dos mesmos, recorremos Ã  classe <b>RandomizedSearchCV</b> do <b>sklearn</b>. NÃ£o Ã© utilizada uma procura exaustiva (por exemplo, utilizando a classe <b>GridSearchCV</b> do <b>sklearn</b>), jÃ¡ que utilizando a grelha de hiperparÃ¢metros definida em baixo seriam treinados <b>2500</b> modelos (<b>500</b> combinaÃ§Ãµes de hiperparÃ¢metros * <b>5 folds</b> na validaÃ§Ã£o cruzada) para cada mÃ©todo de seleÃ§Ã£o de features, tornando a complexidade temporal do problema bastante elevada."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93c2b041",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f4eeb9e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "HYPER = {\"learning_rate\": [0.05, 0.1],\n",
    "         \"max_iter\": np.arange(100, 301, 50),\n",
    "         \"max_leaf_nodes\": np.arange(31, 64, 8),\n",
    "         \"min_samples_leaf\": np.arange(16, 33, 4),\n",
    "         \"warm_start\": [True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef53bf7-e4b6-47b7-9256-75d069b2b6bb",
   "metadata": {},
   "source": [
    "<b>Pearson, Spearman, univariate linear regression and mutual information regression</b>\n",
    "<br>(hyperparameter optimization using the above methods to select features to train the models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76344fba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(models:list, methods:list, corrs:list, num_feats:list, cv=5):\n",
    "    results = []\n",
    "    for mo, me, co, nf in zip(models, methods, corrs, num_feats):\n",
    "        InitModel = mo()\n",
    "        print(f\"Optimizing {InitModel.__class__.__name__} using {me} to select features ({nf})...\")\n",
    "        print(\"----------\")\n",
    "        x_train_gs = X_train_sc.loc[:, get_k_best_corrs(nf, co).keys()]\n",
    "        gs = RandomizedSearchCV(estimator=InitModel,\n",
    "                                param_distributions=HYPER,\n",
    "                                n_iter=40,\n",
    "                                cv=KFold(n_splits=cv, shuffle=True),\n",
    "                                verbose=3)\n",
    "        gs.fit(x_train_gs, y_train)\n",
    "        results.append(gs.best_params_)\n",
    "        print(\"----------\")\n",
    "        print(f\"Optimal hyperparameters: {gs.best_params_}\")\n",
    "        print(f\"Best score: {gs.best_score_}\\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cbba3e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-36-4d2cd6ae2957>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mmodels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mHGBR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mHGBR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mHGBR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mHGBR\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mmethods\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"Pearson correlation\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"Spearman correlation\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"univariate linear regression\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"mutual information regression\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mcorrs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mpearson_corrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspearman_corrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf_values\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmutual_info\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mnum_feats\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m1200\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1200\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1300\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m200\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'f_values' is not defined"
     ]
    }
   ],
   "source": [
    "models = [HGBR, HGBR, HGBR, HGBR]\n",
    "methods = [\"Pearson correlation\", \"Spearman correlation\", \"univariate linear regression\", \"mutual information regression\"]\n",
    "corrs = [pearson_corrs, spearman_corrs, f_values, mutual_info]\n",
    "num_feats = [1200, 1200, 1300, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9186a6ea-e3de-48e4-a4a9-7331eec3fda6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-37-db0232c62d72>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mbest_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgrid_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethods\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcorrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_feats\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "best_params = grid_search(models, methods, corrs, num_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f9a05-5570-4b1e-9861-2ea49af97e20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Optimizing HistGradientBoostingRegressor using Pearson correlation to select features (1200)...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.574 total time=  13.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.574 total time=  13.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.562 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  17.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  12.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.571 total time=  17.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.580 total time=  14.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.556 total time=  14.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  13.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.578 total time=  15.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.572 total time=  17.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.578 total time=  17.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.561 total time=  12.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  14.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  14.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.555 total time=  12.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.564 total time=  12.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.544 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.555 total time=  12.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  12.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.576 total time=  13.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.576 total time=  15.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.558 total time=  13.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.576 total time=  14.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.585 total time=  14.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.573 total time=  21.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.578 total time=  21.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.562 total time=  23.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.578 total time=  19.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  22.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.573 total time=  13.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.581 total time=  15.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.558 total time=  17.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  16.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  17.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.576 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.580 total time=  15.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.558 total time=  15.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.582 total time=  16.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.580 total time=  17.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  15.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  18.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.561 total time=  14.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  13.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  16.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.577 total time=  19.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  13.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.552 total time=  11.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.577 total time=  11.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.583 total time=  15.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  12.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.572 total time=  12.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.555 total time=  11.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.576 total time=  16.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.581 total time=  15.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.570 total time=  16.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  16.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.556 total time=  16.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  16.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.581 total time=  16.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.574 total time=  14.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.573 total time=  15.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.562 total time=  15.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.581 total time=  13.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.579 total time=  13.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  28.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.582 total time=  23.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.562 total time=  22.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.585 total time=  25.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.586 total time=  34.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.578 total time=  22.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.577 total time=  21.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.567 total time=  24.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  26.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.587 total time=  25.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.576 total time=  24.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  27.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.566 total time=  27.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  22.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.585 total time=  30.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.576 total time=  19.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.580 total time=  19.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.559 total time=  19.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.575 total time=  19.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  18.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.572 total time=  16.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  15.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.564 total time=  14.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.578 total time=  15.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.579 total time=  12.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  21.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.582 total time=  23.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.562 total time=  27.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  27.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  23.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.573 total time=  13.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  10.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.560 total time=  13.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  11.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.584 total time=  15.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.571 total time=  15.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.558 total time=  16.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.581 total time=  14.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  13.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  10.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.573 total time=  21.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.549 total time=  11.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.574 total time=  11.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.578 total time=  18.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.569 total time=  12.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.575 total time=  13.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.560 total time=  14.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.577 total time=  12.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.580 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  26.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  27.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.567 total time=  26.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.582 total time=  31.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.582 total time=  29.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.576 total time=  14.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.573 total time=  15.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.560 total time=  14.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.578 total time=  12.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.582 total time=  14.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.573 total time=  20.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.580 total time=  23.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.556 total time=  19.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  33.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.582 total time=  31.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.578 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.577 total time=  12.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.562 total time=  14.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.580 total time=  13.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.580 total time=  15.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.569 total time=  11.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  16.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.559 total time=  18.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  15.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.581 total time=  14.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  16.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.569 total time=  16.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.556 total time=  16.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.571 total time=  17.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.579 total time=  16.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.578 total time=  33.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.580 total time=  30.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.562 total time=  30.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  41.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.591 total time=  45.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.569 total time=  19.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.574 total time=  19.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.555 total time=  18.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.585 total time=  15.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  20.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.576 total time=  16.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  13.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.563 total time=  15.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.576 total time=  14.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.580 total time=  13.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.569 total time=  17.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.574 total time=  17.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.556 total time=  17.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.573 total time=  17.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.581 total time=  16.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  19.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  15.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.559 total time=  12.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.579 total time=  15.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.580 total time=  21.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  12.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  15.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.561 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.565 total time=  10.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.577 total time=  11.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.572 total time=  14.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.579 total time=  13.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.555 total time=  12.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.575 total time=  13.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.577 total time=  18.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  21.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.582 total time=  21.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  21.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  21.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  21.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.574 total time=  20.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  18.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.561 total time=  18.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.580 total time=  15.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  21.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.576 total time=  16.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.577 total time=  17.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.557 total time=  19.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  16.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.582 total time=  20.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.574 total time=  15.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.578 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.562 total time=  14.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  18.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.579 total time=  15.2s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 20, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
    "Best score: 0.5801549654262863\n",
    "\n",
    "Optimizing HistGradientBoostingRegressor using Spearman correlation to select features (1200)...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.537 total time=  14.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.546 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.531 total time=  11.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.535 total time=  16.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.551 total time=  17.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.533 total time=  13.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.545 total time=  13.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.533 total time=  15.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.540 total time=  12.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.555 total time=  13.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.534 total time=  12.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.545 total time=  13.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.534 total time=  13.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.543 total time=  11.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.550 total time=  13.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.529 total time=  11.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.541 total time=  10.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.535 total time=  12.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.535 total time=  12.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.554 total time=  13.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.536 total time=  14.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.557 total time=  16.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.536 total time=  17.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.539 total time=  10.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.552 total time=  17.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.527 total time=  14.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.538 total time=  14.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.529 total time=  14.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.534 total time=  14.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.550 total time=  16.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.544 total time=  25.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  22.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.538 total time=  29.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.542 total time=  25.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.561 total time=  28.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.539 total time=  26.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.548 total time=  21.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.534 total time=  17.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.538 total time=  19.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.562 total time=  25.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.519 total time=  12.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.531 total time=  12.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.523 total time=  12.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.532 total time=  12.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.543 total time=  12.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.539 total time=  22.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  24.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.542 total time=  26.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.544 total time=  21.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.558 total time=  23.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.540 total time=  21.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.552 total time=  22.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.544 total time=  23.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.547 total time=  22.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.558 total time=  23.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.542 total time=  27.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.554 total time=  26.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.542 total time=  28.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.543 total time=  31.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.563 total time=  31.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.542 total time=  28.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.554 total time=  30.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.544 total time=  25.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.546 total time=  27.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.562 total time=  32.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.535 total time=  17.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.544 total time=  17.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.535 total time=  16.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.537 total time=  17.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.553 total time=  17.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.534 total time=  15.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.553 total time=  13.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.534 total time=  13.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.544 total time=  18.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.556 total time=  14.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.539 total time=  16.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.546 total time=  11.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.534 total time=  18.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.545 total time=  16.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.550 total time=  15.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.521 total time=  12.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.534 total time=  12.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.521 total time=  12.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.526 total time=  12.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.539 total time=  12.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.539 total time=  25.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.548 total time=  27.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.541 total time=  26.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.542 total time=  21.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.559 total time=  25.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.536 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.550 total time=  17.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.533 total time=  13.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.535 total time=  15.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.555 total time=  19.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.539 total time=  22.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.555 total time=  25.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.538 total time=  24.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.548 total time=  27.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.562 total time=  22.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.544 total time=  26.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.555 total time=  22.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.541 total time=  22.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.542 total time=  19.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.556 total time=  23.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.538 total time=  15.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.545 total time=  12.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.540 total time=  19.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.538 total time=  11.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.553 total time=  16.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.537 total time=  18.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.545 total time=  12.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.541 total time=  14.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.541 total time=  12.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.558 total time=  13.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.544 total time=  30.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.550 total time=  25.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.545 total time=  39.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.549 total time=  35.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.560 total time=  29.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.539 total time=  18.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.547 total time=  15.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.538 total time=  15.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.543 total time=  17.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.555 total time=  12.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.529 total time=  13.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.541 total time=  11.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.536 total time=  15.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.541 total time=  13.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.550 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.545 total time=  19.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.549 total time=  16.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.535 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.543 total time=  18.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.553 total time=  16.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.542 total time=  27.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.545 total time=  19.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.537 total time=  26.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.544 total time=  22.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.556 total time=  27.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.522 total time=  18.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.534 total time=  19.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.522 total time=  12.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.528 total time=  12.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.543 total time=  12.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.543 total time=  28.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.552 total time=  21.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.544 total time=  30.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.550 total time=  29.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.560 total time=  22.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.542 total time=  25.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.557 total time=  29.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.541 total time=  23.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.545 total time=  24.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.563 total time=  25.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.543 total time=  22.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  22.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.542 total time=  21.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.548 total time=  27.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.558 total time=  29.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.544 total time=  28.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.553 total time=  29.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.542 total time=  29.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.542 total time=  25.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.554 total time=  23.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.543 total time=  26.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.556 total time=  22.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.537 total time=  20.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.548 total time=  27.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.560 total time=  25.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.536 total time=  16.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.545 total time=  13.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.531 total time=  15.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.543 total time=  18.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.555 total time=  14.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.539 total time=  28.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.555 total time=  42.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.542 total time=  36.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.544 total time=  23.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.560 total time=  28.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.531 total time=  18.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.541 total time=  12.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.530 total time=  11.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.534 total time=  11.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.554 total time=  11.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.539 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.539 total time=  16.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.530 total time=  17.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.538 total time=  17.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  14.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.536 total time=  12.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.548 total time=  14.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.529 total time=  18.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.531 total time=  10.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.553 total time=  12.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.540 total time=  21.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.548 total time=  24.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.538 total time=  24.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.538 total time=  20.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.558 total time=  21.4s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Best score: 0.5498209725885485\n",
    "\n",
    "Optimizing HistGradientBoostingRegressor using univariate linear regression to select features (1300)...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.591 total time=  27.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  28.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  27.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.557 total time=  27.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.574 total time=  24.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.587 total time=  16.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.576 total time=  14.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.572 total time=  12.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.555 total time=  14.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.574 total time=  16.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  25.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.580 total time=  27.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.582 total time=  27.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.564 total time=  27.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  28.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.594 total time=  16.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.585 total time=  16.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  20.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.556 total time=  21.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.570 total time=  17.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  14.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.583 total time=  17.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  17.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.552 total time=  22.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.571 total time=  15.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.581 total time=  20.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  18.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.555 total time=  15.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.567 total time=  19.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.591 total time=  23.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.587 total time=  33.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.582 total time=  29.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.562 total time=  23.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.577 total time=  28.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.594 total time=  32.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.580 total time=  32.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.581 total time=  27.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.562 total time=  26.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  28.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.592 total time=  28.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  35.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.579 total time=  23.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.562 total time=  25.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.574 total time=  31.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  27.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.581 total time=  26.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  36.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.562 total time=  30.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.577 total time=  30.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  14.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.576 total time=  17.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.580 total time=  20.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.558 total time=  17.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.570 total time=  22.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.588 total time=  14.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  17.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  16.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.554 total time=  16.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.570 total time=  13.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  17.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.576 total time=  13.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.579 total time=  17.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.553 total time=  11.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.571 total time=  18.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  23.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.582 total time=  24.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.577 total time=  21.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.559 total time=  21.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.572 total time=  21.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  19.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  19.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  19.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.554 total time=  19.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.573 total time=  19.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.588 total time=  13.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.581 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.576 total time=  11.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  15.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.571 total time=  12.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  21.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  21.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.580 total time=  21.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.556 total time=  22.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  21.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  18.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.576 total time=  13.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.574 total time=  12.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.559 total time=  18.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.570 total time=  15.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  21.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.575 total time=  20.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.572 total time=  17.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.555 total time=  15.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.564 total time=  15.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  19.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.582 total time=  17.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.578 total time=  15.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.556 total time=  20.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  15.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.585 total time=  17.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.577 total time=  15.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.576 total time=  13.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.554 total time=  17.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.572 total time=  16.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  18.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.573 total time=  18.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.568 total time=  18.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  18.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.570 total time=  18.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.591 total time=  16.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.577 total time=  21.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.570 total time=  17.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.554 total time=  15.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.577 total time=  18.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  12.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.571 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.579 total time=  16.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.560 total time=  13.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.565 total time=  14.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  19.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.581 total time=  18.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.579 total time=  31.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.558 total time=  13.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.572 total time=  19.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  18.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.589 total time=  18.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.573 total time=  19.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.553 total time=  14.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  18.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  15.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.573 total time=  14.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.571 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.556 total time=  13.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.567 total time=  17.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  31.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.587 total time=  29.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.583 total time=  34.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.558 total time=  30.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.573 total time=  31.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.589 total time=  14.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.578 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  18.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.559 total time=  18.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  12.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.588 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  17.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.573 total time=  14.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.555 total time=  16.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  16.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.589 total time=  22.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.577 total time=  17.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.573 total time=  25.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.554 total time=  22.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.571 total time=  14.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.590 total time=  12.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  15.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  19.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.560 total time=  18.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.574 total time=  19.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.579 total time=  15.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  15.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.565 total time=  15.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.541 total time=  15.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.567 total time=  15.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.576 total time=  17.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.574 total time=  12.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.555 total time=  17.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  15.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.586 total time=  15.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  14.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  14.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.558 total time=  17.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.568 total time=  13.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  16.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.574 total time=  18.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  15.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.555 total time=  18.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  18.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.590 total time=  15.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.579 total time=  20.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  19.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.553 total time=  18.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.568 total time=  16.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  14.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  13.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  18.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.554 total time=  13.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  15.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.594 total time=  27.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  37.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.587 total time=  37.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.565 total time=  32.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  34.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.585 total time=  22.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.587 total time=  18.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.577 total time=  18.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.558 total time=  17.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.572 total time=  17.1s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Best score: 0.5819442316084732\n",
    "\n",
    "Optimizing HistGradientBoostingRegressor using mutual information regression to select features (200)...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.602 total time=  10.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.588 total time=   9.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.602 total time=  10.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  10.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.577 total time=   9.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.596 total time=   5.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.583 total time=   5.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.594 total time=   5.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.587 total time=   5.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.563 total time=   5.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.604 total time=   5.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.596 total time=   7.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.604 total time=   8.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.600 total time=   9.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.575 total time=   9.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.605 total time=   7.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.584 total time=   7.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.608 total time=   7.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.594 total time=   7.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.573 total time=   7.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.601 total time=  10.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  10.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.600 total time=  10.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  11.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.571 total time=  10.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.599 total time=   5.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.585 total time=   5.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.595 total time=   5.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.590 total time=   5.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.571 total time=   5.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.610 total time=  18.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.600 total time=  19.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.610 total time=  16.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.602 total time=  16.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.580 total time=  15.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.613 total time=  14.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.596 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.610 total time=  14.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.598 total time=  14.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  14.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.616 total time=  12.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.577 total time=   4.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.599 total time=   6.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.591 total time=  10.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.572 total time=   6.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.611 total time=   8.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.597 total time=  10.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.603 total time=   8.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.600 total time=   9.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.581 total time=  10.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.613 total time=  10.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  12.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.608 total time=  11.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.601 total time=  12.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.577 total time=  11.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.600 total time=   9.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.589 total time=   9.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.598 total time=   9.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.590 total time=   9.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.576 total time=   9.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.587 total time=   6.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.572 total time=   6.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.585 total time=   6.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.581 total time=   6.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.561 total time=   6.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.614 total time=  14.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  13.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.612 total time=  16.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.603 total time=  19.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.588 total time=  21.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.612 total time=  12.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  12.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.606 total time=  12.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.596 total time=  12.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  12.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.616 total time=  20.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.601 total time=  26.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.615 total time=  19.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.604 total time=  18.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.583 total time=  21.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.612 total time=   8.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  11.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.607 total time=   9.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.596 total time=   9.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.581 total time=   9.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.609 total time=   7.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.593 total time=   8.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.605 total time=   9.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.600 total time=   9.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.570 total time=   9.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.605 total time=   7.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.594 total time=   8.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.598 total time=   7.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.591 total time=   7.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.574 total time=   7.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.613 total time=   9.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  10.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.611 total time=  11.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.601 total time=   9.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.576 total time=   7.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.616 total time=  14.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.592 total time=  12.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.611 total time=  17.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  18.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  11.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.602 total time=  10.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.595 total time=  15.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.606 total time=  14.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.606 total time=  18.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  18.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.610 total time=  13.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.595 total time=  13.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.607 total time=  13.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.603 total time=  13.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.579 total time=  13.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.612 total time=   8.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.598 total time=   8.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.607 total time=   7.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.597 total time=   8.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.581 total time=   8.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.604 total time=   7.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.591 total time=   9.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.605 total time=  10.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.593 total time=   7.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.581 total time=   9.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.605 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  11.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.604 total time=  11.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.599 total time=  11.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.573 total time=  11.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.617 total time=  19.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.601 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.611 total time=  21.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.598 total time=  19.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  20.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.620 total time=  24.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.602 total time=  24.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.610 total time=  15.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.603 total time=  17.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.582 total time=  16.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.603 total time=   7.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.588 total time=   7.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.599 total time=   7.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.584 total time=   5.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.575 total time=   7.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.618 total time=  18.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.596 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.613 total time=  18.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.608 total time=  19.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  20.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.610 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.600 total time=  14.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.608 total time=   9.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.604 total time=   8.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.581 total time=   9.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.622 total time=  21.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.599 total time=  15.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.615 total time=  23.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.599 total time=  15.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.584 total time=  21.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.604 total time=   9.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.588 total time=   9.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.601 total time=   9.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.594 total time=   9.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.575 total time=   9.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.607 total time=  12.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.590 total time=  11.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.606 total time=  11.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  12.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  15.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.578 total time=   5.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.567 total time=   6.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.576 total time=   5.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.573 total time=   6.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.552 total time=   8.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.610 total time=   9.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  10.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.610 total time=   8.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.591 total time=  10.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.579 total time=   9.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.608 total time=   6.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.589 total time=   8.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.600 total time=   7.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.592 total time=   7.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.566 total time=   8.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.598 total time=  11.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.592 total time=  10.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.600 total time=  13.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.592 total time=  12.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.573 total time=  12.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.616 total time=  18.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  15.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.608 total time=  16.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.600 total time=  17.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  17.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.603 total time=  10.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  11.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.601 total time=  10.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.594 total time=  10.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.570 total time=  11.2s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
    "Best score: 0.6039044275109269"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be6d07-34ed-4628-8de1-d48f3cc47d26",
   "metadata": {},
   "source": [
    "Os hiperparÃ¢metros Ã³timos para cada modelo foram, entÃ£o, guardados numa variÃ¡vel <b>best_params</b> de modo a realizar nova validaÃ§Ã£o cruzada de cada um dos modelos (nesta ocasiÃ£o, treinados com hiperparÃ¢metros otimizados)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4189769-b6e7-4bf0-b137-861926c44d1c",
   "metadata": {},
   "source": [
    "<b>SelectFromModel</b>\n",
    "<br>(hyperparameter optmization using SelectFromModel to select the best features to train the models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "33a9874a-cd63-4ce6-a19b-38509293f096",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing HistGradientBoostingRegressor using SelectFromModel to select features...\n",
      "----------\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  27.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  28.7s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.567 total time=  28.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.574 total time=  29.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.595 total time=  29.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  14.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  18.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  16.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.563 total time=  20.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  13.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  18.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  16.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  13.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.560 total time=  15.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.589 total time=  14.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  13.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  13.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.559 total time=  12.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.563 total time=  13.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.590 total time=  13.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  15.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  16.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.561 total time=  15.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.566 total time=  16.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  17.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  24.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  24.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.564 total time=  24.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  24.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.592 total time=  23.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  22.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.581 total time=  23.2s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.565 total time=  24.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.569 total time=  28.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.586 total time=  21.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.592 total time=  26.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.583 total time=  26.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.565 total time=  27.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.572 total time=  28.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  26.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.578 total time=  16.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.573 total time=  16.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.551 total time=  16.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  29.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.589 total time=  25.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  18.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  15.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  16.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  22.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.595 total time=  16.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.583 total time=  22.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.582 total time=  22.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.565 total time=  22.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.570 total time=  22.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.591 total time=  21.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  32.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  31.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.566 total time=  26.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  34.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.596 total time=  28.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.584 total time=  14.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  19.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.561 total time=  17.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.569 total time=  17.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  18.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.580 total time=  17.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.582 total time=  19.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.561 total time=  16.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  17.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.590 total time=  19.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  21.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.579 total time=  21.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.559 total time=  21.3s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  21.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.593 total time=  22.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  14.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  16.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.561 total time=  15.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  17.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  14.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.590 total time=  33.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  27.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.566 total time=  29.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.573 total time=  31.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.599 total time=  34.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  20.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.577 total time=  18.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  17.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.569 total time=  15.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.592 total time=  21.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.581 total time=  13.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  16.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  12.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.567 total time=  16.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.587 total time=  14.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.579 total time=  19.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  21.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.564 total time=  14.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  13.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  15.3s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.585 total time=  22.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  23.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.561 total time=  26.3s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.572 total time=  27.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  27.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.592 total time=  28.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.582 total time=  29.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.566 total time=  28.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.569 total time=  30.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.595 total time=  29.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  17.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.581 total time=  16.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.553 total time=  16.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.563 total time=  17.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.593 total time=  15.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  19.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.565 total time=  28.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  24.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.596 total time=  26.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.587 total time=  24.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  23.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.563 total time=  26.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  24.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.599 total time=  23.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  31.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  30.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.565 total time=  31.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.573 total time=  25.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.598 total time=  36.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.577 total time=  18.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  14.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.562 total time=  17.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  17.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  20.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.587 total time=  29.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.585 total time=  22.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.563 total time=  25.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  28.9s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.592 total time=  29.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  24.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  29.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.568 total time=  30.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.572 total time=  25.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.593 total time=  25.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  22.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  26.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.566 total time=  29.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.569 total time=  23.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  24.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  19.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.575 total time=  16.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.561 total time=  18.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  19.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  15.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.572 total time=  12.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  13.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.547 total time=  13.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  14.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  15.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.586 total time=  29.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  27.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  31.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  29.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  28.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  14.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.564 total time=  15.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.550 total time=  14.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.557 total time=  14.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  15.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  19.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  17.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.565 total time=  19.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.569 total time=  17.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.597 total time=  17.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.591 total time=  30.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.585 total time=  23.2s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.565 total time=  33.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  27.3s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  33.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.582 total time=  22.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  29.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  24.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.597 total time=  30.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.581 total time=  19.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  18.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.559 total time=  18.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.566 total time=  17.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.583 total time=  18.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.580 total time=  18.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.578 total time=  17.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.565 total time=  15.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.566 total time=  14.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.589 total time=  14.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  16.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  12.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.561 total time=  15.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.566 total time=  14.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  16.2s\n",
      "----------\n",
      "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 55, 'max_iter': 200, 'learning_rate': 0.05}\n",
      "Best score: 0.5836554527166748\n"
     ]
    }
   ],
   "source": [
    "print(f\"Optimizing HistGradientBoostingRegressor using SelectFromModel to select features...\")\n",
    "print(\"----------\")\n",
    "x_train_sfm = X_train_sc.iloc[:, feature_mask]\n",
    "gs_sfm = RandomizedSearchCV(estimator=HGBR(),\n",
    "                            param_distributions=HYPER,\n",
    "                            n_iter=40,\n",
    "                            cv=KFold(n_splits=5, shuffle=True),\n",
    "                            verbose=3)\n",
    "gs_sfm.fit(x_train_sfm, y_train)\n",
    "print(\"----------\")\n",
    "print(f\"Optimal hyperparameters: {gs_sfm.best_params_}\")\n",
    "print(f\"Best score: {gs_sfm.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4dd60e-843a-4053-aba0-a280bc37e805",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Optimizing HistGradientBoostingRegressor using SelectFromModel to select features...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  27.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  28.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.567 total time=  28.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.574 total time=  29.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.595 total time=  29.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  14.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  18.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  16.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.563 total time=  20.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  13.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  18.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  16.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  13.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.560 total time=  15.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.589 total time=  14.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  13.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  13.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.559 total time=  12.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.563 total time=  13.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.590 total time=  13.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  15.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  16.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.561 total time=  15.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.566 total time=  16.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  17.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  24.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  24.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.564 total time=  24.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  24.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.592 total time=  23.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  22.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.581 total time=  23.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.565 total time=  24.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.569 total time=  28.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.586 total time=  21.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.592 total time=  26.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.583 total time=  26.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.565 total time=  27.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.572 total time=  28.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  26.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.578 total time=  16.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.573 total time=  16.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.551 total time=  16.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  29.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.589 total time=  25.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  18.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  15.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  16.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  22.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.595 total time=  16.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.583 total time=  22.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.582 total time=  22.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.565 total time=  22.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.570 total time=  22.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.591 total time=  21.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  32.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  31.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.566 total time=  26.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  34.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.596 total time=  28.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.584 total time=  14.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  19.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.561 total time=  17.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.569 total time=  17.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  18.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.580 total time=  17.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.582 total time=  19.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.561 total time=  16.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  17.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.590 total time=  19.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  21.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.579 total time=  21.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.559 total time=  21.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  21.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.593 total time=  22.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  16.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.561 total time=  15.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  17.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  14.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.590 total time=  33.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  27.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.566 total time=  29.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.573 total time=  31.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.599 total time=  34.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  20.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.577 total time=  18.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  17.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.569 total time=  15.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.592 total time=  21.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.581 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  16.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.567 total time=  16.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.587 total time=  14.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.579 total time=  19.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  21.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.564 total time=  14.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  13.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  15.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.585 total time=  22.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  23.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.561 total time=  26.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.572 total time=  27.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  27.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.592 total time=  28.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.582 total time=  29.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.566 total time=  28.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.569 total time=  30.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.595 total time=  29.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  17.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.581 total time=  16.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.553 total time=  16.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.563 total time=  17.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.593 total time=  15.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  19.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.565 total time=  28.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  24.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.596 total time=  26.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.587 total time=  24.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  23.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.563 total time=  26.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  24.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.599 total time=  23.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  31.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  30.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.565 total time=  31.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.573 total time=  25.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.598 total time=  36.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.577 total time=  18.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.562 total time=  17.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  17.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  20.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.587 total time=  29.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.585 total time=  22.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.563 total time=  25.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  28.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.592 total time=  29.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  24.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  29.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.568 total time=  30.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.572 total time=  25.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.593 total time=  25.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  22.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  26.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.566 total time=  29.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.569 total time=  23.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  24.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  19.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.575 total time=  16.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.561 total time=  18.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  19.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  15.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.572 total time=  12.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  13.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.547 total time=  13.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  14.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  15.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.586 total time=  29.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  27.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  31.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  29.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  28.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.564 total time=  15.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.550 total time=  14.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.557 total time=  14.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  19.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  17.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.565 total time=  19.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.569 total time=  17.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.597 total time=  17.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.591 total time=  30.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.585 total time=  23.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.565 total time=  33.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  27.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  33.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.582 total time=  22.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  29.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  24.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.597 total time=  30.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.581 total time=  19.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  18.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.559 total time=  18.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.566 total time=  17.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.583 total time=  18.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.580 total time=  18.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.578 total time=  17.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.565 total time=  15.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.566 total time=  14.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.589 total time=  14.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  16.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  12.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.561 total time=  15.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.566 total time=  14.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  16.2s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 55, 'max_iter': 200, 'learning_rate': 0.05}\n",
    "Best score: 0.5836554527166748"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972f740-8107-4c50-b221-f558b9319eae",
   "metadata": {},
   "source": [
    "<b>Pearson + Spearman + mutual information</b>\n",
    "<br>(hyperparameter optmization using a combination of feature selection methods to select the best features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0b88c56-e926-4a48-967d-a7f010abfe03",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing HistGradientBoostingRegressor using a combination of feature selection methods...\n",
      "----------\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.596 total time= 1.0min\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.587 total time= 1.4min\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.602 total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.608 total time= 1.0min\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.608 total time=  54.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.587 total time=  28.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.585 total time=  28.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  28.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  28.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.593 total time=  28.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  19.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.573 total time=  19.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.578 total time=  19.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.586 total time=  19.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  19.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.586 total time=  17.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  20.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.590 total time=  22.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.599 total time=  23.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.596 total time=  20.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.588 total time=  30.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.585 total time=  30.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.594 total time=  30.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.596 total time=  30.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.596 total time=  30.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.587 total time=  28.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.584 total time=  27.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  30.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.598 total time=  22.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.598 total time=  27.3s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  22.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.582 total time=  22.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  22.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  22.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  22.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  42.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.587 total time=  40.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  36.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.598 total time=  42.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.603 total time=  41.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  52.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.588 total time=  44.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.599 total time=  47.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.602 total time=  53.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.604 total time= 1.0min\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.591 total time=  36.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.586 total time=  36.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.596 total time=  35.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.596 total time=  36.3s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.597 total time=  35.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  26.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.581 total time=  26.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.592 total time=  27.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  27.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.598 total time=  27.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.587 total time=  21.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.591 total time=  21.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.593 total time=  19.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.595 total time=  21.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  14.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  23.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  23.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  26.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  20.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.600 total time=  27.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  21.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  19.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  25.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.590 total time=  18.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.597 total time=  25.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.579 total time=  23.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  23.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  23.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  23.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  21.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.585 total time=  27.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.591 total time=  28.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.597 total time=  22.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.592 total time=  20.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.590 total time=  23.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.588 total time=  31.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  30.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.598 total time=  28.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.598 total time=  27.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.590 total time=  26.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  22.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  22.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.595 total time=  25.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.598 total time=  20.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.591 total time=  30.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.592 total time=  25.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  45.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.600 total time=  23.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.598 total time=  22.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.589 total time=  22.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  28.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.591 total time=  27.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.599 total time=  21.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.595 total time=  17.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  34.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  21.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.590 total time=  19.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  23.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.599 total time=  25.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  21.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.585 total time=  27.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.592 total time=  25.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.596 total time=  29.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.598 total time=  24.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.589 total time=  21.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  20.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  21.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  21.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.595 total time=  21.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.586 total time=  18.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  27.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.595 total time=  29.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.597 total time=  22.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.603 total time=  25.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  21.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.579 total time=  12.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.594 total time=  28.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.594 total time=  18.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.590 total time=  19.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  29.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.589 total time=  29.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  29.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.595 total time=  29.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  29.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  23.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.591 total time=  26.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.596 total time=  28.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.595 total time=  18.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.602 total time=  26.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  30.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  23.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.589 total time=  19.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.596 total time=  27.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.597 total time=  30.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  30.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.583 total time=  29.7s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.594 total time=  29.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.597 total time=  29.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.593 total time=  30.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  50.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.591 total time=  54.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  54.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.610 total time=  59.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.603 total time=  50.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.593 total time=  38.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.587 total time=  49.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.598 total time=  43.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.604 total time=  39.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.601 total time=  53.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.586 total time=  18.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.590 total time=  27.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.592 total time=  28.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.597 total time=  23.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.597 total time=  21.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  51.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  53.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.602 total time=  45.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.605 total time=  48.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.599 total time=  38.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.584 total time=  26.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  22.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.591 total time=  28.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.596 total time=  31.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.595 total time=  21.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  27.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.589 total time=  21.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.597 total time=  27.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.600 total time=  21.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.600 total time=  29.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.582 total time=  15.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  15.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.589 total time=  14.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.595 total time=  14.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.591 total time=  14.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  19.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.581 total time=  19.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  19.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.598 total time=  19.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.595 total time=  19.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  30.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.585 total time=  30.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.591 total time=  30.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.598 total time=  30.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  30.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  45.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.586 total time=  39.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.600 total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.602 total time=  50.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.604 total time=  43.9s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.582 total time=  27.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.589 total time=  27.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  27.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  27.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  27.9s\n",
      "----------\n",
      "Optimal hyperparameters: {'warm_start': True, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
      "Best score: 0.600136158051844\n"
     ]
    }
   ],
   "source": [
    "print(f\"Optimizing HistGradientBoostingRegressor using a combination of feature selection methods...\")\n",
    "print(\"----------\")\n",
    "x_train_psmi = X_train_sc[best_features_psmi]\n",
    "gs_psmi = RandomizedSearchCV(estimator=HGBR(),\n",
    "                             param_distributions=HYPER,\n",
    "                             n_iter=40,\n",
    "                             cv=KFold(n_splits=5, shuffle=True),\n",
    "                             verbose=3)\n",
    "gs_psmi.fit(x_train_psmi, y_train)\n",
    "print(\"----------\")\n",
    "print(f\"Optimal hyperparameters: {gs_psmi.best_params_}\")\n",
    "print(f\"Best score: {gs_psmi.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dc6c1-ff66-4952-a11f-9ebac423757b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Optimizing HistGradientBoostingRegressor using a combination of feature selection methods...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.605 total time=  23.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.593 total time=  19.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.607 total time=  20.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.598 total time=  18.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  18.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.607 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.590 total time=  12.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.602 total time=  12.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.602 total time=  11.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  11.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.612 total time=  21.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.597 total time=  27.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.605 total time=  20.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.603 total time=  24.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.578 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.608 total time=  20.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  20.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.607 total time=  20.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.600 total time=  17.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.577 total time=  16.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.599 total time=   8.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.590 total time=   9.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.595 total time=   8.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.598 total time=  11.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.574 total time=   9.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.603 total time=  15.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.588 total time=  15.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.603 total time=  15.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.593 total time=  16.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.575 total time=  17.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.601 total time=   8.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.589 total time=   9.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.597 total time=   8.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.596 total time=  12.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.574 total time=  10.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.603 total time=  11.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.587 total time=  10.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.601 total time=   8.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  10.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.571 total time=  11.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.598 total time=  13.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.600 total time=  22.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.599 total time=  23.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.603 total time=  18.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.576 total time=  19.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.607 total time=   9.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.582 total time=   7.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.596 total time=   9.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.597 total time=   9.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.581 total time=   9.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  10.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.577 total time=  10.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.593 total time=  10.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.586 total time=  10.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.566 total time=  10.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.604 total time=  15.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  16.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.606 total time=  24.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.593 total time=  16.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.579 total time=  20.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.607 total time=  19.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  18.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.601 total time=  15.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.598 total time=  20.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.576 total time=  19.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.605 total time=  11.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  11.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.599 total time=  11.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.596 total time=  11.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.577 total time=  11.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  10.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  10.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.596 total time=  10.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  10.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  10.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.598 total time=  11.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.583 total time=  11.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.596 total time=  11.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  11.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.570 total time=  11.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.590 total time=   8.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.584 total time=   8.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.596 total time=   8.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.591 total time=   9.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.569 total time=  10.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  10.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  10.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  13.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.587 total time=  10.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.566 total time=  10.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.609 total time=  15.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  18.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.602 total time=  22.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.596 total time=  18.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  19.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.600 total time=  10.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.581 total time=   8.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.598 total time=  10.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  11.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.566 total time=   8.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  10.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  10.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.596 total time=  10.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  10.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.566 total time=  10.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.606 total time=  18.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.594 total time=  17.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.605 total time=  16.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.602 total time=  19.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.576 total time=  24.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.596 total time=  14.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.577 total time=  10.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.594 total time=  16.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.591 total time=   9.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.565 total time=   9.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.611 total time=  18.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  19.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.603 total time=  13.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.601 total time=  12.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.576 total time=  13.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.603 total time=  17.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.589 total time=  21.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.599 total time=  11.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.597 total time=  12.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.575 total time=  11.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.608 total time=  13.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  10.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.599 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.592 total time=   8.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  13.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.602 total time=  11.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.580 total time=  13.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.594 total time=  12.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  12.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.568 total time=  12.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.594 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  11.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.596 total time=  11.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.592 total time=  11.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  13.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.609 total time=  25.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.597 total time=  25.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.602 total time=  18.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.596 total time=  20.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  24.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.608 total time=  19.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  11.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  15.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  14.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.578 total time=  12.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.605 total time=  12.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  12.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.601 total time=  13.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.593 total time=  13.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.576 total time=  13.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.603 total time=  10.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.594 total time=  12.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.596 total time=  11.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.594 total time=   9.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.573 total time=   9.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.603 total time=  11.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.592 total time=  13.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.601 total time=  13.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.594 total time=   9.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  12.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.607 total time=  11.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  12.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  13.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.590 total time=   9.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.576 total time=  13.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.610 total time=  24.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.592 total time=  18.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.601 total time=  16.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.605 total time=  21.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.580 total time=  21.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.603 total time=  15.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.591 total time=  15.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.600 total time=  15.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.597 total time=  15.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.571 total time=  15.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.602 total time=  15.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  15.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.602 total time=  15.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.591 total time=  16.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.581 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.604 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.588 total time=   9.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.598 total time=   8.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.601 total time=  12.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  10.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.603 total time=  10.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  12.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.599 total time=  11.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.594 total time=  12.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.577 total time=   9.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.607 total time=  20.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  17.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.603 total time=  23.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.597 total time=  15.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.579 total time=  16.7s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 24, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Best score: 0.5990082671786074"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a050d6e-23c5-433c-b31d-c8525071ec60",
   "metadata": {},
   "source": [
    "Os hiperparÃ¢metros Ã³timos referentes aos modelos obtidos pelos restantes mÃ©todos de seleÃ§Ã£o de features serÃ£o futuramente acessados atravÃ©s do atributo <b>best_params_</b> de objetos da classe <b>RandomizedSearchCV</b> (<b>gs_sfm.best_params_</b> e <b>gs_psmi.best_params_</b>)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78576f",
   "metadata": {},
   "source": [
    "### Cross-validate best models (with optimized hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d73b7-45c9-4b93-83de-225b313d0e86",
   "metadata": {},
   "source": [
    "Procedemos, entÃ£o, a uma validaÃ§Ã£o cruzada 10-fold dos melhores modelos obtidos atravÃ©s de cada um dos mÃ©todos de seleÃ§Ã£o de features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a6081-a6df-4d98-8e6d-92a41fc35ce6",
   "metadata": {},
   "source": [
    "<b>Pearson, Spearman, univariate linear regression and mutual information regression</b>\n",
    "<br>(cross-validation of the best models with optimized hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f3d9df1f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# only cross-validates HistGradientBoostingRegressor, as it was invariably the best model\n",
    "def cv_best(models, params: list, methods: list, corrs: list, num_feats: list, cv=10):\n",
    "    for mo, pr, me, co, nf in zip(models, params, methods, corrs, num_feats):\n",
    "        InitModel = mo()\n",
    "        print(f\"Cross-validating ({cv}-fold) {InitModel.__class__.__name__} using {me} ({nf} features)...\")\n",
    "        print(f\"Optimized hyperparameters: {pr}\")\n",
    "        x_train = X_train_sc.loc[:,get_k_best_corrs(nf, co).keys()]\n",
    "        result = cross_validate(estimator=InitModel.set_params(**pr),\n",
    "                                X=x_train,\n",
    "                                y=y_train,\n",
    "                                cv=KFold(n_splits=cv, shuffle=True),\n",
    "                                return_train_score=True)\n",
    "        mean_train = np.sum(result[\"train_score\"]) / cv\n",
    "        mean_test = np.sum(result[\"test_score\"]) / cv\n",
    "        print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "        print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e8281b35",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating (10-fold) HistGradientBoostingRegressor using Pearson correlation (1200 features)...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 20, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
      "Train scores: [0.73233652 0.73407498 0.73019125 0.74800317 0.73221829 0.71548573\n",
      " 0.75295105 0.74165818 0.73646702 0.7178306 ] -> mean_train = 0.7341\n",
      "Test scores: [0.56623301 0.60612089 0.57279343 0.57305721 0.56753691 0.60907319\n",
      " 0.59046368 0.57254022 0.61033073 0.58555759] -> mean_test = 0.5854\n",
      "\n",
      "Cross-validating (10-fold) HistGradientBoostingRegressor using Spearman correlation (1200 features)...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
      "Train scores: [0.7046133  0.72345338 0.68532331 0.74236339 0.72630959 0.69784186\n",
      " 0.68999517 0.73570951 0.72595013 0.71897368] -> mean_train = 0.7151\n",
      "Test scores: [0.53102774 0.55152941 0.55988561 0.55823386 0.5664989  0.55229307\n",
      " 0.58424717 0.56240558 0.52764792 0.54849861] -> mean_test = 0.5542\n",
      "\n",
      "Cross-validating (10-fold) HistGradientBoostingRegressor using univariate linear regression (1300 features)...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
      "Train scores: [0.75582173 0.7276507  0.76533005 0.72540476 0.73508961 0.73966701\n",
      " 0.74035541 0.73509884 0.73865676 0.76293388] -> mean_train = 0.7426\n",
      "Test scores: [0.59155216 0.5764809  0.60739257 0.5594956  0.59567879 0.59699155\n",
      " 0.58574327 0.59043057 0.58562394 0.58767947] -> mean_test = 0.5877\n",
      "\n",
      "Cross-validating (10-fold) HistGradientBoostingRegressor using mutual information regression (200 features)...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
      "Train scores: [0.76875166 0.73104154 0.75049263 0.76938016 0.76481907 0.75684443\n",
      " 0.73644814 0.74662982 0.76163698 0.78642204] -> mean_train = 0.7572\n",
      "Test scores: [0.60509896 0.6142814  0.60063617 0.63996885 0.62272178 0.59556783\n",
      " 0.60761713 0.59120005 0.59343065 0.58970676] -> mean_test = 0.6060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all variables defined above (models, best_params, methods, corrs, num_feats)\n",
    "cv_best(models, best_params, methods, corrs, num_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22262248-1303-47d2-ae67-bc9134a62771",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Cross-validating (10-fold) HistGradientBoostingRegressor using Pearson correlation (1200 features)...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 20, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
    "Train scores: [0.73233652 0.73407498 0.73019125 0.74800317 0.73221829 0.71548573\n",
    " 0.75295105 0.74165818 0.73646702 0.7178306 ] -> mean_train = 0.7341\n",
    "Test scores: [0.56623301 0.60612089 0.57279343 0.57305721 0.56753691 0.60907319\n",
    " 0.59046368 0.57254022 0.61033073 0.58555759] -> mean_test = 0.5854\n",
    "\n",
    "Cross-validating (10-fold) HistGradientBoostingRegressor using Spearman correlation (1200 features)...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Train scores: [0.7046133  0.72345338 0.68532331 0.74236339 0.72630959 0.69784186\n",
    " 0.68999517 0.73570951 0.72595013 0.71897368] -> mean_train = 0.7151\n",
    "Test scores: [0.53102774 0.55152941 0.55988561 0.55823386 0.5664989  0.55229307\n",
    " 0.58424717 0.56240558 0.52764792 0.54849861] -> mean_test = 0.5542\n",
    "\n",
    "Cross-validating (10-fold) HistGradientBoostingRegressor using univariate linear regression (1300 features)...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Train scores: [0.75582173 0.7276507  0.76533005 0.72540476 0.73508961 0.73966701\n",
    " 0.74035541 0.73509884 0.73865676 0.76293388] -> mean_train = 0.7426\n",
    "Test scores: [0.59155216 0.5764809  0.60739257 0.5594956  0.59567879 0.59699155\n",
    " 0.58574327 0.59043057 0.58562394 0.58767947] -> mean_test = 0.5877\n",
    "\n",
    "Cross-validating (10-fold) HistGradientBoostingRegressor using mutual information regression (200 features)...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
    "Train scores: [0.76875166 0.73104154 0.75049263 0.76938016 0.76481907 0.75684443\n",
    " 0.73644814 0.74662982 0.76163698 0.78642204] -> mean_train = 0.7572\n",
    "Test scores: [0.60509896 0.6142814  0.60063617 0.63996885 0.62272178 0.59556783\n",
    " 0.60761713 0.59120005 0.59343065 0.58970676] -> mean_test = 0.6060"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695b43f-643c-4d8b-970d-07261b01c51f",
   "metadata": {},
   "source": [
    "Os resultados da validaÃ§Ã£o cruzada demonstram que o melhor score foi obtido utilizando a <b>informaÃ§Ã£o mÃºtua</b> como mÃ©todo de seleÃ§Ã£o de features (<b>0.6060</b>). O modelo respetivo serÃ¡, entÃ£o comparado com os modelos obtidos a partir dos mÃ©todos de seleÃ§Ã£o de features <b>SelectFromModel</b> e <b>Pearson + Spearman + mutual information</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d3a0c-c3b5-4b8f-b634-2017b325da91",
   "metadata": {},
   "source": [
    "<b>SelectFromModel</b>\n",
    "<br>(cross-validation of the best model with optimized hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f685b26d-2c39-42f4-bf57-d9c211140ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating (10-fold) HistGradientBoostingRegressor using SelectFromModel to select features...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 55, 'max_iter': 200, 'learning_rate': 0.05}\n",
      "Train scores: [0.72930953 0.72559338 0.72952691 0.73186194 0.73014827 0.7371733\n",
      " 0.71938107 0.72341578 0.75435627 0.76341954] -> mean_train = 0.7344\n",
      "Test scores: [0.57799925 0.62441839 0.60640188 0.57680143 0.60326652 0.59459631\n",
      " 0.60107882 0.56927381 0.58052564 0.54540325] -> mean_test = 0.5880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross-validating (10-fold) HistGradientBoostingRegressor using SelectFromModel to select features...\")\n",
    "print(f\"Optimized hyperparameters: {gs_sfm.best_params_}\")\n",
    "x_train_sfm = X_train_sc.iloc[:, feature_mask]\n",
    "result = cross_validate(estimator=HGBR(**gs_sfm.best_params_),\n",
    "                        X=x_train_sfm,\n",
    "                        y=y_train,\n",
    "                        cv=KFold(n_splits=10, shuffle=True),\n",
    "                        return_train_score=True)\n",
    "mean_train = np.sum(result[\"train_score\"]) / 10\n",
    "mean_test = np.sum(result[\"test_score\"]) / 10\n",
    "print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb3980-bc0e-484f-a292-90886e05e97c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Cross-validating (10-fold) HistGradientBoostingRegressor using SelectFromModel to select features...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 55, 'max_iter': 200, 'learning_rate': 0.05}\n",
    "Train scores: [0.72930953 0.72559338 0.72952691 0.73186194 0.73014827 0.7371733\n",
    " 0.71938107 0.72341578 0.75435627 0.76341954] -> mean_train = 0.7344\n",
    "Test scores: [0.57799925 0.62441839 0.60640188 0.57680143 0.60326652 0.59459631\n",
    " 0.60107882 0.56927381 0.58052564 0.54540325] -> mean_test = 0.5880"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba12b6-b1d5-4fb3-8ba8-5052acc92014",
   "metadata": {},
   "source": [
    "O score obtido na validaÃ§Ã£o cruzada foi de <b>0.5880</b>. Sendo assim, o melhor modelo atÃ© ao momento Ã© o obtido atravÃ©s da seleÃ§Ã£o de features pela <b>informaÃ§Ã£o mÃºtua</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3dd86-518a-424c-9b3c-7dc45c8e529f",
   "metadata": {},
   "source": [
    "<b>Pearson + Spearman + mutual information</b>\n",
    "<br>(cross-validation of the best model with optimized hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4716ec1-3f24-416c-9efe-1bafa8fa691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating (10-fold) HistGradientBoostingRegressor using a combination of feature selection methods...\n",
      "Optimized hyperparameters: {'warm_start': True, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
      "Train scores: [0.75380586 0.74244005 0.74206205 0.74833658 0.74580747 0.75685111\n",
      " 0.74250112 0.74689319 0.75487387 0.74426017] -> mean_train = 0.7478\n",
      "Test scores: [0.58764092 0.59907974 0.62072532 0.62004219 0.60299351 0.60183481\n",
      " 0.60394989 0.59682932 0.58152845 0.59126593] -> mean_test = 0.6006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross-validating (10-fold) HistGradientBoostingRegressor using a combination of feature selection methods...\")\n",
    "print(f\"Optimized hyperparameters: {gs_psmi.best_params_}\")\n",
    "x_train_psmi = X_train_sc[best_features_psmi]\n",
    "result = cross_validate(estimator=HGBR(**gs_psmi.best_params_),\n",
    "                        X=x_train_psmi,\n",
    "                        y=y_train,\n",
    "                        cv=KFold(n_splits=10, shuffle=True),\n",
    "                        return_train_score=True)\n",
    "mean_train = np.sum(result[\"train_score\"]) / 10\n",
    "mean_test = np.sum(result[\"test_score\"]) / 10\n",
    "print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76691a74-ba12-42e5-9264-e36a86476437",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Cross-validating (10-fold) HistGradientBoostingRegressor using a combination of feature selection methods...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 24, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Train scores: [0.73414891 0.75532122 0.76818821 0.76678538 0.74952505 0.77140543\n",
    " 0.74788207 0.7446634  0.73644775 0.73045008] -> mean_train = 0.7505\n",
    "Test scores: [0.61389366 0.6229216  0.59246623 0.6059233  0.58573252 0.6024856\n",
    " 0.59056188 0.62128784 0.58690858 0.59315414] -> mean_test = 0.6015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d8256-b663-4db0-95f0-e15a5e7e57ae",
   "metadata": {},
   "source": [
    "Finalmente, obteve-se um score mÃ©dio de <b>0.6015</b> na validaÃ§ao cruzada referente ao modelo obtido pela combinaÃ§Ã£o de mÃ©todos de seleÃ§Ã£o de features <b>Pearson + Spearman + mutual information</b>. Verificamos, entÃ£o, que o melhor modelo se trata do obtido atravÃ©s da seleÃ§Ã£o de features pela <b>informaÃ§Ã£o mÃºtua</b>, sendo utilizado para efetuar previsÃµes acerca dos dados de teste (sequÃªncias de aminoÃ¡cidos sem label associada)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b7a3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use best model to predict labels in test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "594e7ed7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_dataset_with_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-63-32118d22649f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# nÃ£o correr! dados em 'data_test.csv'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mtest\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"test.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtest_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_dataset_with_features\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data_test.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'get_dataset_with_features' is not defined"
     ]
    }
   ],
   "source": [
    "# nÃ£o correr! dados em 'data_test.csv'\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_data = get_dataset_with_features(test)\n",
    "test_data.to_csv(\"data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a208d268",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa7958dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# split features and label\n",
    "X_test = test_data.iloc[:, 2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45fec257-488b-4fd2-a036-d49fae6ac00e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      SeqLength       A      R      N      D      C      E      Q      G    H  \\\n0           221   9.955  1.357  8.597  6.787  1.810  3.620  5.882  8.597  0.0   \n1           221   9.955  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n2           220  10.000  1.364  8.636  6.818  1.818  3.182  5.909  8.636  0.0   \n3           221   9.955  1.357  8.597  6.787  2.262  3.167  5.882  8.597  0.0   \n4           221   9.955  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n...         ...     ...    ...    ...    ...    ...    ...    ...    ...  ...   \n2408        221   9.502  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n2409        221   9.502  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n2410        221   9.502  1.357  9.050  6.787  1.810  3.167  5.882  8.597  0.0   \n2411        221   9.502  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n2412        221   9.502  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n\n      ...  MoreauBrotoAuto_Mutability22  MoreauBrotoAuto_Mutability23  \\\n0     ...                        -0.021                        -0.025   \n1     ...                        -0.023                        -0.027   \n2     ...                        -0.025                        -0.029   \n3     ...                        -0.022                        -0.026   \n4     ...                        -0.023                        -0.027   \n...   ...                           ...                           ...   \n2408  ...                        -0.023                        -0.027   \n2409  ...                        -0.014                        -0.018   \n2410  ...                        -0.029                        -0.033   \n2411  ...                        -0.017                        -0.021   \n2412  ...                        -0.011                        -0.015   \n\n      MoreauBrotoAuto_Mutability24  MoreauBrotoAuto_Mutability25  \\\n0                           -0.032                        -0.023   \n1                           -0.034                        -0.025   \n2                           -0.035                        -0.027   \n3                           -0.033                        -0.024   \n4                           -0.034                        -0.025   \n...                            ...                           ...   \n2408                        -0.034                        -0.025   \n2409                        -0.025                        -0.016   \n2410                        -0.040                        -0.031   \n2411                        -0.027                        -0.019   \n2412                        -0.021                        -0.013   \n\n      MoreauBrotoAuto_Mutability26  MoreauBrotoAuto_Mutability27  \\\n0                           -0.019                        -0.016   \n1                           -0.021                        -0.018   \n2                           -0.023                        -0.020   \n3                           -0.020                        -0.017   \n4                           -0.021                        -0.018   \n...                            ...                           ...   \n2408                        -0.021                        -0.018   \n2409                        -0.012                        -0.009   \n2410                        -0.028                        -0.024   \n2411                        -0.015                        -0.012   \n2412                        -0.009                        -0.006   \n\n      MoreauBrotoAuto_Mutability28  MoreauBrotoAuto_Mutability29  \\\n0                           -0.019                        -0.026   \n1                           -0.021                        -0.028   \n2                           -0.023                        -0.030   \n3                           -0.020                        -0.027   \n4                           -0.021                        -0.028   \n...                            ...                           ...   \n2408                        -0.021                        -0.028   \n2409                        -0.012                        -0.019   \n2410                        -0.028                        -0.035   \n2411                        -0.015                        -0.022   \n2412                        -0.009                        -0.016   \n\n      MoreauBrotoAuto_Mutability30  pH  \n0                           -0.021   8  \n1                           -0.023   8  \n2                           -0.025   8  \n3                           -0.022   8  \n4                           -0.023   8  \n...                            ...  ..  \n2408                        -0.023   8  \n2409                        -0.014   8  \n2410                        -0.029   8  \n2411                        -0.017   8  \n2412                        -0.010   8  \n\n[2413 rows x 9298 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SeqLength</th>\n      <th>A</th>\n      <th>R</th>\n      <th>N</th>\n      <th>D</th>\n      <th>C</th>\n      <th>E</th>\n      <th>Q</th>\n      <th>G</th>\n      <th>H</th>\n      <th>...</th>\n      <th>MoreauBrotoAuto_Mutability22</th>\n      <th>MoreauBrotoAuto_Mutability23</th>\n      <th>MoreauBrotoAuto_Mutability24</th>\n      <th>MoreauBrotoAuto_Mutability25</th>\n      <th>MoreauBrotoAuto_Mutability26</th>\n      <th>MoreauBrotoAuto_Mutability27</th>\n      <th>MoreauBrotoAuto_Mutability28</th>\n      <th>MoreauBrotoAuto_Mutability29</th>\n      <th>MoreauBrotoAuto_Mutability30</th>\n      <th>pH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>221</td>\n      <td>9.955</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.620</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.021</td>\n      <td>-0.025</td>\n      <td>-0.032</td>\n      <td>-0.023</td>\n      <td>-0.019</td>\n      <td>-0.016</td>\n      <td>-0.019</td>\n      <td>-0.026</td>\n      <td>-0.021</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>221</td>\n      <td>9.955</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.023</td>\n      <td>-0.027</td>\n      <td>-0.034</td>\n      <td>-0.025</td>\n      <td>-0.021</td>\n      <td>-0.018</td>\n      <td>-0.021</td>\n      <td>-0.028</td>\n      <td>-0.023</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>220</td>\n      <td>10.000</td>\n      <td>1.364</td>\n      <td>8.636</td>\n      <td>6.818</td>\n      <td>1.818</td>\n      <td>3.182</td>\n      <td>5.909</td>\n      <td>8.636</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.025</td>\n      <td>-0.029</td>\n      <td>-0.035</td>\n      <td>-0.027</td>\n      <td>-0.023</td>\n      <td>-0.020</td>\n      <td>-0.023</td>\n      <td>-0.030</td>\n      <td>-0.025</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>221</td>\n      <td>9.955</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>2.262</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.022</td>\n      <td>-0.026</td>\n      <td>-0.033</td>\n      <td>-0.024</td>\n      <td>-0.020</td>\n      <td>-0.017</td>\n      <td>-0.020</td>\n      <td>-0.027</td>\n      <td>-0.022</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>221</td>\n      <td>9.955</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.023</td>\n      <td>-0.027</td>\n      <td>-0.034</td>\n      <td>-0.025</td>\n      <td>-0.021</td>\n      <td>-0.018</td>\n      <td>-0.021</td>\n      <td>-0.028</td>\n      <td>-0.023</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2408</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.023</td>\n      <td>-0.027</td>\n      <td>-0.034</td>\n      <td>-0.025</td>\n      <td>-0.021</td>\n      <td>-0.018</td>\n      <td>-0.021</td>\n      <td>-0.028</td>\n      <td>-0.023</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2409</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.014</td>\n      <td>-0.018</td>\n      <td>-0.025</td>\n      <td>-0.016</td>\n      <td>-0.012</td>\n      <td>-0.009</td>\n      <td>-0.012</td>\n      <td>-0.019</td>\n      <td>-0.014</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2410</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>9.050</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.029</td>\n      <td>-0.033</td>\n      <td>-0.040</td>\n      <td>-0.031</td>\n      <td>-0.028</td>\n      <td>-0.024</td>\n      <td>-0.028</td>\n      <td>-0.035</td>\n      <td>-0.029</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2411</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.017</td>\n      <td>-0.021</td>\n      <td>-0.027</td>\n      <td>-0.019</td>\n      <td>-0.015</td>\n      <td>-0.012</td>\n      <td>-0.015</td>\n      <td>-0.022</td>\n      <td>-0.017</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2412</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.011</td>\n      <td>-0.015</td>\n      <td>-0.021</td>\n      <td>-0.013</td>\n      <td>-0.009</td>\n      <td>-0.006</td>\n      <td>-0.009</td>\n      <td>-0.016</td>\n      <td>-0.010</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>2413 rows Ã— 9298 columns</p>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3a66853",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# scale X_test\n",
    "X_test_arr = preprocessing.MinMaxScaler().fit_transform(X_test)\n",
    "X_test_sc = pd.DataFrame(data=X_test_arr, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7b56157",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get beat_features according to previous results\n",
    "best_features = get_k_best_corrs(200, mutual_info).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df7e19a9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# reduce datasets to the best features\n",
    "X_train_sc_best = X_train_sc.loc[:, best_features]\n",
    "X_test_sc_best = X_test_sc.loc[:, best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "6be7ea8c-c233-4115-8d5d-f1db724e5d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingRegressor(learning_rate=0.05, max_iter=300,\n",
       "                              max_leaf_nodes=63, min_samples_leaf=32)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit best model overall (best combination of model / method of feature selection / number of features / hyperparameters)\n",
    "estimator = HGBR\n",
    "params = best_params[3]\n",
    "model = estimator(**params)\n",
    "model.fit(X_train_sc_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b6edaa75-216b-42a3-a5cb-02232635ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pd.Series(model.predict(X_test_sc_best), name=\"tm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "2ca20fbb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get predictions and create csv file\n",
    "predictions = pd.concat([test_data[\"seq_id\"], y_preds], axis=1)\n",
    "predictions.to_csv(\"novozymes_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3efdff-c481-4447-9355-577d9d9350e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Passando agora para a sub-Ã¡rea do Machine Learning, o Deep Learning permite tratar dados mais extensos com maior facilidade e precisÃ£o (em muitos casos).\n",
    "\n",
    "Visto que o cÃ³digo desenvolvido anteriormente Ã© bastante extenso e demorado, vamos primeiro definir os blocos de cÃ³digo essenciais de correr antes de efetuar a anÃ¡lise por Deep Learning (de forma a poder comeÃ§ar a anÃ¡lise *de novo* a partir daqui)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data_train.csv\")\n",
    "\n",
    "train = train[(train[\"pH\"]<14) & (train[\"pH\"]>0)]\n",
    "y_train = train[\"tm\"]\n",
    "y_train = y_train[(np.abs(stats.zscore(y_train)) < 3)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tendo definido as features com a maior importÃ¢ncia, e que permitiram efetuar previsÃµes com precisÃ£o relativamente elevada, vamos utilizar os mesmos (gerados atravÃ©s do mÃ©todo da InformaÃ§Ã£o MÃºtua) para prosseguir com a anÃ¡lise utilizando 'Deep Learning'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#X_train_sc_best.to_csv(\"x_train_mi.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "x_train_mi = pd.read_csv(\"x_train_psmi.csv\").iloc[:,1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "        OxidizedMEC           VMT  _PolarizabilityD3075           TVK  \\\ncount  28403.000000  28403.000000          28403.000000  28403.000000   \nmean       0.011967      0.019282              0.753314      0.003948   \nstd        0.019489      0.080000              0.076846      0.019061   \nmin        0.000000      0.000000              0.000000      0.000000   \n25%        0.005078      0.000000              0.716411      0.000000   \n50%        0.008499      0.000000              0.766375      0.000000   \n75%        0.014543      0.000000              0.799425      0.000000   \nmax        1.000000      1.000000              1.000000      1.000000   \n\n       MoreauBrotoAuto_Hydrophobicity11           KKL            TH  \\\ncount                      28403.000000  28403.000000  28403.000000   \nmean                           0.292995      0.017712      0.033465   \nstd                            0.056540      0.043839      0.062418   \nmin                            0.000000      0.000000      0.000000   \n25%                            0.254690      0.000000      0.000000   \n50%                            0.288600      0.000000      0.000000   \n75%                            0.325397      0.000000      0.053097   \nmax                            1.000000      1.000000      1.000000   \n\n                 VK  _PolarityD2001            SN  ...            EK  \\\ncount  28403.000000    28403.000000  28403.000000  ...  28403.000000   \nmean       0.083762        0.038799      0.054557  ...      0.067315   \nstd        0.092876        0.055728      0.068581  ...      0.062111   \nmin        0.000000        0.000000      0.000000  ...      0.000000   \n25%        0.000000        0.010179      0.000000  ...      0.022196   \n50%        0.069672        0.020096      0.039095  ...      0.059579   \n75%        0.122951        0.044338      0.088477  ...      0.098131   \nmax        1.000000        1.000000      1.000000  ...      1.000000   \n\n                 LI  _NormalizedVDWVD1001           MLV  _SecondaryStrD1050  \\\ncount  28403.000000          28403.000000  28403.000000        28403.000000   \nmean       0.107193              0.036351      0.014865            0.635295   \nstd        0.095415              0.042654      0.055992            0.067452   \nmin        0.000000              0.000000      0.000000            0.000000   \n25%        0.028571              0.011002      0.000000            0.599930   \n50%        0.098901              0.021478      0.000000            0.637655   \n75%        0.156044              0.046157      0.000000            0.676793   \nmax        1.000000              1.000000      1.000000            1.000000   \n\n                 VA            KR  _PolarizabilityD3025           HKE  \\\ncount  28403.000000  28403.000000          28403.000000  28403.000000   \nmean       0.107986      0.086051              0.224909      0.009250   \nstd        0.096550      0.094041              0.055826      0.037566   \nmin        0.000000      0.000000              0.000000      0.000000   \n25%        0.038000      0.000000              0.190607      0.000000   \n50%        0.092000      0.067568              0.222560      0.000000   \n75%        0.150000      0.128378              0.256052      0.000000   \nmax        1.000000      1.000000              1.000000      1.000000   \n\n                KHP  \ncount  28403.000000  \nmean       0.020491  \nstd        0.081423  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        1.000000  \n\n[8 rows x 496 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OxidizedMEC</th>\n      <th>VMT</th>\n      <th>_PolarizabilityD3075</th>\n      <th>TVK</th>\n      <th>MoreauBrotoAuto_Hydrophobicity11</th>\n      <th>KKL</th>\n      <th>TH</th>\n      <th>VK</th>\n      <th>_PolarityD2001</th>\n      <th>SN</th>\n      <th>...</th>\n      <th>EK</th>\n      <th>LI</th>\n      <th>_NormalizedVDWVD1001</th>\n      <th>MLV</th>\n      <th>_SecondaryStrD1050</th>\n      <th>VA</th>\n      <th>KR</th>\n      <th>_PolarizabilityD3025</th>\n      <th>HKE</th>\n      <th>KHP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>...</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.011967</td>\n      <td>0.019282</td>\n      <td>0.753314</td>\n      <td>0.003948</td>\n      <td>0.292995</td>\n      <td>0.017712</td>\n      <td>0.033465</td>\n      <td>0.083762</td>\n      <td>0.038799</td>\n      <td>0.054557</td>\n      <td>...</td>\n      <td>0.067315</td>\n      <td>0.107193</td>\n      <td>0.036351</td>\n      <td>0.014865</td>\n      <td>0.635295</td>\n      <td>0.107986</td>\n      <td>0.086051</td>\n      <td>0.224909</td>\n      <td>0.009250</td>\n      <td>0.020491</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.019489</td>\n      <td>0.080000</td>\n      <td>0.076846</td>\n      <td>0.019061</td>\n      <td>0.056540</td>\n      <td>0.043839</td>\n      <td>0.062418</td>\n      <td>0.092876</td>\n      <td>0.055728</td>\n      <td>0.068581</td>\n      <td>...</td>\n      <td>0.062111</td>\n      <td>0.095415</td>\n      <td>0.042654</td>\n      <td>0.055992</td>\n      <td>0.067452</td>\n      <td>0.096550</td>\n      <td>0.094041</td>\n      <td>0.055826</td>\n      <td>0.037566</td>\n      <td>0.081423</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.005078</td>\n      <td>0.000000</td>\n      <td>0.716411</td>\n      <td>0.000000</td>\n      <td>0.254690</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010179</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.022196</td>\n      <td>0.028571</td>\n      <td>0.011002</td>\n      <td>0.000000</td>\n      <td>0.599930</td>\n      <td>0.038000</td>\n      <td>0.000000</td>\n      <td>0.190607</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.008499</td>\n      <td>0.000000</td>\n      <td>0.766375</td>\n      <td>0.000000</td>\n      <td>0.288600</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.069672</td>\n      <td>0.020096</td>\n      <td>0.039095</td>\n      <td>...</td>\n      <td>0.059579</td>\n      <td>0.098901</td>\n      <td>0.021478</td>\n      <td>0.000000</td>\n      <td>0.637655</td>\n      <td>0.092000</td>\n      <td>0.067568</td>\n      <td>0.222560</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.014543</td>\n      <td>0.000000</td>\n      <td>0.799425</td>\n      <td>0.000000</td>\n      <td>0.325397</td>\n      <td>0.000000</td>\n      <td>0.053097</td>\n      <td>0.122951</td>\n      <td>0.044338</td>\n      <td>0.088477</td>\n      <td>...</td>\n      <td>0.098131</td>\n      <td>0.156044</td>\n      <td>0.046157</td>\n      <td>0.000000</td>\n      <td>0.676793</td>\n      <td>0.150000</td>\n      <td>0.128378</td>\n      <td>0.256052</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 496 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mi.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0        48.4\n1        48.4\n2        49.0\n3        55.6\n4        48.4\n         ... \n28691    51.8\n28692    37.2\n28693    64.6\n28694    50.7\n28695    37.6\nName: tm, Length: 28403, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Em primeiro lugar, vamos criar uma rede neuronal constituÃ­da por camadas densas (o tipo de rede mais simples e utilizada) para poder efetuar previsÃµes relativamente aos valores de termostabilidade."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "#!pip install scikeras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visto que este tipo de redes (assim como outros) apresenta vÃ¡rios hiperparÃ¢metros que podem ser otimizados para obter um modelo que permite uma previsÃ£o mais precisa, vamos criar uma funÃ§Ã£o (chamada *create_model()*) que permite a adiÃ§Ã£o de um nÃºmero variÃ¡vel de camadas, cada uma com valores variÃ¡veis de nodos (e outros parÃ¢metros que vÃ£o ser discutidos de seguida). A cada camada densa Ã© adicionado tambÃ©m uma regularizaÃ§Ã£o dropout (para evitar sobreajustamentos), e por fim, a rede Ã© compilada com a selecÃ§Ã£o de um dos otimizadores mais utilizados (selecionado atravÃ©s da funÃ§Ã£o auxiliar *_choose_optimizer()*).\n",
    "\n",
    "Os seguintes blocos de cÃ³digo foram inspirados no cÃ³digo apresentado no seguinte site: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "#GRID SEARCH FUNC\n",
    "\n",
    "def _choose_optimizer(optimizer, learning_rate, momentum):\n",
    "    if optimizer == \"sgd\":\n",
    "        return SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        return RMSprop(learning_rate=learning_rate, momentum=momentum)\n",
    "    elif optimizer == \"adagrad\":\n",
    "        return Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adadelta\":\n",
    "        return Adadelta(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adam\":\n",
    "        return Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adamax\":\n",
    "        return Adamax(learning_rate=learning_rate)\n",
    "    elif optimizer == \"nadam\":\n",
    "        return Nadam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized optimizer\")\n",
    "\n",
    "\n",
    "def create_model(first_input, layers, neurons, dropout_rate, weight_constraint, learning_rate, momentum, activation, init_mode='uniform', optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    for ix in range(layers):\n",
    "        if ix == 0:\n",
    "            model.add(Dense(neurons[ix],\n",
    "                            activation=activation,\n",
    "                            input_shape=first_input,\n",
    "                            kernel_initializer=init_mode,\n",
    "                            kernel_constraint=MaxNorm(weight_constraint)))\n",
    "        elif ix != layers-1:\n",
    "            model.add(Dense(neurons[ix],\n",
    "                            activation=activation,\n",
    "                            kernel_initializer=init_mode,\n",
    "                            kernel_constraint=MaxNorm(weight_constraint)))\n",
    "        else:\n",
    "            model.add(Dense(1,\n",
    "                            activation=activation,\n",
    "                            kernel_initializer=init_mode))\n",
    "\n",
    "        if ix != layers-1:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "\n",
    "    opt = _choose_optimizer(optimizer.lower(), learning_rate, momentum)\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=opt, metrics=[\"mse\"])\n",
    "    return model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#Parameter values to optimize:\n",
    "neurons = [grid + (1,) for grid in itertools.product(*[[20,50,100]]*3)]\n",
    "dropout_rate = np.linspace(0.0, 0.5, 6)\n",
    "weight_constraint = np.linspace(0.5, 5, 10) #Max norm value each weight parameter can be\n",
    "learning_rate = np.linspace(0.005, 0.5, 100)\n",
    "momentum = np.linspace(0.0, 0.9, 4) #9\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "#For computational purposes, all layers will have the same  weight_constraint and dropout_rate values\n",
    "\n",
    "param_dist = dict(model__neurons=neurons,\n",
    "                  model__dropout_rate=dropout_rate,\n",
    "                  model__weight_constraint=weight_constraint,\n",
    "                  model__learning_rate=learning_rate,\n",
    "                  model__momentum=momentum,\n",
    "                  model__optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving best parameters for a 4 layered fully-connected network (n_iter=50, cv=5):\n",
      "|\n",
      "Best score: 0.370032506271634\n",
      "Best parameters: {'model__weight_constraint': 2.5, 'model__optimizer': 'Adadelta', 'model__neurons': (100, 100, 50, 1), 'model__momentum': 0.9, 'model__learning_rate': 0.465, 'model__dropout_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "param_dist[\"model__neurons\"] = [grid + (1,) for grid in itertools.product(*[[20,50,100]]*3)]\n",
    "\n",
    "print(f\"Retrieving best parameters for a 4 layered fully-connected network (n_iter=50, cv=5):\\n|\")\n",
    "model = KerasRegressor(model=create_model, epochs=100, batch_size=10, verbose=0,\n",
    "                   first_input=[x_train_mi.shape[1]],\n",
    "                   layers=4,\n",
    "                   activation=\"relu\")\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, n_jobs=-1, cv=5)\n",
    "grid.fit(x_train_mi, y_train)\n",
    "print(f\"Best score: {grid.best_score_}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving best parameters for a 6 layered fully-connected network (n_iter=50, cv=5):\n",
      "|\n",
      "(20, 50, 50, 20, 100, 1)\n",
      "Best score: -0.010840052742769002\n",
      "Best parameters: {'model__weight_constraint': 0.5, 'model__optimizer': 'Adagrad', 'model__neurons': (20, 50, 50, 20, 100, 1), 'model__momentum': 0.3, 'model__learning_rate': 0.255, 'model__dropout_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "param_dist[\"model__neurons\"] = [grid + (1,) for grid in itertools.product(*[[20,50,100]]*5)]\n",
    "\n",
    "print(f\"Retrieving best parameters for a 6 layered fully-connected network (n_iter=50, cv=5):\\n|\")\n",
    "model = KerasRegressor(model=create_model, epochs=100, batch_size=10, verbose=0,\n",
    "                   first_input=[x_train_mi.shape[1]],\n",
    "                   layers=6,\n",
    "                   activation=\"relu\")\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=1, n_jobs=-1, cv=5)\n",
    "grid.fit(x_train_mi, y_train)\n",
    "print(f\"Best score: {grid.best_score_}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving best parameters for a 8 layered fully-connected network (n_iter=50, cv=5):\n",
      "|\n",
      "Best score: -0.009267656321677187\n",
      "Best parameters: {'model__weight_constraint': 3.5, 'model__optimizer': 'Adamax', 'model__neurons': (20, 50, 100, 20, 100, 20, 20, 1), 'model__momentum': 0.0, 'model__learning_rate': 0.17, 'model__dropout_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "param_dist[\"model__neurons\"] = [grid + (1,) for grid in itertools.product(*[[20,50,100]]*7)]\n",
    "\n",
    "print(f\"Retrieving best parameters for a 8 layered fully-connected network (n_iter=50, cv=5):\\n|\")\n",
    "model = KerasRegressor(model=create_model, epochs=100, batch_size=10, verbose=0,\n",
    "                   first_input=[x_train_mi.shape[1]],\n",
    "                   layers=8,\n",
    "                   activation=\"relu\")\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=1, n_jobs=-1, cv=5)\n",
    "grid.fit(x_train_mi, y_train)\n",
    "print(f\"Best score: {grid.best_score_}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def _get_grid():\n",
    "    pass\n",
    "\n",
    "def dense_net_optimizer(layers:int,\n",
    "                        neurons:list,\n",
    "                        dropout_rates:list,\n",
    "                        weight_constraints:list,\n",
    "                        activations:list,\n",
    "                        optimizer:str,\n",
    "                        init_mode=['uniform'],\n",
    "                        randomized=True):\n",
    "    \"\"\"\n",
    "    :param layers:\n",
    "    :param neurons:\n",
    "    :param dropout_rates:\n",
    "    :param weight_constraints:\n",
    "    :param activations:\n",
    "    :param optimizers:\n",
    "    :param init_mode:\n",
    "    :param randomized:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    layers_param_grid = _get_grid(neurons, dropout_rates, weight_constraints, activations)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

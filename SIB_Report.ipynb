{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b35bfb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Context"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data used in this report was retrived from KAGGLE: https://www.kaggle.com/c/novozymes-enzyme-stability-prediction\n",
    "Each data example consists of a protein sequence, a pH value and thermostability index. Predicting the thermostability is fundamental in enzyme engeneering for a wide variety of applications. Employing ML techniques is of great value to achieve the latter purpose as it saves time and money."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "a3550ca3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6778f3ec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "updates = pd.read_csv(\"train_updates_20220929.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definiram-se os dados de teste e treino e, ainda, se definiu dados de treino atualizados, de modo a corrigir-se alguns dos dados de treino."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecba4e3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>47.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31385</th>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31386</th>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31388</th>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31389</th>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31390 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id                                   protein_sequence   pH  \\\n",
       "0           0  AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...  7.0   \n",
       "1           1  AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...  7.0   \n",
       "2           2  AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...  7.0   \n",
       "3           3  AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...  7.0   \n",
       "4           4  AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...  7.0   \n",
       "...       ...                                                ...  ...   \n",
       "31385   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n",
       "31386   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n",
       "31387   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n",
       "31388   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n",
       "31389   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n",
       "\n",
       "                             data_source    tm  \n",
       "0      doi.org/10.1038/s41592-020-0801-4  75.7  \n",
       "1      doi.org/10.1038/s41592-020-0801-4  50.5  \n",
       "2      doi.org/10.1038/s41592-020-0801-4  40.5  \n",
       "3      doi.org/10.1038/s41592-020-0801-4  47.2  \n",
       "4      doi.org/10.1038/s41592-020-0801-4  49.5  \n",
       "...                                  ...   ...  \n",
       "31385  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "31386  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "31387  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "31388  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "31389  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[31390 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63fc0003",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>30738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>30739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>30740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>30741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>30742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2434 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seq_id protein_sequence  pH  data_source  tm\n",
       "0         69              NaN NaN          NaN NaN\n",
       "1         70              NaN NaN          NaN NaN\n",
       "2         71              NaN NaN          NaN NaN\n",
       "3         72              NaN NaN          NaN NaN\n",
       "4         73              NaN NaN          NaN NaN\n",
       "...      ...              ...  ..          ...  ..\n",
       "2429   30738              NaN NaN          NaN NaN\n",
       "2430   30739              NaN NaN          NaN NaN\n",
       "2431   30740              NaN NaN          NaN NaN\n",
       "2432   30741              NaN NaN          NaN NaN\n",
       "2433   30742              NaN NaN          NaN NaN\n",
       "\n",
       "[2434 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0d25d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries to update (num_rows): (2434,)\n",
      "Entries to delete (shape): (2409, 5)\n",
      "Entries to change (shape): (25, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Entries to update (num_rows): {updates['pH'].shape}\")\n",
    "\n",
    "mask = updates[\"pH\"].isna()\n",
    "\n",
    "to_delete = updates.loc[mask,:]\n",
    "to_change = updates.loc[-mask,:]\n",
    "\n",
    "print(f\"Entries to delete (shape): {to_delete.shape}\")\n",
    "print(f\"Entries to change (shape): {to_change.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verificou-se o número de dados para deletar e para modificar."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ddbdb7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# First, change rows with data arrangement errors\n",
    "train.loc[to_change.index, [\"pH\", \"tm\"]] = updates.loc[to_change.index, [\"pH\", \"tm\"]]train.loc[to_change.index, [\"pH\", \"tm\"]] = updates.loc[to_change.index, [\"pH\", \"tm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29776aa0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries (original data): 31390\n",
      "Number of entries (after cut): 28981\n"
     ]
    }
   ],
   "source": [
    "# Next, remove rows with data issues\n",
    "print(f\"Number of entries (original data): {train.shape[0]}\")\n",
    "train_cut = train.drop(to_delete.index)\n",
    "print(f\"Number of entries (after cut): {train_cut.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Após a realização das modificações foram eliminadas 2409 entradas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a711cb73",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31385</th>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31386</th>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31388</th>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31389</th>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28981 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id                                   protein_sequence   pH  \\\n",
       "25         25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...  7.0   \n",
       "28         28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...  7.0   \n",
       "29         29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...  7.0   \n",
       "30         30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...  5.5   \n",
       "33         33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...  7.0   \n",
       "...       ...                                                ...  ...   \n",
       "31385   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n",
       "31386   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n",
       "31387   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n",
       "31388   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n",
       "31389   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n",
       "\n",
       "                             data_source    tm  \n",
       "25     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "28     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "29     doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "30     doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "33     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "...                                  ...   ...  \n",
       "31385  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "31386  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "31387  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "31388  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "31389  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[28981 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Realizou-se a verificação das alterações realizadas aos dados de treino e a presença de NaNs -> verificou-se a existência de dados omissos (3494)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99e423e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows still containing NaNs: 3494\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31385</th>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31386</th>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31388</th>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31389</th>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25487 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id                                   protein_sequence   pH  \\\n",
       "25         25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...  7.0   \n",
       "28         28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...  7.0   \n",
       "29         29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...  7.0   \n",
       "30         30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...  5.5   \n",
       "33         33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...  7.0   \n",
       "...       ...                                                ...  ...   \n",
       "31385   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n",
       "31386   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n",
       "31387   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n",
       "31388   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n",
       "31389   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n",
       "\n",
       "                             data_source    tm  \n",
       "25     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "28     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "29     doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "30     doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "33     doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "...                                  ...   ...  \n",
       "31385  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "31386  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "31387  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "31388  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "31389  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[25487 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are still NaNs and remove them\n",
    "idxs = train_cut[train_cut.isna().any(axis=1)].index\n",
    "print(f\"Number of rows still containing NaNs: {len(idxs)}\")\n",
    "train_cut.drop(index=idxs, inplace=True)\n",
    "train_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voltou-se a realizar a eliminação das linhas com NaNs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e58d64",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25486</th>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25487 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id                                   protein_sequence   pH  \\\n",
       "0          25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...  7.0   \n",
       "1          28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...  7.0   \n",
       "2          29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...  7.0   \n",
       "3          30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...  5.5   \n",
       "4          33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...  7.0   \n",
       "...       ...                                                ...  ...   \n",
       "25482   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n",
       "25483   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n",
       "25484   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n",
       "25485   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n",
       "25486   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n",
       "\n",
       "                             data_source    tm  \n",
       "0      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "1      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "2      doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "3      doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "4      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "...                                  ...   ...  \n",
       "25482  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "25483  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "25484  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "25485  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "25486  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[25487 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset indexes\n",
    "train_cut.reset_index(drop=True, inplace=True)\n",
    "train_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verificaram-se os parâmetros estatísticos para as colunas pH e tm. Analisando cada coluna observou-se que os valores médios e medianos são semelhates, que se elimanaram todos os valores omissos e que a distribuição nas duas colunas é relativamente uniforme (baixo skewness)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db4276b9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25487.000000</td>\n",
       "      <td>25487.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.903579</td>\n",
       "      <td>51.436933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.752407</td>\n",
       "      <td>12.190382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.990000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>43.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>54.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pH            tm\n",
       "count  25487.000000  25487.000000\n",
       "mean       6.903579     51.436933\n",
       "std        0.752407     12.190382\n",
       "min        1.990000      0.000000\n",
       "25%        7.000000     43.650000\n",
       "50%        7.000000     48.700000\n",
       "75%        7.000000     54.500000\n",
       "max       11.000000    130.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cut.describe().loc[:,[\"pH\",\"tm\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70624647",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b426e1e",
   "metadata": {},
   "source": [
    "Seguimos com o passo da extração de features, com a esperança de obter um conjunto de descritores correlacionados com a variável dependente (termostabilidade), capazes de a prever com algoritmos adequados.\n",
    "\n",
    "Para isto, utilizámos funções do BioPython e ProPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e61981f2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!pip install propy3\n",
    "#!conda install propy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557ee3ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from propy.PyPro import GetProDes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e65f49",
   "metadata": {},
   "source": [
    "#### Descriptors\n",
    "\n",
    "- sequence length (1 feature) -- <b>pypro3</b> (propy.PyPro)\n",
    "- aminoacid composition (20 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- dipeptide composition (400 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- tripeptide composition (8000 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- ctd descriptors -> composition, transition, distribution (147 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- molecular weight (1 feature) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- aromaticity (1 feature) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- instability index (1 feature) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- isoelectric point (1 feature) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- secondary structure fraction -> helix, turn, sheet (3 features) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- molar extinction coefficient -> reduced, oxidized (2 features) -- <b>Biopython</b> (Bio.SeqUtils.ProtParam)\n",
    "- geary autocorrelation descriptors (240 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- moran autocorrelation descriptors (240 features) -- <b>pypro3</b> (propy.PyPro)\n",
    "- normalized moreau-broto autocorrelation descriptors (240 features) -- <b>pypro3</b> (propy.PyPro)<br><br>\n",
    "\n",
    "- Total number of features: <b>9297</b>\n",
    "\n",
    "\n",
    "Extraímos inicialmente o tamanho de cada sequência (**'sequence length´**), seguido pela sua composição de aminoácidos individuais (**'aminoacid composition'**), e todos os dipéptidos ('dipeptide composition') e tripéptidos possíveis (**'tripeptide composition'**).\n",
    "\n",
    "**'ctd descriptors'** são um conjunto de descritores relativamente às propriedades dos aminoácidos, como hidrofobicidade, polaridade, carga, etc. Para cada propriedade, os aminoácidos de cada proteína são agrupadas numa de 3 grupos, sendo calculadas a composição (percentagem de aminoácidos), transição (percentagem de transições de um grupo para outro), e distribuição (índices de cada categoria ao longo da sequência presentes em cada quartil são devolvidos e divididos pelo número total dessa categoria presente na sequência).\n",
    "\n",
    "Seguem-se o peso molecular de cada proteína (**'molecular weight'**), frequência relativa de aminoácidos aromáticos (Phe, Trp e Tyr) (**'aromaticity'**), valor indicativo da instabilidade da proteína, onde valores altos significam proteínas mais instáveis (**'instability index'**), e o pH onde a carga global da proteína é neutra (**'isoelectric point'**).\n",
    "\n",
    "**'secondary structure fraction'** refere-se à fração de aminoácidos na sequência que costumam estar presentes em hélices, 'turns' ou folhas. **'molar extinction coefficiente´** é uma medida do quão forte uma espécie química absorve luz numa dada onda de luz (considera cisteínas e pontes dissulfito).\n",
    "\n",
    "Por fim, **'greary autocorrelation'**, **'moran autocorrelation'** e **'normalized moreau_broto autocorrelation'** são diferentes cálculos da distribuição espacial de um conjunto de descritores estruturais e fisioquímicos.\n",
    "\n",
    "Para extrair estes descritores, foram criadas funções auxiliares para devolver os resultados em forma de dicionário. Desta forma é mais simples posteriormente juntar os resultados para criar um novo DataFrame do pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c4313",
   "metadata": {},
   "source": [
    "#### Compute descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d01f8c0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# sequence lenght (1 feature)\n",
    "def get_length(protein: str) -> dict:\n",
    "    return {\"SeqLength\": len(protein)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8317c0e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# aminoacid composition (20 features)\n",
    "def get_aminoacid_composition(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetAAComp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f0ad19e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# dipeptide composition (400 features)\n",
    "def get_dipeptide_composition(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetDPComp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5968555-c1ff-475f-9c1a-c00ff0785e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripeptide composition (8000 features)\n",
    "def get_tripeptide_composition(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetTPComp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f44c015-7d97-4f52-aa64-056e5e98cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctd descriptors (147 features)\n",
    "def get_ctd_descriptors(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetCTD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23203487-26a2-49f9-bca4-54cd397d4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# molecular weight (1 feature)\n",
    "def get_molecular_weight(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    return {\"MolecularWeight\": X.molecular_weight()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a54efc8f-0d80-489c-b4be-6a1baed7499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aromaticity (1 feature)\n",
    "def get_aromaticity(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    return {\"Aromaticity\": X.aromaticity()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50fa4b4d-c397-441e-843c-c8da14e6ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instability index (1 feature)\n",
    "def get_instability_index(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    return {\"InstabilityIndex\": X.instability_index()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "200c064b-585b-40d7-b8e9-cdc01e3e2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isoelectric point (1 feature)\n",
    "def get_isoelectric_point(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    return {\"IsoelectricPoint\": X.isoelectric_point()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97d38b6b-796b-4eea-8e1a-dfdd71627c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary structure fraction (3 features)\n",
    "def get_secondary_structure_fraction(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    helix, turn, sheet = X.secondary_structure_fraction()\n",
    "    return {\"HelixSSF\": helix, \"TurnSSF\": turn, \"SheetSSF\": sheet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b3da4b-cda1-4c3a-9dbb-5e9fc6ec2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# molar extinction coefficient (2 features)\n",
    "def get_molar_extinction_coefficient(protein: str) -> dict:\n",
    "    X = ProteinAnalysis(protein)\n",
    "    reduced, oxidized = X.molar_extinction_coefficient()\n",
    "    return {\"ReducedMEC\": reduced, \"OxidizedMEC\": oxidized}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db2afdd6-0485-446a-becd-96cfde5cc2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geary autocorrelation descriptors (240 features)\n",
    "def get_geary_autocorrelation_descriptors(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetGearyAuto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d096e273-28de-4131-974b-9cc80054dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moran autocorrelation descriptors (240 features)\n",
    "def get_moran_autocorrelation_descriptors(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetMoranAuto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a870587-2594-4f67-9978-ae0757736821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moreau-broto autocorrelation descriptors (240 features)\n",
    "def get_moreau_broto_autocorrelation_descriptors(protein: str) -> dict:\n",
    "    return GetProDes(protein).GetMoreauBrotoAuto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4196419-2b2d-4127-bcb6-56074c9bf253",
   "metadata": {},
   "source": [
    "#### Compute descriptors for all sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b41d8413",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_id                                   protein_sequence   pH  \\\n",
       "0      25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...  7.0   \n",
       "1      28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...  7.0   \n",
       "2      29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...  7.0   \n",
       "3      30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...  5.5   \n",
       "4      33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...  7.0   \n",
       "\n",
       "                         data_source    tm  \n",
       "0  doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "1  doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "2  doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "3  doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "4  doi.org/10.1038/s41592-020-0801-4  48.4  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5441c",
   "metadata": {},
   "source": [
    "Criámos uma função que junta as funções anteriores todas, de forma a criar um novo dataset, juntando os descritores do dataset original (nomeadamente o 'pH' e 'tm') com os novos descritores inferidos a partir de cada sequência do dataset ('protein_sequence').\n",
    "\n",
    "Uma vez que este processo demora bastante a correr, utilizámos a função 'tqdm' para visualizar o progresso da extração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba67e06b-599b-4177-a11b-22d40a9106c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53756ad5-cda8-45b0-974e-8e705480c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all descriptors (9297 features)\n",
    "def get_dataset_with_features(dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    # get protein sequences from dataset and initialize an empty protein_features list\n",
    "    proteins = np.array(dataset.protein_sequence, dtype=\"str\")\n",
    "    protein_features = []\n",
    "    for protein in tqdm(proteins):\n",
    "        # compute features for each protein\n",
    "        length = get_length(protein)\n",
    "        aa_comp = get_aminoacid_composition(protein)\n",
    "        dp_comp = get_dipeptide_composition(protein)\n",
    "        tp_comp = get_tripeptide_composition(protein)\n",
    "        ctd = get_ctd_descriptors(protein)\n",
    "        mw = get_molecular_weight(protein)\n",
    "        arom = get_aromaticity(protein)\n",
    "        ii = get_instability_index(protein)\n",
    "        iso_p = get_isoelectric_point(protein)\n",
    "        ssf = get_secondary_structure_fraction(protein)\n",
    "        mec = get_molar_extinction_coefficient(protein)\n",
    "        geary = get_geary_autocorrelation_descriptors(protein)\n",
    "        moran = get_moran_autocorrelation_descriptors(protein)\n",
    "        moreau_broto = get_moreau_broto_autocorrelation_descriptors(protein)\n",
    "        # merge dictionaries and add result to protein_features\n",
    "        features = dict(length, **aa_comp, **dp_comp, **tp_comp,  **ctd, **mw, **arom, **ii, **iso_p, **ssf, **mec,\n",
    "                        **geary, **moran, **moreau_broto)\n",
    "        protein_features.append(features)\n",
    "    # return pandas DataFrame with results\n",
    "    features_df = pd.DataFrame(protein_features)\n",
    "    features_df.insert(0, \"seq_id\", dataset.seq_id)\n",
    "    return pd.concat([features_df, dataset.loc[:,[\"pH\",\"tm\"]]], axis=1) #Removeu-se, 'protein_sequence', e 'data_source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52c95307-4645-4e0a-9089-30afc091a7de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7a767a2b3341549779536df3d8ae4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>501</td>\n",
       "      <td>10.379</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.591</td>\n",
       "      <td>5.589</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.387</td>\n",
       "      <td>5.389</td>\n",
       "      <td>4.990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>313</td>\n",
       "      <td>7.987</td>\n",
       "      <td>7.668</td>\n",
       "      <td>4.473</td>\n",
       "      <td>3.834</td>\n",
       "      <td>2.236</td>\n",
       "      <td>7.029</td>\n",
       "      <td>3.834</td>\n",
       "      <td>9.904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>109</td>\n",
       "      <td>7.339</td>\n",
       "      <td>3.670</td>\n",
       "      <td>1.835</td>\n",
       "      <td>6.422</td>\n",
       "      <td>1.835</td>\n",
       "      <td>9.174</td>\n",
       "      <td>2.752</td>\n",
       "      <td>8.257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.048</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>329</td>\n",
       "      <td>7.295</td>\n",
       "      <td>3.343</td>\n",
       "      <td>6.991</td>\n",
       "      <td>7.599</td>\n",
       "      <td>0.304</td>\n",
       "      <td>6.079</td>\n",
       "      <td>3.343</td>\n",
       "      <td>8.815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.082</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>278</td>\n",
       "      <td>10.432</td>\n",
       "      <td>7.554</td>\n",
       "      <td>2.878</td>\n",
       "      <td>2.158</td>\n",
       "      <td>0.719</td>\n",
       "      <td>8.273</td>\n",
       "      <td>15.108</td>\n",
       "      <td>5.396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.049</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>31385</td>\n",
       "      <td>549</td>\n",
       "      <td>6.011</td>\n",
       "      <td>7.650</td>\n",
       "      <td>4.372</td>\n",
       "      <td>6.922</td>\n",
       "      <td>2.186</td>\n",
       "      <td>5.647</td>\n",
       "      <td>4.372</td>\n",
       "      <td>9.290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>31386</td>\n",
       "      <td>469</td>\n",
       "      <td>7.889</td>\n",
       "      <td>5.330</td>\n",
       "      <td>4.051</td>\n",
       "      <td>4.478</td>\n",
       "      <td>1.066</td>\n",
       "      <td>6.183</td>\n",
       "      <td>3.412</td>\n",
       "      <td>5.757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>31387</td>\n",
       "      <td>128</td>\n",
       "      <td>10.156</td>\n",
       "      <td>2.344</td>\n",
       "      <td>3.906</td>\n",
       "      <td>5.469</td>\n",
       "      <td>0.781</td>\n",
       "      <td>5.469</td>\n",
       "      <td>6.250</td>\n",
       "      <td>8.594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.097</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>31388</td>\n",
       "      <td>593</td>\n",
       "      <td>7.926</td>\n",
       "      <td>4.216</td>\n",
       "      <td>4.216</td>\n",
       "      <td>5.734</td>\n",
       "      <td>0.843</td>\n",
       "      <td>6.071</td>\n",
       "      <td>2.024</td>\n",
       "      <td>8.769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25486</th>\n",
       "      <td>31389</td>\n",
       "      <td>537</td>\n",
       "      <td>6.331</td>\n",
       "      <td>5.214</td>\n",
       "      <td>3.724</td>\n",
       "      <td>2.793</td>\n",
       "      <td>0.931</td>\n",
       "      <td>5.959</td>\n",
       "      <td>3.352</td>\n",
       "      <td>4.469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.065</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25487 rows × 900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id  SeqLength       A      R      N      D      C      E       Q  \\\n",
       "0          25        501  10.379  4.192  4.591  5.589  0.000  6.387   5.389   \n",
       "1          28        313   7.987  7.668  4.473  3.834  2.236  7.029   3.834   \n",
       "2          29        109   7.339  3.670  1.835  6.422  1.835  9.174   2.752   \n",
       "3          30        329   7.295  3.343  6.991  7.599  0.304  6.079   3.343   \n",
       "4          33        278  10.432  7.554  2.878  2.158  0.719  8.273  15.108   \n",
       "...       ...        ...     ...    ...    ...    ...    ...    ...     ...   \n",
       "25482   31385        549   6.011  7.650  4.372  6.922  2.186  5.647   4.372   \n",
       "25483   31386        469   7.889  5.330  4.051  4.478  1.066  6.183   3.412   \n",
       "25484   31387        128  10.156  2.344  3.906  5.469  0.781  5.469   6.250   \n",
       "25485   31388        593   7.926  4.216  4.216  5.734  0.843  6.071   2.024   \n",
       "25486   31389        537   6.331  5.214  3.724  2.793  0.931  5.959   3.352   \n",
       "\n",
       "           G  ...  MoreauBrotoAuto_Mutability23  MoreauBrotoAuto_Mutability24  \\\n",
       "0      4.990  ...                        -0.058                        -0.057   \n",
       "1      9.904  ...                         0.019                         0.017   \n",
       "2      8.257  ...                         0.087                         0.079   \n",
       "3      8.815  ...                         0.074                         0.077   \n",
       "4      5.396  ...                         0.057                         0.051   \n",
       "...      ...  ...                           ...                           ...   \n",
       "25482  9.290  ...                        -0.006                        -0.004   \n",
       "25483  5.757  ...                        -0.049                        -0.048   \n",
       "25484  8.594  ...                         0.098                         0.097   \n",
       "25485  8.769  ...                         0.030                         0.029   \n",
       "25486  4.469  ...                         0.063                         0.063   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability25  MoreauBrotoAuto_Mutability26  \\\n",
       "0                            -0.058                        -0.056   \n",
       "1                             0.014                         0.017   \n",
       "2                             0.068                         0.051   \n",
       "3                             0.074                         0.073   \n",
       "4                             0.053                         0.052   \n",
       "...                             ...                           ...   \n",
       "25482                        -0.003                        -0.002   \n",
       "25483                        -0.048                        -0.048   \n",
       "25484                         0.100                         0.115   \n",
       "25485                         0.029                         0.030   \n",
       "25486                         0.064                         0.065   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability27  MoreauBrotoAuto_Mutability28  \\\n",
       "0                            -0.056                        -0.056   \n",
       "1                             0.014                         0.012   \n",
       "2                             0.065                         0.059   \n",
       "3                             0.074                         0.078   \n",
       "4                             0.050                         0.050   \n",
       "...                             ...                           ...   \n",
       "25482                        -0.003                        -0.002   \n",
       "25483                        -0.048                        -0.046   \n",
       "25484                         0.099                         0.107   \n",
       "25485                         0.030                         0.030   \n",
       "25486                         0.067                         0.064   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability29  MoreauBrotoAuto_Mutability30  \\\n",
       "0                            -0.056                        -0.057   \n",
       "1                             0.013                         0.010   \n",
       "2                             0.050                         0.048   \n",
       "3                             0.081                         0.082   \n",
       "4                             0.051                         0.049   \n",
       "...                             ...                           ...   \n",
       "25482                        -0.002                        -0.005   \n",
       "25483                        -0.044                        -0.046   \n",
       "25484                         0.102                         0.097   \n",
       "25485                         0.030                         0.031   \n",
       "25486                         0.066                         0.065   \n",
       "\n",
       "                             data_source    tm  \n",
       "0      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "1      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "2      doi.org/10.1038/s41592-020-0801-4  49.0  \n",
       "3      doi.org/10.1038/s41592-020-0801-4  55.6  \n",
       "4      doi.org/10.1038/s41592-020-0801-4  48.4  \n",
       "...                                  ...   ...  \n",
       "25482  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "25483  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "25484  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "25485  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "25486  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[25487 rows x 900 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_dataset_with_features(train_cut)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daec4b2",
   "metadata": {},
   "source": [
    "Para facilitar o processo de recolha dos descritores sempre que se corre este notebook, guardou-se os resultados num ficheiro csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b920449-1c7c-4607-914d-29f7a56713df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-048cec40ba11>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# export data_train to csv\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data_train.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# export data_train to csv\n",
    "train.to_csv(\"data_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9547b",
   "metadata": {},
   "source": [
    "Todos os passos efetuados anteriormente podem ser saltados, sendo possível correr 'de novo' o notebook a partir deste ponto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac551f0e-11e3-4c6c-a9e8-b08bae94686f",
   "metadata": {},
   "source": [
    "#### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1feacc-2b9d-4cef-82e2-a162b335ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a05c82-f719-499a-a4ff-12a4bc0360fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98521744",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "      <td>28696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14347.500000</td>\n",
       "      <td>16805.942257</td>\n",
       "      <td>450.583775</td>\n",
       "      <td>7.933964</td>\n",
       "      <td>5.422100</td>\n",
       "      <td>4.263457</td>\n",
       "      <td>5.527051</td>\n",
       "      <td>1.460943</td>\n",
       "      <td>7.105625</td>\n",
       "      <td>4.064779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021212</td>\n",
       "      <td>0.020981</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.020869</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>6.852437</td>\n",
       "      <td>49.079321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8283.965999</td>\n",
       "      <td>8351.341517</td>\n",
       "      <td>660.478906</td>\n",
       "      <td>2.826397</td>\n",
       "      <td>2.264102</td>\n",
       "      <td>1.838423</td>\n",
       "      <td>1.772346</td>\n",
       "      <td>1.322568</td>\n",
       "      <td>2.513279</td>\n",
       "      <td>1.888433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.069089</td>\n",
       "      <td>0.068423</td>\n",
       "      <td>0.068465</td>\n",
       "      <td>0.069619</td>\n",
       "      <td>0.069951</td>\n",
       "      <td>0.070658</td>\n",
       "      <td>0.070678</td>\n",
       "      <td>1.168815</td>\n",
       "      <td>14.210971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.959000</td>\n",
       "      <td>-2.066000</td>\n",
       "      <td>-1.015000</td>\n",
       "      <td>-0.362000</td>\n",
       "      <td>-0.355000</td>\n",
       "      <td>-0.366000</td>\n",
       "      <td>-0.382000</td>\n",
       "      <td>-0.399000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7173.750000</td>\n",
       "      <td>9589.750000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>5.938000</td>\n",
       "      <td>3.950750</td>\n",
       "      <td>3.061000</td>\n",
       "      <td>4.361000</td>\n",
       "      <td>0.637000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>2.932000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>41.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14347.500000</td>\n",
       "      <td>16767.500000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>7.692000</td>\n",
       "      <td>5.205000</td>\n",
       "      <td>4.110000</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>6.923000</td>\n",
       "      <td>3.823000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21521.250000</td>\n",
       "      <td>24006.250000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>9.494000</td>\n",
       "      <td>6.627000</td>\n",
       "      <td>5.263000</td>\n",
       "      <td>6.473000</td>\n",
       "      <td>1.935000</td>\n",
       "      <td>8.451000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>53.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28695.000000</td>\n",
       "      <td>31389.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>29.866000</td>\n",
       "      <td>24.540000</td>\n",
       "      <td>31.990000</td>\n",
       "      <td>20.530000</td>\n",
       "      <td>16.071000</td>\n",
       "      <td>24.658000</td>\n",
       "      <td>24.346000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.593000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 9301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        seq_id     SeqLength             A             R  \\\n",
       "count  28696.000000  28696.000000  28696.000000  28696.000000  28696.000000   \n",
       "mean   14347.500000  16805.942257    450.583775      7.933964      5.422100   \n",
       "std     8283.965999   8351.341517    660.478906      2.826397      2.264102   \n",
       "min        0.000000     25.000000      5.000000      0.000000      0.000000   \n",
       "25%     7173.750000   9589.750000    195.000000      5.938000      3.950750   \n",
       "50%    14347.500000  16767.500000    335.000000      7.692000      5.205000   \n",
       "75%    21521.250000  24006.250000    526.000000      9.494000      6.627000   \n",
       "max    28695.000000  31389.000000  32767.000000     29.866000     24.540000   \n",
       "\n",
       "                  N             D             C             E             Q  \\\n",
       "count  28696.000000  28696.000000  28696.000000  28696.000000  28696.000000   \n",
       "mean       4.263457      5.527051      1.460943      7.105625      4.064779   \n",
       "std        1.838423      1.772346      1.322568      2.513279      1.888433   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        3.061000      4.361000      0.637000      5.556000      2.932000   \n",
       "50%        4.110000      5.429000      1.220000      6.923000      3.823000   \n",
       "75%        5.263000      6.473000      1.935000      8.451000      5.000000   \n",
       "max       31.990000     20.530000     16.071000     24.658000     24.346000   \n",
       "\n",
       "       ...  MoreauBrotoAuto_Mutability23  MoreauBrotoAuto_Mutability24  \\\n",
       "count  ...                  28696.000000                  28696.000000   \n",
       "mean   ...                      0.021212                      0.020981   \n",
       "std    ...                      0.067654                      0.069089   \n",
       "min    ...                     -0.959000                     -2.066000   \n",
       "25%    ...                     -0.020000                     -0.020000   \n",
       "50%    ...                      0.019000                      0.019000   \n",
       "75%    ...                      0.062000                      0.062000   \n",
       "max    ...                      0.644000                      0.641000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability25  MoreauBrotoAuto_Mutability26  \\\n",
       "count                  28696.000000                  28696.000000   \n",
       "mean                       0.020948                      0.021123   \n",
       "std                        0.068423                      0.068465   \n",
       "min                       -1.015000                     -0.362000   \n",
       "25%                       -0.020000                     -0.021000   \n",
       "50%                        0.019000                      0.019000   \n",
       "75%                        0.062000                      0.062000   \n",
       "max                        0.638000                      0.700000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability27  MoreauBrotoAuto_Mutability28  \\\n",
       "count                  28696.000000                  28696.000000   \n",
       "mean                       0.020842                      0.021070   \n",
       "std                        0.069619                      0.069951   \n",
       "min                       -0.355000                     -0.366000   \n",
       "25%                       -0.021000                     -0.021000   \n",
       "50%                        0.019000                      0.019000   \n",
       "75%                        0.061000                      0.061000   \n",
       "max                        0.638000                      0.593000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability29  MoreauBrotoAuto_Mutability30  \\\n",
       "count                  28696.000000                  28696.000000   \n",
       "mean                       0.020869                      0.021026   \n",
       "std                        0.070658                      0.070678   \n",
       "min                       -0.382000                     -0.399000   \n",
       "25%                       -0.021000                     -0.021000   \n",
       "50%                        0.019000                      0.019000   \n",
       "75%                        0.061000                      0.061000   \n",
       "max                        0.879000                      0.855000   \n",
       "\n",
       "                 pH            tm  \n",
       "count  28696.000000  28696.000000  \n",
       "mean       6.852437     49.079321  \n",
       "std        1.168815     14.210971  \n",
       "min        1.990000     -1.000000  \n",
       "25%        7.000000     41.900000  \n",
       "50%        7.000000     48.000000  \n",
       "75%        7.000000     53.800000  \n",
       "max       64.900000    130.000000  \n",
       "\n",
       "[8 rows x 9301 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ba6ca",
   "metadata": {},
   "source": [
    "Após observar a descrição da coluna do pH, observamos que o valor máximo é 64.9, que não é um valor aceitável de pH (valor máximo de 14).\n",
    "\n",
    "Devido a tal discrepância, procurou-se todas as ocorrências onde o valor do pH é superior a 14, eliminando as respetivas linhas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "685c94cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train = train[(train[\"pH\"]<14) & (train[\"pH\"]>0)]\n",
    "#train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29adc5c",
   "metadata": {},
   "source": [
    "Observamos que foram eliminadas 7 linhas (passou de 28696 para 28689)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d320c4bc-94d8-42a0-96b5-73dca33a969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y\n",
    "X_train = train.iloc[:,2:-1] #Remove sequence id from the X dataset\n",
    "y_train = train[\"tm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee94aa7b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501</td>\n",
       "      <td>10.379</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.591</td>\n",
       "      <td>5.589</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.387</td>\n",
       "      <td>5.389</td>\n",
       "      <td>4.990</td>\n",
       "      <td>1.996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313</td>\n",
       "      <td>7.987</td>\n",
       "      <td>7.668</td>\n",
       "      <td>4.473</td>\n",
       "      <td>3.834</td>\n",
       "      <td>2.236</td>\n",
       "      <td>7.029</td>\n",
       "      <td>3.834</td>\n",
       "      <td>9.904</td>\n",
       "      <td>2.236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>7.339</td>\n",
       "      <td>3.670</td>\n",
       "      <td>1.835</td>\n",
       "      <td>6.422</td>\n",
       "      <td>1.835</td>\n",
       "      <td>9.174</td>\n",
       "      <td>2.752</td>\n",
       "      <td>8.257</td>\n",
       "      <td>1.835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.048</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>329</td>\n",
       "      <td>7.295</td>\n",
       "      <td>3.343</td>\n",
       "      <td>6.991</td>\n",
       "      <td>7.599</td>\n",
       "      <td>0.304</td>\n",
       "      <td>6.079</td>\n",
       "      <td>3.343</td>\n",
       "      <td>8.815</td>\n",
       "      <td>2.128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.082</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278</td>\n",
       "      <td>10.432</td>\n",
       "      <td>7.554</td>\n",
       "      <td>2.878</td>\n",
       "      <td>2.158</td>\n",
       "      <td>0.719</td>\n",
       "      <td>8.273</td>\n",
       "      <td>15.108</td>\n",
       "      <td>5.396</td>\n",
       "      <td>1.439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.049</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeqLength       A      R      N      D      C      E       Q      G      H  \\\n",
       "0        501  10.379  4.192  4.591  5.589  0.000  6.387   5.389  4.990  1.996   \n",
       "1        313   7.987  7.668  4.473  3.834  2.236  7.029   3.834  9.904  2.236   \n",
       "2        109   7.339  3.670  1.835  6.422  1.835  9.174   2.752  8.257  1.835   \n",
       "3        329   7.295  3.343  6.991  7.599  0.304  6.079   3.343  8.815  2.128   \n",
       "4        278  10.432  7.554  2.878  2.158  0.719  8.273  15.108  5.396  1.439   \n",
       "\n",
       "   ...  MoreauBrotoAuto_Mutability22  MoreauBrotoAuto_Mutability23  \\\n",
       "0  ...                        -0.060                        -0.058   \n",
       "1  ...                         0.020                         0.019   \n",
       "2  ...                         0.086                         0.087   \n",
       "3  ...                         0.079                         0.074   \n",
       "4  ...                         0.063                         0.057   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability24  MoreauBrotoAuto_Mutability25  \\\n",
       "0                        -0.057                        -0.058   \n",
       "1                         0.017                         0.014   \n",
       "2                         0.079                         0.068   \n",
       "3                         0.077                         0.074   \n",
       "4                         0.051                         0.053   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability26  MoreauBrotoAuto_Mutability27  \\\n",
       "0                        -0.056                        -0.056   \n",
       "1                         0.017                         0.014   \n",
       "2                         0.051                         0.065   \n",
       "3                         0.073                         0.074   \n",
       "4                         0.052                         0.050   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability28  MoreauBrotoAuto_Mutability29  \\\n",
       "0                        -0.056                        -0.056   \n",
       "1                         0.012                         0.013   \n",
       "2                         0.059                         0.050   \n",
       "3                         0.078                         0.081   \n",
       "4                         0.050                         0.051   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability30   pH  \n",
       "0                        -0.057  7.0  \n",
       "1                         0.010  7.0  \n",
       "2                         0.048  7.0  \n",
       "3                         0.082  5.5  \n",
       "4                         0.049  7.0  \n",
       "\n",
       "[5 rows x 9298 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b672ef73",
   "metadata": {},
   "source": [
    "#### Outlier treatment (dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b66ce90e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "X_train = X_train[(np.abs(stats.zscore(y_train)) < 3)]\n",
    "y_train = y_train[(np.abs(stats.zscore(y_train)) < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f28298",
   "metadata": {},
   "source": [
    "#### Standardization (MinMaxScaler and StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8617881",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501</td>\n",
       "      <td>10.379</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.591</td>\n",
       "      <td>5.589</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.387</td>\n",
       "      <td>5.389</td>\n",
       "      <td>4.990</td>\n",
       "      <td>1.996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313</td>\n",
       "      <td>7.987</td>\n",
       "      <td>7.668</td>\n",
       "      <td>4.473</td>\n",
       "      <td>3.834</td>\n",
       "      <td>2.236</td>\n",
       "      <td>7.029</td>\n",
       "      <td>3.834</td>\n",
       "      <td>9.904</td>\n",
       "      <td>2.236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>7.339</td>\n",
       "      <td>3.670</td>\n",
       "      <td>1.835</td>\n",
       "      <td>6.422</td>\n",
       "      <td>1.835</td>\n",
       "      <td>9.174</td>\n",
       "      <td>2.752</td>\n",
       "      <td>8.257</td>\n",
       "      <td>1.835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.048</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>329</td>\n",
       "      <td>7.295</td>\n",
       "      <td>3.343</td>\n",
       "      <td>6.991</td>\n",
       "      <td>7.599</td>\n",
       "      <td>0.304</td>\n",
       "      <td>6.079</td>\n",
       "      <td>3.343</td>\n",
       "      <td>8.815</td>\n",
       "      <td>2.128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.082</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278</td>\n",
       "      <td>10.432</td>\n",
       "      <td>7.554</td>\n",
       "      <td>2.878</td>\n",
       "      <td>2.158</td>\n",
       "      <td>0.719</td>\n",
       "      <td>8.273</td>\n",
       "      <td>15.108</td>\n",
       "      <td>5.396</td>\n",
       "      <td>1.439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.049</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28691</th>\n",
       "      <td>549</td>\n",
       "      <td>6.011</td>\n",
       "      <td>7.650</td>\n",
       "      <td>4.372</td>\n",
       "      <td>6.922</td>\n",
       "      <td>2.186</td>\n",
       "      <td>5.647</td>\n",
       "      <td>4.372</td>\n",
       "      <td>9.290</td>\n",
       "      <td>2.732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28692</th>\n",
       "      <td>469</td>\n",
       "      <td>7.889</td>\n",
       "      <td>5.330</td>\n",
       "      <td>4.051</td>\n",
       "      <td>4.478</td>\n",
       "      <td>1.066</td>\n",
       "      <td>6.183</td>\n",
       "      <td>3.412</td>\n",
       "      <td>5.757</td>\n",
       "      <td>4.691</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28693</th>\n",
       "      <td>128</td>\n",
       "      <td>10.156</td>\n",
       "      <td>2.344</td>\n",
       "      <td>3.906</td>\n",
       "      <td>5.469</td>\n",
       "      <td>0.781</td>\n",
       "      <td>5.469</td>\n",
       "      <td>6.250</td>\n",
       "      <td>8.594</td>\n",
       "      <td>1.562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.097</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28694</th>\n",
       "      <td>593</td>\n",
       "      <td>7.926</td>\n",
       "      <td>4.216</td>\n",
       "      <td>4.216</td>\n",
       "      <td>5.734</td>\n",
       "      <td>0.843</td>\n",
       "      <td>6.071</td>\n",
       "      <td>2.024</td>\n",
       "      <td>8.769</td>\n",
       "      <td>1.855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28695</th>\n",
       "      <td>537</td>\n",
       "      <td>6.331</td>\n",
       "      <td>5.214</td>\n",
       "      <td>3.724</td>\n",
       "      <td>2.793</td>\n",
       "      <td>0.931</td>\n",
       "      <td>5.959</td>\n",
       "      <td>3.352</td>\n",
       "      <td>4.469</td>\n",
       "      <td>3.911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.065</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28403 rows × 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeqLength       A      R      N      D      C      E       Q      G  \\\n",
       "0            501  10.379  4.192  4.591  5.589  0.000  6.387   5.389  4.990   \n",
       "1            313   7.987  7.668  4.473  3.834  2.236  7.029   3.834  9.904   \n",
       "2            109   7.339  3.670  1.835  6.422  1.835  9.174   2.752  8.257   \n",
       "3            329   7.295  3.343  6.991  7.599  0.304  6.079   3.343  8.815   \n",
       "4            278  10.432  7.554  2.878  2.158  0.719  8.273  15.108  5.396   \n",
       "...          ...     ...    ...    ...    ...    ...    ...     ...    ...   \n",
       "28691        549   6.011  7.650  4.372  6.922  2.186  5.647   4.372  9.290   \n",
       "28692        469   7.889  5.330  4.051  4.478  1.066  6.183   3.412  5.757   \n",
       "28693        128  10.156  2.344  3.906  5.469  0.781  5.469   6.250  8.594   \n",
       "28694        593   7.926  4.216  4.216  5.734  0.843  6.071   2.024  8.769   \n",
       "28695        537   6.331  5.214  3.724  2.793  0.931  5.959   3.352  4.469   \n",
       "\n",
       "           H  ...  MoreauBrotoAuto_Mutability22  MoreauBrotoAuto_Mutability23  \\\n",
       "0      1.996  ...                        -0.060                        -0.058   \n",
       "1      2.236  ...                         0.020                         0.019   \n",
       "2      1.835  ...                         0.086                         0.087   \n",
       "3      2.128  ...                         0.079                         0.074   \n",
       "4      1.439  ...                         0.063                         0.057   \n",
       "...      ...  ...                           ...                           ...   \n",
       "28691  2.732  ...                        -0.005                        -0.006   \n",
       "28692  4.691  ...                        -0.047                        -0.049   \n",
       "28693  1.562  ...                         0.104                         0.098   \n",
       "28694  1.855  ...                         0.028                         0.030   \n",
       "28695  3.911  ...                         0.062                         0.063   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability24  MoreauBrotoAuto_Mutability25  \\\n",
       "0                            -0.057                        -0.058   \n",
       "1                             0.017                         0.014   \n",
       "2                             0.079                         0.068   \n",
       "3                             0.077                         0.074   \n",
       "4                             0.051                         0.053   \n",
       "...                             ...                           ...   \n",
       "28691                        -0.004                        -0.003   \n",
       "28692                        -0.048                        -0.048   \n",
       "28693                         0.097                         0.100   \n",
       "28694                         0.029                         0.029   \n",
       "28695                         0.063                         0.064   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability26  MoreauBrotoAuto_Mutability27  \\\n",
       "0                            -0.056                        -0.056   \n",
       "1                             0.017                         0.014   \n",
       "2                             0.051                         0.065   \n",
       "3                             0.073                         0.074   \n",
       "4                             0.052                         0.050   \n",
       "...                             ...                           ...   \n",
       "28691                        -0.002                        -0.003   \n",
       "28692                        -0.048                        -0.048   \n",
       "28693                         0.115                         0.099   \n",
       "28694                         0.030                         0.030   \n",
       "28695                         0.065                         0.067   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability28  MoreauBrotoAuto_Mutability29  \\\n",
       "0                            -0.056                        -0.056   \n",
       "1                             0.012                         0.013   \n",
       "2                             0.059                         0.050   \n",
       "3                             0.078                         0.081   \n",
       "4                             0.050                         0.051   \n",
       "...                             ...                           ...   \n",
       "28691                        -0.002                        -0.002   \n",
       "28692                        -0.046                        -0.044   \n",
       "28693                         0.107                         0.102   \n",
       "28694                         0.030                         0.030   \n",
       "28695                         0.064                         0.066   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability30   pH  \n",
       "0                            -0.057  7.0  \n",
       "1                             0.010  7.0  \n",
       "2                             0.048  7.0  \n",
       "3                             0.082  5.5  \n",
       "4                             0.049  7.0  \n",
       "...                             ...  ...  \n",
       "28691                        -0.005  7.0  \n",
       "28692                        -0.046  7.0  \n",
       "28693                         0.097  7.0  \n",
       "28694                         0.031  7.0  \n",
       "28695                         0.065  7.0  \n",
       "\n",
       "[28403 rows x 9298 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7aaed25",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Standardizar os valores\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Para se utilizar nos modelos de aprendizagem supervisionada\n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_arr = scaler.transform(X_train)\n",
    "X_train_sc = pd.DataFrame(data=X_train_arr, columns=X_train.columns)\n",
    "\n",
    "#Apenas para aplicar o PCA (remoção de outliers nos dados das variáveis independentes)\n",
    "X_train_sc_z = pd.DataFrame(data=preprocessing.scale(X_train), columns=X_train.columns)\n",
    "\n",
    "#O feature \"tri-peptide\" é (quase) binário. Pode ser standardizado também?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7d6978b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.347519</td>\n",
       "      <td>0.170823</td>\n",
       "      <td>0.143514</td>\n",
       "      <td>0.272236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259023</td>\n",
       "      <td>0.221351</td>\n",
       "      <td>0.081911</td>\n",
       "      <td>0.136395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538762</td>\n",
       "      <td>0.562071</td>\n",
       "      <td>0.742150</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.288136</td>\n",
       "      <td>0.301108</td>\n",
       "      <td>0.323253</td>\n",
       "      <td>0.258525</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.267428</td>\n",
       "      <td>0.312469</td>\n",
       "      <td>0.139825</td>\n",
       "      <td>0.186751</td>\n",
       "      <td>0.139133</td>\n",
       "      <td>0.285060</td>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.152795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.610106</td>\n",
       "      <td>0.769487</td>\n",
       "      <td>0.622505</td>\n",
       "      <td>0.356874</td>\n",
       "      <td>0.371601</td>\n",
       "      <td>0.394161</td>\n",
       "      <td>0.313243</td>\n",
       "      <td>0.326156</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.245731</td>\n",
       "      <td>0.149552</td>\n",
       "      <td>0.057362</td>\n",
       "      <td>0.312811</td>\n",
       "      <td>0.114181</td>\n",
       "      <td>0.372050</td>\n",
       "      <td>0.113037</td>\n",
       "      <td>0.135538</td>\n",
       "      <td>0.125393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633876</td>\n",
       "      <td>0.652527</td>\n",
       "      <td>0.792390</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.422961</td>\n",
       "      <td>0.443170</td>\n",
       "      <td>0.342585</td>\n",
       "      <td>0.356459</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009890</td>\n",
       "      <td>0.244258</td>\n",
       "      <td>0.136227</td>\n",
       "      <td>0.218537</td>\n",
       "      <td>0.370141</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>0.246533</td>\n",
       "      <td>0.137312</td>\n",
       "      <td>0.144698</td>\n",
       "      <td>0.145415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629316</td>\n",
       "      <td>0.644417</td>\n",
       "      <td>0.791651</td>\n",
       "      <td>0.658802</td>\n",
       "      <td>0.409605</td>\n",
       "      <td>0.432024</td>\n",
       "      <td>0.462982</td>\n",
       "      <td>0.367169</td>\n",
       "      <td>0.383573</td>\n",
       "      <td>0.389567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.349294</td>\n",
       "      <td>0.307824</td>\n",
       "      <td>0.089966</td>\n",
       "      <td>0.105114</td>\n",
       "      <td>0.044739</td>\n",
       "      <td>0.335510</td>\n",
       "      <td>0.620554</td>\n",
       "      <td>0.088575</td>\n",
       "      <td>0.098333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618893</td>\n",
       "      <td>0.633812</td>\n",
       "      <td>0.782047</td>\n",
       "      <td>0.646098</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.407855</td>\n",
       "      <td>0.433785</td>\n",
       "      <td>0.343378</td>\n",
       "      <td>0.357257</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeqLength         A         R         N         D         C         E  \\\n",
       "0   0.015139  0.347519  0.170823  0.143514  0.272236  0.000000  0.259023   \n",
       "1   0.009401  0.267428  0.312469  0.139825  0.186751  0.139133  0.285060   \n",
       "2   0.003174  0.245731  0.149552  0.057362  0.312811  0.114181  0.372050   \n",
       "3   0.009890  0.244258  0.136227  0.218537  0.370141  0.018916  0.246533   \n",
       "4   0.008333  0.349294  0.307824  0.089966  0.105114  0.044739  0.335510   \n",
       "\n",
       "          Q         G         H  ...  MoreauBrotoAuto_Mutability22  \\\n",
       "0  0.221351  0.081911  0.136395  ...                      0.538762   \n",
       "1  0.157480  0.162574  0.152795  ...                      0.590879   \n",
       "2  0.113037  0.135538  0.125393  ...                      0.633876   \n",
       "3  0.137312  0.144698  0.145415  ...                      0.629316   \n",
       "4  0.620554  0.088575  0.098333  ...                      0.618893   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability23  MoreauBrotoAuto_Mutability24  \\\n",
       "0                      0.562071                      0.742150   \n",
       "1                      0.610106                      0.769487   \n",
       "2                      0.652527                      0.792390   \n",
       "3                      0.644417                      0.791651   \n",
       "4                      0.633812                      0.782047   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability25  MoreauBrotoAuto_Mutability26  \\\n",
       "0                      0.578947                      0.288136   \n",
       "1                      0.622505                      0.356874   \n",
       "2                      0.655172                      0.388889   \n",
       "3                      0.658802                      0.409605   \n",
       "4                      0.646098                      0.389831   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability27  MoreauBrotoAuto_Mutability28  \\\n",
       "0                      0.301108                      0.323253   \n",
       "1                      0.371601                      0.394161   \n",
       "2                      0.422961                      0.443170   \n",
       "3                      0.432024                      0.462982   \n",
       "4                      0.407855                      0.433785   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability29  MoreauBrotoAuto_Mutability30        pH  \n",
       "0                      0.258525                      0.272727  0.556049  \n",
       "1                      0.313243                      0.326156  0.556049  \n",
       "2                      0.342585                      0.356459  0.556049  \n",
       "3                      0.367169                      0.383573  0.389567  \n",
       "4                      0.343378                      0.357257  0.556049  \n",
       "\n",
       "[5 rows x 9298 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15167fa7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073179</td>\n",
       "      <td>0.884308</td>\n",
       "      <td>-0.540551</td>\n",
       "      <td>0.166229</td>\n",
       "      <td>0.028724</td>\n",
       "      <td>-1.113421</td>\n",
       "      <td>-0.280073</td>\n",
       "      <td>0.692977</td>\n",
       "      <td>-0.764141</td>\n",
       "      <td>-0.144585</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.198806</td>\n",
       "      <td>-1.178724</td>\n",
       "      <td>-1.136078</td>\n",
       "      <td>-1.161830</td>\n",
       "      <td>-1.134499</td>\n",
       "      <td>-1.111612</td>\n",
       "      <td>-1.110298</td>\n",
       "      <td>-1.095428</td>\n",
       "      <td>-1.111168</td>\n",
       "      <td>0.178177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.210196</td>\n",
       "      <td>0.031288</td>\n",
       "      <td>1.007495</td>\n",
       "      <td>0.101659</td>\n",
       "      <td>-0.964606</td>\n",
       "      <td>0.580559</td>\n",
       "      <td>-0.024101</td>\n",
       "      <td>-0.131609</td>\n",
       "      <td>1.167583</td>\n",
       "      <td>0.065466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021403</td>\n",
       "      <td>-0.038921</td>\n",
       "      <td>-0.063606</td>\n",
       "      <td>-0.107821</td>\n",
       "      <td>-0.066506</td>\n",
       "      <td>-0.104390</td>\n",
       "      <td>-0.136385</td>\n",
       "      <td>-0.117148</td>\n",
       "      <td>-0.161443</td>\n",
       "      <td>0.178177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.517688</td>\n",
       "      <td>-0.199798</td>\n",
       "      <td>-0.773025</td>\n",
       "      <td>-1.341856</td>\n",
       "      <td>0.500202</td>\n",
       "      <td>0.276763</td>\n",
       "      <td>0.831132</td>\n",
       "      <td>-0.705373</td>\n",
       "      <td>0.520137</td>\n",
       "      <td>-0.285494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949954</td>\n",
       "      <td>0.967659</td>\n",
       "      <td>0.834952</td>\n",
       "      <td>0.682685</td>\n",
       "      <td>0.430915</td>\n",
       "      <td>0.629443</td>\n",
       "      <td>0.536761</td>\n",
       "      <td>0.407436</td>\n",
       "      <td>0.377208</td>\n",
       "      <td>0.178177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.186079</td>\n",
       "      <td>-0.215489</td>\n",
       "      <td>-0.918656</td>\n",
       "      <td>1.479510</td>\n",
       "      <td>1.166384</td>\n",
       "      <td>-0.883113</td>\n",
       "      <td>-0.402876</td>\n",
       "      <td>-0.391977</td>\n",
       "      <td>0.739490</td>\n",
       "      <td>-0.029057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846931</td>\n",
       "      <td>0.775225</td>\n",
       "      <td>0.805967</td>\n",
       "      <td>0.770519</td>\n",
       "      <td>0.752776</td>\n",
       "      <td>0.758942</td>\n",
       "      <td>0.808884</td>\n",
       "      <td>0.846953</td>\n",
       "      <td>0.859158</td>\n",
       "      <td>-1.506388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.262952</td>\n",
       "      <td>0.903208</td>\n",
       "      <td>0.956725</td>\n",
       "      <td>-0.771125</td>\n",
       "      <td>-1.913223</td>\n",
       "      <td>-0.568711</td>\n",
       "      <td>0.471894</td>\n",
       "      <td>5.846773</td>\n",
       "      <td>-0.604540</td>\n",
       "      <td>-0.632079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611450</td>\n",
       "      <td>0.523580</td>\n",
       "      <td>0.429152</td>\n",
       "      <td>0.463100</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>0.413609</td>\n",
       "      <td>0.407861</td>\n",
       "      <td>0.421614</td>\n",
       "      <td>0.391383</td>\n",
       "      <td>0.178177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeqLength         A         R         N         D         C         E  \\\n",
       "0   0.073179  0.884308 -0.540551  0.166229  0.028724 -1.113421 -0.280073   \n",
       "1  -0.210196  0.031288  1.007495  0.101659 -0.964606  0.580559 -0.024101   \n",
       "2  -0.517688 -0.199798 -0.773025 -1.341856  0.500202  0.276763  0.831132   \n",
       "3  -0.186079 -0.215489 -0.918656  1.479510  1.166384 -0.883113 -0.402876   \n",
       "4  -0.262952  0.903208  0.956725 -0.771125 -1.913223 -0.568711  0.471894   \n",
       "\n",
       "          Q         G         H  ...  MoreauBrotoAuto_Mutability22  \\\n",
       "0  0.692977 -0.764141 -0.144585  ...                     -1.198806   \n",
       "1 -0.131609  1.167583  0.065466  ...                     -0.021403   \n",
       "2 -0.705373  0.520137 -0.285494  ...                      0.949954   \n",
       "3 -0.391977  0.739490 -0.029057  ...                      0.846931   \n",
       "4  5.846773 -0.604540 -0.632079  ...                      0.611450   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability23  MoreauBrotoAuto_Mutability24  \\\n",
       "0                     -1.178724                     -1.136078   \n",
       "1                     -0.038921                     -0.063606   \n",
       "2                      0.967659                      0.834952   \n",
       "3                      0.775225                      0.805967   \n",
       "4                      0.523580                      0.429152   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability25  MoreauBrotoAuto_Mutability26  \\\n",
       "0                     -1.161830                     -1.134499   \n",
       "1                     -0.107821                     -0.066506   \n",
       "2                      0.682685                      0.430915   \n",
       "3                      0.770519                      0.752776   \n",
       "4                      0.463100                      0.445545   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability27  MoreauBrotoAuto_Mutability28  \\\n",
       "0                     -1.111612                     -1.110298   \n",
       "1                     -0.104390                     -0.136385   \n",
       "2                      0.629443                      0.536761   \n",
       "3                      0.758942                      0.808884   \n",
       "4                      0.413609                      0.407861   \n",
       "\n",
       "   MoreauBrotoAuto_Mutability29  MoreauBrotoAuto_Mutability30        pH  \n",
       "0                     -1.095428                     -1.111168  0.178177  \n",
       "1                     -0.117148                     -0.161443  0.178177  \n",
       "2                      0.407436                      0.377208  0.178177  \n",
       "3                      0.846953                      0.859158 -1.506388  \n",
       "4                      0.421614                      0.391383  0.178177  \n",
       "\n",
       "[5 rows x 9298 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc_z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f4ab1-a888-47ce-97a9-2d7322dce4ae",
   "metadata": {},
   "source": [
    "#### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801636fc-0dbf-4d69-b8ce-8973a14fdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RealPython -> https://realpython.com/python-statistics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c938784-1c8d-46fe-9a60-692392c8699a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLength</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>MoreauBrotoAuto_Mutability22</th>\n",
       "      <th>MoreauBrotoAuto_Mutability23</th>\n",
       "      <th>MoreauBrotoAuto_Mutability24</th>\n",
       "      <th>MoreauBrotoAuto_Mutability25</th>\n",
       "      <th>MoreauBrotoAuto_Mutability26</th>\n",
       "      <th>MoreauBrotoAuto_Mutability27</th>\n",
       "      <th>MoreauBrotoAuto_Mutability28</th>\n",
       "      <th>MoreauBrotoAuto_Mutability29</th>\n",
       "      <th>MoreauBrotoAuto_Mutability30</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "      <td>28403.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.264490</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>0.134017</td>\n",
       "      <td>0.269764</td>\n",
       "      <td>0.091449</td>\n",
       "      <td>0.287511</td>\n",
       "      <td>0.167674</td>\n",
       "      <td>0.113819</td>\n",
       "      <td>0.147683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591827</td>\n",
       "      <td>0.611746</td>\n",
       "      <td>0.771108</td>\n",
       "      <td>0.626960</td>\n",
       "      <td>0.361154</td>\n",
       "      <td>0.378907</td>\n",
       "      <td>0.404090</td>\n",
       "      <td>0.319796</td>\n",
       "      <td>0.335239</td>\n",
       "      <td>0.538440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.093893</td>\n",
       "      <td>0.091502</td>\n",
       "      <td>0.057128</td>\n",
       "      <td>0.086060</td>\n",
       "      <td>0.082135</td>\n",
       "      <td>0.101717</td>\n",
       "      <td>0.077459</td>\n",
       "      <td>0.041758</td>\n",
       "      <td>0.078078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044265</td>\n",
       "      <td>0.042144</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>0.041326</td>\n",
       "      <td>0.064363</td>\n",
       "      <td>0.069989</td>\n",
       "      <td>0.072808</td>\n",
       "      <td>0.055934</td>\n",
       "      <td>0.056258</td>\n",
       "      <td>0.098829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.198252</td>\n",
       "      <td>0.160839</td>\n",
       "      <td>0.096186</td>\n",
       "      <td>0.213444</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>0.225322</td>\n",
       "      <td>0.121437</td>\n",
       "      <td>0.087311</td>\n",
       "      <td>0.096112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564821</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.755818</td>\n",
       "      <td>0.601936</td>\n",
       "      <td>0.321092</td>\n",
       "      <td>0.336354</td>\n",
       "      <td>0.359750</td>\n",
       "      <td>0.286281</td>\n",
       "      <td>0.301435</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.256814</td>\n",
       "      <td>0.211573</td>\n",
       "      <td>0.129072</td>\n",
       "      <td>0.265075</td>\n",
       "      <td>0.075913</td>\n",
       "      <td>0.279950</td>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.108831</td>\n",
       "      <td>0.142818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>0.610106</td>\n",
       "      <td>0.770225</td>\n",
       "      <td>0.625529</td>\n",
       "      <td>0.358757</td>\n",
       "      <td>0.377644</td>\n",
       "      <td>0.402503</td>\n",
       "      <td>0.318002</td>\n",
       "      <td>0.334131</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.015994</td>\n",
       "      <td>0.315476</td>\n",
       "      <td>0.268786</td>\n",
       "      <td>0.165098</td>\n",
       "      <td>0.315636</td>\n",
       "      <td>0.120403</td>\n",
       "      <td>0.341451</td>\n",
       "      <td>0.206071</td>\n",
       "      <td>0.136244</td>\n",
       "      <td>0.192497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618241</td>\n",
       "      <td>0.636931</td>\n",
       "      <td>0.786110</td>\n",
       "      <td>0.651543</td>\n",
       "      <td>0.400188</td>\n",
       "      <td>0.418933</td>\n",
       "      <td>0.446298</td>\n",
       "      <td>0.351308</td>\n",
       "      <td>0.366826</td>\n",
       "      <td>0.556049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 9298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SeqLength             A             R             N             D  \\\n",
       "count  28403.000000  28403.000000  28403.000000  28403.000000  28403.000000   \n",
       "mean       0.013658      0.264490      0.220284      0.134017      0.269764   \n",
       "std        0.020250      0.093893      0.091502      0.057128      0.086060   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.005830      0.198252      0.160839      0.096186      0.213444   \n",
       "50%        0.010103      0.256814      0.211573      0.129072      0.265075   \n",
       "75%        0.015994      0.315476      0.268786      0.165098      0.315636   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                  C             E             Q             G             H  \\\n",
       "count  28403.000000  28403.000000  28403.000000  28403.000000  28403.000000   \n",
       "mean       0.091449      0.287511      0.167674      0.113819      0.147683   \n",
       "std        0.082135      0.101717      0.077459      0.041758      0.078078   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.039886      0.225322      0.121437      0.087311      0.096112   \n",
       "50%        0.075913      0.279950      0.157973      0.108831      0.142818   \n",
       "75%        0.120403      0.341451      0.206071      0.136244      0.192497   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...  MoreauBrotoAuto_Mutability22  MoreauBrotoAuto_Mutability23  \\\n",
       "count  ...                  28403.000000                  28403.000000   \n",
       "mean   ...                      0.591827                      0.611746   \n",
       "std    ...                      0.044265                      0.042144   \n",
       "min    ...                      0.000000                      0.000000   \n",
       "25%    ...                      0.564821                      0.586400   \n",
       "50%    ...                      0.590879                      0.610106   \n",
       "75%    ...                      0.618241                      0.636931   \n",
       "max    ...                      1.000000                      1.000000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability24  MoreauBrotoAuto_Mutability25  \\\n",
       "count                  28403.000000                  28403.000000   \n",
       "mean                       0.771108                      0.626960   \n",
       "std                        0.025490                      0.041326   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.755818                      0.601936   \n",
       "50%                        0.770225                      0.625529   \n",
       "75%                        0.786110                      0.651543   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability26  MoreauBrotoAuto_Mutability27  \\\n",
       "count                  28403.000000                  28403.000000   \n",
       "mean                       0.361154                      0.378907   \n",
       "std                        0.064363                      0.069989   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.321092                      0.336354   \n",
       "50%                        0.358757                      0.377644   \n",
       "75%                        0.400188                      0.418933   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability28  MoreauBrotoAuto_Mutability29  \\\n",
       "count                  28403.000000                  28403.000000   \n",
       "mean                       0.404090                      0.319796   \n",
       "std                        0.072808                      0.055934   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.359750                      0.286281   \n",
       "50%                        0.402503                      0.318002   \n",
       "75%                        0.446298                      0.351308   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       MoreauBrotoAuto_Mutability30            pH  \n",
       "count                  28403.000000  28403.000000  \n",
       "mean                       0.335239      0.538440  \n",
       "std                        0.056258      0.098829  \n",
       "min                        0.000000      0.000000  \n",
       "25%                        0.301435      0.556049  \n",
       "50%                        0.334131      0.556049  \n",
       "75%                        0.366826      0.556049  \n",
       "max                        1.000000      1.000000  \n",
       "\n",
       "[8 rows x 9298 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_stats = X_train_sc.describe()\n",
    "X_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd707a0a-c88e-41cd-98eb-3ed05bb22040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28689.000000\n",
       "mean        49.091216\n",
       "std         14.192283\n",
       "min         -1.000000\n",
       "25%         41.900000\n",
       "50%         48.000000\n",
       "75%         53.800000\n",
       "max        130.000000\n",
       "Name: tm, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_stats = y_train.describe()\n",
    "y_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb9cd537-770e-4fd6-a4d5-bc5260d731f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# violin plot (tm)\n",
    "plt.violinplot(y_train, vert=False, widths=0.5, showmeans=True)\n",
    "plt.title(\"tm violin plot\") \n",
    "plt.xlabel(\"thermostability\")\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c0fb016-55e6-450a-a837-40b97af99b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# density curve of label (tm)\n",
    "bins = 100\n",
    "plt.hist(y_train, color=\"b\", bins=bins, density=True)\n",
    "y_mean, y_std = y_stats['mean'], y_stats['std']\n",
    "plt.axvline(y_mean, color=\"r\", label=\"mu\")\n",
    "plt.axvline(y_mean-y_std*1.96, color=\"g\", label=\"mu +/- 1.96 * sigma\")\n",
    "plt.axvline(y_mean+y_std*1.96, color=\"g\")\n",
    "plt.title(f\"tm density curve ({bins} bins) - mu = {y_mean:.2f} - sigma = {y_std:.2f}\")\n",
    "plt.xlabel(\"tm values\"), plt.ylabel(\"relative frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9f7b782-9b1e-4d21-a3f6-35517cb8c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d82d2060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install outlier_utils\n",
    "\n",
    "#from outliers import smirnov_grubbs as grubbs\n",
    "\n",
    "#result = {}\n",
    "#for col in X_train.columns:\n",
    "#    result[col] = grubbs.two_sided_test_indices(np.array(X_train_sc[col]), alpha=0.05)\n",
    "\n",
    "#print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf00d4-8085-44ed-b0bf-4357309c68ee",
   "metadata": {},
   "source": [
    "#### Correlations\n",
    "(with respect to the output variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4463e4-5b90-4e8e-9ea3-9fe2f2978c95",
   "metadata": {},
   "source": [
    "<b>k best correlations</b> (given an array of correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9784d330-b01f-456a-8bcb-43482dc6685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get k best scores between features and label -> pearson, spearman, f_regression and multi_info_regression\n",
    "def get_k_best_corrs(k, scores):\n",
    "    idxs = np.argsort(scores)[-k:]\n",
    "    feats = X_train_sc.columns[idxs]\n",
    "    scores = np.sort(scores)[-k:]\n",
    "    return {f: c for f, c in zip(feats, scores)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180eeb84-00c0-4d8b-9d06-aa0f8baf24b7",
   "metadata": {},
   "source": [
    "<b>Pearson and Spearman correlations</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17fbea7d-f9d3-4d6f-a5fa-72210af8dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RealPython -> https://realpython.com/numpy-scipy-pandas-correlation-python/\n",
    "\n",
    "# Linear correlation measures the proximity of the mathematical relationship between variables or dataset features\n",
    "# to a linear function. If the relationship between the two features is closer to some linear function, then their\n",
    "# linear correlation is stronger and the absolute value of the correlation coefficient is higher.\n",
    "\n",
    "# pearson correlations with respect to tm (label) -> measures linear correlations\n",
    "def pearson_correlations(x: np.ndarray):\n",
    "    return abs(scipy.stats.pearsonr(x, y_train)[0])\n",
    "\n",
    "# Rank correlation compares the ranks or the orderings of the data related to two variables or dataset features.\n",
    "# If the orderings are similar, then the correlation is strong, positive, and high. However, if the orderings are\n",
    "# close to reversed, then the correlation is strong, negative, and low. In other words, rank correlation is concerned\n",
    "# only with the order of values, not with the particular values from the dataset.\n",
    "# Allows to capture non-linear relationships (see figure below).\n",
    "\n",
    "# spearman correlations with respect to tm (label) -> compares the ranks of data\n",
    "def spearman_correlations(x: np.ndarray):\n",
    "    return abs(scipy.stats.spearmanr(x, y_train).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17090ef6-5d4b-493c-bf42-88d8f55f2e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corrs = np.apply_along_axis(pearson_correlations, axis=0, arr=X_train_sc)\n",
    "spearman_corrs = np.apply_along_axis(spearman_correlations, axis=0, arr=X_train_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728c0206-47e4-4495-bf2f-f87c63543a2e",
   "metadata": {},
   "source": [
    "![title](corrs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95f4297a-8d6f-469a-bf42-ba4720fa5804",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'DKY': 0.15266814153133518,\n 'GQ': 0.15286365153343026,\n 'EAQ': 0.15289552301813222,\n 'AV': 0.15344493003827891,\n 'FAT': 0.15350338513524256,\n 'KKM': 0.15442712483828158,\n 'AKK': 0.15442951930601523,\n 'QT': 0.1546754948448122,\n 'KLM': 0.15506147575685586,\n 'KPN': 0.15614679682260235,\n 'SCL': 0.15649190277972555,\n 'GQR': 0.15682237066803156,\n 'RTD': 0.15697681444754621,\n 'LHK': 0.157142284572514,\n 'LVM': 0.15716188338196335,\n 'QHL': 0.1572030391749388,\n 'KL': 0.15829185569280568,\n 'YAD': 0.1584168666638824,\n 'GKM': 0.15856469543391877,\n 'SKG': 0.15859564646039082,\n 'ADG': 0.1587400200194572,\n 'HK': 0.15963941435489323,\n 'GDT': 0.16125895341758134,\n 'TK': 0.1613779793990864,\n 'GVN': 0.16198659215162237,\n 'FDK': 0.16301496580571873,\n 'KM': 0.16308080977110492,\n 'THE': 0.16358028851350914,\n 'NAD': 0.16516995458724865,\n 'YIY': 0.1653405413090765,\n 'MVN': 0.16567866339095877,\n 'CM': 0.16576213874417398,\n 'RQG': 0.16612259484366063,\n 'NNT': 0.1662320325215987,\n '_SolventAccessibilityD2025': 0.1663795203988362,\n '_HydrophobicityD1025': 0.1663795203988362,\n 'DN': 0.16662540632843809,\n 'QRT': 0.16684819108492252,\n 'KYG': 0.16790013862926198,\n 'YGR': 0.16801742648684775,\n 'TEY': 0.16825757266898983,\n 'DNA': 0.1683978989752596,\n 'CLV': 0.16842695563884486,\n 'DNG': 0.1684670971662174,\n 'YKP': 0.1684910579437615,\n 'HKE': 0.1691882522378345,\n 'FTK': 0.16965980107031012,\n 'DKG': 0.17075882008240365,\n 'HPK': 0.17160534356016785,\n 'VMT': 0.17185540368894434,\n 'TKH': 0.17251365919039408,\n 'L': 0.17294123718090823,\n 'RL': 0.17321933189239813,\n '_SolventAccessibilityC3': 0.17448767292774933,\n 'TSC': 0.17453366162784117,\n '_PolarityD3025': 0.17554693821240022,\n 'MTE': 0.17586377302911707,\n 'FFF': 0.17596995635823132,\n 'TDN': 0.17689305728505958,\n 'SED': 0.17699520786504994,\n 'ATS': 0.17755888274895162,\n 'IYA': 0.17803292169453505,\n 'HEQ': 0.17955821357569288,\n 'PNN': 0.17966024815225387,\n 'GIC': 0.18129205666928488,\n 'KMV': 0.18158145959740257,\n 'PMT': 0.1816846338038438,\n 'PL': 0.1820052510936252,\n 'KK': 0.18472441604382256,\n 'MTF': 0.1860549934617688,\n 'QTD': 0.18623045532225346,\n 'K': 0.18654800240267072,\n 'S': 0.1868199281998313,\n 'KHP': 0.18910241141519374,\n 'TKK': 0.19130538790939045,\n 'RA': 0.19236663421871336,\n 'EQH': 0.1924393292130661,\n 'LE': 0.19329383612557985,\n 'IWS': 0.19394052968248318,\n 'NTH': 0.19454212925880504,\n 'MYK': 0.1966319885685232,\n 'T': 0.19703776685959035,\n 'WSE': 0.19794258198957057,\n 'SheetSSF': 0.19894453707295545,\n 'IGM': 0.19930074750815063,\n 'ER': 0.19979457778478138,\n 'LG': 0.20135332559530894,\n 'QPM': 0.20383850084146743,\n 'R': 0.20607523845993456,\n 'GE': 0.2073068465356687,\n 'LMY': 0.20859605883048965,\n 'MAI': 0.2098502061617197,\n 'CMA': 0.2102361141843166,\n 'NIW': 0.21033923038841174,\n '_SolventAccessibilityT23': 0.21300734265585397,\n '_SolventAccessibilityC1': 0.21858633645296022,\n 'ICM': 0.21971119131894587,\n 'KGQ': 0.2205654300833148,\n 'AR': 0.24282747044304423,\n 'AL': 0.25215464973986446}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest 100 pearson correlations\n",
    "best_pearson = get_k_best_corrs(100, pearson_corrs)\n",
    "best_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82db4ff2-760a-4a02-85f7-d19e9590c16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c923da3d0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD3CAYAAADSftWOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOx9e3RV1b3ut147ITSY+EDbg8eKBROFVqOBSFtsL42RIb1V4WBRSnuqx2OPtNhWBBk82iNVLK3n0MNpbYfHVp41Q0TvxaEBUyCVNHT3xkdELK0PFFBSNdAIJHvvteb947fnWnPNNdfaOyGBvXF9YzCy12uuuXbIN3/r+700xhhDjBgxYsQoKugnewIxYsSIEaPviMk7RowYMYoQMXnHiBEjRhEiJu8YMWLEKELE5B0jRowYRQjzRNzEcRzYdnEFtRiGVnRzDsOp8izxcxQeTpVnKdTnsCwj9NgJIW/bZjh06OiJuNWAoaKirOjmHIZT5Vni5yg8nCrPUqjPcdZZ5aHHYtkkRowYMYoQMXnHiBEjRhEiJu8YMWLEKELE5B0jRowYRYiYvGPEiBGjCBGTd4wYMWIUIU5IqOBgIZnU0dpqYsKEDGprnaK536pVJjZtsjBlShqzZmUix811z2RSx8qVCRw8qGHCBBunnYbIcSorHXR0UOzo9OnpE/K9FQpO9P+XGDEGE9qJKAmbTtsDHkOZTOqYOrUM6TRgWcCGDUcj/yCTSR2NjRYAj7Q4iY4ZEyQ9Oe4z6n75EiMn2qef9tbMujob7e0GbBswDGDGjLR7reqeAFwCAoD//b/LYNv+ZzVNYNmyHsyaRee8+moZrrpKRyoFOMKUEglg40b19zbQRNef8eRrKirKsGVLj2+fatywfbn+vxzvM+d7faHGFPcHUc9STItlof5OouK8C97ylq1UjsZGC729AGMaAIbWVhO1tSnlGMmkjuuuK0Mqe3jtWgu33ZbCypUJAMC2bQY0DSgpSYQuAo2NFnp6AEADY3Q/IIPGRgtr11qwbUBcBtessXD//R6BcvKgMWgcgKGtzXC3bZth1SoL69bRgnLOOQzpNGDbGhyH4etfL8UHH5DSlUgk8MUvZrLErWXHYAA0ZDIM8+eXorqanmX7dg3pNOA4mnsOAKTT6u+NzzWVAnQ9gWXLelBd7QQWv3zhJ84Eli7tCV3kxIVw4cJS95oNG46ivBy47joaR9cTuPbaNJ580oLj0PfBx12/nn4f/LraWgetrabvu6RnSfsWQj5Hw0j4FtH+PGMuY+JUR/x9DD5ykncqlcLdd9+Nt99+Gx/72MewePFiaJqG+fPnQ9M0jBo1CkuWLIGuD7x8vmqViTvvLAVABAv0uDLD+vVWliwZDAPuH6CMZFLH8uUlWeIm0spkGDZs4I9OhMaYhlSKYfnyEsyd24v6ev8Ya9da2S0GxwEOH4ZvQeDj8HvYNsO8eR6BcvLwzmPSdbTNmIZ0muH554nc6GtlYAx47z3dvSaVYjh4kJN2cA6coFpbGXp7mXAM7k/LUn9vra1m1kqncebNK4WmAZnsqevXW6EWuwoycd51V6n7BiCOJf7Baxq9JfAFp7XVRGen5v4ebZthwwb+O9HQ20sLlreI+hf1CRMyMIwEbJu+y3XrLJfkDSOBMWNs95ltm+GRRyw8+qgVeNsJs9b37dPcZ8xlTHwUIP7O4+9jcJCTvBsbG1FWVobGxka8/vrruOeee2BZFu644w6MHz8eixcvRnNzM+pFthsgrFvn/XECDOvWWZg1K4PWVtO1ODWNYcYMtYXEyaC3l+/xyPX00xneeYfvo5+OA7S0GGhrK8PmzQ6qqjzyly3cX/zCEvaJypNHyrZNBLp7t42nnyYy1jQGTQNOP91BV5cOx2E+spFJ3fE9lnd/xoBhw0Qy9pOzptEbRkbiZsMArroqg+HDGcaOtd03CFGCqKx0oOuA43gLgTdHstj5Igf4ZRxunZeXM7z8soEpU9IB4pTH4n/Y4h+8rjPoOn1ffJF58klLeBJxsWQu2fM3Mf5dVFbSF1hb62DGjDRWrbLAGL2dAHS+bTO0t/M3IO/7T6Xo9/foo5bSghQXG8OgfwBTLoqihFBeDjQ1JSL9GMUiN4RhwoQMLCuBsO8jxvEjJ3n/9a9/xcSJEwEAI0eOxGuvvQbbtjFu3DgAwMSJE7Fjx45BIe+zz2bKbfk/xvTpaeX13IL0/qABbqmn05wI6dgnPuHg3Xd1OA790f77v2u4+moTCxeWZscARJImi0KE2nXw5z/reOQRy39m1oo2DGDUKBt79sjFZzTps0zONMa2baZ0DjB6tI3XXzcE0g6+EQwfzjB9ejogZXCZwjCAyy+3kUwabrEej8zp3tu3G/j978sAEGkaBklQ8mKxbZuB2bNTPuL0v2l4BCv/Xpcu7UFXl+6SWHk5w69/TW8m8vc+cWIGbW0mUilvwbNtYMEC7+1n+vR0lohZlmhp8eCLiab5F1L+MhlmQcrW5cyZaYwYwQKk6yf5RPYtJqFcDBob6Y0gk/EkK1EuLBbU1jrYsOFo0S9ChYyc5F1dXY2tW7fiS1/6El588UUcPHgQZ5xxBjSNyGDo0KHo7u6OHMMwNFRUlPV5ch4RsOy2joqKMtTXA5s3k5Z75ZUMdXWlyusbGoD77uPXewRn28CePX6Zx3E0aBpZeo4DNDdr2Lat1Pfq7odsKQf3myZw+LAu7fd+2jZDaSk/zkLGlIlbRebe9pEjuuKNwD//NWssdHX5ieeZZ0p8ssHOnYZLXtxa/vSnSYPfvVtzLVY+PrdkZf0dYPj5zxNYudJBYyPQ0+O34gGGY8dKUFGRQH098MADDh5/XMP11zPccksCbW3A9u0WyssZPvtZHc3NDtas0fDUU8D+/Zp7D9M0sHmzg3//dw3NzVp2kSBybm8fgvp6Fvh/Q9+Fht/8hp7FMEiuSaeJuH/2MwdjxhhobARSKYZEAmhoMFFRQX82DQ3AAw94x26+2UBdHSD/WbW3az7ZiL5TmjefW1sbMG2ajp4e783EcUgKGjfOyY5beDAMPfRvu74eWfmx4F1rkc9RqMj5rU6dOhWvvfYaZs2ahZqaGlx88cXo7Ox0jx85cgTDhg2LHKO/VQXb2oZmP3HnnoZDh44AAKqq6B8AHDoUvJZHdjiOSI7eWDKhvfuu35Lm5MQ1Z+9aIEjY4riidU5E510TXATee4/vjyLoMGIPzokILfx+fNF46ikNhkHWtG0Du3Y5cBzDPV8mZ4Cho0NzLdbw8SHso3MYY2hsZLj55hRaWw28+KJn0ScSQE3NMRw6RLLN975HFupzz2k4erRHcFpqWSnrKJYuBUaP5v4QGufqq3tRVZXBd7+ro6WlDKkU7TcMoLXVxr/8C3MdkPz/DQAsXQp85SueTLF7t+46yKdNI+vhsce841VVjvv/raoq/JiImhodllUG/tZHlje9XfBnb2pKIJVKSG8mROBNTRlUVRWmXlyoURp9RaE+x3FFm3R0dOCyyy7DggUL0NHRgbfeegtnnnkmdu7cifHjx6OlpQV1g2QWfOxjDrq7Dd92PgiL7CCE/QySnmEAF15oY9cuA35C1RTXkKUtOsy8KMxwEr7iChtPPKFnySyMeOXPYfNX3S+7RxOlHyKFf/xHG2+8Qd/vO+8Yvms1jRYusuI9Eqa3IXn8IIFXVjo4dEgH1+e3bTOwbRtZ84YBXHCBjQsuYJg9O+W+UssyxKZNlm97+3bNJV6SEnoCkUi1tQ42bjyKxkYLnZ0ann3WdEMz16+3cO+9nhTD7zlhQgZz5qSQTOruYtHWZrhyC/1Tk2fUMfEcUUIoLy/F//yPP75TlIxIogIYI4u+stLBihVqjfxU0Mdj9A85yfu8887DihUr8PDDD6O8vBw/+tGPcPToUSxatAgPPPAARo4ciYaGhkGZXHm5lnUqetv5QB3Z4ZGerhORaRowbpyN//f/jICOahgUK+05TeE77oHG/fjHHVx1lY3Vq0VdN8wy9eb2sY+RA1GM/RavI9KViV01VvDzGWc4+OADHYypFhK4xK0ae9Qo0s7Vzxz+PPy8w4d1WBbwyU86WYmKO2Bp4fjLXwy89RYwe7ZHfLLmPWVKOhtKSdtc6hAJa9asY4GZEKH2YsWKBJ55xnu+dJpkCMcBNC3hLmhce+5rhES+MebenGisV1+F6wTlES0ywQMIDZlUx67H4XgfNeQk79NPPx2/+c1vAvvXrFkzGPPxwbJY5LYI8Y9GjG4geIRFUgFcQvvTnwwsW9aDX/0q4ZKMpjHcfDPDrFkZvPmmno1E8FuZlZUULcK3zzuPobNTg2nCfWWXNe6g9e3Fg2/ebAY6eeg6UF3NLX+RwP3P5If3nH//uy45Wr1rvJj0YLRMIgFccAHDnj38uHoM+c0DoMUGIO08k2H42MfkOXqyTDpN0RyNjXRk+vQ0NmzwrOaODsPntKyrK8WWLcEY9DCHHl8M+O+Dv0n4Hdhe3D7/f+M40eGngJo4AeRFpjzuXl4kZCu+tjaFFSsSeTtM43C8jxYK2pPwt79pkdscqiQQNRiuvTaDxx+3IMoHzc0mXnvN08YtC5g5kyGZ1PHQQwnheiL2WbMogeMrXylznao82cY0gcmTM3jrLQ2vvGIgmMDql1xsm6Gjw8D/+T9HsXJlAq2tBg4f1ty5EXF78w8LKRSh68AFFzj4y1906XjYYuKNo+vArbem8KtfJYRr/N8hOXa96BP+ms/H4AuG4wD79olvD945muYtXjxDlMsa69dbbvx8IuGPKZdj0MVkJBmihAIAY8famD+/NOtc9Z7fcYD2dh2VlfnnKojz8JK2wiNTRFx5JYNl0Tm5wuiiQu7icLyPNgqavD/8MHqbQ6WVqmKwzzhDTOwAOFmR1eudf/HFNgBNKb+Y2W+ssdGCGFbGyTiTYdi82cyGz4mauUof9haj2loHs2ensGVLmXSeSuP2iJYTqDgPx2FCNE2UJq4m9h07DOm5xUWTyJu/wRgGcO21aTzxhOU6eMV4685OHt9OC5vj0PW2DXhp/Z6swXVucZ9IghMmZKDrCV8MepTFySUUDz3ZZB5/WOAzz5hoajKzkTXkrI0at7LSyS5YRP6VlQ6qq528yLSuDu4bRi5Ehdz1JRwv1sZPPRQ0eRuGFrnNEaaVesklRFBnnMHw/vuASFpyRh4AvPCCgYYG4J57HFgWWY08djidBlatsmBZcKM1gjHgNF4mI1rOKpmDtvfu1TB3bgk6OnTBISieQ9vDhzt47z1K7KEoDTtr8cvni/cLyiIyNA1ZPwAtTi+/bPicm/KCIzouGWNZ4qajjkMk7fkQaG6MMdx4I8Xjr1kjL3ye1DNlShqtrYYrdZgm/X6TSR3t7RpqasgXQdo1zXffPg3JpJ4XKc2alUF1Nb3l0CLLXMLmbwe6ntuS7erSswsVJRR1demorc2EkqmcpMPjuW3br3urIMspMhHnkkpWrTJdrT+RiLXxUwUFTd4lJQzd3ZpvWwWVBVJdfRTLl5dk0+q9V1SCX+/09vHXfkrU6erSsWHDUSxcWJJNV/cfr6uz8ac/qRJiZHCpQF4o6KeXbCPPz7/d2em91jsOkEyKWYFhenh4RAi/jjGGqiobH3xAmv3+/bLcAgwfbuP99w2X4AGSfLy0eY+kbZsKbnFnIwA3maq11QwsllyOuummdNbP4NWdYQzYvVsXnHZl2LDhKJ588qhLgGvW5JfKLmLrVpoHd15zS17TGCZOtDF3bm/k9RMmZJBIJNyEH3EBCasVIybppFK673vIV6/uq5MymdSzUhHdK5WKtfFTBQVdz/vKK/l7NZO2g6itdTBnjhd2VlvrYMwY//V+K5jvV1mtREr79tGxT39a/OPwSOePfzQErVe8Xv6c3aNce0QNnD6PHu2grs6Gv1yM5js3kwH8Kfu+O2VTy+V7yPfz5rlrl4F33tHx9tu6Kwfw46YJ/PrXvbj//h585jM2Jk3K4NZbU/jMZ2xcfrmdJXPPGUsyAsNPftKDSy+1MXlyBk88QSQzYUJGOJ+g6wwlJUTuyaSOX/yC6+30nD/9aQK9vSSLpVLI1myhFYTkF3IANjZamDq1DMuWJTB1ahmSSfV/b17UjJKvgIYGmhOfRy7iBjyDYeZM720i7J6irJdOQ8j6hS/9Px/IY/HvIep80R+h6/3TxpNJHStWJEK/0xgnHgVteb/6qj870dvODy+/rJIscoXvAQBZj9yiu+aatLtfPJdHJRgGy+q84hji+WqdO4zs33xTxxVXpLFzpyiJ8IVGNf9czyTr5zSe+k0AkL+ryy+nRdCz4HLj6adNTJqUQVOTP5RPrjGi6wyXXGLj7LOZqwHLi9I773j6vePQ7wUI1hMBcjsMVUXNZs9OYfbsVM666fJxKjjG3AVEdc9kUse+fZo7TzFJxzCASZOozky+6KuTkr8hpFJE3MuW9fRZMolDEgsTBU3ecgq7vC1DLKzU1aVjzBg7K5vkctRB8dn7g/zDH8LjoWtrbUyaZKO52RDKuwbHCoYKkoZ92WX0R/Daa1q2xgmF0HV2atnQNrWE4k+6kZ8N7sLiv95/rvcm4P8uvLEJO3cauOeeEkmPl8k+uEDedZcXCSKSH68xkkrRAvLSS570FMzglJ+N+ZzL3PIFKJrEsiiSKKpiYlhRM5WUINYbEcvM8rEqK53swhG8p1y4auZMilIqLy9FU1PGF8OdS/fm6GvNkIGoMRKHJBYmCpq8EwlkIw+87TCINagdh7TMRAKYOjWNxx+3JKITySZIOnV1Np5/npxmhkESwIED4t380sm0aWlceKEmkLc8vhp/+5uOZ5/V3RKo/FrGgC1bTJxxhpPVuWXilysRBhcjw5BlGtWC5b1KT5yYwfbtng7MM/y4Jk5vAZCuj7IY6c1k5coEhg9nAfJburRHUcJVXGzCdHvuPyCyHDvWFgpqWa4lKzbcWLvWwjnnUDanaLnyhUJ0doqLDAC3KqX4ffsrDQYLaHHIpDdiBMs2lQCqqqJjuKOQj5My7Pz+RJ3EIYmFiYIm79GjnayjkLnbYeB/KLyIlOOQBfv++3rWglVLJ14lOQCgKI5p09JuiVC5S40sQfBY42XLeqDrluv4Cp4vj0GkyMPi/HHQ9FotOiiDUIf5AcC55zrYv1/3aZ1q2ci77sABz4Fm2wznnuvg7bc92Yoxz5Lnero/1E+1EALPPGMK369Hfnv36soSrrLVr5qzrpNOzaUOToC2TSF/XD8X68EDwLPPmnjiiaNumJ7K2SnKAzfckEY67c2RLxiAX57p6tIxZ06QTHOR3okmxf7KH3GFwMJEQZO3SB4AE7aD4H8IPKyPh3sFwwYBbnV961spvPyyge3bDTDmvUZ3dBjuH61ti+F+agnCcSjRxktWUUsmHiGqrPEwwpeJMczq9c6Rv7do0HdBCT0exoxxcOCA7lrCpgnU13v67KpVVsic/PcULVZNo3vxkqeUpu5p74x5skkmw9w6KJmM/03DcejNZNKkjPt7F0P+eGz4jh1+uYvvnzMnpdSq6Rz/Qs8lEbFFHUAyRz6ke8MNdL6qK8+JJsXjkT/6au3HGHwUNHn39joADGnbD/E1kP8hiL0kAeCLXxRrh9B/3NpaG4sXp7Bqlenq4oxRE4Ff/SqhiHP2/+TWrRg657d0xc8eAXoIZioG4b8nb6QA+DXyMPlHvQjIzkuG88+3pbGAri7/ApPJAE1NJhIJ4Jpr0j4Z6uKLbZSXkzbu1WHxz0XTgKuvJvJfs8bKluD1mijwcxljuOqqDLZsMbPkDlx0kZzoRDH08+aV4v77e3DDDWm3CBUn/X37tIDPgxOt7ETk+3fv1rMx716deB7eKJNrLtKVe2aqas6HSRiDlVAjGjia5tVRj1GcKGjylluryduq10BeHe7uu0uzkoTcfYXwxz8aWLXKFNLAiWQ2bzaFlmnhVqX4FpBOA3/6k64gfL9T74035KxHIvSaGhv791Mrr/feMwQy8+5tmsBtt1HaejrAA2HWeZjl7e331zHxjom9NfkcHIfm+Mwz/iieXbsMN/KDx0zrOmnnntUMNDeTtcxJ0yPuoCzBa5BkMiTp+OdNz8pbzQFizRr6faxebSGRoEiSHTsMV/MG4HMi8q5CPJac+0uWLu2JdGTmskRzWblhEsZgRnbU1jqur8FxgIULSwGo9foYhY+CJm/G/JY3bXuQeyN+97sluOIKBy0tuiK9209qci9FDq8ec5g1G/zMmKoGCaTtoIXMX/HJYhXP9whT06jC3wUXMLz2mi4tLPL9iDQ/9SkHr7+uCyng4hy88889l2Ljq6sdPPusKVVWVC9AjAFHjgTlK9smS5pb152ddM3BgxpeeMFwOxQ9/bTpRl54zkZPlhg71saCBaW++ijeW0BQluGRI7Kjk/s8TjsNvnBF0UnIGMOWLWa2wqTlNt7QNNKxj8cCzqVnh5H7YEd2dHXp2QWWfh/z55f6KivGBF48KGjy/vvf9chtuTfinj2GoqVYOIIyB1BSwj+prFYVoUH6HCa1qMYUyVUkKP/CQM8FKWlHHs/Tg//6Vx2mSaGIZLX6SZvj7bd1LFhQio0bj+KJJyhl/LXXNLz+uiFoyLmeyf8sW7aY2W40tNc0IVVaJKLt7NTcVHWRIFesSOToBMQdm0T4Yjil37nsrwwohpFyHVtscqzrXMbiEUbOcVvAUXp3GLkPthNTHF/V5DnWtYsHBU3ecuSBJvFFba2DSZO4nh1GoO7VwjEgjIg//FB1HkL2hWnVslMxyooXt1WOTO9+njYePS5vZeaFOKoWIUIqxXDPPSWYNi3t6sxi+7Pcz+S/v9wOzbYp7X3LFkOQP8giB5AltYzbCDlYztdDdTXD9den3Th+ue71ggWlQk9KD2IYqa6T/HTaacDhw8CDDxKRUdEs7xrutO6PBZyP3h3mrBxsJyaXTjZtsjBmjI2HHqIU/zgEsPhQ4OTN3DRivi3Dn52Wz2ffHSATuPeKrpYmgs0RyGGXTmu+euBXX51BMmngvfc0+Ek5jLjFeaocjuL96TgvJuW3jj3r8dVX/dr05MkZNDWZQjgjjdnWZgjSjQZ/pUIam1cS9OKy/fMK+744eZWXs2y9Eto/YQKZybnL+XrjfvvbDNOmBeOVJ0wg8r/3XiKllhbDXcB4FIlYRvbBB6kO+E9/6mnckyZlsHmzCbH9Gy9K1lfnXj7SR5QkM5iRHXK3oLAY9RiFj4Imb157ImwbIGKg+s9+Ehk2zEF3ty7JEjJJqhBO2rffTn9QHgnRua+8YuDKKzN4/XWv4t/s2SncdlsJRM3eGy/M0g4jdj/Z6jpZijwhpbyc4Re/8JoI3HQTWXr+cD6q8R0MZ6TjwWJRwXP8LdBk+M8dPdrBFVfYrmTQ2OgtippGWnQyqWPRopJsuzq6LljOl8blkTorViR8mYm8az0lAJGjsa3N8BWMGjvWFsrnEoHz0rNc4x4+nEHMlJw+Pe3W/+bOvbC64TJySR9tbcGmDUB+BbWOF/LCEhajHqPwkZO80+k05s+fj/3790PXddxzzz0wTRPz58+HpmkYNWoUlixZEogEOVEQC+5TFh9ZSp4+riJAlRQib/v3M0av2J/+tO2zfrkuzSsDGgaFJgLAmDEMb78dnLOXGBRmaTPpPG8fb9/mOFSH3LIobG3y5Izvj3/VKhOMeU0nACaUelVpyPyNgo7ztxw+T38/y8ATwf/9Un2WW28lB9zTT3v1SDihVVY6uO66MrfpAteoxdZngN8h+Z3v6GAs4dNq5W7svBJkY6OFtWutbPleC7fdlsKDDybcxVVusaYKC+QVELnzsy8ZkFHSh9xJx5+xObiOw/5o6nEt8MJETvLevn07MpkMfvvb32LHjh34z//8T6TTadxxxx0YP348Fi9ejObmZtTX15+I+SpRW+vg6afJ2h4yBBgyBL6+iWprMex1X97njZHJMDfz0k/A3jm2TREVTU0mJk7kfxje+HV1NioraburS4uMjf74xx28+67uOpRE7ZsnpPDXcqqo6EkKmzZZvrFMExgzxsbvfy/GS3vHeVo8l2IA+CzgykoH77+vw99CTP4uvfmn0xTN4zk9aT9PhOrqEiOC6NoxY2xUVzsu+f75z7pLsIx5pWd1nWd5einutu0no5de0n1lULu7NbeMrKrFGg/TEyGn0velbniU9HHllQyG4RU2A/LrwDMQ6KumHhelKlzkJO/zzz8ftm3DcRx8+OGHME0TL7zwAsaNGwcAmDhxInbs2BFJ3oahoaKiLPR4X6Aa5xvfANatU1n+Kicb/6kpPodrzR6IgC6/nOGNN5DVtIPk5ThinW6/vsxhGMBnP8vw3HPq+7/7ri687vvnQp3q6S3jH/7BREWFibY2YPVqDatWaT6LFgCmT3fwP/+T8CXE+BcLIu1Roxi6uoB33/U7Zd97Lxij7vtWNM/RyaN/VPVXDAO4+Wb6Dn7yE6C31xvv+ecNXH99Gb79bQdr1+qK9HsvgaahgeGcc6hdHUDWLDUoLkVDg56VYjyUlJgoLzfw29/q6M021kkkLDz7rIO6Ovrupk2jUMxEIoGmJgf19cDmzY77na5ZY6Gx0UJTk4O6OpI/vPt6n+vqlF+RC/ktdfx4A42N5DxOJICGBvp9Dhbq6+lfPqppe7v/LaG9fQjq673fmWHoA/a3fTJRjM+R87dXVlaG/fv3Y/Lkyejq6sKDDz6IZDIJLRv6MXToUHR3d0eOYdsMhw4d7cf0hgb2yOMkkzrWreNfelhEST6fVfozh1920TT6T60iF+/8MIveO27bDC++qLK6CY7D8KlPid3XvfEvu4waQdg28J3v6HjllRQeeigRKKLEf27diuwxtUQDINv4QOVclb/XIPi4n/kMFfUKWuj0+bbbUqiqopXl8cepYt8f/mBgzx6y6nt7GX7yk3DJ61OfcvDmmzqeekqDZQFf+cox1NY6qKqiK1asSCCVSvieM5Gg85qaTKRSCfd50mmGpqYMqqpSaGqi66hmuLe/qgoYPjyBTMZ/rLs7IyT78MgawLK0nNbp1q1Ds3Hm9H9g//4MHnvMk72qqhwh3+DkoqZGh2WVgcssNTXHcOiQ92wVFWX9/NsuLBTqc5x1VnnosZzk/Th1a2YAACAASURBVJvf/Aaf+9zn8P3vfx/vvPMOvv71ryMtpPgdOXIEw4YNG5iZ9gNeMXqVJR0kxDCiVBNTUF7g4YpBp1qYI08ezx990t0tElVwHq+/rkt6NCGZNNzCTpkMw89/zjvPqMmZ18Tmzs5PftLxSUtnnulkrWvVdxL8HsT99J3Qd3P22fRHnsmwgGNU18lRycH7S86dW6Io96v+PocOja6fLUsdvB4JD0kUu8nnE18dlkovJ4iJ3704J5VerGpAXKi1Q+KiVIWLnOQ9bNiwbI1k4LTTTkMmk8FFF12EnTt3Yvz48WhpaUFdrvfEQQR1ZkkI8cUcUbqsTEB+4lQ39iWdtbqa19nIZcmHWd3y3ORFxz8WY9StvqVFx5tvcs1Zc0PYuF7O+zkCDP6sUf99y8sZhg1j+OtfPRnENIHDh6NkkbCFSYxU8eqfmCbwta9RtEZHh+E6ksMcZGERQ6LU4jh0/U03pbF7t+E+/+HDZG17BBjdsFfsJi8mz/DrxKbAYfW4xYWAz4P/LmTiV+nFvAFxsRBioS4sH3XkJO9vfOMbWLBgAW688Uak02l897vfxZgxY7Bo0SI88MADGDlyJBoaGk7EXEMRbBcmI8oiFomCPjsO8JnPMLz4oqi10tn+NHjxenmssPvSvqFDHRw7pktFqWQCp7n86U869u0TU+iJcL/85TQ2bLDcMS+80Ma772p4/325BjifG3D4sIbDh/0ae0WFgw8+CPat5F1fuLbuWdLhTl4eXz1iBEN1NRUIk2tsc4hWqRgxxBNtNI3aknHHYkODiaqqDLwO8BS2SbXbPXKMIptgN3k/eNTHo49abklYuR43H0esExK08qPjvWNCjHG8yEneQ4cOxYoVKwL716xZMygT6itaW82I+GPal0gwpFKyVQvIxCYSUyIB/OQnlPTxt79BYW2L9wxe7z/u19QvvtjG1q3HfI0CysqYj4jdGTJ1780ZM0i6EsMW5foqwTZn8rMSuDOSR3HwMDwu1cgRI6pFiUffcIeiHAroVVRMhxZgWr68F2PH2ti0ycIZZ1B0y5Qp1JQYACoqTBw65NXn4M/d11A+DlnSkMkW8ErCqt4axDohfMESF6e4iUGMwURBJ+nkg8OH5aSToPORiFs8BwiGEfq16E98gmKVn39eFyzVKA1dQ3BM1flAebk/0233bnqN/uY30/jud0sUpV7hGy+RQKCAU/A+DOPH+zu4B78fvx49caKNKVPSvjTz8I49fhiGl3YuasL8XpkMwyOPUOz1smU9bqigv552BgsXlmazIak+elubEUiOCabQ++uY5AN/yjxlXMpkG1USls8jipxjvTjGYKKoyTuZ1LO1KYAg2YVp0jLUpDR0KE/n5pAJT6WdR4/J8cc/GmhstALkNWFCBm+8ITd+8Ma4+GIbl1/uuIQSLODknW9ZwKJFvXj4YcttA0fhhXC74lx1VQbNzaarR8+dS3KC39KOeh6/Nn/aaRCy9fzOQX5eJuN1HpKt2rBuSLJFLTcxlntRRoFb2/v2ab6U+fnzS/Hkk0dD6o2ESzC5yDmWR2IMFoqavFtbTakyYJiswT/LkC1ouOc//rim2K9Btm6j5Bo1vOgEsUvLvn0aVq5MCNZq8DlefdXAj3/c63OY8eupM403ny99iazAjRst13p2HHJ+jhjBfIkpclU/OXnG/zP4FsOlEtHyFJ2DnZ0aNm82s5YyzYNnQvqJT90NSbZoeTKNZXnJOariTzJkBySPkuFzkpOd8kFMzjFOFoqavHmkiWzdEUStOcphKcKTPnp6VCSt2g7TucPuS/vGjqUg8c5ODc3NJlavtiRrVxyLPvNCS7W1qYDVt3JlQugWRFX77rmnJFD2lpMclylk8pkwIQNdT/h6ceo68A//YOPtt+W3Ahr3kkts3HNPb8DyFJ2Dq1aZWece+RNU4XHiM4mVA2UnZ1gEiFj2NZ+GwF7HHm9OJwtxCnqMvqKoybu21sEZZzjZGGaVtQoEdW1ATaph16uOcUQtCiqJgca0LOZqu4CqrrhamjEMVWgcdQ4aPtxrEAwAL7wgN3igJg1AsCiSSBa7d4uhO3R/xhgOHFD18SS88w4CBCsTkVy7G/CeA/AXZepLhxq+b/duR9DLEYhAAYIa9ezZKbeJcV9Jc9UqE5s2WT6Hqox8CTlOQY/RHxQ1ea9aZbrJJwSVExJQv/qHR5qot8MiVVSfc+nj8FXSCzuH7+dRIzw0TtOAkhKvGp2/wBPBq4fizePWW1NobLR8mZZyQsm8eaXSYqJuVyaW6qXQRLhjXHedR0T33uuvH8IXG896FqsC5iYuOQmHYsgRaCyg0stVsdz9kT3ErvTUI7MnQOB9IeTB7p4T49REUZP3ihWisxKIsnajoTpP3o6y3FVRJmERKQzpdNhbQXBBOfNMRyBHOocxStNubLTQ0SG3RlNFujDU1VHCzLp1lhuhommkta9aZaKrS0d7u+5zgvJ6Jbw3JA8H9Iib7sFrcwNAY6PlzieV8npMigSWb3aiCqK0sm8f1Ruxba9YFRF3uF4O+GO5+2PlykW/Nm2yAuTdF0LuS0hhLK/E4Cha8qa0ZVUxKtnRGIYoWQXCsbBtlZWvssbDHKVRY3nHPvhAV4braRqyWYny2Fw+8d8nmTR8TYU5EVPEhuUrLMUxapSD116jrE5dZzjvPAd793pVDg2D4fOft9HY2JO9h46ODv8g4jw4gcnWM52Xfyy0aME/+ijFxvNa3l1deqjmDQyMlTtlStrXlX7KlKCztC+EnG9IYSyvxBBRtOTtr2micijKx8JkEpnswyJQwpySwfv427flQ+LqhWb4cAednbKeT9mV9fXU+UUkfMOghgunn86QTBpudAfAJIvaI3hu8TJGVjCPwLAsklmowzht3357CgsWlLoOYsPQMHeuJ7nwuGlxnrzHJCcwbjmK5ViB/jUiUJFeLst0IBJnyMruidS8+xrjnY98E8srMUQULXnzP0Iv0kRFpvK+XAizwsOIV7yOfvqzGuV5Rd1XHptlidsbQ9MYrrzSduOxt2413doatbVUZZAXeDIM+sePi815L73Uxo03pjF/fmm2JgwncLjtzu69t0fZILijw4uvFqNfxBhtnvDD5yk6KcXejqLlqCKhfCQCkfTysUwHKnFm1qxMqKNSNbeBQJyxGUNE0ZL37t06hgxxkEoFLVM1cskiKj1bFRIoH/Pfz29xy2PmG+3iv5ZruYkEJdJwwhFra/zpT4ZQJoBivq++OoNjxzRcfrmGn/1MRypFRD5hgo1ZszJ4880Ufv5zCgukJgxkiTNGcdhAkICmT09nNePorufiPPn1PIY8H8tRlQH5ne8oT3WRr2U6GLHZJ0KL7s/CE2vkpy6KkrxFb78fKrIV5RGZRMMJM9xBGTVGWJSJPIY/ksOf4u6/TyKBQMQGR0eH4UofXslY+qnrQHMz1X157jngc5/LYNs2auu1cmUC77yj4cknvczL225L5dVJXBWxIe5XhQLyOVdWOlltPbfl2NpqBjIgx43z6narcLIs0xOpRfdl4Yk18lMbRUnev/qV39sftILD5JIw+SLKcg+LRImKKFHNRSWziJa6d1zTKPHl0592hKQavyMwmdSxfr0/coTLNZpGTRFeeMFwyW/7dr+PgKfMA3T8tNP6VqZUFbGhCgUUG+wuXOh1a1+6tCdnSKCYLETPoEWS98mqJVKoWnShzivGwKDoyDuZ1PHXv0aVZQ2Ll5bPVTsbcztAw4g+zDpnCM4lOlJF04BzzmEucYtEyB19+/ZprhOSNwvm97Ys4MYb03jpJcMlP9kyFyNYdL1vDQFykYLqOABft3Yuy4ShttbBsmU9vqxM3m4s13UnmqAKVYsu1HnFGBgUHXk3NlqKjES+rUI+zkaVZR12vUzMRLZnneUIDsaoeYhkriYjxwGeftpEc7OJSZMyblKN41BTX4CkDt7dRUyi0TSGSZMy6OrSfR3TeYMGXQeuuy6Np56i5ge6DixbFm0FiwjrLCMijDT6SiSyw7SurrRg2oOJKNTqgYU6rxgDA43J/bUGAem03a/+cMOHD4Xf2mVIJDRFbLOMfKI7VKQcRepRenouK1+cUy7npV8+oVC74Li6ztDQQA7JMWPsrF4NIW4abuzzM8+U4He/0+A4GgyDYf78lFvFL1dcsRyGx52ImkZVCWfPTimvVznKjtd5Vqh9BvuKU+U5gFPnWQr1OY6rh+Xjjz+OjRs3AgB6e3uxe/durFu3Dvfeey80TcOoUaOwZMmSQEfswUKwDGqYBa4i1jCpBCHXyHKJjHyclqprwqJN/Nd5xB18XsaAzZvJAdnWZvjkFJ51CJA8sXgxQ0sLpYvzute55AWVbi06EQGGLVtMzJ4d1bEmlXNfjBgx+oecjHv99ddj9erVWL16NS6++GIsXLgQ//3f/4077rgD69atA2MMzc3NJ2KuAMiaNAwWyAYM6tHyfhFhhC5/zm0dq++vIn/53uroEoCiMmpqbFx7bVo45p8Lr3XiOPQm0tWlY86cFMaOtfOO6IiCqFun016sNg9bBEhzl6NOYsSIcWKQt2zS0dGBH//4x1i9ejU+//nPo6WlBZqm4dlnn8WOHTuwZMmS0GsdxxG6nuSPREIkUSLFlhaGNWs0PPywlo1rdh8F4Y7HXDKJ6rh4njx+2PWy5a66Bqivd7Bli1xQS7wX3GQZdYs3/71ME/jd70iGaGjQ0dtLVvvPfubglluA5ct1LF7sORA/9zmG3/0u+vfR1kZjpVIUrtjURI1zH3oI+Pa3dVfKKSkBtmyhY4MNw9Bh28Wv254qzwGcOs9SqM9hWXJwhoe8HZa//OUvcfvttwNANmuPCGfo0KHo7u6OvNa2WT/1pKGBPVVVR3HWWQk4TgLhUSZymGCUBh6lW6usacB/T/k+YXIMQdeB7u6waBSPxBnTstmP/jmaJlwHJE9zX7asB1VVGaxYkUAqlXAjOvbvz+DQoRQ+//ky0EsWjffccxq+9700Fi8OlzC6u3VMn+51Wa+qcnDoEDBtGrBzZwkeecQCoKG3l6GpKYOqqsGRQ0SdvL6+tCB1yb6iUPXV/uBUeZZCfY7j0rwB4O9//ztef/111GXNK1HfPnLkCIYNG3acU+wbKisdqW8lh0q/FveHyR1hx1Ux2qprVdq4elzHYUKBqLD5qxYT2v7KV9KoqmLK4kthUR51dcDZZzs4cMDLRn3qKTOUvP16d7BLzYcf+uf06qu5HMT9g6y7b94cnaQTI8ZHCXmRdzKZxIQJE9ztiy66CDt37sT48ePR0tLikvqJghcjrCLnXNEdUGyrokrCJBB57DBrW7bao6QPQL3wBCNe3nhDxy9+cQwqRIWGXXGFjQ0bPOu7piYQwuIiKo47mdSzBbG8Z2htDX+1Ox7I88iVpBMjxkcJeYWIvPHGGxgxYoS7PW/ePPzXf/0XbrjhBqTTaTQ0NAzaBFWg7uFAuMUbdiwf3V0lxcjjRV2rIm0VxHuEyS/icdp+8UXD7eHIkUzqWLEigWRSR22t4zYB5vsAoKrKfw9vOzgGWfDkGBYteG4Jd3f7n+n00/vuz8gH8jzySdKJEeOjgrws71tuucW3ff7552PNmjWDMqF8UFvr4P77e7L1TcIs41wOxFzErPqsInVIx0SEafCqaJd8rif/wezZpbj99hRmzcqEpqLLcsPhw/55ettif0mvdZjKgueWsPwWcfnlJ6YQU6Em6cSIcTJQdBmWHNXVjtvlJVy3Vjkso/aFbQPRVnRYBIqKkL3Fg+avdmwGt73Pb7yh4847S/HmmymcdhqUqeg8HpsxkhteftlrxAAwdzuZ1LOlYelYby/D8uUlmDu317XgObimzru7a1r+ndtjxIgxsDgxmTWDgNZWUyBujrCoESA8YiTss1+uiL6P/Fl1jbiffjqhBqtatx861PHt//nPE6isdAISh+jQdRzgjDMYxoyxfWPxbf/3SMk/27cbmDq1zJVcuKQCUPGqu+9O4QtfyKCiguHLX04PWto1f6tYtiyBqVPL0NY2KLeJEaMoUbSW94QJGWhaIltwSaV5c4jHozRTVWRJLgs8V6giQvapHJ1hDk3v87BhDEeOeNc7DvVPFNt/8d6OZNVTyOCvf63h8GG/5c11a/IfJHxvALxHJlnxmYAsc/gwsG0b/dfZsMHCxz/OIsMO+4vYYRkjRjiKlrxrax3cfnsKK1dSaJwHWcJQSRqq8yBsQzoWRqpRunnUnFRj59oGOjt1zJ7tNVAAgJYWA62tBkaNsvHKK2QdWxYVrspkyPJOJjUA/oiQzk6aR22tgzFjbDz/vOGbG680qIo8eeopf7RJVNhhXyHGdYsyjabRG0SMGDEIRSubAMDixSnMnp1CSUm+kSBR+6NitWWLXDwvKIdEXxPmmFTt859r21TPpLraxic+QVIFT4/ftctwO+GkUsCMGWlccoktjBW8B48uuekmMQ3fX2lQjPgwDKC9XUdZmf95r7lmYEqNyjIJQIW1uG/j+9/XA5E2MWJ8VFG0lncyqaOx0cLatZaUJh+mRYdFncjnAX6rVyV7QLFPDg8Mt+CzyamBGtu5iV3Dnj1hUS7+Zxk7loi7vV1MCPLmsHmziaYmL7rkJz/pwdq1Fs45h/kqBYqdc9autfD00/RfRteBc85xcP31mUirm1vSUR3dOcLqgDPGF6m4oUCMGBxFSd7cQqM614DaelYRroqsRVKTyVPW0XM5RMPG8Y/nLycTJqOo7he2gIiLBm13dekYO9aGYViBujJeQ2KPEOfMSYU21K2tddDaKnagpyiZ0aMZJk8Ot7rFErK8gw5fLPrS2Z3vSyQKr6FA3CMyxslCUZJ3Y6PlNigIj+4QIVvQYQ7FfDTVMImD30c+J583AXk7nzcCeUz/Nc3NBtrbE2CMd5GHr9GwGK6YDyFyYk2lvHu3tBhoaysLJWOxozxFvlBZ2qjGwKr4cr6vocFEVVXhEGTcIzLGyUTRkbfcu9FDrugNlZNRRhjpisdk614cM0o6kecI6VrxuLxPNe8wGYg+e/VTqHGDe5XmOTPz6aIjWpYbN5J80tGhu/0xo8hYjgvPp0xtVB3wigqzoJJ04h6RMU4mio68W1vNkAYFIlRRJUA4cUc5LcNIX9bMVRawSltXkW4+0gik83J9prE1jflkEttmqK21MWmSnfNVX2VZLl/ei2RSx3XXlfmaO6ggWtL5aN7FhrhHZIyTiaIjb9GaA6CoLqiyZPlnFXGrCBUIEqyMsGtyWfYqC1o1DyCcyKMWLoKuU/nYGTPSeO01E8895523c6eBRYt6AyQq67fHa1me6npw3CMyxslE0ZE3AHzxixls3mwKvR3Dokdk6QEIJ08ozolyPqqcheJcoqBaGMIs8rC5hlnttH/iRBtz5/YCAH7wA9N3DmMMjY0Wamt73b2ilW0YCcyYkUZ5OVN25eFvP4yRJa8i9f7owcVI9nFrtxgnC0VH3sEok3DJQC1ZRMkaKpIPWwjycSb2BXSdpgGaxrIx26rzcr0Z0OeeHmD3bh0LF5YKDZu9Z/3zn/3x0qKVbdsMq1aRX4F39Fm61NPG85ELclntYc2NY+dfjBj5oejIO51WRZmIUDksVUQrni/vVzkew7TnKKkj7L7h0S5E3iJxq5yhYc/ijdfWZiCZNNwYafm8/fv9bxyckB2Huck+AHX0YYyho8PAihW6S9Q33ECJPdOnq2ubRBF8WHPj2PkXI0b+KDrytiwA2RC3YcMcvP++3AsyjLhzWczyGJD2iefL+1T3Vmns0VIHoAk1RsLeKlT3kp+HzrFtpqh7Tujt9V8nJuOsX2+5qfW6TmOsX2/BtklSAai3pq5TMpCKvKP0YJmoeRNjPtfY+RcjRm7k3YD4eJBO2/3qDzd8+FDIVudTTx1zCSYVMMyinH/yearokbBzxTFVn8PGzOfcfObKr1U5LKHY9vZNnpzBSy8ZWUvbG0vTgOXLe5SJOXJW5L59GtassWDbmivp8PFNE3jyyb5JHH59nfbRwkAO1jBrvlD7DPYVp8pzAKfOsxTqcxx3D8tf/vKX+N3vfod0Oo0ZM2Zg3LhxmD9/PjRNw6hRo7BkyRJfX8vBBM/283dVz+V0zCVlRGnhYZa2yroOk1BU0kcuuSXMGRqF4LwnTcrgy1/W8W//5n8Wxhjmzi1Fc3MGs2fTKihaybI+/eijFgCywm0b2axNelPoq8QhWuXiwgAwjBjBYq27HyhGZ2+M40NO8t65cyeef/55rF+/HseOHcPDDz+M++67D3fccQfGjx+PxYsXo7m5GfX19SdivgDolVrXeWU9lTUMBAkvTI5QSRsyonTxKPlERtS1YYuNai5hEkpwrI4OAzffDJd0xeOMMTz9tIlnnzXdWHCxG49IBkuX9mDTJgtTppDWTZ13+p+yzhcIcWHor1zyUSeu2Nn70URO8n7uuecwevRo3H777fjwww9x1113obGxEePGjQMATJw4ETt27Dhh5M3/UG+7zV8alRAVeRJmIUeRpeqcsHFy6eZhCFtUwsaK0rrVz7F9u+arSyKfn06zrJPU06AffdRyyWDp0h4sXFiKdBpoazOwYcNRPPnkwMQ3H2+sdExccabnRxU5yburqwsHDhzAgw8+iH379uFb3/pWtr4y/eEPHToU3d3dkWMYhoaKirIBmfBXvlIGx6EUb68NGlBS4qC3V+wqn8uClaGy4qN07nwlDP5ZtS+M4MMWHtX5wX30qyGrePx4A+vXq94+vG3TRDbChK4pKfGTwTPPlPi229uHYN48Blqvj9/nXV+PvMYyDD3w/6i9XQvMrb5+0N04xwXVcxwPGhqABx4AUin6/TU0mKioODGxCAP9LCcLxfgcOX/DFRUVGDlyJBKJBEaOHImSkhK8++677vEjR45g2LBhkWPYNuunM2CotK25WrdXIIn+aP3ELf6U0ZfoEhVpqrTwXI7RXMiH3MMWjOBCdc45Ni68kFqdfe97CfT0qOdz7rk2hgzR8PrrOhijxfCee3pQXe1g1aoycCnj6qt78dxzpe72kCG9+OEPT3yqu8qpVFOjw7K8udbUHMOhQ4VteQ+0c6yqCnjsMU86qqpyTlgNmEJ19PUVhfocx+WwvOyyy7Bq1Sr88z//Mzo7O3Hs2DFcccUV2LlzJ8aPH4+WlhbU1dUN6ISjQQTkj4UOi94Ij8IIt6LzsarDHIphTk6V7CKPwY/l48iMmhPwzjsGOjuB554zpAbN3j01DTh40MjGzdM5PJ571qxMQMqorvZqlHAJpRBkijhFnRBnehYmBtMfk5O8v/jFLyKZTGLatGlgjGHx4sUYMWIEFi1ahAceeAAjR45EQ0PDgE4qGkRsZ51lo7NTbjSAiJ/etWrHpip6JOycsM+qcVVzEM8Vx1Bp9rmiZcR7eMdsm6oJ+jvUe+cwFkx4YoziuXmonooMOjoMpb56Mp2GMXHFKEQMtj8mL2HsrrvuCuxbs2bNgE2ibyDSUBM33/bOC48m6Yt8ErYt3i/sPNVbgMqyDos8USGXw5LImJd8ffLJEvz+90FJhqQSssIdB75aJUAGK1cm8O67Gj77WRsPPZRw47LlZJrYaRgjRhCD7UgusgzLfDThMItX3g6TH8IIWjVWLpJVWfrydlTYX67FRTWmN6dMBnjzTR0lJar70jnnnefgmmsyWXImQj58GPjyl8tcZzA1J/aumTkzjc5ODe++q2H3bh1dXXq2Ww5JL/n+J/2oh/jFOLUx2CWDi4y883EShl2Xj47dl2ujdGwI+3PNU6XTy3NSOTTD5uofd+XKRMhxwptv6njoIQoH7OrSUVnpZGO4xfvSdby6YHk5wyOPUEr7888bmDo17ZbmdRygsjI3EcfWeoxTHYPtjymyVty5JIow5OuAlM+LsqzDzuWf5X1h1/D9sqQSpn9HzSFsW/zp38cYhdp1demYMyeFri49xMkJnHceJeu0thq+Mf7wBwOUYKtB12msZFJ3u9OrIL5SptNwmw3HiHEqobbWwZw5qUExTIr4LyYqKiMXokg1TLbINVaYozMsGkUL+QyoF4uotwfVfeRj8n6/Nc1f6SornWyfS8+xyeuZ7N1LJWYvucSGCMOgGie2TWNVVjq+2uCTJmUwfDjD2LG2200n7kITI8bxoUjJO5cUkUvqyOdYviSeb3SKuF8m7aixwkIK5WPy/dULATVXoFR4XQfOPtvBhAk2WltN7N5NkgmvGPjjH1PM9/LlJWhp8XpWVlb6x377bQOGAdTW2rjwQscXkWLblIJPsHwd5OMQvxgx+o8iJe98nXf57lcd64slz5FLJhHPC7s2LBwRCJI4FMfoOq+WiX9Mxpi733EY3nlHx4YNultHnEsmjsPQ3Gxi1qwezJ3bi7a2MtehGbwnkXRbm4E//tGAaVJECq8NLj6P2LSYXifjEL8YMfqDItO8+0KwfXFo9hWqML3jPTeXU1KOtFG9QXjbwWYOUaRP2rcjGb8HD9Ix7niZPz/lFq3yw1sciJypmuGsWWmYJj+ulmlixIjRPxSh5Z2vRdwfy/l45hAVd626Nt/oFpmww/b7JRV1wa6oexOpptPe8RtvTLtHxUSYt94KPpdX55t+Njeb2LjxKKZPT7vNFsrLGV5+2cCUKep63TFixMgfRUjeUbr1yUIUSQPRzsawKBXVuLIOH+aIDAtXVM2DJJaZM6kJwu7dOjZtsjBmjO1GjQBeeVgAeOUVwzfC6NEO/umfMmhv1/HMM6Yv2YekkV5faGBbm4Hq6uIODYxj1GOcbBQZeQfD1woDuSJB8t2fy2EZFQoY5tiMSgICRo+28R//0esSENUx8aJFqG46yTCJRMLtXSmOfeutKcyaRZmWW7earjbOsy9504WByDYrBNKMY9RjFAKKjLyjLMyTiYGcR76JOWorOtzSljVv+vzaa34rGgAaG61sJUIt2zGHPvO+l1we4Vi82MKsWRlfUkJlpeO2lOOZ4gAAIABJREFUq+MtzgwD2XLC4Yk8cgs2kaTb2lAQpBnXz45RCChC8pY13sEY/0RCjixRyS1h+3Lp6mHwruPyBiefVatMrF5tCefx8UjL/vDD4ByOHvX83kSmGUydWobeXkDsd3nVVRls2WLCcYCFC0sD0gm3aCnVHr6wwtpaB9u3D4z1fryIY9RjFAKKLNpExGCQ7GARdz7RKPmEFeYKI1Q5JEWZSV4ESO/m5JNM6pg3T0yND4Y9bthgKeaq+TIpuWVKFQvJmWlZwPDhtADwiBQ5q5Jf5zj+yBV+3pVX0jiGcXJJU46+iSWTGCcDRWZ5c0SRWCGiL/Hl+R4DcseGqz779fGZM73Ij8ZGS4oNF++DwLXi50WLSjB2rIPp09OYMCEDw6AWdYYB3HQTOUMBRPar5BYtjw/npM/Pq6tDwST2xGVoY5xsFJnlrdKBC524oxCmZedzTVgykPzdiFq3n3B1HRg71nZrkHR25rNYyHOgz+3tBh55xMJ115Vh927vv5Wuw60PDgA33JDGzJlppcVaW+vglltS2TZupJEvXdrjO28wa0XEiFFMKELLW5N+FjNUDkcZcnig6twoJ2eYlEK68l13lQIATDMR6C4fPn54sk86zbBpE1nwcn1wrmfzRUMm4GRSx4MPJnxZnl1dunusvV1DTY0eE3eMGMiTvK+99lqUl1MvtREjRuC2227D/PnzoWkaRo0ahSVLlkDXT5QRL0dUFBuJh8k8YdEj+SDsOlHmUIcNcqJMp+VUdtX9ozI/6ZhlAVOmpNHWZkCURxobrawDk0h5/vygw7K11fRVNNR1VbOHslhnjhEDeZB3b28vAGD16tXuvttuuw133HEHxo8fj8WLF6O5uRn11P57kFHsxA30Pe47V+KODJUVzvfL+rjfkg62TAvOw9871L9I1NTYuOeeXl/PS65Xr19vCSGGZJE3NlqoraX/X8mkjn37NJgmkMlQOOHll9tudmYhRJnEiFFIyEner776Ko4dO4ZvfvObyGQy+N73voddu3Zh3LhxAICJEydix44dJ4i8OYqRtDn66mANC4tUhQ+K+2UrW97n32ZMJGX5XI+kGZPJnaxu04RL3DJaW03JEervlwlAKCELNDRk8OyzJtraDLS1UaErKpzlRceEJesUQhJPjBgnAjnJu7S0FDfffDP+6Z/+CW+++Sb+5V/+JZtoQX+8Q4cORXd3d+QYhqGhoqJsAKZbzKTNke8zqEIB5f1RiTqqOHDVdXIESdh9IJ3nv8+llzLU15N+3tYGTJtGrdESiQR++lMHiQSQSnlaO9fD29uHAPBb1um0gUzGm69tM3BVTtOAvXtL8f3ve+M3NTmoqwvel+8vNBiGPkB/Dycfp8qzFONz5CTv888/H+eddx40TcP555+PiooK7Nq1yz1+5MgRDBs2LHIM22Y4dEhVjS4Xhir2nQoEroKKaFXx2blCJKO+nzBCls+RP4dZ/945Z55pY8sWigJpakoglUrAtjWkUgz792fw2GMZN3Ny4cJSN4W+puYYANKyuUZ+9dW9aGkpdcmemkMQ4WcyDI2NDKkU3PGbmjKoqkoF7sv39xWDbb1XVJT18++h8HCqPEuhPsdZZ5WHHstJ3o899hj27NmDH/zgBzh48CA+/PBDfPazn8XOnTsxfvx4tLS0oO6EmzfFENvdV6hkkCjHZlioYBjJhvkK5PNVRE2yCGMQ0uX9eOYZE1u3mtiw4agvA9EwgH376H5z5hCRino4J0cxfhsAZsygJse8A49I+CqHKDAwmY9x3ZIYxQKNMRb21w4ASKVSuPvuu3HgwAFomoY777wTlZWVWLRoEdLpNEaOHImlS5fCMII1MjjSabtfq9rw4UOhjpQATj3yzifxSBXCFyabhH1WOX3DknC8a4cPd/DBB3pWzhDhnatpDAsWpDBnTgqrVplYt87CSy8ZYIyiUPIhQj95etdQqOAQ1NQcc7cHQ/NesSKBZcvIejcMhvnzU+6iM1AoVCuvPzhVnqVQn+O4LG/SLH8a2L9mzZrjm1W/EGWRFjv6+kwqeSPXuSoCl8lcPo/Q2clDQcMXAMao4FQySb0u5dom+USJhBV9qq11UF/PcOiQV/1QNdbxZj7GdUtiFAuKLEknl2VajFA9i8q6DnM+AuGEzK+X76eag/eTwgGDMeHqeXsErmmUVNPaqgu1TVggzT3KOj7Z5ClWRowjVmIUMoqMvIHiJu1cRK1CmLMwF5mHjaOSUYAvfCGDv/9dw9ln0zZvquAtBsj2xWRSrHd2dIGgd+/Ws42OKUpk5EgHF1xAJKjSlAH4yFLWv1esSGDChAz6Go3aXwklrlsSoxhQhORdzMhn4cnXEg/Tp6PivMOOMfztbxpefdWAbQOmSXpzJkNSyBlnOLjyShv/9/9acBzeXJgSenjjYqoWCKxcmUBzM2VK8hole/bo2LNHR3OziRkz0j5ZpLHRwqOPWgEHYW1tKkD0mzc7qKrK/Q0mk7qvlnjseIxxKqLIClOdisjHEavSrMVzVZo13y8Tv1pG2bXLcBNpMhlg1CjbJeX33tPxxBMWMhkenw23WTEnbQrjA55+2szW46aGxl68tpbtjwlfWVfAi/GWy8SK+nc6DWzfnnvx44S/apXlhhOqys+eaCSTulsALEaMgUBseZ905BuXneuafP0BMtGrr3vlFcNX68S2WTbTkQnZmOHOS54NyS10gEh7+nQqDyvKImFlYmX9+8orwx2zcru1ML39ZKC/bxAxYkQhJu8TjihyDdOx882GVEWOqEIJ5fvJCTua265MdFzedlsKp50GvPqqlm3KELwOIJ27oSHjyieGAVx1VQazZ3ulXEVNOcxBKOvfdXWlOHQo+K2J5MjbrfEY8xkz0r6StCcDcgTN9u1aTN4xjhtFSN7FHmkSFaedi9TzJWXxHLVlzNPNuVVMzkj/1SNGOHj7bR2ABl1nOO00CgXcuLHUd9655/LzCA0NGdTUONi8meQTw2CoqXFCCTTKQZiP81Amx5kz0xgxghVMtEhf3iBixMgXRUjexRgu2Bf5I8yKlnXuMCdlWMigf5/jMEyenMHw4QwdHTqef96QzgEOHNDdcU2TiHv+fLFNGh0780yGd94hB6dpArNnE9nmG/LX36gQsVkx6efMlWb6M85gkX2+bxAxYvQFRUjeQHERN5A7KzLsXNW1UXIJFD9VDlHa19RkQteRbZwgz82r9a1pDDNmpNHVpfvqbXOMHOlg1y4jGx5I+/KNl+5vOrqcibl0aU+g23w+OFHp8HH4YYyBRpGSdzERt4y+6N0yOYe9daiSeMKckp4F7zhMImP/OETEnjULUMZtT48/Mef99/VA5xyeFdnfjMpckK/r6tL7lcYuNonoy/1jxDjZKDLyLkbJJBeiiFn+CcW2Ku4biu2w+4qE7v1MJIB77/WsWYAIc+nSHnR0GFi/3kImQ9r5mDG2slAUkFuS6G9G5UAVoRKbRPBa4TFiFAOKjLxl3bfQEaZf5yub5LtIqWK8w8YI6ui6Tgk13GFpGETcs2Z56exysajycoaf/5z6Xj70UEIpW+QjSeSSV0TyFzMsByKNXWwSwaWhQnBwxoiRD4qQvIuFuIHcFrS8T9azVftz3U8VmSKOF1xI5NZntk1NhKurKUJEligaGy2sXWu5kksqpZYtVJIEkAkQbpi8kis+eqCLUHFpKEaMYkCRkXcxEXcYVNq0yskY5nAUj4c5LKPivuUx1Z9bWgy0tZUp63N3dOi+tma8UbAIlSRRWen0yTk42PHRcRGqGMWMIszVLXYCj9KgVeeIenYueUS8Rra0w8YW7+EdcxwvrZyT3MyZZJm+8AJlX2oahQYuW9YTID6/JAE3WiUsFV4FWjS8VPrBiI+urXUwZ04qJu4YRYcis7yB4pNOciEstC+XRq46rvpuwr6rqMgUWihERyDJJyxb14SSdi65xMbYsQ6qq/3NEBobLXR2am6moyhJ9MXJGMdHx4gRjrzI+/3338f111+Phx9+GKZpYv78+dA0DaNGjcKSJUug6yfSgM8VRVFMyEW2uZJ4xH1R9xAzKOXIEjU0jWKnRYuUyyc8df6llwy8+KKBRx+13NKu111XhlRWhjZNYOZMf3p6X2WKOD46Rgw1crJuOp3G4sWLUVpKKdH33Xcf7rjjDqxbtw6MMTQ3Nw/6JP04lVKLw8hZ/Cwm5mgh18ihhn4YBnD//T2YPDkjnC9eR9tUwpXupWlAV5f334NHfdxyS8pN7Mlk/BII16j5mLYNjBjBAvVK+ipT8Ip8bW15XzKgiCsCxihE5PzfeP/99+OrX/0qhg8fDgDYtWsXxo0bBwCYOHEiWltbB3eGPuRrbRY6VNZvmFyiyrBUXSfHi3s/HQfYtMnCpEkZJBKkVcvjmSZw++0pmCY1UUgk/J1vpk4tw7JlCTz4YMKXHq9pZIVXVjquRq2SXfoL8d4NDfoJJ1Dx/lOnlsUEHqNgECmbPP744zj99NPx+c9/Hr/61a8AIPvKTH+4Q4cORXd3d86bGIaGioqyAZguRzFJJrmiS+QkG8BvReeKQJHHkselEq7btxvYscNrEm1ZQF0dw44dGhgj6/yii0x885t0/te+xlBXR29b7e2a62jk3XE0jX5SyVdg0aJSNDU5ePZZB6tXk+U+c6Y3Rn8h3juVYmhvH4L6+hO3cIv3Bwbm/oahD/Dfw8nDqfIsxfgckeS9YcMGaJqGP/zhD9i9ezfmzZuHDz74wD1+5MgRDBs2LOdNbJv1szPz0H5cUwhQhf9Bsa2K5Q4jBhU5y9eJUSn+sRjTkE77Y7sNw4GmGdnIEobvfEd3O71fe+0xt9lvTY0OyyoDt6Z5Qs6+fRrWrLHgOESsTU0ZzJmTwo9+5M36eB2M4r0TCaCmxpvXiYD87ANx/0LtVN4fnCrPUqjP0e/u8WvXrnU/f+1rX8MPfvADLF++HDt37sT48ePR0tKCurq6gZtp3ih0h2WuueVKgQ+Th2QrXCbpILmr+k3yuOspU9JuWrumcSvaS6gRHYU33EDRIqLzMZnUQxspDBTEiJOGBhNVVSc2pC+OBY9RqOhzqOC8efOwaNEiPPDAAxg5ciQaGhoGY14FilyLRj6LSj71R1QyS1QcNzB6tI09ewzfvvPPt7F3ryE0EvbIf9KkDKqrHZeUy8sZHnwwGMYnp8aLWYgnith4xElFhXlSQgXjiJcYhYi8yXv16tXu5zVr1gzKZPJHVAjdibhv2L3CyDhKRuHHVWPkypT0zv/b33TfdmWljaoqhrfeEsf3z03sPgOQ5a3r/hDBsKp/Ys2R/lTzixEjxvGhyJJ0whx/8rGTMQ852kM+nmussPNUkgj/6UWedHX5nZnd3Qaefjp7piud0DW6DgwfzlxS5rVNGKMCTWKIoKp634mqgR0jRoxwFGHcU5QFK+JERSTk0qxVUMVyi5/zcXIGyZxC9hjq6mxf13bGvNrcAH0eO9b2pZ7z5sJyWVQujcyfn3JJWu7qfrI7s8eI8VFEEf7VyZbuQI45UNf2VRdXZUwGCduzoOXIEtrHGHD4sIb2diMbxueN86lP2fjLX0j/Zoyho8Nw9e6xY20sWBAe0idrvgNRSztGjBjHhyKzvNXarRp9IePjWQTCrpWt76jMSSh+BmUhXQcmT84IVnRQpnEcymxsaMi4tUVKSoBbb02jpIQsbcMA1q+3sGaNhUcftdDRYQidcHJb0iprPEaMGCcWRWd5f+ELGWzbZiI6+SUfRJ0fZt2rwvbCrlWRcnTEiFrD9yxsw6DmvpMmZTB3bikYC46naWQNz56dwuzZKSHELoPqaooM4fHZ3AkJwNfANx9LOo7AiBHj5KLoyHv7dj7lvkgVKqhIOSr2WnVNVNy1nA0Z5shUJd5EJesA1dUOLrnEDnR8NwzgqqsymD1brB2SwfbtFrq7dZdw5fjs6dOpeFQcyxwjRvGg6Mjbi5rw7c1zX953ET6Hyxjqa6KiRmSCFsdSJ+ace66D/fv1rBzCsHJlAlu2mG7LMp6uzhj927rVxOzZZBH7o0LKXIkjPD4743a7GQgCz9W/MkaMGP1H0ZE3QSbXXOF24jVh8dny9WEyh8qyli3yXIk4KoudwOuF8P0HDugwTSoxYBjA5s2mr4vNeec5qKpysHmz6aa581jsqM7ssuwx0OF/cThhjBiDiyJzWHLkoyOrrsnXyamOpc4lZ+R+A5BDAsXjqrA+ciBefLGNmTPTmDEj7YvXBoC9e3U0N5swDC/sj2vWcieaKC17oMP/4nDCGDEGF0X+FxUV0RF1br7atepcQE3iYdtBLXv0aAdXXGHjww+BDRss37WWBXz5y2nf/hdeMLB7t4GlS3uQSFhIpWg/r0WSyTB87WtpjBjBAo19N2w4ivb2IaipORZp+Q50+F8cThgjxuCiSMk7iihzIUpiCYsAEa3jsEQacWzV4uDN+YorbCxf3ou5c0t89xg92sZ//EcvWlvNrHxC+3lFwK4u3dWqDx8GVq4kcnQcitWeNStIkLW1DurrWc5KeANdpyQu6BQjxuCioMnbshjSaY8Iebc1TmrR0R5AkGRl+QIIWtEqiQPCZ9X4YSGFwbFM01/cScTHPkY/J0zIIJFIIJVi2XojnvXKteoVKxIuweu6P6W9vxjo8L84nDBGjMFDQZO3SNwAyQSlpUBPT1Rkh0e2lJGojuIIIoz0w4g5X8nGI3dNY7jpJq+k6vTpaaxf78kgzz9vYOpUigoRLeyXXzYwZUraZ71ygk+nY1kiRoyPIgqavFXYsOEoli8vwbZtYowzoLJ2x4+38cEHwMGDOg4flqNSROQi5zBL2m+1axowahQvzRq0ulUlVW+9NYX//u9ENtSPmho0NloAgM5ODc3NFF3S1magupqKxXMpghN8ZaUzoCF+MWLEKHwUHXnX1jqYO7cXbW1l6O2lJgITJ2bw+9+bQnd0Ik5qNCBDZTGrEmToZ12djQ8+0LBnjy5dr4rZZrjiCgdvvmm41jQ/rmkMM2b4redkUseDDyZ8ESSaBqxbZ2Ub+XrXM0ak/uijli/8bsKETBySFyPGRxBFGSpYW+tg6dIeGAay/RnF2GcgKg5c08T9YTKJhwsvJOs4eJ4IcmJyy3rjxqP4+tfTqKuz3eOMkVNRRGur6Yvp1nXKkBQrAvLrHYcs8VSK93P0d2yPQ/JixPhoISd527aNu+++G1/96ldx00034a233sLevXsxY8YM3HjjjViyZAkcZ3AsPdNkodtdXTocB9kqeXwvOQQnT5b1Xzrh619PY/nyHmFfWMggoGnUM3H69DS6uvQs6atlGk0DampsbNzoZTAuX96LSZPsrJOVikrJTkXSrckhaZrAj3/cg9mzU74O7PwenrOWjjmOv2N7PrHcMWLEOHWQ00zbunUrAOC3v/0tdu7cifvuuw+MMdxxxx0YP348Fi9ejObmZtTX1w/45AyDZa1Qb5ujspIvGH6r+aabKN6ZGhF4ZHvppRSeBwDz5rFs1iGkMejcqVPTuOQSU4iNzqCkJCE4Sr2xNY2q9t1zD429YkXCJdB9+zQ3O9K2gR/9yMJ//ZeB9et7I9PUN248isZGS9C8iZiHD2eBCJPa2kyfQvI+ainrxfC8xTDHGIWHnOT9pS99CV/4whcAAAcOHMCZZ56Jbdu2Ydy4cQCAiRMnYseOHYNC3r29unI7mdSxcGGpz+IG4FrKAKDrCaGeNcM553jE+4//yPDGG/4QQl0HzjnHwfXXZ7B4cQoVFYYbG11b6+Caa3jijP+eF11k48c/JuL22oolAAC2TS3GSkpsHD1KTsy//93ANdeU4amnyErfvVvHjh0GKisdX3JNbW2v+6z8DxtAVvP2W9n5huR91FLWi+F5i2GOMQoTeQmkpmli3rx52LJlC372s59h69at0LLi8dChQ9Hd3R15vWFoqKgo6/PkSkqA3l7/dkVFGdrbSd9ljCzQyy5juOQS4GtfY6iro6YC557LsHevR9BvvGG4c5g7F/i3fwNEq91xGL71LQ3z5pkATBiG7pvzCy+oapUw9PToqK8vxf33a8q2YgBDKiX2l6T7trcPwd69DHfeSce2bTNQVubgllv830F9Pf3jv6rNmx1s367hyiu9ZwWAb3wDeOYZDVdfzfCb3/jH4M/Cvzde66S9fQjq66PCJwsL8u8kFwr1ecXnKNQ55ou+/k4KFcX4HHl7t+6//37ceeedmD59OnoFRj1y5AiGDRsWea1tMxw6dLTPk7v00iG+iJFLL3Vw6NAx1NTosKwycCfhD37gpX7z7uIf//gQ7N3rXVtRQdcCwP79CQAJyE7KIUN6cehQJnt+mW/Okycn3IxG8ZpLLsng0KFe35wMg7TpTIZkjjPOcNDZaQjXAjU1x7B8uT/DsrGRYdq0Y5HfSVUV/Usmdfzwh2SRP/yw5b4VrFunobc3jV/8wvsd8WeRv7eammM5My8LCfLvJBcK9XnF5yjUOeaLvv5OChWF+hxnnVUeeiwneT/xxBM4ePAg/vVf/xVDhgyBpmkYM2YMdu7cifHjx6OlpQV1dXUDOuFcON7Ua79eDnDy7OgwAKgdfosXkyyxdq2VbfZL11RVscCcvNR1IJ0G7rorjRUrgLff1jFsmONq3lOmpLPx6jTGlCnqzEsZ8qu2Zfmf43e/MwH0Bq77qKWsF8PzFsMcYxQmcpL3VVddhbvvvhs33XQTMpkMFixYgAsuuACLFi3CAw88gJEjR6KhoWFQJvfBB+HbuXTeVCp8u7k5rKFDNBYvTuGTn3Rw552l4ITrLQTenKZPHyKMz/DDH5ZgyZLeQO0R2u7Bpk0WpkxJK2uTiOD69759/lftCy5wsGuXtwj8r/8VPs5HLWW9GJ63GOYYo/CQk7zLysqwYsWKwP41a9YMyoRE7NmjRW5HYcIEG+3tHqElEkR+tbUODh4MZlRG1RwR8dhj3GlJxPnYY1aAdMeMsX0WdXe3liX8HiWB5yLt/9/e/cdEcaZxAP/uDrsLi4eLTffC5WJSWjltrolHRWwjtvVCpCWmaSGI3GHa/uWGC9L4i1PExDYt6MU06QVpTS49f/XXUa9eTSBnG6VCJKS0XvXUP5qLFxWl1iUKB7uzM3N/zM7OzuwyOzvssjPL80mIDLs7876rPvvyzvs+D6AcbYvpX8W2OxzA/v0B/OUvDnz1VQ7Wrg0ppkwIIdnJ5Ds64mX902fhQim3iRhkh4bkvCHqwA4AHR3Tun5l/e9/bZrH0rVj2yvgiy9iA71e6sIKv/+9MgWsuDqFgjYh84XJg/dMSaESe/ppcW12ICBE8oZIVWYePFCnbhUD67JlfMIAXlLC49Yte6QtJSWxz4+dUxfpndOeqT/R+bHr6liaHyVkHjP19viaGnl7ufI4MelG0KZNLJxO5Q7Ea9eiuy2eu79fHJkPDyd6S+JV21Hy++2RnZUA8Itf8PjTn2KnTJIh9ae1NUhrgQkh5g7e4tQGIAVB+VgfaZv6yZPKoHfvXmzAFes/Js4NIo+eZ14hIm17ZxgBubnA4cOzC9zR/Sks5HHggAtHjpj8lyZCSFqZOgKUlnL4z3/kKYrSUv0j72jqu/mPPspHZQkUizzYbKnLDZKu5V9HjuSEb3wifEM0NR8KhBDrMXXwlirLSCs75GPZz3+eB0GwA+AhZ+LjwTD2cKZBQDsbICI7IjkOqK7Oizzm9eZhbMwOm40PXwMxWQl37nThj3904Ze/5OHxAJcv2+FwCJiclJ7IQPkLjtwWhgE4jo88XlgI7N4dwPHjDnz/vR1PPMGjr0/etPPFF8qVLtu2ubBtmyvcd+kaPMbGYjf6FBXlgePE5zz0kICNG0ORteup8Otfi++V18tjxw42svxx2TI+qQ8xn89Fq2YI0cEmKEvNpAXLcoZ2L3m9bohBSdqSzmNsTD6PGLiTm0pRildI2Fx+8xsuEsC93jyIHwaJcIoAXlTkjgTuaH/4QzAlAVwM3PHb5XCIu00dDiScq/f5XIr8MTU18XeKWl229APInr6YtR9aOyxNPeedaKmgNBqWR9zRObDVP4v3pfU89TWNni/Ra9WPK6/7/ffRf0XqHCnxzhH9PJGcQVF5ndOnU/OL19iYul3y98nkGhd3hsqvlY8JIWomD97qJXfKUZvNFv149Fe8n+n5gup7aJxvNj/Telx53SeeiO6z+v2Yqd3K90lOpau8TnV1aubLvd54SyPF75PJNS7vDE28U5SQ+c7UQ5vCQjv8fkCa3igsVH7W3LkzNYs575kLMUgBzusVwqNKAcrpG5ndzoNhbBpz3tHz0cprJTvnPTY2FZ46sUM9z6015z01BeTlcWmb8750aSolc97SFAnNeROSmKnnvBPNgWpRJm9Szrdu3+7CX//qgBSMXS4BgYCcbOqhh3iMjiLS5uhzidV7EHluSQmP8+fnbq7MyA09s87nJYv6YT7Z0hez9sPCc97GDQ7mIBAQ51sDAeV869iYchTuVqXxXbJE+XkWvUGmvFy5XPHRR+dus4z0Yeb329DT44DP50r8IkJIVjJ18D51SnkDSz5ObGDAHh4hi9vjr16VA7bXqwzOfr8yR3dtLYsLF8SSZtKOy7IyHlu2BFFbq9yk89vfzt28rNYNveFhu6K98Rw5koO6ujxTbPDR015CyMwy/79Yg7qusd46x8PDdpw7Fx3oBMXuTLnCjhS07Yrn/u1vDuzZY0cw6IwpTSXm/Jafq5UDPNXWrg2Fp5GUN/T0lNIy0wYfKv1FyOyZetizdCmveTyTwcEcxbw0ALjdQmSUd/Gictu9+vt//cuGYFD/Ere5cuhQADU1LAoLBcX8f3TGwZnaq9zgE3089/S0lxCizdTBe//+QDjBk1hOTCr0m8jTT4eQkyO+TgpW//63nHhKvSRN/b3DYYtJZiWpqxMTXdlsgqLg8Vw5dCiAa9cmFTcrxYyD2kvy9ORkmSt62ksI0WbqIU9ZGY9//CP5HCFYhcSVAAAKsUlEQVRlZTw6OqbR2poLjotNCatektbTY4e4c1EMbI2NLOrqctDXF4q5blkZj5MnzVW2Sk8ulWSr9qQTlf4iZPY0lwqyLItdu3bh5s2bCAaD8Pl8eOyxx9Da2gqbzYYlS5Zg7969sNu1B/BGlwoCUKxrjpezQ99rxdF3bi5QXc1iZISJbFA5fToHHo+Aa9dsYFkbSkp47N8fQGVlLvLzBbCsHQ4Hj7//PRAJNoD4q35hIR+ZA4+XX1sqWzYwYEd/PwNBAJYv5/G737FzGkTNugwqWdQP88mWvpi1H1pLBTWDd09PD65evYrdu3fD7/fjpZdewtKlS/Hqq6+ivLwc7e3tqKioQGVlpWYDjOc2Uefy4HQH8Hh5QFwuDoFA4twgTqe4eUadD0QuPwaEQsobqE4ncPKkfONNuik3Pa19rdnm+dbDrP8wk0X9MJ9s6YtZ+2G4enxVVZWiuDDDMLh8+TJWrlwJAFizZg0GBgYSBm+GscHjcWs+J77onBziLkf954mtlhMIKFeVKL+Xb1iyrKDKmyJlHbRFMhBK5dXkHB4CRkbyUFkpPj4yIt6Miz2/8rq9vS40Nzt19skYhknmfTMv6of5ZEtfrNgPzeCdn58PAJiYmEBzczNaWlrQ2dkJWzgvan5+Ph48eJDwIhwnGPxUk0bPcs6O8XG9Uyfq1wJuN4///U/5M2VuEJHDET3yln/OMELUyFsIj7zlHB6lpVMYHxdH3qWldjgcbnBc7Pmjj6uqAhgfp5G3HtQP88mWvpi1H4ZH3gAwOjqKpqYmNDQ0YP369Thw4EDkscnJSRQUFKSmlXGoc3kkM+etfK2YPOnSpSns2+fE6dM5MXPet2/bsGiRgBUreNTVseE5b87wnHf0TblMz3kTQrKP5pz33bt30djYiPb2djz11FMAgM2bNyvmvFetWoUXXnhB8yKzuWGZKVqfxNKNSKuslDDrqCJZ1A/zyZa+mLUfhkfe3d3duH//Prq6utDV1QUA2L17N958800cPHgQxcXFijnx+YB2BxJCzEAzeLe1taGtrS3m58eOHUtbg8wuencgIK4bj66PmSyrjeIJIeZg6k066WQ0aIq7A50AZr87kEbxhBCj5mXwnk3QTOXuwFSP4gkh80fWBW89I+rZBs2yMj4lQTaVo3hCyPySVcFb74jaLEGTcnwQQowydVZBILkCAnpTjUpBk+N4TE8LqK5OriKNnkIC+/Y5UV7uxr592rsnr1yxY2CAwZUrpv+rIISYiKlH3skWEEhmRC0GbClgMvB683RtAtIzut+3z4k//1kM2tKf8Yr9mqlAAiHEWkw93Eu2gEB0rcnENyGjc5dEH2vTM7o/fVpZrkw+VjJTgQRCiLWYOngbKSAg1ZpMPH8sPS6ojrXpKSQgbb2Xzi0fK5mpQAIhxFpMPW2SzgICRvOm6LnJKE2RSDlU4k2ZAOYqkEAIsRbN3Capkm25TawmW/pC/TCfbOmLWfuhldvE1NMmhBBC4qPgTQghFjRvg7fP58KvfpUPny+5Nd6EEGIGpr5hmS4+nws9PeKyPOlPqaI8IYRYwbwceX/1lXIdtnxMCCHWMC+D99q1ynXY8jEhhFiDruB98eJFNDY2AgCuX7+OjRs3oqGhAXv37gXPpzeZUlFRHrzefBQV5aXsnIcOBVBTw6KwUEBNDauYMqmry8Xixfmoro59XTJ5VqLpyYVCCCHJSBhNDh8+jLa2NgQCYoB7++230dLSghMnTkAQBHz55Zdpa1xRUR44jgFgA8cxsw7g0UH00KEA/H4ePT054c06YuA+ezYH09M2/POfdtTV5UZeK+UhOXuWwbZtuboDuJQLpaPDiZoaNwVwQkhKJIxAixcvxrvvvosdO3YAAC5fvoyVK1cCANasWYOBgQFUVlZqnoNhbPB43Ek3Tsy3DYhz0wI4zm7oPABw4QJQW2tHMAg4nU5MTfFQJqZyIy9Peb2hISZyvd5e5WO9vS40N2tnDASAkRGbInf4yEgeKivTvi9KgWGMv29mQv0wn2zpixX7kTB4r1u3Djdu3IgcC4IAm00MZPn5+Xjw4EHCi3CcYGj3EsNII28hfMxjfFzfNna1vj4ngkEnOM6GYFCAnJDKFj6/DeXlHM6ezYlcr7ycw/j4NACgqioHZ87kRh6rqgpgfDzxXHlpqR0OhxtSpsPS0imMj89t3m6z7h5LFvXDfLKlL2bth+Hq8fHY7fKv/ZOTkygoKDDWKh1GR6fCUyd2MAyP0VFjgRuITRfLcTwA+YMB4PHJJ9Ooq8vFhQsMKioEHD8+HXm90TwkVHCBEJIOSQfvxx9/HENDQygvL0d/fz9WrVqVjnZFzCZgR4sXROMlpvrkEzFgi5/EynNs2hQylDwqVWXTCCFEknTw3rlzJ/bs2YODBw+iuLgY69atS0e70kIdRPVmEiSEELOhrIIzMOscmBHZ0hfqh/lkS1/M2g/KKkgIIVmGgjchhFgQBW9CCLEgCt6EEGJBFLwJIcSC5mS1CSGEkNSikTchhFgQBW9CCLEgCt6EEGJBFLwJIcSCKHgTQogFUfAmhBALouBNCCEWRMFbhed5tLe3Y8OGDWhsbMT169cz3SRDWJbF9u3b0dDQgNra2rTWGp0LP/30E5555hn88MMPmW7KrLz33nvYsGEDXn75ZXz66aeZbo4hLMti69atqK+vR0NDgyX/TjJZVD1VKHirnDlzBsFgEB9//DG2bt2Kjo6OTDfJkFOnTsHj8eDEiRM4fPgw3njjjUw3yTCWZdHe3o7c3NzETzaxoaEhfPvtt/jwww9x9OhR3L59O9NNMuTcuXMIhUL46KOP0NTUhHfeeSfTTUpKJouqpxIFb5VvvvkGFRUVAIDly5fj0qVLGW6RMVVVVdiyZUvkmGGYDLZmdjo7O1FfXw+v15vppszK+fPnUVJSgqamJmzevBnPPvtspptkyCOPPAKO48DzPCYmJpCTk3RNl4ySiqpL1EXVBwcHM9W0pFjrXZ8DExMTWLBgQeSYYRiEQiHL/QPNz88HIPanubkZLS0tGW6RMZ999hkWLVqEiooKvP/++5luzqz4/X7cunUL3d3duHHjBnw+H3p7eyMFva3C7Xbj5s2beP755+H3+9Hd3Z3pJiUlFUXVzYBG3ioLFizA5ORk5JjnecsFbsno6Cg2bdqEF198EevXr890cwzp6enB4OAgGhsbceXKFezcuRM//vhjpptliMfjwerVq+F0OlFcXAyXy4V79+5lullJ++CDD7B69Wr09fXh888/R2tra2QKwormsqh6KlHwViktLUV/fz8A4LvvvkNJSUmGW2TM3bt38dprr2H79u2ora3NdHMMO378OI4dO4ajR49i2bJl6OzsxMMPP5zpZhny5JNP4uuvv4YgCLhz5w6mpqbg8Xgy3aykFRQU4Gc/E8tzLVy4EKFQCBzHZbhVxklF1QGgv78fK1asyHCL9LHmkDKNKisrMTAwgPr6egiCgLfeeivTTTKku7sb9+/fR1dXF7q6ugCIN2qsftPPyp577jkMDw+jtrYWgiCgvb3dkvciXnnlFezatQsNDQ1gWRavv/463G53pptlmFWLqlNKWEIIsSCaNiGEEAui4E0IIRZEwZsQQiyIgjchhFgQBW9CCLEgCt6EEGJBFLwJIcSC/g+r+6T6OyWOSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# highest correlation (pearson) -> 'AL'\n",
    "plt.plot(X_train_sc[\"AL\"], y_train, \"b.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1b795e0-80cf-46b6-bee0-e8ddf7351a26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'GQR': 0.12962660212067384,\n 'ETK': 0.13004809789779256,\n 'KRF': 0.1303176805773361,\n 'GKM': 0.1303421571404401,\n 'LVM': 0.13047556331329602,\n 'ADG': 0.13071474455829585,\n 'RQG': 0.13098661870594847,\n 'TS': 0.13121349362229823,\n 'SAN': 0.13125223264214886,\n 'NRS': 0.13182856454436126,\n 'RTD': 0.13192560905438364,\n 'GDT': 0.13196690532358818,\n 'VSI': 0.13206023662371805,\n 'HK': 0.13212793065896916,\n 'YIY': 0.13272219915855835,\n 'R': 0.13272362653837938,\n 'MVN': 0.13277013284658468,\n 'ST': 0.13342347819268413,\n 'QT': 0.13358051373961205,\n 'EFD': 0.13370615927206225,\n 'KLM': 0.13372278039552202,\n 'TLI': 0.13403988547059595,\n 'STK': 0.13420492753514432,\n 'EDN': 0.13447137015118002,\n 'KM': 0.13480177065334706,\n 'FAT': 0.13537791704118815,\n 'RA': 0.13581753888988382,\n 'DKG': 0.13605421762315262,\n 'THE': 0.1361808260910424,\n 'YKP': 0.13641926459247944,\n 'KKM': 0.1365192400190705,\n 'GQP': 0.13662112389017164,\n 'TKK': 0.13698864077372286,\n 'KPN': 0.1371519884529183,\n 'CLV': 0.13719551451934017,\n 'GVN': 0.13736638737249368,\n 'YAD': 0.13752910959770148,\n 'TKH': 0.137762298669474,\n 'CL': 0.13791529159322993,\n 'EYL': 0.13796716129289552,\n 'VMT': 0.13816296634982508,\n 'FFF': 0.13837333441667957,\n 'KS': 0.13855670461919273,\n 'KSE': 0.13877134160394788,\n 'AL': 0.1391110093285619,\n 'QHL': 0.13938019525701648,\n 'FDK': 0.13982330997119552,\n 'QRT': 0.13990960439483677,\n 'ATS': 0.14005834252985655,\n 'YGR': 0.140405157531982,\n 'EAQ': 0.14069326295569376,\n 'HPK': 0.14085186118470205,\n 'DNG': 0.14141339348675241,\n 'CM': 0.14162343384703374,\n 'LHK': 0.14217787945257798,\n 'MAI': 0.14281128629880893,\n 'IYA': 0.14292779600903768,\n 'TST': 0.14333246807570577,\n 'TSC': 0.1433801738258743,\n 'DNA': 0.14360282799887317,\n 'GQY': 0.14375475164367674,\n 'TEY': 0.14443603992833884,\n 'NAD': 0.14444000193168216,\n 'AV': 0.14460588603057814,\n 'HEQ': 0.14461027360569045,\n 'GIC': 0.14474969443092636,\n 'MTF': 0.1457508613592253,\n 'NNT': 0.14671971339381965,\n 'MTE': 0.14689412630616858,\n 'TDN': 0.14689623598732662,\n 'S': 0.14719515071510747,\n 'KK': 0.14745940241889877,\n 'PMT': 0.14747057767007035,\n 'SKG': 0.14793057796079345,\n 'FTK': 0.14831430688599637,\n 'KL': 0.15023880442959944,\n 'HKE': 0.15034994745391414,\n 'SS': 0.15221145401569905,\n 'PNN': 0.15235491351350935,\n 'DN': 0.15255612937015095,\n 'GE': 0.15283538490055804,\n 'WSE': 0.1532962307162211,\n 'IWS': 0.1535302946042737,\n 'EQH': 0.15362545050517953,\n 'AR': 0.15435658376281985,\n 'NTH': 0.1547725685316063,\n 'PKK': 0.1554762958157815,\n 'KHP': 0.1555367803206601,\n 'QTD': 0.15583484667431138,\n 'MYK': 0.15742487902922675,\n 'IGM': 0.15949995501591946,\n '_SolventAccessibilityT23': 0.16130325910679302,\n 'QPM': 0.16222914043458805,\n 'NIW': 0.1622475590563388,\n 'T': 0.16238018121382103,\n 'CMA': 0.1630329662959836,\n 'K': 0.16305691936479175,\n 'LMY': 0.16725274183361946,\n 'ICM': 0.1714719834168786,\n '_SolventAccessibilityC1': 0.17256894129742167}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest 100 spearman correlations\n",
    "best_spearman = get_k_best_corrs(100, spearman_corrs)\n",
    "best_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78ac70f2-34dd-4d54-9195-82e7504cffeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c926ce0a0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# highest correlation (spearman) -> '_SolventAccessibilityC1'\n",
    "plt.plot(X_train_sc[\"_SolventAccessibilityC1\"], y_train, \"r.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff037e-a1ee-4454-9db0-0bc2900dfc1f",
   "metadata": {},
   "source": [
    "<b>Univariate linear regression</b> (F-statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aa38703-c2da-466c-84f8-b19b05763b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From sklearn docs:\n",
    "# Univariate linear regression tests returning F-statistic and p-values.\n",
    "# f_regression is derived from r_regression (Pearson) and will rank features in the same order if all the features are\n",
    "# positively correlated with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835e0cd-017a-493f-9412-337af8decd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935851bc-306e-433e-b2d8-ac2a87835ce6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# highest 100 f-values\n",
    "f_values, _ = f_regression(X_train_sc, y_train)\n",
    "best_f_scores = get_k_best_corrs(100, f_values)\n",
    "best_f_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b9f3223-cbc7-4e03-9fab-411ad008c1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if pearson_corrs and f_values are equal\n",
    "(pearson_corrs == f_values).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31984a-accf-4f5a-bbf0-4b792427c377",
   "metadata": {},
   "source": [
    "<b>Mutual information regression</b> (MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ec47de7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# From sklearn docs:\n",
    "# Estimate mutual information for a continuous target variable.\n",
    "# Mutual information (MI) (https://en.wikipedia.org/wiki/Mutual_information) between two random variables is\n",
    "# a non-negative value, which measures the dependency between the variables. It is equal to zero if and only\n",
    "# if two random variables are independent, and higher values mean higher dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3af22040-c707-4c73-8bbd-66e961e482d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression as m_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1c5a0a6-3137-481d-825d-26a40a248962",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'_HydrophobicityD2075': 0.32902886547082577,\n '_SecondaryStrD1050': 0.3304501295378115,\n '_PolarizabilityD1050': 0.33054686774029474,\n 'H': 0.3309465925258799,\n '_SecondaryStrD1075': 0.3311222768815094,\n '_NormalizedVDWVD2075': 0.33224528918198093,\n '_ChargeD2075': 0.33235799469791427,\n 'TurnSSF': 0.3327013710268689,\n '_SecondaryStrD3050': 0.33311620298295797,\n '_SecondaryStrD2075': 0.33439838763635166,\n '_HydrophobicityD2025': 0.3344450393308298,\n '_PolarizabilityD1025': 0.33580054905334755,\n '_PolarityD3075': 0.3358156798436065,\n '_SecondaryStrD2050': 0.33686624673186305,\n '_SecondaryStrD1025': 0.33721485474885604,\n '_HydrophobicityD3075': 0.33740484394942616,\n '_SolventAccessibilityD3025': 0.3375037265858696,\n '_PolarityD2050': 0.3377859468522546,\n '_SecondaryStrD3025': 0.3380721369837483,\n '_PolarityD2075': 0.33863889442838424,\n '_PolarityD2025': 0.33874739462867076,\n '_NormalizedVDWVD3075': 0.33880768727176047,\n '_SolventAccessibilityD3050': 0.33890215147032965,\n '_NormalizedVDWVD1075': 0.3393145565007467,\n '_PolarizabilityD1075': 0.33938288605730627,\n '_NormalizedVDWVD1025': 0.3404034750094178,\n '_PolarityD3050': 0.3404611153621282,\n 'Y': 0.3404816999999216,\n '_PolarizabilityD3075': 0.3405405103403014,\n '_SolventAccessibilityD3075': 0.3406136830346531,\n '_SolventAccessibilityD2050': 0.3406327503388633,\n '_HydrophobicityD1075': 0.34064967345721975,\n '_SolventAccessibilityD2075': 0.34074321685984454,\n 'M': 0.3420869373270241,\n 'HelixSSF': 0.3422129184148224,\n '_SolventAccessibilityD1025': 0.34235507155581946,\n '_HydrophobicityD1050': 0.3425819822758376,\n '_PolarityD1050': 0.3439516911927596,\n '_SolventAccessibilityD3100': 0.3442868918438293,\n '_NormalizedVDWVD3050': 0.34514203884657224,\n '_SecondaryStrD2025': 0.34572211996066926,\n '_PolarizabilityD2025': 0.34611474781836193,\n 'Aromaticity': 0.34638659323764465,\n '_NormalizedVDWVD2025': 0.3467978132053222,\n '_PolarizabilityD3001': 0.3471738808819209,\n '_HydrophobicityD3001': 0.34719306404742767,\n '_PolarizabilityD3050': 0.3472621445423485,\n '_SecondaryStrD3075': 0.34776548315162525,\n '_NormalizedVDWVD3001': 0.34779303287796104,\n 'V': 0.3479631806321519,\n '_PolarizabilityD3025': 0.34841251929080386,\n 'G': 0.3485939174289987,\n '_PolarityD1075': 0.34873645322298774,\n '_ChargeD1001': 0.34895539490591254,\n '_SecondaryStrD1001': 0.3490386576963225,\n 'E': 0.35019348327693134,\n '_NormalizedVDWVD3025': 0.35030216824152394,\n '_PolarityD3025': 0.35096437782151035,\n '_SolventAccessibilityD3001': 0.35124413394625975,\n '_HydrophobicityD3050': 0.3522451161258431,\n '_PolarityD1001': 0.35261467937359203,\n '_HydrophobicityD1025': 0.35310389980675616,\n '_SolventAccessibilityD2025': 0.35348254341593055,\n 'T': 0.3541657520982353,\n '_SolventAccessibilityD2001': 0.35446344332156077,\n '_PolarityD3001': 0.35480791188985883,\n 'C': 0.3553292650871578,\n '_HydrophobicityD1001': 0.3568047461065449,\n '_ChargeD1075': 0.3572657153749077,\n '_ChargeD3075': 0.35738778878050237,\n '_ChargeD3050': 0.35893170961289833,\n 'L': 0.3589857198095743,\n '_HydrophobicityD3025': 0.3593163214183672,\n '_PolarizabilityD2001': 0.36030932599752585,\n '_SecondaryStrD2001': 0.36081354116108155,\n '_ChargeD1050': 0.36087832313144297,\n '_ChargeD2001': 0.36093953868916095,\n 'D': 0.3610534078021699,\n '_PolarityD1025': 0.3613991973330064,\n 'SeqLength': 0.36203385469972194,\n 'P': 0.36217435267699294,\n 'R': 0.3622266171257307,\n '_NormalizedVDWVD2001': 0.3624050334482076,\n 'A': 0.3624549058920916,\n '_ChargeD3025': 0.365045650802152,\n '_ChargeD1025': 0.36511212649082303,\n 'SheetSSF': 0.36663682443516876,\n '_SolventAccessibilityD1001': 0.36699320220513787,\n 'K': 0.36789142610185355,\n '_ChargeD3001': 0.37002209033022737,\n '_SecondaryStrD3001': 0.37293131502140753,\n 'MolecularWeight': 0.3752828458447528,\n '_PolarityD2001': 0.3785249554566139,\n '_PolarizabilityD1001': 0.37956737915830896,\n '_HydrophobicityD2001': 0.3820277982223086,\n '_NormalizedVDWVD1001': 0.3861979754761862,\n 'S': 0.39256524060559705,\n 'N': 0.40014260965557025,\n 'I': 0.4012911237467387,\n 'Q': 0.41277206504060526}"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest 100 mi's (by default, n_neighbors=3 -> explore)\n",
    "mutual_info = m_info(X_train_sc, y_train)\n",
    "best_mis = get_k_best_corrs(100, mutual_info)\n",
    "best_mis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f62968",
   "metadata": {},
   "source": [
    "#### Creating datasets with best features\n",
    "(Pearson and Spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85782239",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create new training data based on the top 100 features (for both spearman and pearson)\n",
    "\n",
    "X_train_SM = X_train_sc_z.loc[:,best_spearman.keys()]\n",
    "X_train_PS = X_train_sc_z.loc[:,best_pearson.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8b609a45",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GQR</th>\n",
       "      <th>ETK</th>\n",
       "      <th>KRF</th>\n",
       "      <th>GKM</th>\n",
       "      <th>LVM</th>\n",
       "      <th>ADG</th>\n",
       "      <th>RQG</th>\n",
       "      <th>TS</th>\n",
       "      <th>SAN</th>\n",
       "      <th>NRS</th>\n",
       "      <th>...</th>\n",
       "      <th>IGM</th>\n",
       "      <th>_SolventAccessibilityT23</th>\n",
       "      <th>QPM</th>\n",
       "      <th>NIW</th>\n",
       "      <th>T</th>\n",
       "      <th>CMA</th>\n",
       "      <th>K</th>\n",
       "      <th>LMY</th>\n",
       "      <th>ICM</th>\n",
       "      <th>_SolventAccessibilityC1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>1.817367</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>-0.921269</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>0.151038</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>0.309394</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>-0.378718</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>-0.107799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>-0.335474</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>-0.073354</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>-0.458539</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>-0.678440</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>-1.029394</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>1.151108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>-0.335474</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>-0.921269</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>-0.702369</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>-0.970259</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>0.950440</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>0.243955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>-0.335474</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>-0.126348</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>-0.214708</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>-0.065802</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>-0.589146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.287743</td>\n",
       "      <td>-0.301368</td>\n",
       "      <td>-0.289975</td>\n",
       "      <td>-0.248041</td>\n",
       "      <td>-0.26803</td>\n",
       "      <td>-0.335474</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>-0.315313</td>\n",
       "      <td>-0.279966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248737</td>\n",
       "      <td>1.705457</td>\n",
       "      <td>-0.218189</td>\n",
       "      <td>-0.192412</td>\n",
       "      <td>1.810782</td>\n",
       "      <td>-0.193642</td>\n",
       "      <td>-0.450274</td>\n",
       "      <td>-0.226035</td>\n",
       "      <td>-0.185827</td>\n",
       "      <td>-1.644406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GQR       ETK       KRF       GKM      LVM       ADG       RQG  \\\n",
       "0 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803  1.817367 -0.300111   \n",
       "1 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803 -0.335474 -0.300111   \n",
       "2 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803 -0.335474 -0.300111   \n",
       "3 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803 -0.335474 -0.300111   \n",
       "4 -0.287743 -0.301368 -0.289975 -0.248041 -0.26803 -0.335474 -0.300111   \n",
       "\n",
       "         TS       SAN       NRS  ...       IGM  _SolventAccessibilityT23  \\\n",
       "0 -0.921269 -0.315313 -0.279966  ... -0.248737                  0.151038   \n",
       "1 -0.073354 -0.315313 -0.279966  ... -0.248737                 -0.458539   \n",
       "2 -0.921269 -0.315313 -0.279966  ... -0.248737                 -0.702369   \n",
       "3 -0.126348 -0.315313 -0.279966  ... -0.248737                 -0.214708   \n",
       "4  0.032636 -0.315313 -0.279966  ... -0.248737                  1.705457   \n",
       "\n",
       "        QPM       NIW         T       CMA         K       LMY       ICM  \\\n",
       "0 -0.218189 -0.192412  0.309394 -0.193642 -0.378718 -0.226035 -0.185827   \n",
       "1 -0.218189 -0.192412 -0.678440 -0.193642 -1.029394 -0.226035 -0.185827   \n",
       "2 -0.218189 -0.192412 -0.970259 -0.193642  0.950440 -0.226035 -0.185827   \n",
       "3 -0.218189 -0.192412 -0.065802 -0.193642  0.366500 -0.226035 -0.185827   \n",
       "4 -0.218189 -0.192412  1.810782 -0.193642 -0.450274 -0.226035 -0.185827   \n",
       "\n",
       "   _SolventAccessibilityC1  \n",
       "0                -0.107799  \n",
       "1                 1.151108  \n",
       "2                 0.243955  \n",
       "3                -0.589146  \n",
       "4                -1.644406  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_SM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "112f982a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DKY</th>\n",
       "      <th>GQ</th>\n",
       "      <th>EAQ</th>\n",
       "      <th>AV</th>\n",
       "      <th>FAT</th>\n",
       "      <th>KKM</th>\n",
       "      <th>AKK</th>\n",
       "      <th>QT</th>\n",
       "      <th>KLM</th>\n",
       "      <th>KPN</th>\n",
       "      <th>...</th>\n",
       "      <th>LMY</th>\n",
       "      <th>MAI</th>\n",
       "      <th>CMA</th>\n",
       "      <th>NIW</th>\n",
       "      <th>_SolventAccessibilityT23</th>\n",
       "      <th>_SolventAccessibilityC1</th>\n",
       "      <th>ICM</th>\n",
       "      <th>KGQ</th>\n",
       "      <th>AR</th>\n",
       "      <th>AL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.235935</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>0.824652</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.760302</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>0.161105</td>\n",
       "      <td>-0.117881</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>1.140561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.743002</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.989898</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>0.337159</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.445497</td>\n",
       "      <td>1.130644</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>3.146741</td>\n",
       "      <td>-1.184397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.680907</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.989898</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>2.429193</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.688137</td>\n",
       "      <td>0.230972</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.815957</td>\n",
       "      <td>0.166985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.680907</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.445533</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.760302</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.202856</td>\n",
       "      <td>-0.595258</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.815957</td>\n",
       "      <td>0.588383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.680907</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.336660</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>4.178271</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>1.707939</td>\n",
       "      <td>-1.641816</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.072951</td>\n",
       "      <td>-1.184397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DKY        GQ       EAQ        AV       FAT       KKM       AKK  \\\n",
       "0 -0.267463 -0.235935 -0.346617  0.824652 -0.283886 -0.269837 -0.391064   \n",
       "1 -0.267463  0.743002 -0.346617 -0.989898 -0.283886 -0.269837 -0.391064   \n",
       "2 -0.267463 -0.680907 -0.346617 -0.989898 -0.283886 -0.269837 -0.391064   \n",
       "3 -0.267463 -0.680907 -0.346617 -0.445533 -0.283886 -0.269837 -0.391064   \n",
       "4 -0.267463 -0.680907 -0.346617 -0.336660 -0.283886 -0.269837 -0.391064   \n",
       "\n",
       "         QT       KLM       KPN  ...       LMY       MAI       CMA       NIW  \\\n",
       "0 -0.760302 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "1  0.337159 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "2  2.429193 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "3 -0.760302 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "4  4.178271 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "\n",
       "   _SolventAccessibilityT23  _SolventAccessibilityC1       ICM       KGQ  \\\n",
       "0                  0.161105                -0.117881 -0.184867 -0.257779   \n",
       "1                 -0.445497                 1.130644 -0.184867 -0.257779   \n",
       "2                 -0.688137                 0.230972 -0.184867 -0.257779   \n",
       "3                 -0.202856                -0.595258 -0.184867 -0.257779   \n",
       "4                  1.707939                -1.641816 -0.184867 -0.257779   \n",
       "\n",
       "         AR        AL  \n",
       "0  0.009605  1.140561  \n",
       "1  3.146741 -1.184397  \n",
       "2 -0.815957  0.166985  \n",
       "3 -0.815957  0.588383  \n",
       "4 -0.072951 -1.184397  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_PS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99dae9f",
   "metadata": {},
   "source": [
    "#### Correlations\n",
    "(pairs of variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd19bd",
   "metadata": {},
   "source": [
    "Um problema que pode ocorrer nos dados é a multicolinearidade, quando se observa correlações elevadas entre variáveis independentes. Isto pode fazer com que os resultados obtidos de análises de machine leraning, como na aplicação de regressões lineares, não sejam fidedígnos. **(explicar?)** Desta forma, deve-se remover uma das variáveis altamente correlacionadas, de preferência a que está menos correlacionada com a variável alvo.\n",
    "\n",
    "Desta forma, criou-se uma função para averiguar a possibilidade de multicolinearidade (usando as correlações de pearson e spearman) e devolvendo os pares de variáveis com correlações elevadas. Na generalidade, considera-se uma correlação elevada quando se obtém um valor absoluto igual ou superior a 0.8.\n",
    "\n",
    "Após ser analisado uma correlação elevada, compara-se cada variável independente com a dependente, de forma a averiguar qual é a que está menos correlacionada e, portanto, deve ser removida. A função devolve, assim, os pares de variáveis altamente correlacionados, e ainda qual a variável desse par que deverá ser removida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eb437c5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to determine the independent variables that are highly correlated with one another\n",
    "# (they result in less reliable statistical inference)\n",
    "\n",
    "def _check_xy_corr(y_data:pd.DataFrame, var1:str, var2:str):\n",
    "    \"\"\"\n",
    "    Returns the name of the variable worse correlated to y\n",
    "    \"\"\"\n",
    "    corr1 = y_data.loc[var1,:]\n",
    "    corr2 = y_data.loc[var2,:]\n",
    "\n",
    "    if corr1 < corr2:\n",
    "        return var1\n",
    "    else:\n",
    "        return var2\n",
    "\n",
    "\n",
    "def multicolinearity(x_data:pd.DataFrame, y_data:pd.DataFrame, perc:float=0.8, method=\"pearson\") -> list:\n",
    "    \"\"\"\n",
    "    Selects pair os variables with collinearity above a given threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    :param x_data: Dataframe with independent variables\n",
    "    :param y_var: Indicates column index or name of the dependent variable. If non-existent, define this parameter as None.\n",
    "    :param perc: Collinearity percentage threshold\n",
    "    :param method: Method to determine correlation between variables ('pearson', 'kendall', 'spearman')\n",
    "    \"\"\"\n",
    "\n",
    "    corr = x_data.corr(method=method.lower())\n",
    "    result = []\n",
    "    check = 1\n",
    "    for l in corr:\n",
    "        for ix,val in enumerate(corr[l][check:]):\n",
    "            if val>=perc:\n",
    "                var1, var2 = (l, corr.index[ix])\n",
    "                if y_data:\n",
    "                    least_corr = _check_xy_corr(y_data, var1, var2)\n",
    "                    result.append(((var1, var2), least_corr))\n",
    "                else:\n",
    "                    result.append((var1, var2))\n",
    "            check += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2a98576",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "multicol_sm = multicolinearity(X_train_SM, y_train, perc=0.8, method=\"spearman\")\n",
    "\n",
    "for elem in multicol_sm:\n",
    "    print(elem)\n",
    "#Multicollinearity non-existent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbd813d7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "multicol_ps = multicolinearity(X_train_PS, y_train, perc=0.8, method=\"pearson\")\n",
    "\n",
    "for elem in multicol_ps:\n",
    "    print(elem)\n",
    "#Multicollinearity non-existent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0f01b",
   "metadata": {},
   "source": [
    "Em nenhum dos casos (considerando os 100 descritores mais relevantes pelo método de spearman e pearson) se observou multicolinearidade.\n",
    "\n",
    "Caso tivesse sido observado, utilizaríamos o seguinte bloco de código para remover as variáveis menos correlacionadas com a variável dependente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2ab6349",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Eliminate variables with multicollinearity\n",
    "\n",
    "#pairs, least_corr = list(zip(*multicol))\n",
    "#least_corr = set(least_corr)\n",
    "\n",
    "#for elem in least_corr:\n",
    "#    del X_train[elem]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7d27c",
   "metadata": {},
   "source": [
    "# Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d616fbdc",
   "metadata": {},
   "source": [
    "Passando para a análise dos dados, começamos aplicar algoritmos de aprendizagem não-supervisionada, ou seja, que não tem em conta a variável dependente. Retiram inferências apenas a partir dos descritores, podendo ser aplicados para reduzir a dimensionalidade do dataset, e até mesmo agrupar os dados de acordo com a sua proximidade.\n",
    "\n",
    "Os algoritmos de aprendizagem não-supervivionada, como o PCA, são sensíveis às escalas dos valores e outliers. Uma vez que já se efetuou a standardização dos dados, não é necessário efetuar esse passo novamente. Relativamente aos outliers, procuraram-se as linhas que contêm apenas valores inferiores a 3, ou seja, que contêm valores inferiores a 3 vezes o desvio padrão (considerando-se outlier). Desta forma, são removidas as linhas que não satisfazem esta condição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "737e0521",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28403, 100)\n",
      "(5948, 100)\n",
      "(5948,)\n",
      "\n",
      "(28403, 100)\n",
      "(6477, 100)\n",
      "(6477,)\n"
     ]
    }
   ],
   "source": [
    "#Removing outliers\n",
    "\n",
    "\n",
    "\n",
    "X_train_PS_clean = X_train_PS[(np.abs(X_train_PS) < 3).all(axis=1)]\n",
    "X_train_PS_clean.index = range(len(X_train_PS_clean))\n",
    "X_train_SM_clean = X_train_SM[(np.abs(X_train_SM) < 3).all(axis=1)]\n",
    "X_train_SM_clean.index = range(len(X_train_SM_clean))\n",
    "\n",
    "y_train_PS = y_train.loc[list((np.abs(X_train_PS) < 3).all(axis=1))]\n",
    "y_train_PS.index = range(len(y_train_PS))\n",
    "y_train_SM = y_train.loc[list((np.abs(X_train_SM) < 3).all(axis=1))]\n",
    "y_train_SM.index = range(len(y_train_SM))\n",
    "\n",
    "print(X_train_PS.shape)\n",
    "print(X_train_PS_clean.shape)\n",
    "print(y_train_PS.shape)\n",
    "print()\n",
    "print(X_train_SM.shape)\n",
    "print(X_train_SM_clean.shape)\n",
    "print(y_train_SM.shape)\n",
    "#df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236e9d10",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DKY</th>\n",
       "      <th>GQ</th>\n",
       "      <th>EAQ</th>\n",
       "      <th>AV</th>\n",
       "      <th>FAT</th>\n",
       "      <th>KKM</th>\n",
       "      <th>AKK</th>\n",
       "      <th>QT</th>\n",
       "      <th>KLM</th>\n",
       "      <th>KPN</th>\n",
       "      <th>...</th>\n",
       "      <th>LMY</th>\n",
       "      <th>MAI</th>\n",
       "      <th>CMA</th>\n",
       "      <th>NIW</th>\n",
       "      <th>_SolventAccessibilityT23</th>\n",
       "      <th>_SolventAccessibilityC1</th>\n",
       "      <th>ICM</th>\n",
       "      <th>KGQ</th>\n",
       "      <th>AR</th>\n",
       "      <th>AL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.431522</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.082623</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>0.954480</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>0.464406</td>\n",
       "      <td>-0.521816</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>0.215995</td>\n",
       "      <td>0.254170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.720753</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>0.389160</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.314459</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.384836</td>\n",
       "      <td>0.084086</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.299981</td>\n",
       "      <td>0.094330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.146941</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.554406</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>0.062793</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>0.858697</td>\n",
       "      <td>-0.852308</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>-0.320620</td>\n",
       "      <td>-0.835654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>-0.680907</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.391097</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.760302</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.263516</td>\n",
       "      <td>0.561464</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>0.546220</td>\n",
       "      <td>0.239639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.267463</td>\n",
       "      <td>0.387025</td>\n",
       "      <td>-0.346617</td>\n",
       "      <td>-0.554406</td>\n",
       "      <td>-0.283886</td>\n",
       "      <td>-0.269837</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>-0.760302</td>\n",
       "      <td>-0.280619</td>\n",
       "      <td>-0.252688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>-0.241228</td>\n",
       "      <td>-0.192832</td>\n",
       "      <td>-0.191415</td>\n",
       "      <td>-0.172526</td>\n",
       "      <td>-0.319848</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>-0.257779</td>\n",
       "      <td>0.174717</td>\n",
       "      <td>-0.138166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DKY        GQ       EAQ        AV       FAT       KKM       AKK  \\\n",
       "15 -0.267463  0.431522 -0.346617 -0.082623 -0.283886 -0.269837 -0.391064   \n",
       "16 -0.267463  0.720753 -0.346617  0.389160 -0.283886 -0.269837 -0.391064   \n",
       "19 -0.267463 -0.146941 -0.346617 -0.554406 -0.283886 -0.269837 -0.391064   \n",
       "29 -0.267463 -0.680907 -0.346617 -0.391097 -0.283886 -0.269837 -0.391064   \n",
       "31 -0.267463  0.387025 -0.346617 -0.554406 -0.283886 -0.269837 -0.391064   \n",
       "\n",
       "          QT       KLM       KPN  ...       LMY       MAI       CMA       NIW  \\\n",
       "15  0.954480 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "16 -0.314459 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "19  0.062793 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "29 -0.760302 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "31 -0.760302 -0.280619 -0.252688  ... -0.225019 -0.241228 -0.192832 -0.191415   \n",
       "\n",
       "    _SolventAccessibilityT23  _SolventAccessibilityC1       ICM       KGQ  \\\n",
       "15                  0.464406                -0.521816 -0.184867 -0.257779   \n",
       "16                 -0.384836                 0.084086 -0.184867 -0.257779   \n",
       "19                  0.858697                -0.852308 -0.184867 -0.257779   \n",
       "29                 -0.263516                 0.561464 -0.184867 -0.257779   \n",
       "31                 -0.172526                -0.319848 -0.184867 -0.257779   \n",
       "\n",
       "          AR        AL  \n",
       "15  0.215995  0.254170  \n",
       "16 -0.299981  0.094330  \n",
       "19 -0.320620 -0.835654  \n",
       "29  0.546220  0.239639  \n",
       "31  0.174717 -0.138166  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_PS_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2300a55",
   "metadata": {},
   "source": [
    "Foi possível remover 22222 amostras do dataset do pearson, e 21726 amostras do dataset do spearman. As novas variáveis criadas têm valores mais homogênios que vão permitir uma prestação mais fidedígna dos algoritmos de aprendizagem não-supervisionada. Vamos analisar o efeito de 2 algoritmos: **PCA** e **tSNE**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d52c2",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675964e6",
   "metadata": {},
   "source": [
    "Começamos com o algorítmo do PCA (Principal Components Analysis). Este algoritmo tem o objetivo de reduzir a dimensionalidade, ao encontrar uma nova forma de representar os dados que explique o máximo da variância possível. Desta forma, é geralmente possível eliminar informação que não contribui muito para a variabilidade dos dados, fornecendo dados menos ruidosos aos eventuais algoritmos de aprendizagem aplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d818e4e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_SM = PCA()\n",
    "pca_SM.fit(X_train_SM_clean)\n",
    "x_reduced_SM = pca_SM.transform(X_train_SM_clean)\n",
    "\n",
    "pca_PS = PCA()\n",
    "pca_PS.fit(X_train_PS_clean)\n",
    "x_reduced_PS = pca_PS.transform(X_train_PS_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5936e78c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.58349946e+01 1.19868417e+01 7.69860902e+00 5.78776121e+00\n",
      " 4.55715104e+00 3.61589294e+00 3.09353735e+00 2.80958183e+00\n",
      " 2.66072014e+00 2.34178112e+00 2.09030455e+00 1.95181483e+00\n",
      " 1.92950259e+00 1.77384607e+00 1.70977808e+00 1.68653116e+00\n",
      " 1.57966308e+00 1.48635047e+00 1.36186695e+00 1.30986550e+00\n",
      " 1.25323662e+00 1.10317744e+00 1.07231966e+00 1.00774743e+00\n",
      " 9.86784333e-01 9.46418059e-01 9.26852830e-01 8.92194457e-01\n",
      " 8.77838259e-01 8.48371205e-01 8.46325056e-01 8.29659537e-01\n",
      " 8.01798273e-01 7.94884979e-01 7.80413081e-01 7.67277296e-01\n",
      " 7.44147847e-01 7.16520115e-01 7.05616514e-01 6.92158194e-01\n",
      " 6.65515813e-01 5.57787611e-01 5.55566651e-01 5.27902376e-01\n",
      " 5.06248142e-01 4.82487518e-01 4.39759189e-01 4.06054190e-01\n",
      " 4.02015064e-01 3.83264184e-01 2.13263837e-01 3.12417291e-30\n",
      " 1.00606850e-30 9.32823811e-31 6.77004404e-31 4.91479842e-31\n",
      " 4.90945494e-31 3.03792203e-31 2.53950748e-31 2.40682866e-31\n",
      " 1.30506360e-31 9.62562489e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.45212637e-32 8.45212637e-32 8.45212637e-32 8.45212637e-32\n",
      " 8.30633775e-32 4.79376546e-32 2.81308248e-32 1.09771841e-32]\n",
      "\n",
      "Spearman:\n",
      "Número total de PCs: 100\n",
      "Número de PCs necessários para explicar 95% da variância: 41\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pca_SM.explained_variance_ratio_*100)\n",
    "\n",
    "print()\n",
    "print(\"Spearman:\")\n",
    "print(f\"Número total de PCs: {pca_SM.n_components_}\")\n",
    "print(f\"Número de PCs necessários para explicar 95% da variância: \\\n",
    "{sum(pca_SM.explained_variance_ratio_.cumsum() < 0.95) + 1}\")\n",
    "\n",
    "plt.bar(range(4), pca_SM.explained_variance_ratio_[:4]*100)\n",
    "plt.xticks(range(4), ['PC'+str(i) for i in range(1,5)])\n",
    "plt.title(\"Variância explicada por PC\")\n",
    "plt.ylabel(\"Percentagem\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c65706fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.37852940e+01 1.16982816e+01 9.24791356e+00 6.62364218e+00\n",
      " 5.17924856e+00 4.23030726e+00 3.15678657e+00 2.96802570e+00\n",
      " 2.75196204e+00 2.59458985e+00 2.07394720e+00 2.06367677e+00\n",
      " 1.93450496e+00 1.87517368e+00 1.78896947e+00 1.67624857e+00\n",
      " 1.56575690e+00 1.53979298e+00 1.48090454e+00 1.44162142e+00\n",
      " 1.34480829e+00 1.20400829e+00 1.12530345e+00 1.09938136e+00\n",
      " 9.86151953e-01 9.26902232e-01 8.61259244e-01 8.56166813e-01\n",
      " 8.48130658e-01 8.13589295e-01 7.91618237e-01 7.36713830e-01\n",
      " 7.26963634e-01 7.06370113e-01 6.50835634e-01 6.21134742e-01\n",
      " 5.93519139e-01 5.72303308e-01 5.35604244e-01 5.14758114e-01\n",
      " 5.03816602e-01 4.96057283e-01 4.45902545e-01 4.34321668e-01\n",
      " 4.02778364e-01 3.97518502e-01 3.81252062e-01 2.98513360e-01\n",
      " 2.56083975e-01 1.91585319e-01 2.71890802e-30 7.99448038e-31\n",
      " 6.01647897e-31 4.84908893e-31 4.28612401e-31 4.08482469e-31\n",
      " 3.30915483e-31 2.52591868e-31 1.93035826e-31 1.55499273e-31\n",
      " 9.69289533e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.17276016e-32\n",
      " 6.17276016e-32 6.17276016e-32 6.17276016e-32 6.14515070e-32\n",
      " 5.33539671e-32 2.50275243e-32 2.33903103e-32 1.77107162e-33]\n",
      "\n",
      "Pearson:\n",
      "Número total de PCs: 100\n",
      "Número de PCs necessários para explicar 95% da variância: 38\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pca_PS.explained_variance_ratio_*100)\n",
    "\n",
    "print()\n",
    "print(\"Pearson:\")\n",
    "print(f\"Número total de PCs: {pca_PS.n_components_}\")\n",
    "print(f\"Número de PCs necessários para explicar 95% da variância: \\\n",
    "{sum(pca_PS.explained_variance_ratio_.cumsum() < 0.95) + 1}\")\n",
    "\n",
    "plt.bar(range(4), pca_PS.explained_variance_ratio_[:4]*100)\n",
    "plt.xticks(range(4), ['PC'+str(i) for i in range(1,5)])\n",
    "plt.title(\"Variância explicada por PC\")\n",
    "plt.ylabel(\"Percentagem\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829cd64",
   "metadata": {},
   "source": [
    "Os resultados demonstram que, para os 100 melhores features selecionados pelo método de spearman, é possível utilizar apenas 41 componentes para explicar 95% da variância, e para os 100 features selecionados pelo método de spearman, é possível utilizar apenas 38 componentes.\n",
    "\n",
    "*NOTA: ao utilizar os dados isentos de outliers (valores standardizados superiores a 3), obtivemos resultados muito insatisfatórios na aprendizagem supervisionada, pelo que decidimos não utilizar estes dados, nem os reduzidos pelo PCA.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95d947",
   "metadata": {},
   "source": [
    "#### t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e64ee4",
   "metadata": {},
   "source": [
    "tSNE ('t-distributed Stochastic Neighbor Embedding') aplica um método de redução de dimensionalidade semelhante ao PCA, mas tem como principal foco a visualização dos dados transformados. Neste caso, é necessário definir em quantos grupos deverão ser separados os dados. Como a variável dependente se trata de de valores contínuos, não é óbvio o número de grupos que se deverá separar os dados. Desta forma, optou-se por separá-los em 3 grupos baseados na variável dependente:\n",
    "\n",
    "- os que estão próximos da média;\n",
    "- os que estão acima de um desvio-padrão da média;\n",
    "- os que estão abaixo de um desvio-padrão da média.\n",
    "\n",
    "Apesar deste algoritmo não ser tão sensível a outliers como no caso do PCA, vamos efetuar a análise sem outliers para visualizar melhor os gráficos resultantes. É, contudo, um algoritmo com elevado peso computacional, pelo que pode demorar bastante tempo a correr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d4b8295",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mean = y_train.mean()\n",
    "std = y_train.std()\n",
    "\n",
    "ub = mean+std\n",
    "lb = mean-std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0c13e48",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, n_iter=1000)\n",
    "\n",
    "points_sm = tsne.fit_transform(X_train_SM_clean)\n",
    "points_ps = tsne.fit_transform(X_train_PS_clean)\n",
    "\n",
    "group1_sm = y_train_SM.index[y_train_SM > ub]\n",
    "group2_sm = y_train_SM.index[(y_train_SM <= ub) & (y_train_SM > lb)]\n",
    "group3_sm = y_train_SM.index[y_train_SM <= lb]\n",
    "\n",
    "group1_ps = y_train_PS.index[y_train_PS > ub]\n",
    "group2_ps = y_train_PS.index[(y_train_PS <= ub) & (y_train_PS > lb)]\n",
    "group3_ps = y_train_PS.index[y_train_PS <= lb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a59d6d71",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for group, lab in zip((group1_sm, group2_sm, group3_sm), (\"> mean+std\", \"> mean-std\", \"< mean-std\")):\n",
    "    plt.plot(points_sm[group,0], points_sm[group,1], \"o\", label=lab)\n",
    "plt.title(\"tSNE (Spearman)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66f2f54c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for group, lab in zip((group1_ps, group2_ps, group3_ps), (\"> mean+std\", \"> mean-std\", \"< mean-std\")):\n",
    "    plt.plot(points_ps[group,0], points_ps[group,1], \"o\", label=lab)\n",
    "plt.title(\"tSNE (Pearson)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d187c7e",
   "metadata": {},
   "source": [
    "Os resultados demonstram que não é possível separar de forma clara os pontos com base nos grupos definidos."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KMeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k=3\n",
    "kmeans_sm = KMeans(n_clusters=k, max_iter=1000)\n",
    "kmeans_ps = KMeans(n_clusters=k, max_iter=1000)\n",
    "\n",
    "#Using the TSNE fitted points for the KMeans analysis\n",
    "kmeans_sm.fit(points_sm)\n",
    "kmeans_ps.fit(points_ps)\n",
    "\n",
    "\n",
    "labels_sm = kmeans_sm.labels_\n",
    "labels_ps = kmeans_ps.labels_\n",
    "\n",
    "centroids_sm = kmeans_ps.cluster_centers_\n",
    "centroids_ps = kmeans_sm.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "tm        10.0  12.0  15.0  16.6  17.2  20.0  21.7  22.0  22.5  23.0  ...  \\\nclusters                                                              ...   \n0            0     0     1     0     0     2     0     0     0     3  ...   \n1            1     0     1     0     1     6     3     3     2     0  ...   \n2            2     3     0     1     0     0     0     1     0     0  ...   \n\ntm        90.3  90.4  90.7  90.8  91.0  91.1  91.2  91.4  91.5  91.6  \nclusters                                                              \n0            0     0     0     0     0     0     0     0     0     1  \n1            0     0     0     0     0     0     0     0     0     0  \n2            2     1     2     1     2     1     1     1     1     0  \n\n[3 rows x 598 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>tm</th>\n      <th>10.0</th>\n      <th>12.0</th>\n      <th>15.0</th>\n      <th>16.6</th>\n      <th>17.2</th>\n      <th>20.0</th>\n      <th>21.7</th>\n      <th>22.0</th>\n      <th>22.5</th>\n      <th>23.0</th>\n      <th>...</th>\n      <th>90.3</th>\n      <th>90.4</th>\n      <th>90.7</th>\n      <th>90.8</th>\n      <th>91.0</th>\n      <th>91.1</th>\n      <th>91.2</th>\n      <th>91.4</th>\n      <th>91.5</th>\n      <th>91.6</th>\n    </tr>\n    <tr>\n      <th>clusters</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 598 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(labels_ps, y_train_PS, rownames=['clusters'] )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "tm        10.0  12.0  15.0  16.6  20.0  21.7  22.0  22.5  23.1  23.5  ...  \\\nclusters                                                              ...   \n0            2     3     0     1     1     3     1     2     1     1  ...   \n1            1     0     0     0     0     0     0     0     0     0  ...   \n2            0     0     1     0     7     0     3     0     0     0  ...   \n\ntm        90.6  90.7  90.8  91.0  91.1  91.2  91.3  91.4  91.5  91.6  \nclusters                                                              \n0            0     0     0     1     0     0     0     0     0     0  \n1            0     0     0     0     0     1     0     0     0     0  \n2            1     2     2     2     1     0     1     2     1     1  \n\n[3 rows x 609 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>tm</th>\n      <th>10.0</th>\n      <th>12.0</th>\n      <th>15.0</th>\n      <th>16.6</th>\n      <th>20.0</th>\n      <th>21.7</th>\n      <th>22.0</th>\n      <th>22.5</th>\n      <th>23.1</th>\n      <th>23.5</th>\n      <th>...</th>\n      <th>90.6</th>\n      <th>90.7</th>\n      <th>90.8</th>\n      <th>91.0</th>\n      <th>91.1</th>\n      <th>91.2</th>\n      <th>91.3</th>\n      <th>91.4</th>\n      <th>91.5</th>\n      <th>91.6</th>\n    </tr>\n    <tr>\n      <th>clusters</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 609 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(labels_sm, y_train_SM, rownames=['clusters'] )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    # select only data observations with cluster label == i\n",
    "    ds = points_sm[list(np.where(labels_sm==i)[0]),:]\n",
    "    #print(ds)\n",
    "\n",
    "    # plot the data observations (only 2 first colums)\n",
    "    plt.plot(points_sm[:,0], points_sm[:,1])\n",
    "    #plt.plot(ds[\"_SolventAccessibilityT23\"],ds[\"_SolventAccessibilityC1\"],'o')\n",
    "    # plot the centroids\n",
    "    lines = plt.plot(centroids_sm[i,0],centroids_sm[i,1],'kx')\n",
    "    # make the centroid x's bigger\n",
    "    plt.setp(lines,ms=10.0)    # x size\n",
    "    plt.setp(lines,mew=2.0)    # line thickness\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "[1517,\n 1705,\n 3009,\n 3218,\n 3219,\n 3220,\n 3221,\n 3231,\n 3232,\n 3233,\n 3234,\n 3237,\n 3238,\n 3239,\n 3245,\n 3246,\n 3247,\n 3248,\n 3249,\n 3262,\n 3263,\n 3264,\n 3265,\n 3266,\n 3267,\n 3275,\n 3276,\n 3277,\n 3278,\n 3296,\n 3297,\n 3298,\n 3299,\n 3300,\n 3301,\n 3302,\n 3303,\n 3304,\n 3305,\n 3306,\n 3307,\n 3308,\n 3309,\n 3310,\n 3311,\n 3312,\n 3313,\n 3314,\n 3315,\n 3316,\n 3317,\n 3318,\n 3319,\n 3320,\n 3321,\n 3322,\n 3323,\n 3324,\n 3325,\n 3326,\n 3327,\n 3328,\n 3329,\n 3330,\n 3331,\n 3332,\n 3333,\n 3334,\n 3335,\n 3336,\n 3337,\n 3338,\n 3339,\n 3340,\n 3341,\n 3342,\n 3343,\n 3344,\n 3345,\n 3346,\n 3347,\n 3348,\n 3349,\n 3350,\n 3351,\n 3352,\n 3353,\n 3354,\n 3355,\n 3356,\n 3357,\n 3358,\n 3359,\n 3360,\n 3361,\n 3362,\n 3363,\n 3364,\n 3365,\n 3366,\n 3367,\n 3368,\n 3369,\n 3370,\n 3371,\n 3372,\n 3373,\n 3374,\n 3375,\n 3376,\n 3377,\n 3378,\n 3379,\n 3380,\n 3381,\n 3382,\n 3383,\n 3384,\n 3385,\n 3386,\n 3387,\n 3388,\n 3389,\n 3390,\n 3391,\n 3392,\n 3393,\n 3394,\n 3395,\n 3396,\n 3397,\n 3398,\n 3399,\n 3400,\n 3401,\n 3402,\n 3403,\n 3404,\n 3405,\n 3406,\n 3407,\n 3408,\n 3409,\n 3410,\n 3411,\n 3412,\n 3413,\n 3414,\n 3415,\n 3416,\n 3417,\n 3418,\n 3419,\n 3420,\n 3421,\n 3422,\n 3423,\n 3424,\n 3425,\n 3426,\n 3427,\n 3428,\n 3429,\n 3430,\n 3431,\n 3432,\n 3433,\n 3434,\n 3435,\n 3436,\n 3437,\n 3438,\n 3439,\n 3440,\n 3441,\n 3442,\n 3443,\n 3444,\n 3445,\n 3446,\n 3447,\n 3448,\n 3449,\n 3450,\n 3451,\n 3452,\n 3453,\n 3454,\n 3455,\n 3456,\n 3457,\n 3458,\n 3459,\n 3460,\n 3461,\n 3462,\n 3463,\n 3464,\n 3465,\n 3466,\n 3467,\n 3468,\n 3469,\n 3470,\n 3471,\n 3472,\n 3473,\n 3474,\n 3475,\n 3476,\n 3477,\n 3478,\n 3479,\n 3480,\n 3481,\n 3482,\n 3483,\n 3484,\n 3485,\n 3486,\n 3487,\n 3488,\n 3489,\n 3490,\n 3491,\n 3492,\n 3493,\n 3494,\n 3495,\n 3496,\n 3497,\n 3498,\n 3499,\n 3500,\n 3501,\n 3502,\n 3503,\n 3504,\n 3505,\n 3506,\n 3507,\n 3508,\n 3509,\n 3510,\n 3511,\n 3512,\n 3513,\n 3514,\n 3515,\n 3516,\n 3517,\n 3518,\n 3519,\n 3520,\n 3521,\n 3522,\n 3523,\n 3524,\n 3525,\n 3526,\n 3527,\n 3528,\n 3529,\n 3530,\n 3531,\n 3532,\n 3533,\n 3534,\n 3535,\n 3536,\n 3537,\n 3538,\n 3539,\n 3540,\n 3541,\n 3542,\n 3543,\n 3544,\n 3545,\n 3546,\n 3547,\n 3548,\n 3549,\n 3550,\n 3551,\n 3552,\n 3553,\n 3554,\n 3555,\n 3556,\n 3557,\n 3558,\n 3559,\n 3560,\n 3561,\n 3562,\n 3563,\n 3564,\n 3565,\n 3566,\n 3567,\n 3568,\n 3569,\n 3570,\n 3571,\n 3572,\n 3573,\n 3574,\n 3575,\n 3576,\n 3577,\n 3578,\n 3579,\n 3580,\n 3581,\n 3582,\n 3583,\n 3584,\n 3585,\n 3586,\n 3587,\n 3588,\n 3589,\n 3590,\n 3591,\n 3592,\n 3593,\n 3594,\n 3595,\n 3596,\n 3597,\n 3598,\n 3599,\n 3600,\n 3601,\n 3602,\n 3603,\n 3604,\n 3605,\n 3606,\n 3607,\n 3608,\n 3609,\n 3610,\n 3611,\n 3612,\n 3613,\n 3614,\n 3615,\n 3616,\n 3617,\n 3618,\n 3619,\n 3620,\n 3621,\n 3622,\n 3623,\n 3624,\n 3625,\n 3626,\n 3627,\n 3628,\n 3629,\n 3630,\n 3631,\n 3632,\n 3633,\n 3634,\n 3635,\n 3636,\n 3637,\n 3638,\n 3639,\n 3640,\n 3641,\n 3642,\n 3643,\n 3644,\n 3645,\n 3646,\n 3647,\n 3648,\n 3649,\n 3650,\n 3651,\n 3652,\n 3653,\n 3654,\n 3655,\n 3656,\n 3657,\n 3658,\n 3659,\n 3660,\n 3661,\n 3662,\n 3663,\n 3664,\n 3665,\n 3666,\n 3667,\n 3668,\n 3669,\n 3670,\n 3671,\n 3672,\n 3673,\n 3674,\n 3675,\n 3676,\n 3677,\n 3678,\n 3679,\n 3680,\n 3681,\n 3682,\n 3683,\n 3684,\n 3685,\n 3686,\n 3687,\n 3688,\n 3689,\n 3690,\n 3691,\n 3692,\n 3693,\n 3694,\n 3695,\n 3696,\n 3697,\n 3698,\n 3699,\n 3700,\n 3701,\n 3702,\n 3703,\n 3704,\n 3705,\n 3706,\n 3707,\n 3708,\n 3709,\n 3710,\n 3711,\n 3712,\n 3713,\n 3714,\n 3715,\n 3716,\n 3717,\n 3718,\n 3719,\n 3720,\n 3721,\n 3722,\n 3723,\n 3724,\n 3725,\n 3726,\n 3727,\n 3728,\n 3729,\n 3730,\n 3731,\n 3732,\n 3733,\n 3734,\n 3735,\n 3736,\n 3737,\n 3738,\n 3739,\n 3740,\n 3741,\n 3742,\n 3743,\n 3744,\n 3745,\n 3746,\n 3747,\n 3748,\n 3749,\n 3750,\n 3751,\n 3752,\n 3753,\n 3754,\n 3755,\n 3756,\n 3757,\n 3758,\n 3759,\n 3760,\n 3761,\n 3762,\n 3763,\n 3764,\n 3765,\n 3766,\n 3767,\n 3768,\n 3769,\n 3770,\n 3771,\n 3772,\n 3773,\n 3774,\n 3775,\n 3776,\n 3777,\n 3778,\n 3779,\n 3780,\n 3781,\n 3782,\n 3783,\n 3784,\n 3785,\n 3786,\n 3787,\n 3788,\n 3789,\n 3790,\n 3791,\n 3792,\n 3793,\n 3794,\n 3795,\n 3796,\n 3797,\n 3798,\n 3799,\n 3800,\n 3801,\n 3802,\n 3803,\n 3804,\n 3805,\n 3806,\n 3807,\n 3808,\n 3809,\n 3810,\n 3811,\n 3812,\n 3813,\n 3814,\n 3815,\n 3816,\n 3817,\n 3818,\n 3819,\n 3820,\n 3821,\n 3822,\n 3823,\n 3824,\n 3825,\n 3826,\n 3827,\n 3828,\n 3829,\n 3830,\n 3831,\n 3832,\n 3833,\n 3834,\n 3835,\n 3836,\n 3837,\n 3838,\n 3839,\n 3840,\n 3841,\n 3842,\n 3843,\n 3844,\n 3845,\n 3846,\n 3847,\n 3848,\n 3849,\n 3850,\n 3851,\n 3852,\n 3853,\n 3854,\n 3855,\n 3856,\n 3857,\n 3858,\n 3859,\n 3860,\n 3861,\n 3862,\n 3863,\n 3864,\n 3865,\n 3866,\n 3867,\n 3868,\n 3869,\n 3870,\n 3871,\n 3872,\n 3873,\n 3874,\n 3875,\n 3876,\n 3877,\n 3878,\n 3879,\n 3880,\n 3881,\n 3882,\n 3883,\n 3884,\n 3885,\n 3886,\n 3887,\n 3888,\n 3889,\n 3890,\n 3891,\n 3892,\n 3893,\n 3894,\n 3895,\n 3896,\n 3897,\n 3898,\n 3899,\n 3900,\n 3901,\n 3902,\n 3903,\n 3904,\n 3905,\n 3906,\n 3907,\n 3908,\n 3909,\n 3910,\n 3911,\n 3912,\n 3913,\n 3914,\n 3915,\n 3916,\n 3917,\n 3918,\n 3919,\n 3920,\n 3921,\n 3922,\n 3923,\n 3924,\n 3925,\n 3926,\n 3927,\n 3928,\n 3929,\n 3930,\n 3931,\n 3932,\n 3933,\n 3934,\n 3935,\n 3936,\n 3937,\n 3938,\n 3939,\n 3940,\n 3941,\n 3942,\n 3943,\n 3944,\n 3945,\n 3946,\n 3947,\n 3948,\n 3949,\n 3950,\n 3951,\n 3952,\n 3953,\n 3954,\n 3955,\n 3956,\n 3957,\n 3958,\n 3959,\n 3960,\n 3961,\n 3962,\n 3963,\n 3964,\n 3965,\n 3966,\n 3967,\n 3968,\n 3969,\n 3970,\n 3971,\n 3972,\n 3973,\n 3974,\n 3975,\n 3976,\n 3977,\n 3978,\n 3979,\n 3980,\n 3981,\n 3982,\n 3983,\n 3984,\n 3985,\n 3986,\n 3987,\n 3988,\n 3989,\n 3990,\n 3991,\n 3992,\n 3993,\n 3994,\n 3995,\n 3996,\n 3997,\n 3998,\n 3999,\n 4000,\n 4001,\n 4002,\n 4003,\n 4004,\n 4005,\n 4006,\n 4007,\n 4008,\n 4009,\n 4010,\n 4011,\n 4012,\n 4013,\n 4014,\n 4015,\n 4016,\n 4017,\n 4018,\n 4019,\n 4020,\n 4021,\n 4022,\n 4023,\n 4024,\n 4025,\n 4056,\n 4057,\n 4058,\n 4059,\n 4060,\n 4061,\n 4062,\n 4072,\n 4073,\n 4074,\n 4119,\n 4120,\n 4121,\n 4122,\n 4359,\n 4360,\n 4361,\n 4373,\n 4374,\n 4375,\n 4376,\n 4377,\n 4378,\n 4385,\n 4386,\n 4387,\n 4388,\n 4402,\n 4403,\n 4407,\n 4408,\n 4409,\n 5079,\n 5218,\n 5316,\n 6167]"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.where(labels_sm==i)[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    # select only data observations with cluster label == i\n",
    "    ds = X_train_PS_clean.iloc[list(np.where(labels_ps==i)[0])]\n",
    "    # plot the data observations (only 2 first colums)\n",
    "    plt.plot(ds[\"_SolventAccessibilityT23\"],ds[\"_SolventAccessibilityC1\"],'o')\n",
    "    # plot the centroids\n",
    "    lines = plt.plot(centroids_ps[i,0],centroids_ps[i,1],'kx')\n",
    "    # make the centroid x's bigger\n",
    "    plt.setp(lines,ms=10.0)    # x size\n",
    "    plt.setp(lines,mew=2.0)    #grossura da linha\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "5725a1ab-4187-4b44-9100-e4dd166f0d8e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33b782-54c4-40c5-8bcb-1551754bb2a6",
   "metadata": {},
   "source": [
    "Por fim, aplicámos algoritmos de aprendizagem supervisionada de modo a conseguirmos fazer previsões acerca da variável de output (<b>tm</b>) a partir de sequências de aminoácidos cujo valor de termostabilidade é desconhecido. Para isso, utilizámos sete algoritmos distintos implementados na biblioteca <b>sklearn</b>.\n",
    "\n",
    "- <b>LinearRegression</b> (LR)\n",
    "- <b>KNeighborsRegressor</b> (KNR)\n",
    "- <b>RandomForestRegressor</b> (RFR)\n",
    "- <b>SVR</b> -> Support Vector Regressor\n",
    "- <b>MLPRegressor</b> (MLPR) -> Multi Layer Perceptron Regressor\n",
    "- <b>AdaBoostRegressor</b> (ADA)\n",
    "- <b>HistGradientBoostingRegressor</b> (HGBR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc515b9c-8d8f-4772-9153-b700e8454baa",
   "metadata": {},
   "source": [
    "### Get best combination dataset-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2ff20ec-333d-426f-a9fb-7531c1658800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor as ADA\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor as HGBR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNR\n",
    "from sklearn.neural_network import MLPRegressor as MLPR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ee745-d87f-495d-a580-4b902a5e4c2f",
   "metadata": {},
   "source": [
    "Começámos por determinar, a partir de cada um dos métodos de seleção de features referidos anteriormente (<b>Pearson</b>, <b>Spearman</b>, <b>ANOVA f-values</b> e <b>informação mútua</b>), qual a melhor combinação <b>modelo / número de features selecionadas</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62077a11-790f-431f-8422-b78393b31403",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_NUMS = [200, 400, 600, 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd667d78-a525-4f69-9a23-adf08ba73cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_corr_models(model, method, corrs, cv=5, num_feats=DEFAULT_NUMS):\n",
    "    print(f\"Getting results for {model.__class__.__name__} using {method} to select features...\\n\")\n",
    "    for k in num_feats:\n",
    "        # get best corrs and cross-validate\n",
    "        best_scores = get_k_best_corrs(k, corrs) # Get best features\n",
    "        result = cross_validate(estimator=model,\n",
    "                                X=X_train_sc.loc[:, best_scores.keys()],\n",
    "                                y=y_train,\n",
    "                                cv=KFold(n_splits=cv, shuffle=True),\n",
    "                                return_train_score=True)\n",
    "        # print results\n",
    "        mean_train = np.sum(result[\"train_score\"]) / cv\n",
    "        mean_test = np.sum(result[\"test_score\"]) / cv\n",
    "        print(f\"Results for {k} best features\")\n",
    "        print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "        print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab4536-e6b1-422f-b881-8e9f5b8b87e9",
   "metadata": {},
   "source": [
    "<b>Pearson</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "edf92216",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.31830325 0.31392415 0.31633945 0.31182916 0.3066358 ] -> mean_train = 0.3134\n",
      "Test scores: [0.27919092 0.29974493 0.29115746 0.30118958 0.33140716] -> mean_test = 0.3005\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.39371228 0.38799135 0.39360352 0.39383614 0.39987173] -> mean_train = 0.3938\n",
      "Test scores: [0.38300769 0.35232374 0.37767527 0.37743098 0.35830092] -> mean_test = 0.3697\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.42371335 0.4146264  0.42294396 0.42536268 0.42076352] -> mean_train = 0.4215\n",
      "Test scores: [0.37103912 0.37512818 0.38437575 0.3865769  0.40484428] -> mean_test = 0.3844\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.43373677 0.43318539 0.43969612 0.43861505 0.43600294] -> mean_train = 0.4362\n",
      "Test scores: [0.41054996 0.3655078  0.38919964 0.39444717 0.36578661] -> mean_test = 0.3851\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for RandomForestRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.86762202 0.86455812 0.86756847 0.8654831  0.86635326] -> mean_train = 0.8663\n",
      "Test scores: [0.46893692 0.47474253 0.47183767 0.47635708 0.46603657] -> mean_test = 0.4716\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.86865287 0.8708922  0.86909876 0.86407208 0.87073908] -> mean_train = 0.8687\n",
      "Test scores: [0.48321788 0.4651082  0.48409388 0.51644364 0.45168042] -> mean_test = 0.4801\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.86692848 0.86931937 0.86943738 0.86686052 0.87293123] -> mean_train = 0.8691\n",
      "Test scores: [0.4851075  0.48528567 0.49189294 0.52378137 0.46479614] -> mean_test = 0.4902\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.86701671 0.86933204 0.87158342 0.86787022 0.87067643] -> mean_train = 0.8693\n",
      "Test scores: [0.50926646 0.47984863 0.4709283  0.48995825 0.4742135 ] -> mean_test = 0.4848\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for SVR using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.27768877 0.28164607 0.27543778 0.28223729 0.27169098] -> mean_train = 0.2777\n",
      "Test scores: [0.27372642 0.26373777 0.28260736 0.2527845  0.28642668] -> mean_test = 0.2719\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.26833298 0.26359706 0.26154189 0.26092158 0.27139692] -> mean_train = 0.2652\n",
      "Test scores: [0.25027263 0.26140355 0.27630936 0.2633784  0.24690274] -> mean_test = 0.2597\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.25604641 0.2557586  0.2542764  0.26941398 0.26639608] -> mean_train = 0.2604\n",
      "Test scores: [0.26574554 0.25771847 0.27268954 0.23138731 0.24560992] -> mean_test = 0.2546\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.25269249 0.25810787 0.25484969 0.25800937 0.26009149] -> mean_train = 0.2568\n",
      "Test scores: [0.25179683 0.25459869 0.26067716 0.24756907 0.23981551] -> mean_test = 0.2509\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for MLPRegressor using Pearson correlation to select features...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 200 best features\n",
      "Train scores: [0.52105186 0.51666136 0.51690926 0.52675541 0.52715188] -> mean_train = 0.5217\n",
      "Test scores: [0.43688842 0.45549741 0.42600597 0.45694164 0.44466639] -> mean_test = 0.4440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 400 best features\n",
      "Train scores: [0.46204741 0.49887642 0.4694671  0.45133553 0.50712451] -> mean_train = 0.4778\n",
      "Test scores: [0.42765406 0.46299803 0.43444477 0.43355555 0.45313489] -> mean_test = 0.4424\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 600 best features\n",
      "Train scores: [0.50828932 0.48730197 0.53997773 0.52672009 0.51295359] -> mean_train = 0.5150\n",
      "Test scores: [0.48259759 0.42385795 0.48960782 0.47330764 0.47066749] -> mean_test = 0.4680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 800 best features\n",
      "Train scores: [0.55768337 0.53201379 0.57710713 0.54583701 0.53376656] -> mean_train = 0.5493\n",
      "Test scores: [0.50072421 0.44872076 0.47927216 0.48096196 0.48445523] -> mean_test = 0.4788\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for AdaBoostRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.30878064 0.31747994 0.2821283  0.33309379 0.30994882] -> mean_train = 0.3103\n",
      "Test scores: [0.31653165 0.28572524 0.27650359 0.31991506 0.28990877] -> mean_test = 0.2977\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.31737068 0.33604038 0.30093692 0.30342464 0.29648123] -> mean_train = 0.3109\n",
      "Test scores: [0.3274757  0.33384534 0.29182668 0.27977979 0.28082602] -> mean_test = 0.3028\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.31718018 0.28876691 0.30003358 0.29836457 0.32519596] -> mean_train = 0.3059\n",
      "Test scores: [0.29306934 0.26952092 0.28428521 0.30487058 0.31365367] -> mean_test = 0.2931\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.28814453 0.30092214 0.32320997 0.28723039 0.34017101] -> mean_train = 0.3079\n",
      "Test scores: [0.26270269 0.30130176 0.30585807 0.27255919 0.32357272] -> mean_test = 0.2932\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.61760073 0.61823471 0.62163874 0.62513078 0.62371354] -> mean_train = 0.6213\n",
      "Test scores: [0.52983723 0.53351532 0.51879814 0.49154409 0.50710966] -> mean_test = 0.5162\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.65205709 0.64711572 0.64902128 0.65037379 0.65255898] -> mean_train = 0.6502\n",
      "Test scores: [0.52083674 0.54288122 0.55053516 0.52329081 0.5269    ] -> mean_test = 0.5329\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.6641068  0.66170629 0.66909358 0.64717522 0.66185312] -> mean_train = 0.6608\n",
      "Test scores: [0.5458077  0.55594568 0.51133182 0.54347462 0.54799937] -> mean_test = 0.5409\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.66427657 0.66246132 0.65999607 0.66341141 0.67036066] -> mean_train = 0.6641\n",
      "Test scores: [0.54249578 0.54910128 0.52700264 0.54868719 0.52947596] -> mean_test = 0.5394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, Model in enumerate([LR, RFR, SVR, MLPR, ADA, HGBR]):\n",
    "    test_corr_models(model=Model(), method=\"Pearson correlation\", corrs=pearson_corrs)\n",
    "    if i < 5:\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ae4c5-0eeb-46ef-940a-4b06c9f39f43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(BEFORE UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.27011736 0.28650022 0.22313226 0.26490225 0.26940456] -> mean_train = 0.2628\n",
    "Test scores: [0.14711361 0.10705096 0.27218331 0.20173697 0.18240789] -> mean_test = 0.1821\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.41665499 0.39386691 0.3850985  0.39537238 0.41242381] -> mean_train = 0.4007\n",
    "Test scores: [0.08573871 0.2893108  0.33210872 0.30932031 0.1514813 ] -> mean_test = 0.2336\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.44620921 0.43236111 0.43381858 0.43981191 0.4531923 ] -> mean_train = 0.4411\n",
    "Test scores: [0.06293847 0.27328139 0.33204977 0.30332439 0.17662368] -> mean_test = 0.2296\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.47941186 0.45920366 0.44087096 0.46595271 0.46848766] -> mean_train = 0.4628\n",
    "Test scores: [0.08041124 0.27869326 0.287661   0.29106935 0.1168009 ] -> mean_test = 0.2109\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.81861813 0.84025213 0.85172038 0.81723961 0.82355589] -> mean_train = 0.8303\n",
    "Test scores: [0.22094994 0.23278113 0.25640221 0.31260307 0.2571411 ] -> mean_test = 0.2560\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.84739424 0.86756812 0.87518231 0.84538561 0.85187832] -> mean_train = 0.8575\n",
    "Test scores: [0.23421498 0.35857337 0.24336712 0.36769986 0.31232961] -> mean_test = 0.3032\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.84771979 0.86827125 0.87595901 0.8461804  0.85253105] -> mean_train = 0.8581\n",
    "Test scores: [0.22143367 0.32069786 0.19008172 0.38143426 0.31148471] -> mean_test = 0.2850\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.87676433 0.90002164 0.89224492 0.87385361 0.87793775] -> mean_train = 0.8842\n",
    "Test scores: [0.27083525 0.33920909 0.20056345 0.38527337 0.27747011] -> mean_test = 0.2947\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.21789023 0.24789051 0.1688259  0.1946165  0.24299579] -> mean_train = 0.2144\n",
    "Test scores: [0.0217743  0.0393838  0.06749173 0.11066504 0.1454537 ] -> mean_test = 0.0770\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.32242365 0.32898748 0.27168506 0.28805197 0.30137941] -> mean_train = 0.3025\n",
    "Test scores: [0.12702293 0.20443145 0.13614342 0.22957511 0.14922126] -> mean_test = 0.1693\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.29640638 0.31946727 0.28776308 0.29008702 0.32292222] -> mean_train = 0.3033\n",
    "Test scores: [0.09409807 0.17705651 0.13124845 0.21650374 0.18319332] -> mean_test = 0.1604\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.30405968 0.21448556 0.23909915 0.28300452 0.30514278] -> mean_train = 0.2692\n",
    "Test scores: [0.07639932 0.08501833 0.0728567  0.18245674 0.12884878] -> mean_test = 0.1091\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.31371592 0.31834536 0.3022404  0.31092042 0.31666435] -> mean_train = 0.3124\n",
    "Test scores: [0.21283891 0.16427215 0.07069547 0.25263497 0.24485791] -> mean_test = 0.1891\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.28378963 0.26807723 0.24905719 0.26710835 0.28725249] -> mean_train = 0.2711\n",
    "Test scores: [0.18274096 0.15177209 0.24838459 0.22915948 0.18186443] -> mean_test = 0.1988\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.27629772 0.25743841 0.23863574 0.26184484 0.27565766] -> mean_train = 0.2620\n",
    "Test scores: [0.17035563 0.15027543 0.22394396 0.19866285 0.16760289] -> mean_test = 0.1822\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.26972242 0.25406078 0.23311293 0.25886046 0.27116362] -> mean_train = 0.2574\n",
    "Test scores: [0.16767649 0.14030832 0.19821048 0.1878921  0.1576652 ] -> mean_test = 0.1704\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.45202777 0.43871447 0.45321541 0.45765465 0.45912327] -> mean_train = 0.4521\n",
    "Test scores: [ 0.2031334   0.16033084 -0.08987277  0.2116972   0.15462226] -> mean_test = 0.1280\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.47475198 0.4923954  0.50451639 0.50400392 0.47938821] -> mean_train = 0.4910\n",
    "Test scores: [0.23719782 0.36519414 0.2931955  0.35681098 0.23217787] -> mean_test = 0.2969\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.55805531 0.56752787 0.54657214 0.52045875 0.54403841] -> mean_train = 0.5473\n",
    "Test scores: [0.14783581 0.36859843 0.27241315 0.3401092  0.34026483] -> mean_test = 0.2938\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.60004007 0.60734283 0.6379186  0.53613144 0.58864283] -> mean_train = 0.5940\n",
    "Test scores: [0.18884443 0.32031392 0.36322389 0.28063518 0.31413352] -> mean_test = 0.2934\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(Z-scores)\n",
    "\n",
    "Getting results for LinearRegression using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.67160102 0.6689632  0.68186929 0.66149608 0.67386646] -> mean_train = 0.6716\n",
    "Test scores: [-1.07791337 -0.18159527 -0.02480662 -0.27529876 -1.04734993] -> mean_test = -0.5214\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.67160102 0.6689632  0.68186929 0.66149608 0.67386646] -> mean_train = 0.6716\n",
    "Test scores: [-1.07791337 -0.18159527 -0.02480662 -0.27529876 -1.04734993] -> mean_test = -0.5214\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.67160102 0.6689632  0.68186929 0.66149608 0.67386646] -> mean_train = 0.6716\n",
    "Test scores: [-1.07791337 -0.18159527 -0.02480662 -0.27529876 -1.04734993] -> mean_test = -0.5214\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.80727911 0.83041557 0.84220175 0.80666646 0.81338696] -> mean_train = 0.8200\n",
    "Test scores: [0.1891794  0.18649405 0.18417251 0.27658475 0.22553633] -> mean_test = 0.2124\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.84161805 0.86398035 0.86833273 0.84003347 0.84644822] -> mean_train = 0.8521\n",
    "Test scores: [0.19887344 0.31872482 0.23552122 0.35482832 0.28120151] -> mean_test = 0.2778\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.84235855 0.86518026 0.86934521 0.8409079  0.84660065] -> mean_train = 0.8529\n",
    "Test scores: [0.18125953 0.29988959 0.12022268 0.3604441  0.2963378 ] -> mean_test = 0.2516\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.24087864 0.23950204 0.16925286 0.19086963 0.25147329] -> mean_train = 0.2184\n",
    "Test scores: [0.08491198 0.0297712  0.16957604 0.10801696 0.14612454] -> mean_test = 0.1077\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.29832073 0.31678918 0.27567914 0.30577065 0.30121334] -> mean_train = 0.2996\n",
    "Test scores: [0.0998887  0.18089942 0.15771938 0.25511451 0.15684757] -> mean_test = 0.1701\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.34946497 0.26841796 0.33437571 0.29196208 0.33172762] -> mean_train = 0.3152\n",
    "Test scores: [0.1768113  0.12819227 0.15462779 0.20862672 0.19958328] -> mean_test = 0.1736\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.3470447  0.34487087 0.35734174 0.34269595 0.35251758] -> mean_train = 0.3489\n",
    "Test scores: [0.18790998 0.14018134 0.10888095 0.225853   0.22270535] -> mean_test = 0.1771\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.40986956 0.39526794 0.41410988 0.39641576 0.41763621] -> mean_train = 0.4067\n",
    "Test scores: [0.206643   0.18902751 0.11136261 0.27958821 0.22978204] -> mean_test = 0.2033\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.42662508 0.4044915  0.4269925  0.40696331 0.42792255] -> mean_train = 0.4186\n",
    "Test scores: [0.20535089 0.19830048 0.1409307  0.28567528 0.23900059] -> mean_test = 0.2139\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Pearson correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.53202    0.52313445 0.57137021 0.53976422 0.54659028] -> mean_train = 0.5426\n",
    "Test scores: [-0.05543219  0.1250431   0.2640586   0.1859917   0.05506732] -> mean_test = 0.1149\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.78213761 0.78802413 0.82398603 0.7461426  0.77420503] -> mean_train = 0.7829\n",
    "Test scores: [-0.17832807  0.17922449 -0.82818129  0.17095727 -0.17155348] -> mean_test = -0.1656\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.65240063 0.81298679 0.85650392 0.80202072 0.81944741] -> mean_train = 0.7887\n",
    "Test scores: [-0.3428903   0.13659494 -6.15435645  0.14391498 -0.25913343] -> mean_test = -1.2952\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6784a-af1b-4d05-8eef-846d2b503d79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.31830325 0.31392415 0.31633945 0.31182916 0.3066358 ] -> mean_train = 0.3134\n",
    "Test scores: [0.27919092 0.29974493 0.29115746 0.30118958 0.33140716] -> mean_test = 0.3005\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.39371228 0.38799135 0.39360352 0.39383614 0.39987173] -> mean_train = 0.3938\n",
    "Test scores: [0.38300769 0.35232374 0.37767527 0.37743098 0.35830092] -> mean_test = 0.3697\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.42371335 0.4146264  0.42294396 0.42536268 0.42076352] -> mean_train = 0.4215\n",
    "Test scores: [0.37103912 0.37512818 0.38437575 0.3865769  0.40484428] -> mean_test = 0.3844\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.43373677 0.43318539 0.43969612 0.43861505 0.43600294] -> mean_train = 0.4362\n",
    "Test scores: [0.41054996 0.3655078  0.38919964 0.39444717 0.36578661] -> mean_test = 0.3851\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.86762202 0.86455812 0.86756847 0.8654831  0.86635326] -> mean_train = 0.8663\n",
    "Test scores: [0.46893692 0.47474253 0.47183767 0.47635708 0.46603657] -> mean_test = 0.4716\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.86865287 0.8708922  0.86909876 0.86407208 0.87073908] -> mean_train = 0.8687\n",
    "Test scores: [0.48321788 0.4651082  0.48409388 0.51644364 0.45168042] -> mean_test = 0.4801\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.86692848 0.86931937 0.86943738 0.86686052 0.87293123] -> mean_train = 0.8691\n",
    "Test scores: [0.4851075  0.48528567 0.49189294 0.52378137 0.46479614] -> mean_test = 0.4902\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.86701671 0.86933204 0.87158342 0.86787022 0.87067643] -> mean_train = 0.8693\n",
    "Test scores: [0.50926646 0.47984863 0.4709283  0.48995825 0.4742135 ] -> mean_test = 0.4848\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.27768877 0.28164607 0.27543778 0.28223729 0.27169098] -> mean_train = 0.2777\n",
    "Test scores: [0.27372642 0.26373777 0.28260736 0.2527845  0.28642668] -> mean_test = 0.2719\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.26833298 0.26359706 0.26154189 0.26092158 0.27139692] -> mean_train = 0.2652\n",
    "Test scores: [0.25027263 0.26140355 0.27630936 0.2633784  0.24690274] -> mean_test = 0.2597\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.25604641 0.2557586  0.2542764  0.26941398 0.26639608] -> mean_train = 0.2604\n",
    "Test scores: [0.26574554 0.25771847 0.27268954 0.23138731 0.24560992] -> mean_test = 0.2546\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.25269249 0.25810787 0.25484969 0.25800937 0.26009149] -> mean_train = 0.2568\n",
    "Test scores: [0.25179683 0.25459869 0.26067716 0.24756907 0.23981551] -> mean_test = 0.2509\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.52105186 0.51666136 0.51690926 0.52675541 0.52715188] -> mean_train = 0.5217\n",
    "Test scores: [0.43688842 0.45549741 0.42600597 0.45694164 0.44466639] -> mean_test = 0.4440\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.46204741 0.49887642 0.4694671  0.45133553 0.50712451] -> mean_train = 0.4778\n",
    "Test scores: [0.42765406 0.46299803 0.43444477 0.43355555 0.45313489] -> mean_test = 0.4424\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.50828932 0.48730197 0.53997773 0.52672009 0.51295359] -> mean_train = 0.5150\n",
    "Test scores: [0.48259759 0.42385795 0.48960782 0.47330764 0.47066749] -> mean_test = 0.4680\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.55768337 0.53201379 0.57710713 0.54583701 0.53376656] -> mean_train = 0.5493\n",
    "Test scores: [0.50072421 0.44872076 0.47927216 0.48096196 0.48445523] -> mean_test = 0.4788\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.30878064 0.31747994 0.2821283  0.33309379 0.30994882] -> mean_train = 0.3103\n",
    "Test scores: [0.31653165 0.28572524 0.27650359 0.31991506 0.28990877] -> mean_test = 0.2977\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.31737068 0.33604038 0.30093692 0.30342464 0.29648123] -> mean_train = 0.3109\n",
    "Test scores: [0.3274757  0.33384534 0.29182668 0.27977979 0.28082602] -> mean_test = 0.3028\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.31718018 0.28876691 0.30003358 0.29836457 0.32519596] -> mean_train = 0.3059\n",
    "Test scores: [0.29306934 0.26952092 0.28428521 0.30487058 0.31365367] -> mean_test = 0.2931\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.28814453 0.30092214 0.32320997 0.28723039 0.34017101] -> mean_train = 0.3079\n",
    "Test scores: [0.26270269 0.30130176 0.30585807 0.27255919 0.32357272] -> mean_test = 0.2932\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.61760073 0.61823471 0.62163874 0.62513078 0.62371354] -> mean_train = 0.6213\n",
    "Test scores: [0.52983723 0.53351532 0.51879814 0.49154409 0.50710966] -> mean_test = 0.5162\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.65205709 0.64711572 0.64902128 0.65037379 0.65255898] -> mean_train = 0.6502\n",
    "Test scores: [0.52083674 0.54288122 0.55053516 0.52329081 0.5269    ] -> mean_test = 0.5329\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.6641068  0.66170629 0.66909358 0.64717522 0.66185312] -> mean_train = 0.6608\n",
    "Test scores: [0.5458077  0.55594568 0.51133182 0.54347462 0.54799937] -> mean_test = 0.5409\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.66427657 0.66246132 0.65999607 0.66341141 0.67036066] -> mean_train = 0.6641\n",
    "Test scores: [0.54249578 0.54910128 0.52700264 0.54868719 0.52947596] -> mean_test = 0.5394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32293ce6-597d-40f9-a8b4-d9bcbf06671f",
   "metadata": {},
   "source": [
    "<b>Pearson</b> (further testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25586e2a-f437-4ee5-be32-ecd60fa5a41c",
   "metadata": {},
   "source": [
    "Novos testes para um novo modelo (<b>KNeighborsRegressor</b>) e para uma gama de features distinta da anterior (para os modelos <b>SVR</b>, <b>MLPRegressor</b> e <b>HistGradientBoostingRegressor</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "042156fd-b2f6-4b19-b465-da540458166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for KNeighborsRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.58503702 0.58997743 0.59379933 0.58816645 0.58779664] -> mean_train = 0.5890\n",
      "Test scores: [0.3928789  0.36819901 0.36770372 0.38222477 0.39573199] -> mean_test = 0.3813\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.61136161 0.60893551 0.60805813 0.61107387 0.60937698] -> mean_train = 0.6098\n",
      "Test scores: [0.41522946 0.427479   0.40978524 0.41295209 0.41445057] -> mean_test = 0.4160\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.61533186 0.61624814 0.61941333 0.6153637  0.62533147] -> mean_train = 0.6183\n",
      "Test scores: [0.43304784 0.4479805  0.43914913 0.43093723 0.39303128] -> mean_test = 0.4288\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.6232438  0.6171689  0.62247578 0.61839789 0.62404356] -> mean_train = 0.6211\n",
      "Test scores: [0.41433254 0.43647186 0.4307311  0.4435146  0.42248312] -> mean_test = 0.4295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=KNR(), method=\"Pearson correlation\", corrs=pearson_corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d328182-3745-4e7c-be32-260198b7c5ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for KNeighborsRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.58503702 0.58997743 0.59379933 0.58816645 0.58779664] -> mean_train = 0.5890\n",
    "Test scores: [0.3928789  0.36819901 0.36770372 0.38222477 0.39573199] -> mean_test = 0.3813\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.61136161 0.60893551 0.60805813 0.61107387 0.60937698] -> mean_train = 0.6098\n",
    "Test scores: [0.41522946 0.427479   0.40978524 0.41295209 0.41445057] -> mean_test = 0.4160\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.61533186 0.61624814 0.61941333 0.6153637  0.62533147] -> mean_train = 0.6183\n",
    "Test scores: [0.43304784 0.4479805  0.43914913 0.43093723 0.39303128] -> mean_test = 0.4288\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.6232438  0.6171689  0.62247578 0.61839789 0.62404356] -> mean_train = 0.6211\n",
    "Test scores: [0.41433254 0.43647186 0.4307311  0.4435146  0.42248312] -> mean_test = 0.4295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e70e8d9-f390-421a-af19-b18bc6c407de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for SVR using Pearson correlation to select features...\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.25385633 0.24365601 0.24720895 0.2442057  0.25017659] -> mean_train = 0.2478\n",
      "Test scores: [0.22252446 0.23985421 0.24987935 0.2456937  0.24385969] -> mean_test = 0.2404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=SVR(), method=\"Pearson correlation\", corrs=pearson_corrs, num_feats=[2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595ca00-3bd1-4027-ba34-a5b690d244d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for SVR using Pearson correlation to select features...\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.25385633 0.24365601 0.24720895 0.2442057  0.25017659] -> mean_train = 0.2478\n",
    "Test scores: [0.22252446 0.23985421 0.24987935 0.2456937  0.24385969] -> mean_test = 0.2404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37b20309-bb1a-4a43-9a3d-4fff5ec4a8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for MLPRegressor using Pearson correlation to select features...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1000 best features\n",
      "Train scores: [0.56490654 0.55768887 0.55608917 0.55828499 0.52461717] -> mean_train = 0.5523\n",
      "Test scores: [0.46331716 0.46617747 0.48015719 0.49865836 0.47098379] -> mean_test = 0.4759\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 1200 best features\n",
      "Train scores: [0.60046975 0.62332129 0.58112659 0.60393118 0.58597108] -> mean_train = 0.5990\n",
      "Test scores: [0.46578919 0.49174316 0.497005   0.47763045 0.49677766] -> mean_test = 0.4858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonioduarte/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=MLPR(), method=\"Pearson correlation\", corrs=pearson_corrs, num_feats=[1000, 1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dbcdbc-0d48-4125-8b3a-eb0695cbbfb7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for MLPRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.56490654 0.55768887 0.55608917 0.55828499 0.52461717] -> mean_train = 0.5523\n",
    "Test scores: [0.46331716 0.46617747 0.48015719 0.49865836 0.47098379] -> mean_test = 0.4759\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.60046975 0.62332129 0.58112659 0.60393118 0.58597108] -> mean_train = 0.5990\n",
    "Test scores: [0.46578919 0.49174316 0.497005   0.47763045 0.49677766] -> mean_test = 0.4858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d32bc681-3c20-4137-9bba-4b133540f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for HistGradientBoostingRegressor using Pearson correlation to select features...\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.66663238 0.66909042 0.66829338 0.64459554 0.64295293] -> mean_train = 0.6583\n",
      "Test scores: [0.5530253  0.53940209 0.53295276 0.53978152 0.52986614] -> mean_test = 0.5390\n",
      "\n",
      "Results for 900 best features\n",
      "Train scores: [0.65743789 0.66979245 0.66498664 0.6695574  0.66648605] -> mean_train = 0.6657\n",
      "Test scores: [0.52125799 0.53635422 0.54399451 0.55205156 0.55057303] -> mean_test = 0.5408\n",
      "\n",
      "Results for 1000 best features\n",
      "Train scores: [0.66787554 0.67396278 0.67286435 0.66773249 0.66925989] -> mean_train = 0.6703\n",
      "Test scores: [0.54568328 0.52206459 0.53540264 0.55007844 0.54338797] -> mean_test = 0.5393\n",
      "\n",
      "Results for 1100 best features\n",
      "Train scores: [0.69352346 0.6948638  0.68931223 0.69610607 0.68214437] -> mean_train = 0.6912\n",
      "Test scores: [0.57321944 0.57223914 0.59692036 0.55132183 0.55748441] -> mean_test = 0.5702\n",
      "\n",
      "Results for 1200 best features\n",
      "Train scores: [0.69206243 0.69502702 0.69416212 0.69338847 0.6969137 ] -> mean_train = 0.6943\n",
      "Test scores: [0.57839476 0.57089618 0.58192688 0.57475982 0.55218899] -> mean_test = 0.5716\n",
      "\n",
      "Results for 1300 best features\n",
      "Train scores: [0.69576919 0.69370551 0.69591981 0.69425998 0.67655226] -> mean_train = 0.6912\n",
      "Test scores: [0.5726625  0.57750318 0.56965538 0.57275846 0.56328342] -> mean_test = 0.5712\n",
      "\n",
      "Results for 1400 best features\n",
      "Train scores: [0.6912309  0.69517008 0.69510343 0.69311147 0.68308284] -> mean_train = 0.6915\n",
      "Test scores: [0.5802304  0.56588862 0.56999854 0.57888254 0.54718202] -> mean_test = 0.5684\n",
      "\n",
      "Results for 1500 best features\n",
      "Train scores: [0.69648327 0.69624902 0.69995392 0.69291142 0.68118336] -> mean_train = 0.6934\n",
      "Test scores: [0.56878518 0.56883332 0.55616613 0.59378321 0.58255785] -> mean_test = 0.5740\n",
      "\n",
      "Results for 1600 best features\n",
      "Train scores: [0.69645181 0.65683526 0.70009776 0.69207575 0.69738217] -> mean_train = 0.6886\n",
      "Test scores: [0.55683351 0.57472355 0.55793864 0.58730223 0.57331733] -> mean_test = 0.5700\n",
      "\n",
      "Results for 1700 best features\n",
      "Train scores: [0.68402266 0.67682186 0.69298539 0.69737798 0.69693916] -> mean_train = 0.6896\n",
      "Test scores: [0.59166452 0.55001258 0.57317637 0.55063248 0.56945549] -> mean_test = 0.5670\n",
      "\n",
      "Results for 1800 best features\n",
      "Train scores: [0.69636665 0.69543724 0.6926872  0.69620411 0.69621706] -> mean_train = 0.6954\n",
      "Test scores: [0.56216641 0.57699126 0.56875645 0.57260295 0.5738527 ] -> mean_test = 0.5709\n",
      "\n",
      "Results for 1900 best features\n",
      "Train scores: [0.69199944 0.69749367 0.69985996 0.69853    0.69549178] -> mean_train = 0.6967\n",
      "Test scores: [0.5899744  0.56577578 0.5450411  0.5664836  0.57838029] -> mean_test = 0.5691\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.69645712 0.67113174 0.69395222 0.69647604 0.6989796 ] -> mean_train = 0.6914\n",
      "Test scores: [0.57832126 0.58382683 0.57307968 0.57548771 0.5519819 ] -> mean_test = 0.5725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=HGBR(), method=\"Pearson correlation\", corrs=pearson_corrs, num_feats=range(800, 2001, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875ef8c-bff5-49db-bf40-1082b60c5830",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using Pearson correlation to select features...\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.66663238 0.66909042 0.66829338 0.64459554 0.64295293] -> mean_train = 0.6583\n",
    "Test scores: [0.5530253  0.53940209 0.53295276 0.53978152 0.52986614] -> mean_test = 0.5390\n",
    "\n",
    "Results for 900 best features\n",
    "Train scores: [0.65743789 0.66979245 0.66498664 0.6695574  0.66648605] -> mean_train = 0.6657\n",
    "Test scores: [0.52125799 0.53635422 0.54399451 0.55205156 0.55057303] -> mean_test = 0.5408\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.66787554 0.67396278 0.67286435 0.66773249 0.66925989] -> mean_train = 0.6703\n",
    "Test scores: [0.54568328 0.52206459 0.53540264 0.55007844 0.54338797] -> mean_test = 0.5393\n",
    "\n",
    "Results for 1100 best features\n",
    "Train scores: [0.69352346 0.6948638  0.68931223 0.69610607 0.68214437] -> mean_train = 0.6912\n",
    "Test scores: [0.57321944 0.57223914 0.59692036 0.55132183 0.55748441] -> mean_test = 0.5702\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.69206243 0.69502702 0.69416212 0.69338847 0.6969137 ] -> mean_train = 0.6943\n",
    "Test scores: [0.57839476 0.57089618 0.58192688 0.57475982 0.55218899] -> mean_test = 0.5716\n",
    "\n",
    "Results for 1300 best features\n",
    "Train scores: [0.69576919 0.69370551 0.69591981 0.69425998 0.67655226] -> mean_train = 0.6912\n",
    "Test scores: [0.5726625  0.57750318 0.56965538 0.57275846 0.56328342] -> mean_test = 0.5712\n",
    "\n",
    "Results for 1400 best features\n",
    "Train scores: [0.6912309  0.69517008 0.69510343 0.69311147 0.68308284] -> mean_train = 0.6915\n",
    "Test scores: [0.5802304  0.56588862 0.56999854 0.57888254 0.54718202] -> mean_test = 0.5684\n",
    "\n",
    "Results for 1500 best features\n",
    "Train scores: [0.69648327 0.69624902 0.69995392 0.69291142 0.68118336] -> mean_train = 0.6934\n",
    "Test scores: [0.56878518 0.56883332 0.55616613 0.59378321 0.58255785] -> mean_test = 0.5740\n",
    "\n",
    "Results for 1600 best features\n",
    "Train scores: [0.69645181 0.65683526 0.70009776 0.69207575 0.69738217] -> mean_train = 0.6886\n",
    "Test scores: [0.55683351 0.57472355 0.55793864 0.58730223 0.57331733] -> mean_test = 0.5700\n",
    "\n",
    "Results for 1700 best features\n",
    "Train scores: [0.68402266 0.67682186 0.69298539 0.69737798 0.69693916] -> mean_train = 0.6896\n",
    "Test scores: [0.59166452 0.55001258 0.57317637 0.55063248 0.56945549] -> mean_test = 0.5670\n",
    "\n",
    "Results for 1800 best features\n",
    "Train scores: [0.69636665 0.69543724 0.6926872  0.69620411 0.69621706] -> mean_train = 0.6954\n",
    "Test scores: [0.56216641 0.57699126 0.56875645 0.57260295 0.5738527 ] -> mean_test = 0.5709\n",
    "\n",
    "Results for 1900 best features\n",
    "Train scores: [0.69199944 0.69749367 0.69985996 0.69853    0.69549178] -> mean_train = 0.6967\n",
    "Test scores: [0.5899744  0.56577578 0.5450411  0.5664836  0.57838029] -> mean_test = 0.5691\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.69645712 0.67113174 0.69395222 0.69647604 0.6989796 ] -> mean_train = 0.6914\n",
    "Test scores: [0.57832126 0.58382683 0.57307968 0.57548771 0.5519819 ] -> mean_test = 0.5725"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6297b9a-6268-4433-b3af-6d56498ce72d",
   "metadata": {},
   "source": [
    "Para este método de seleção de features (<b>correlação de Pearson</b>) obtivemos um score máximo de <b>0.5740</b> para a combinação <b>HistGradientBoostingRegressor / 1500 features</b>. No entanto, selecionámos a combinação <b>HistGradientBoostingRegressor / 1200 features </b> por se encontrar numa região mais estável no espaço de procura do número de features ótimo. Neste caso, o score obtido foi <b>0.5716</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aba4df-9491-439c-a2f9-185237f4cac4",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca67e625-89da-4e16-a524-be56c7afb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings -> MLPR related\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0042a47-91d1-4508-9b9b-bd500b38bb57",
   "metadata": {},
   "source": [
    "<b>Spearman</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1d76400-cfd1-471f-bee0-c1a2df54e35e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.30276032 0.30999642 0.29627182 0.30485768 0.30062867] -> mean_train = 0.3029\n",
      "Test scores: [0.29231614 0.26266536 0.31845467 0.28441096 0.30099507] -> mean_test = 0.2918\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.38744808 0.38428109 0.3826784  0.33979449 0.38501327] -> mean_train = 0.3758\n",
      "Test scores: [0.3538583  0.36657723 0.33417186 0.30842076 0.36367539] -> mean_test = 0.3453\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.41855357 0.41669686 0.41262532 0.41615306 0.42218293] -> mean_train = 0.4172\n",
      "Test scores: [0.37755745 0.38235578 0.39904554 0.39122124 0.34962146] -> mean_test = 0.3800\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.43666678 0.42842225 0.43421242 0.43776558 0.43959521] -> mean_train = 0.4353\n",
      "Test scores: [0.39523955 0.38230352 0.37197668 0.39334337 0.39326577] -> mean_test = 0.3872\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for KNeighborsRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.58144722 0.56791155 0.57262067 0.57422373 0.57555677] -> mean_train = 0.5744\n",
      "Test scores: [0.34116207 0.38116106 0.36167522 0.36244282 0.34761941] -> mean_test = 0.3588\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.60354152 0.60200782 0.6085737  0.60455412 0.59745753] -> mean_train = 0.6032\n",
      "Test scores: [0.41038186 0.41923013 0.36877787 0.39774969 0.43388593] -> mean_test = 0.4060\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.61668517 0.61529299 0.61350762 0.61218549 0.62025389] -> mean_train = 0.6156\n",
      "Test scores: [0.40996733 0.42958298 0.45250813 0.42477277 0.39997428] -> mean_test = 0.4234\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.60642041 0.60735275 0.61471306 0.60815288 0.61213709] -> mean_train = 0.6098\n",
      "Test scores: [0.42858132 0.42051792 0.41496123 0.4170616  0.42208561] -> mean_test = 0.4206\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for RandomForestRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.86286666 0.86327227 0.86515871 0.86526029 0.86058221] -> mean_train = 0.8634\n",
      "Test scores: [0.45806815 0.45428154 0.43739402 0.44168913 0.47137121] -> mean_test = 0.4526\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.86659924 0.86960868 0.8664068  0.87180788 0.86824758] -> mean_train = 0.8685\n",
      "Test scores: [0.50130257 0.48736882 0.50682832 0.46481167 0.47564835] -> mean_test = 0.4872\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.87154669 0.86740715 0.8687975  0.86999956 0.86789773] -> mean_train = 0.8691\n",
      "Test scores: [0.47269618 0.49320745 0.49477457 0.49530748 0.48645884] -> mean_test = 0.4885\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.86992188 0.86863113 0.86980674 0.86922954 0.86885264] -> mean_train = 0.8693\n",
      "Test scores: [0.47346002 0.48232316 0.49540531 0.48162644 0.48545635] -> mean_test = 0.4837\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for SVR using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.27542999 0.2723476  0.27631393 0.2772708  0.28241463] -> mean_train = 0.2768\n",
      "Test scores: [0.28283144 0.28564874 0.25955313 0.26985495 0.2524273 ] -> mean_test = 0.2701\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.25050722 0.24563219 0.24316983 0.24466171 0.25483817] -> mean_train = 0.2478\n",
      "Test scores: [0.22647406 0.24715775 0.24966636 0.2546818  0.23105567] -> mean_test = 0.2418\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.24899087 0.24717708 0.24506422 0.24771682 0.24762889] -> mean_train = 0.2473\n",
      "Test scores: [0.24235095 0.22966731 0.26202853 0.2312249  0.24195584] -> mean_test = 0.2414\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.24881949 0.26274852 0.25277209 0.25090909 0.25622489] -> mean_train = 0.2543\n",
      "Test scores: [0.26830012 0.2200019  0.24973791 0.26164309 0.24226996] -> mean_test = 0.2484\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for MLPRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.55277466 0.55306357 0.54210614 0.47871056 0.58166296] -> mean_train = 0.5417\n",
      "Test scores: [0.43527307 0.42055891 0.43856691 0.32758635 0.40498687] -> mean_test = 0.4054\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.52406768 0.53170162 0.55011785 0.52939447 0.50005963] -> mean_train = 0.5271\n",
      "Test scores: [0.47915438 0.47292983 0.48500241 0.46352347 0.45960753] -> mean_test = 0.4720\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.5295686  0.48546583 0.52897515 0.53093441 0.51876645] -> mean_train = 0.5187\n",
      "Test scores: [0.46535184 0.44473846 0.46850541 0.4922603  0.44927276] -> mean_test = 0.4640\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.53871824 0.55747297 0.56545089 0.51894987 0.56946029] -> mean_train = 0.5500\n",
      "Test scores: [0.47679662 0.48825781 0.4961454  0.43920372 0.47527757] -> mean_test = 0.4751\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for AdaBoostRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.27077418 0.28118372 0.28132986 0.27185248 0.28699682] -> mean_train = 0.2784\n",
      "Test scores: [0.29456676 0.27699162 0.2566113  0.24467112 0.27629458] -> mean_test = 0.2698\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.30250501 0.29647762 0.32411476 0.34112609 0.29839447] -> mean_train = 0.3125\n",
      "Test scores: [0.29654511 0.28648838 0.30943204 0.32816846 0.28505545] -> mean_test = 0.3011\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.27707697 0.29286917 0.29149421 0.27581087 0.30896063] -> mean_train = 0.2892\n",
      "Test scores: [0.27402579 0.28327587 0.25670492 0.27295977 0.29208173] -> mean_test = 0.2758\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.29183765 0.2888603  0.30779433 0.28695369 0.31408741] -> mean_train = 0.2979\n",
      "Test scores: [0.25761796 0.29439967 0.29200319 0.28608114 0.30552038] -> mean_test = 0.2871\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.60516408 0.5987729  0.60463261 0.60686439 0.60086074] -> mean_train = 0.6033\n",
      "Test scores: [0.49752306 0.51061865 0.49868967 0.50033296 0.52337996] -> mean_test = 0.5061\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.65131722 0.64860272 0.64927219 0.65068186 0.6526421 ] -> mean_train = 0.6505\n",
      "Test scores: [0.53977152 0.53134494 0.54185351 0.54044321 0.52402806] -> mean_test = 0.5355\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.66156741 0.65808232 0.6616351  0.65506371 0.6288157 ] -> mean_train = 0.6530\n",
      "Test scores: [0.53542535 0.54794698 0.51950571 0.53169638 0.55002214] -> mean_test = 0.5369\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.66139306 0.64139385 0.65894965 0.66316064 0.66545993] -> mean_train = 0.6581\n",
      "Test scores: [0.53807847 0.52731971 0.5485689  0.54767644 0.52776092] -> mean_test = 0.5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, Model in enumerate([LR, KNR, RFR, SVR, MLPR, ADA, HGBR]):\n",
    "    test_corr_models(model=Model(), method=\"Spearman correlation\", corrs=spearman_corrs)\n",
    "    if i < 6:\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda8abca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(BEFORE UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.24921425 0.27093374 0.19917184 0.24836267 0.25260701] -> mean_train = 0.2441\n",
    "Test scores: [0.12833164 0.08071247 0.30922312 0.16954245 0.07740915] -> mean_test = 0.1530\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.4025985  0.38290001 0.36831767 0.39148884 0.40252618] -> mean_train = 0.3896\n",
    "Test scores: [ 0.11624326  0.23527244  0.35650679  0.27089772 -0.14652723] -> mean_test = 0.1665\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.44845567 0.43248325 0.4326496  0.44199982 0.45568573] -> mean_train = 0.4423\n",
    "Test scores: [0.16300762 0.30164229 0.31059724 0.31290982 0.07484427] -> mean_test = 0.2326\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.48010521 0.45825764 0.46333424 0.45450236 0.47633618] -> mean_train = 0.4665\n",
    "Test scores: [0.10893423 0.28829533 0.29607386 0.27848742 0.10913831] -> mean_test = 0.2162\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.79790694 0.81899067 0.83845994 0.79660533 0.8045238 ] -> mean_train = 0.8113\n",
    "Test scores: [ 0.18483478  0.15368858 -0.25720172  0.2958112   0.21631886] -> mean_test = 0.1187\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.8474152  0.86798361 0.87595374 0.84598044 0.85213325] -> mean_train = 0.8579\n",
    "Test scores: [0.22281325 0.31339996 0.18994458 0.37560868 0.32661866] -> mean_test = 0.2857\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.8477982  0.86835485 0.87645327 0.84625799 0.85241732] -> mean_train = 0.8583\n",
    "Test scores: [0.24889581 0.34326805 0.16376661 0.37541566 0.31084247] -> mean_test = 0.2884\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.84772302 0.86877618 0.87635444 0.84619647 0.85224971] -> mean_train = 0.8583\n",
    "Test scores: [0.25188013 0.34737981 0.19047434 0.37756621 0.29847012] -> mean_test = 0.2932\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.24821102 0.25230277 0.21134905 0.21002211 0.23393682] -> mean_train = 0.2312\n",
    "Test scores: [0.1175337  0.03529187 0.08088012 0.16061473 0.14581597] -> mean_test = 0.1080\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.29865158 0.31315385 0.25569119 0.33387219 0.32322424] -> mean_train = 0.3049\n",
    "Test scores: [0.07679387 0.17580784 0.10835713 0.28114289 0.21491714] -> mean_test = 0.1714\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.3076953  0.3517414  0.32845105 0.34109796 0.31832754] -> mean_train = 0.3295\n",
    "Test scores: [0.08846429 0.20249093 0.13341789 0.27885762 0.17941891] -> mean_test = 0.1765\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.31154677 0.30782744 0.27839546 0.29130889 0.32315659] -> mean_train = 0.3024\n",
    "Test scores: [0.11880103 0.18370943 0.11145375 0.21734129 0.174815  ] -> mean_test = 0.1612\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.30884939 0.32273583 0.30089287 0.3053253  0.31058927] -> mean_train = 0.3097\n",
    "Test scores: [0.21621466 0.12125812 0.1112789  0.25380752 0.23638237] -> mean_test = 0.1878\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.26754801 0.25625888 0.22697208 0.25103663 0.26315251] -> mean_train = 0.2530\n",
    "Test scores: [0.1723757  0.13718039 0.25440779 0.20893442 0.17647675] -> mean_test = 0.1899\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.27200646 0.25702211 0.23535592 0.25894348 0.27205739] -> mean_train = 0.2591\n",
    "Test scores: [0.18259951 0.14574259 0.21460884 0.20840586 0.16562045] -> mean_test = 0.1834\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.27213732 0.25572714 0.23750669 0.25962499 0.27161214] -> mean_train = 0.2593\n",
    "Test scores: [0.17233394 0.13768511 0.17746137 0.19825448 0.15705791] -> mean_test = 0.1686\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Spearman correlation...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.46308    0.43662746 0.44424994 0.43677552 0.44358956] -> mean_train = 0.4449\n",
    "Test scores: [ 0.03581221  0.13530282 -0.8988539   0.23407946  0.05936877] -> mean_test = -0.0869\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.52548503 0.5186544  0.55516421 0.52769569 0.44315011] -> mean_train = 0.5140\n",
    "Test scores: [0.25086634 0.37064945 0.35341974 0.34305033 0.11683819] -> mean_test = 0.2870\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.56269636 0.57803714 0.55488283 0.5593286  0.52405762] -> mean_train = 0.5558\n",
    "Test scores: [0.15751221 0.37946022 0.29111232 0.37348009 0.30562286] -> mean_test = 0.3014\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.59737034 0.55466742 0.59562882 0.5875031  0.53883696] -> mean_train = 0.5748\n",
    "Test scores: [0.19248025 0.32994159 0.20769372 0.32922724 0.26530933] -> mean_test = 0.2649"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d660ab4b-464a-42da-8dde-5336b6df14f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.30276032 0.30999642 0.29627182 0.30485768 0.30062867] -> mean_train = 0.3029\n",
    "Test scores: [0.29231614 0.26266536 0.31845467 0.28441096 0.30099507] -> mean_test = 0.2918\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.38744808 0.38428109 0.3826784  0.33979449 0.38501327] -> mean_train = 0.3758\n",
    "Test scores: [0.3538583  0.36657723 0.33417186 0.30842076 0.36367539] -> mean_test = 0.3453\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.41855357 0.41669686 0.41262532 0.41615306 0.42218293] -> mean_train = 0.4172\n",
    "Test scores: [0.37755745 0.38235578 0.39904554 0.39122124 0.34962146] -> mean_test = 0.3800\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.43666678 0.42842225 0.43421242 0.43776558 0.43959521] -> mean_train = 0.4353\n",
    "Test scores: [0.39523955 0.38230352 0.37197668 0.39334337 0.39326577] -> mean_test = 0.3872\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for KNeighborsRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.58144722 0.56791155 0.57262067 0.57422373 0.57555677] -> mean_train = 0.5744\n",
    "Test scores: [0.34116207 0.38116106 0.36167522 0.36244282 0.34761941] -> mean_test = 0.3588\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.60354152 0.60200782 0.6085737  0.60455412 0.59745753] -> mean_train = 0.6032\n",
    "Test scores: [0.41038186 0.41923013 0.36877787 0.39774969 0.43388593] -> mean_test = 0.4060\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.61668517 0.61529299 0.61350762 0.61218549 0.62025389] -> mean_train = 0.6156\n",
    "Test scores: [0.40996733 0.42958298 0.45250813 0.42477277 0.39997428] -> mean_test = 0.4234\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.60642041 0.60735275 0.61471306 0.60815288 0.61213709] -> mean_train = 0.6098\n",
    "Test scores: [0.42858132 0.42051792 0.41496123 0.4170616  0.42208561] -> mean_test = 0.4206\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.86286666 0.86327227 0.86515871 0.86526029 0.86058221] -> mean_train = 0.8634\n",
    "Test scores: [0.45806815 0.45428154 0.43739402 0.44168913 0.47137121] -> mean_test = 0.4526\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.86659924 0.86960868 0.8664068  0.87180788 0.86824758] -> mean_train = 0.8685\n",
    "Test scores: [0.50130257 0.48736882 0.50682832 0.46481167 0.47564835] -> mean_test = 0.4872\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.87154669 0.86740715 0.8687975  0.86999956 0.86789773] -> mean_train = 0.8691\n",
    "Test scores: [0.47269618 0.49320745 0.49477457 0.49530748 0.48645884] -> mean_test = 0.4885\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.86992188 0.86863113 0.86980674 0.86922954 0.86885264] -> mean_train = 0.8693\n",
    "Test scores: [0.47346002 0.48232316 0.49540531 0.48162644 0.48545635] -> mean_test = 0.4837\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.27542999 0.2723476  0.27631393 0.2772708  0.28241463] -> mean_train = 0.2768\n",
    "Test scores: [0.28283144 0.28564874 0.25955313 0.26985495 0.2524273 ] -> mean_test = 0.2701\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.25050722 0.24563219 0.24316983 0.24466171 0.25483817] -> mean_train = 0.2478\n",
    "Test scores: [0.22647406 0.24715775 0.24966636 0.2546818  0.23105567] -> mean_test = 0.2418\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.24899087 0.24717708 0.24506422 0.24771682 0.24762889] -> mean_train = 0.2473\n",
    "Test scores: [0.24235095 0.22966731 0.26202853 0.2312249  0.24195584] -> mean_test = 0.2414\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.24881949 0.26274852 0.25277209 0.25090909 0.25622489] -> mean_train = 0.2543\n",
    "Test scores: [0.26830012 0.2200019  0.24973791 0.26164309 0.24226996] -> mean_test = 0.2484\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.55277466 0.55306357 0.54210614 0.47871056 0.58166296] -> mean_train = 0.5417\n",
    "Test scores: [0.43527307 0.42055891 0.43856691 0.32758635 0.40498687] -> mean_test = 0.4054\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.52406768 0.53170162 0.55011785 0.52939447 0.50005963] -> mean_train = 0.5271\n",
    "Test scores: [0.47915438 0.47292983 0.48500241 0.46352347 0.45960753] -> mean_test = 0.4720\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.5295686  0.48546583 0.52897515 0.53093441 0.51876645] -> mean_train = 0.5187\n",
    "Test scores: [0.46535184 0.44473846 0.46850541 0.4922603  0.44927276] -> mean_test = 0.4640\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.53871824 0.55747297 0.56545089 0.51894987 0.56946029] -> mean_train = 0.5500\n",
    "Test scores: [0.47679662 0.48825781 0.4961454  0.43920372 0.47527757] -> mean_test = 0.4751\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.27077418 0.28118372 0.28132986 0.27185248 0.28699682] -> mean_train = 0.2784\n",
    "Test scores: [0.29456676 0.27699162 0.2566113  0.24467112 0.27629458] -> mean_test = 0.2698\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.30250501 0.29647762 0.32411476 0.34112609 0.29839447] -> mean_train = 0.3125\n",
    "Test scores: [0.29654511 0.28648838 0.30943204 0.32816846 0.28505545] -> mean_test = 0.3011\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.27707697 0.29286917 0.29149421 0.27581087 0.30896063] -> mean_train = 0.2892\n",
    "Test scores: [0.27402579 0.28327587 0.25670492 0.27295977 0.29208173] -> mean_test = 0.2758\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.29183765 0.2888603  0.30779433 0.28695369 0.31408741] -> mean_train = 0.2979\n",
    "Test scores: [0.25761796 0.29439967 0.29200319 0.28608114 0.30552038] -> mean_test = 0.2871\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.60516408 0.5987729  0.60463261 0.60686439 0.60086074] -> mean_train = 0.6033\n",
    "Test scores: [0.49752306 0.51061865 0.49868967 0.50033296 0.52337996] -> mean_test = 0.5061\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.65131722 0.64860272 0.64927219 0.65068186 0.6526421 ] -> mean_train = 0.6505\n",
    "Test scores: [0.53977152 0.53134494 0.54185351 0.54044321 0.52402806] -> mean_test = 0.5355\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.66156741 0.65808232 0.6616351  0.65506371 0.6288157 ] -> mean_train = 0.6530\n",
    "Test scores: [0.53542535 0.54794698 0.51950571 0.53169638 0.55002214] -> mean_test = 0.5369\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.66139306 0.64139385 0.65894965 0.66316064 0.66545993] -> mean_train = 0.6581\n",
    "Test scores: [0.53807847 0.52731971 0.5485689  0.54767644 0.52776092] -> mean_test = 0.5379"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffe67f-bbe5-47c2-ac2a-fb8ead3b8127",
   "metadata": {},
   "source": [
    "<b>Spearman</b> (further testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb8a42-bbf8-48ce-ba85-155fe0cab687",
   "metadata": {},
   "source": [
    "Novos testes para uma gama de features distinta da anterior. Testes efetuados para o melhor modelo - <b>HistGradientBoostingRegressor</b> - e para o modelo <b>LinearRegression</b> (progresão de scores promissora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48f496d9-e076-4fcc-b1a1-8c73ff2b59b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using Spearman correlation to select features...\n",
      "\n",
      "Results for 900 best features\n",
      "Train scores: [0.44845659 0.44690669 0.45188674 0.44772917 0.4460683 ] -> mean_train = 0.4482\n",
      "Test scores: [0.37239857 0.40371682 0.36711783 0.40791929 0.41591596] -> mean_test = 0.3934\n",
      "\n",
      "Results for 1000 best features\n",
      "Train scores: [0.44677465 0.45609028 0.45454997 0.46056612 0.44835278] -> mean_train = 0.4533\n",
      "Test scores: [0.38473902 0.39825773 0.40052927 0.38249102 0.41902439] -> mean_test = 0.3970\n",
      "\n",
      "Results for 1100 best features\n",
      "Train scores: [0.45673772 0.46337917 0.45801098 0.45532306 0.46020887] -> mean_train = 0.4587\n",
      "Test scores: [0.39463812 0.37497419 0.41201434 0.42376544 0.39754653] -> mean_test = 0.4006\n",
      "\n",
      "Results for 1200 best features\n",
      "Train scores: [0.46731002 0.46380396 0.47062831 0.46190505 0.46045568] -> mean_train = 0.4648\n",
      "Test scores: [0.39199155 0.39522075 0.38187573 0.42181252 0.41388638] -> mean_test = 0.4010\n",
      "\n",
      "Results for 1300 best features\n",
      "Train scores: [0.47142267 0.46782679 0.46742981 0.46838148 0.46693459] -> mean_train = 0.4684\n",
      "Test scores: [0.39921763 0.38336105 0.41378528 0.40241595 0.41758455] -> mean_test = 0.4033\n",
      "\n",
      "Results for 1400 best features\n",
      "Train scores: [0.46847459 0.47484548 0.47232039 0.47313792 0.47524504] -> mean_train = 0.4728\n",
      "Test scores: [0.43056256 0.3855252  0.4116635  0.39009259 0.39527261] -> mean_test = 0.4026\n",
      "\n",
      "Results for 1500 best features\n",
      "Train scores: [0.47858775 0.47802305 0.46858288 0.47044577 0.47881881] -> mean_train = 0.4749\n",
      "Test scores: [0.38243632 0.3995922  0.42093709 0.40010573 0.37637554] -> mean_test = 0.3959\n",
      "\n",
      "Results for 1600 best features\n",
      "Train scores: [0.4858436  0.47689532 0.47976781 0.48110309 0.48202328] -> mean_train = 0.4811\n",
      "Test scores: [0.35896603 0.42488088 0.35953264 0.40529942 0.4013409 ] -> mean_test = 0.3900\n",
      "\n",
      "Results for 1700 best features\n",
      "Train scores: [0.48145071 0.48511768 0.48920228 0.48001406 0.48410548] -> mean_train = 0.4840\n",
      "Test scores: [0.41967937 0.39818969 0.39131978 0.41330345 0.3542309 ] -> mean_test = 0.3953\n",
      "\n",
      "Results for 1800 best features\n",
      "Train scores: [0.48788269 0.48986427 0.48178563 0.48823181 0.49033944] -> mean_train = 0.4876\n",
      "Test scores: [0.41527967 0.39016132 0.41973562 0.40783465 0.34565396] -> mean_test = 0.3957\n",
      "\n",
      "Results for 1900 best features\n",
      "Train scores: [0.49636614 0.48962182 0.49556593 0.48604723 0.49170334] -> mean_train = 0.4919\n",
      "Test scores: [0.36662858 0.36986296 0.39454486 0.43095738 0.4014067 ] -> mean_test = 0.3927\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.49159278 0.49793264 0.49522585 0.49662057 0.49429215] -> mean_train = 0.4951\n",
      "Test scores: [0.40642492 0.35235637 0.40593204 0.38819664 0.41421353] -> mean_test = 0.3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=LR(), method=\"Spearman correlation\", corrs=spearman_corrs, num_feats=range(900, 2001, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee720e6-318a-4b32-aa69-aac307918ad5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using Spearman correlation to select features...\n",
    "\n",
    "Results for 900 best features\n",
    "Train scores: [0.44845659 0.44690669 0.45188674 0.44772917 0.4460683 ] -> mean_train = 0.4482\n",
    "Test scores: [0.37239857 0.40371682 0.36711783 0.40791929 0.41591596] -> mean_test = 0.3934\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.44677465 0.45609028 0.45454997 0.46056612 0.44835278] -> mean_train = 0.4533\n",
    "Test scores: [0.38473902 0.39825773 0.40052927 0.38249102 0.41902439] -> mean_test = 0.3970\n",
    "\n",
    "Results for 1100 best features\n",
    "Train scores: [0.45673772 0.46337917 0.45801098 0.45532306 0.46020887] -> mean_train = 0.4587\n",
    "Test scores: [0.39463812 0.37497419 0.41201434 0.42376544 0.39754653] -> mean_test = 0.4006\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.46731002 0.46380396 0.47062831 0.46190505 0.46045568] -> mean_train = 0.4648\n",
    "Test scores: [0.39199155 0.39522075 0.38187573 0.42181252 0.41388638] -> mean_test = 0.4010\n",
    "\n",
    "Results for 1300 best features\n",
    "Train scores: [0.47142267 0.46782679 0.46742981 0.46838148 0.46693459] -> mean_train = 0.4684\n",
    "Test scores: [0.39921763 0.38336105 0.41378528 0.40241595 0.41758455] -> mean_test = 0.4033\n",
    "\n",
    "Results for 1400 best features\n",
    "Train scores: [0.46847459 0.47484548 0.47232039 0.47313792 0.47524504] -> mean_train = 0.4728\n",
    "Test scores: [0.43056256 0.3855252  0.4116635  0.39009259 0.39527261] -> mean_test = 0.4026\n",
    "\n",
    "Results for 1500 best features\n",
    "Train scores: [0.47858775 0.47802305 0.46858288 0.47044577 0.47881881] -> mean_train = 0.4749\n",
    "Test scores: [0.38243632 0.3995922  0.42093709 0.40010573 0.37637554] -> mean_test = 0.3959\n",
    "\n",
    "Results for 1600 best features\n",
    "Train scores: [0.4858436  0.47689532 0.47976781 0.48110309 0.48202328] -> mean_train = 0.4811\n",
    "Test scores: [0.35896603 0.42488088 0.35953264 0.40529942 0.4013409 ] -> mean_test = 0.3900\n",
    "\n",
    "Results for 1700 best features\n",
    "Train scores: [0.48145071 0.48511768 0.48920228 0.48001406 0.48410548] -> mean_train = 0.4840\n",
    "Test scores: [0.41967937 0.39818969 0.39131978 0.41330345 0.3542309 ] -> mean_test = 0.3953\n",
    "\n",
    "Results for 1800 best features\n",
    "Train scores: [0.48788269 0.48986427 0.48178563 0.48823181 0.49033944] -> mean_train = 0.4876\n",
    "Test scores: [0.41527967 0.39016132 0.41973562 0.40783465 0.34565396] -> mean_test = 0.3957\n",
    "\n",
    "Results for 1900 best features\n",
    "Train scores: [0.49636614 0.48962182 0.49556593 0.48604723 0.49170334] -> mean_train = 0.4919\n",
    "Test scores: [0.36662858 0.36986296 0.39454486 0.43095738 0.4014067 ] -> mean_test = 0.3927\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.49159278 0.49793264 0.49522585 0.49662057 0.49429215] -> mean_train = 0.4951\n",
    "Test scores: [0.40642492 0.35235637 0.40593204 0.38819664 0.41421353] -> mean_test = 0.3934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96da6235-a27a-4703-9856-6484fd416aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for HistGradientBoostingRegressor using Spearman correlation to select features...\n",
      "\n",
      "Results for 900 best features\n",
      "Train scores: [0.66640621 0.66761633 0.66318797 0.66438972 0.66299885] -> mean_train = 0.6649\n",
      "Test scores: [0.5385035  0.53013342 0.53696804 0.54630403 0.53912704] -> mean_test = 0.5382\n",
      "\n",
      "Results for 1000 best features\n",
      "Train scores: [0.66843968 0.66608647 0.66707098 0.67020146 0.65024564] -> mean_train = 0.6644\n",
      "Test scores: [0.54170773 0.53339188 0.55513566 0.52840985 0.54995223] -> mean_test = 0.5417\n",
      "\n",
      "Results for 1100 best features\n",
      "Train scores: [0.66817317 0.65897502 0.66969823 0.66850961 0.66736228] -> mean_train = 0.6665\n",
      "Test scores: [0.54798365 0.54820868 0.54489859 0.53689083 0.53303332] -> mean_test = 0.5422\n",
      "\n",
      "Results for 1200 best features\n",
      "Train scores: [0.66697576 0.67070654 0.67109184 0.67369563 0.66743542] -> mean_train = 0.6700\n",
      "Test scores: [0.56181496 0.53415526 0.54248205 0.5224809  0.55233844] -> mean_test = 0.5427\n",
      "\n",
      "Results for 1300 best features\n",
      "Train scores: [0.67069024 0.67527102 0.66286378 0.66742903 0.67396175] -> mean_train = 0.6700\n",
      "Test scores: [0.54450774 0.52375611 0.56018647 0.55024704 0.53476782] -> mean_test = 0.5427\n",
      "\n",
      "Results for 1400 best features\n",
      "Train scores: [0.67654191 0.66878745 0.66998537 0.67230986 0.66403637] -> mean_train = 0.6703\n",
      "Test scores: [0.52383477 0.54404493 0.55101852 0.53449349 0.54573617] -> mean_test = 0.5398\n",
      "\n",
      "Results for 1500 best features\n",
      "Train scores: [0.67044806 0.67563318 0.67118479 0.66868364 0.66982355] -> mean_train = 0.6712\n",
      "Test scores: [0.55567347 0.53332231 0.54208241 0.54953324 0.54846705] -> mean_test = 0.5458\n",
      "\n",
      "Results for 1600 best features\n",
      "Train scores: [0.67593141 0.67537575 0.67382011 0.64675993 0.67344937] -> mean_train = 0.6691\n",
      "Test scores: [0.53136766 0.53740612 0.55298813 0.5473727  0.54057805] -> mean_test = 0.5419\n",
      "\n",
      "Results for 1700 best features\n",
      "Train scores: [0.67209529 0.67042095 0.67559447 0.66762051 0.66367423] -> mean_train = 0.6699\n",
      "Test scores: [0.55008033 0.54208193 0.532531   0.54504007 0.52712765] -> mean_test = 0.5394\n",
      "\n",
      "Results for 1800 best features\n",
      "Train scores: [0.66989339 0.62961343 0.67362719 0.65298226 0.67519948] -> mean_train = 0.6603\n",
      "Test scores: [0.53343463 0.54984739 0.54449213 0.54810165 0.52855286] -> mean_test = 0.5409\n",
      "\n",
      "Results for 1900 best features\n",
      "Train scores: [0.6755778  0.66552389 0.67168683 0.67462481 0.65582312] -> mean_train = 0.6686\n",
      "Test scores: [0.53451847 0.53947979 0.54446444 0.53571897 0.54730343] -> mean_test = 0.5403\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.67643412 0.67331554 0.67335111 0.67241284 0.67489739] -> mean_train = 0.6741\n",
      "Test scores: [0.53448304 0.55207278 0.54070753 0.53314925 0.54743649] -> mean_test = 0.5416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=HGBR(), method=\"Spearman correlation\", corrs=spearman_corrs, num_feats=range(900, 2001, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8edb9-0ad6-4c62-a8a0-7894a6dbc83e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using Spearman correlation to select features...\n",
    "\n",
    "Results for 900 best features\n",
    "Train scores: [0.66640621 0.66761633 0.66318797 0.66438972 0.66299885] -> mean_train = 0.6649\n",
    "Test scores: [0.5385035  0.53013342 0.53696804 0.54630403 0.53912704] -> mean_test = 0.5382\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.66843968 0.66608647 0.66707098 0.67020146 0.65024564] -> mean_train = 0.6644\n",
    "Test scores: [0.54170773 0.53339188 0.55513566 0.52840985 0.54995223] -> mean_test = 0.5417\n",
    "\n",
    "Results for 1100 best features\n",
    "Train scores: [0.66817317 0.65897502 0.66969823 0.66850961 0.66736228] -> mean_train = 0.6665\n",
    "Test scores: [0.54798365 0.54820868 0.54489859 0.53689083 0.53303332] -> mean_test = 0.5422\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.66697576 0.67070654 0.67109184 0.67369563 0.66743542] -> mean_train = 0.6700\n",
    "Test scores: [0.56181496 0.53415526 0.54248205 0.5224809  0.55233844] -> mean_test = 0.5427\n",
    "\n",
    "Results for 1300 best features\n",
    "Train scores: [0.67069024 0.67527102 0.66286378 0.66742903 0.67396175] -> mean_train = 0.6700\n",
    "Test scores: [0.54450774 0.52375611 0.56018647 0.55024704 0.53476782] -> mean_test = 0.5427\n",
    "\n",
    "Results for 1400 best features\n",
    "Train scores: [0.67654191 0.66878745 0.66998537 0.67230986 0.66403637] -> mean_train = 0.6703\n",
    "Test scores: [0.52383477 0.54404493 0.55101852 0.53449349 0.54573617] -> mean_test = 0.5398\n",
    "\n",
    "Results for 1500 best features\n",
    "Train scores: [0.67044806 0.67563318 0.67118479 0.66868364 0.66982355] -> mean_train = 0.6712\n",
    "Test scores: [0.55567347 0.53332231 0.54208241 0.54953324 0.54846705] -> mean_test = 0.5458\n",
    "\n",
    "Results for 1600 best features\n",
    "Train scores: [0.67593141 0.67537575 0.67382011 0.64675993 0.67344937] -> mean_train = 0.6691\n",
    "Test scores: [0.53136766 0.53740612 0.55298813 0.5473727  0.54057805] -> mean_test = 0.5419\n",
    "\n",
    "Results for 1700 best features\n",
    "Train scores: [0.67209529 0.67042095 0.67559447 0.66762051 0.66367423] -> mean_train = 0.6699\n",
    "Test scores: [0.55008033 0.54208193 0.532531   0.54504007 0.52712765] -> mean_test = 0.5394\n",
    "\n",
    "Results for 1800 best features\n",
    "Train scores: [0.66989339 0.62961343 0.67362719 0.65298226 0.67519948] -> mean_train = 0.6603\n",
    "Test scores: [0.53343463 0.54984739 0.54449213 0.54810165 0.52855286] -> mean_test = 0.5409\n",
    "\n",
    "Results for 1900 best features\n",
    "Train scores: [0.6755778  0.66552389 0.67168683 0.67462481 0.65582312] -> mean_train = 0.6686\n",
    "Test scores: [0.53451847 0.53947979 0.54446444 0.53571897 0.54730343] -> mean_test = 0.5403\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.67643412 0.67331554 0.67335111 0.67241284 0.67489739] -> mean_train = 0.6741\n",
    "Test scores: [0.53448304 0.55207278 0.54070753 0.53314925 0.54743649] -> mean_test = 0.5416"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e968f-c580-45da-8aaa-52d8f7ad7d38",
   "metadata": {},
   "source": [
    "Através deste método de seleção de features (<b>correlação de Spearman</b>) obtivemos um score máximo de <b>0.5458</b> para a combinação <b>HistGradientBoostingRegressor / 1500 features</b>. No entanto, mais uma vez, selecionámos a combinação <b>HistGradientBoostingRegressor / 1200 features </b> por se encontrar numa região mais estável no espaço de procura do número de features ótimo. Neste caso, o score obtido foi <b>0.5427</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84aa4a-59ef-4964-b1ec-5b63ff0069c8",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe710b8-4e41-460a-adf9-b0ed082bcedc",
   "metadata": {},
   "source": [
    "<b>Univariate linear regression</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e31188f-10eb-4487-b50c-92d23e3d0d8c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.31373502 0.31453924 0.30417023 0.31123685 0.31630096] -> mean_train = 0.3120\n",
      "Test scores: [0.28783469 0.29779471 0.30135783 0.31145979 0.29140639] -> mean_test = 0.2980\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.39764482 0.39875594 0.39529086 0.39313225 0.39097182] -> mean_train = 0.3952\n",
      "Test scores: [0.36595936 0.36158467 0.37670695 0.37031297 0.38661595] -> mean_test = 0.3722\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.42097787 0.42265563 0.42186017 0.42585712 0.42528314] -> mean_train = 0.4233\n",
      "Test scores: [0.40439878 0.40036036 0.40637312 0.38183613 0.30668828] -> mean_test = 0.3799\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.43038356 0.43612914 0.43978573 0.44180339 0.43237401] -> mean_train = 0.4361\n",
      "Test scores: [0.38657825 0.40212593 0.34410856 0.37866801 0.42163509] -> mean_test = 0.3866\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for KNeighborsRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.58418731 0.58761806 0.58538494 0.59134022 0.59104524] -> mean_train = 0.5879\n",
      "Test scores: [0.39551114 0.38906299 0.40408989 0.37811526 0.35545967] -> mean_test = 0.3844\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.60920937 0.61170261 0.6108256  0.61009618 0.61126893] -> mean_train = 0.6106\n",
      "Test scores: [0.42115555 0.41674847 0.40392014 0.41160636 0.40854717] -> mean_test = 0.4124\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.60560376 0.62121132 0.61906993 0.62097345 0.62114381] -> mean_train = 0.6176\n",
      "Test scores: [0.47479312 0.426869   0.42171527 0.41947493 0.39440085] -> mean_test = 0.4275\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.61991044 0.62148301 0.62284772 0.62001424 0.61840822] -> mean_train = 0.6205\n",
      "Test scores: [0.42825631 0.42061052 0.4388823  0.41319129 0.44369429] -> mean_test = 0.4289\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for RandomForestRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.8655547  0.86781916 0.86922104 0.865152   0.86404984] -> mean_train = 0.8664\n",
      "Test scores: [0.46708494 0.4685512  0.45384547 0.47275276 0.47673177] -> mean_test = 0.4678\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.86970501 0.86995028 0.86384063 0.86740251 0.87094993] -> mean_train = 0.8684\n",
      "Test scores: [0.47498573 0.48671501 0.51024889 0.47597489 0.45133407] -> mean_test = 0.4799\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.86849813 0.87306993 0.86734382 0.86760202 0.86648112] -> mean_train = 0.8686\n",
      "Test scores: [0.49520044 0.4626488  0.5081917  0.49469975 0.50113926] -> mean_test = 0.4924\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.86669763 0.86905955 0.873318   0.8691455  0.86850394] -> mean_train = 0.8693\n",
      "Test scores: [0.49135522 0.47788815 0.47668487 0.47902245 0.50758556] -> mean_test = 0.4865\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for SVR using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.27740995 0.27944163 0.28039117 0.27269153 0.27814691] -> mean_train = 0.2776\n",
      "Test scores: [0.26537281 0.27334189 0.26638405 0.28994056 0.26355078] -> mean_test = 0.2717\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.26640452 0.26723274 0.26763332 0.26570439 0.25921702] -> mean_train = 0.2652\n",
      "Test scores: [0.25655023 0.2491282  0.26175801 0.2637441  0.26534464] -> mean_test = 0.2593\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.2633362  0.25717587 0.26141754 0.26372821 0.25696623] -> mean_train = 0.2605\n",
      "Test scores: [0.24922436 0.2637499  0.25923562 0.24439915 0.25890932] -> mean_test = 0.2551\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.25483685 0.25661253 0.25750852 0.2579038  0.25711309] -> mean_train = 0.2568\n",
      "Test scores: [0.25750941 0.24639282 0.25115945 0.24799389 0.25132416] -> mean_test = 0.2509\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for MLPRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.54430174 0.49224234 0.49570655 0.52271968 0.52896249] -> mean_train = 0.5168\n",
      "Test scores: [0.45825457 0.39281788 0.4275423  0.41115331 0.44533216] -> mean_test = 0.4270\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.44218338 0.47154214 0.46907953 0.50640186 0.52612966] -> mean_train = 0.4831\n",
      "Test scores: [0.41794719 0.40787312 0.46285865 0.4551712  0.4717947 ] -> mean_test = 0.4431\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.50729017 0.50026381 0.48247831 0.52337791 0.53190939] -> mean_train = 0.5091\n",
      "Test scores: [0.43744918 0.46668748 0.46659086 0.46733173 0.47559299] -> mean_test = 0.4627\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.51564951 0.533168   0.5462754  0.51449448 0.52771785] -> mean_train = 0.5275\n",
      "Test scores: [0.46981089 0.48904764 0.47320711 0.4360045  0.47072816] -> mean_test = 0.4678\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for AdaBoostRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.31135141 0.29206503 0.25498672 0.32811158 0.31501928] -> mean_train = 0.3003\n",
      "Test scores: [0.31578124 0.265545   0.26295658 0.30517282 0.30600072] -> mean_test = 0.2911\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.3124823  0.28744464 0.28341977 0.27703655 0.28536512] -> mean_train = 0.2891\n",
      "Test scores: [0.30490637 0.26035061 0.23991877 0.27369385 0.30046343] -> mean_test = 0.2759\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.29051633 0.30135369 0.29399859 0.28739016 0.30473563] -> mean_train = 0.2956\n",
      "Test scores: [0.25262018 0.27319283 0.31489678 0.29137544 0.28354113] -> mean_test = 0.2831\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.31043962 0.31909498 0.29958588 0.31864839 0.28153108] -> mean_train = 0.3059\n",
      "Test scores: [0.32475499 0.30761267 0.28309899 0.29929982 0.25241269] -> mean_test = 0.2934\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.62287758 0.61627686 0.6203058  0.61895197 0.6068761 ] -> mean_train = 0.6171\n",
      "Test scores: [0.51206187 0.52476304 0.52843164 0.53115901 0.49411325] -> mean_test = 0.5181\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.64348381 0.65269333 0.65288184 0.64936361 0.65076979] -> mean_train = 0.6498\n",
      "Test scores: [0.55823305 0.50265354 0.52208418 0.53948546 0.52743806] -> mean_test = 0.5300\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.65881413 0.66029417 0.64909058 0.6650785  0.66054107] -> mean_train = 0.6588\n",
      "Test scores: [0.54466073 0.52675804 0.53552745 0.53019041 0.5483749 ] -> mean_test = 0.5371\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.65846428 0.67083182 0.66793144 0.63553435 0.66818127] -> mean_train = 0.6602\n",
      "Test scores: [0.55374652 0.52408791 0.53612751 0.54250362 0.53651148] -> mean_test = 0.5386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, Model in enumerate([LR, KNR, RFR, SVR, MLPR, ADA, HGBR]):\n",
    "    test_corr_models(model=Model(), method=\"univariate linear regression\", corrs=f_values)\n",
    "    if i < 6:\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f394470-0615-4d7a-b801-b3778df0a5c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.31373502 0.31453924 0.30417023 0.31123685 0.31630096] -> mean_train = 0.3120\n",
    "Test scores: [0.28783469 0.29779471 0.30135783 0.31145979 0.29140639] -> mean_test = 0.2980\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.39764482 0.39875594 0.39529086 0.39313225 0.39097182] -> mean_train = 0.3952\n",
    "Test scores: [0.36595936 0.36158467 0.37670695 0.37031297 0.38661595] -> mean_test = 0.3722\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.42097787 0.42265563 0.42186017 0.42585712 0.42528314] -> mean_train = 0.4233\n",
    "Test scores: [0.40439878 0.40036036 0.40637312 0.38183613 0.30668828] -> mean_test = 0.3799\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.43038356 0.43612914 0.43978573 0.44180339 0.43237401] -> mean_train = 0.4361\n",
    "Test scores: [0.38657825 0.40212593 0.34410856 0.37866801 0.42163509] -> mean_test = 0.3866\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for KNeighborsRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.58418731 0.58761806 0.58538494 0.59134022 0.59104524] -> mean_train = 0.5879\n",
    "Test scores: [0.39551114 0.38906299 0.40408989 0.37811526 0.35545967] -> mean_test = 0.3844\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.60920937 0.61170261 0.6108256  0.61009618 0.61126893] -> mean_train = 0.6106\n",
    "Test scores: [0.42115555 0.41674847 0.40392014 0.41160636 0.40854717] -> mean_test = 0.4124\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.60560376 0.62121132 0.61906993 0.62097345 0.62114381] -> mean_train = 0.6176\n",
    "Test scores: [0.47479312 0.426869   0.42171527 0.41947493 0.39440085] -> mean_test = 0.4275\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.61991044 0.62148301 0.62284772 0.62001424 0.61840822] -> mean_train = 0.6205\n",
    "Test scores: [0.42825631 0.42061052 0.4388823  0.41319129 0.44369429] -> mean_test = 0.4289\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.8655547  0.86781916 0.86922104 0.865152   0.86404984] -> mean_train = 0.8664\n",
    "Test scores: [0.46708494 0.4685512  0.45384547 0.47275276 0.47673177] -> mean_test = 0.4678\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.86970501 0.86995028 0.86384063 0.86740251 0.87094993] -> mean_train = 0.8684\n",
    "Test scores: [0.47498573 0.48671501 0.51024889 0.47597489 0.45133407] -> mean_test = 0.4799\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.86849813 0.87306993 0.86734382 0.86760202 0.86648112] -> mean_train = 0.8686\n",
    "Test scores: [0.49520044 0.4626488  0.5081917  0.49469975 0.50113926] -> mean_test = 0.4924\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.86669763 0.86905955 0.873318   0.8691455  0.86850394] -> mean_train = 0.8693\n",
    "Test scores: [0.49135522 0.47788815 0.47668487 0.47902245 0.50758556] -> mean_test = 0.4865\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.27740995 0.27944163 0.28039117 0.27269153 0.27814691] -> mean_train = 0.2776\n",
    "Test scores: [0.26537281 0.27334189 0.26638405 0.28994056 0.26355078] -> mean_test = 0.2717\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.26640452 0.26723274 0.26763332 0.26570439 0.25921702] -> mean_train = 0.2652\n",
    "Test scores: [0.25655023 0.2491282  0.26175801 0.2637441  0.26534464] -> mean_test = 0.2593\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.2633362  0.25717587 0.26141754 0.26372821 0.25696623] -> mean_train = 0.2605\n",
    "Test scores: [0.24922436 0.2637499  0.25923562 0.24439915 0.25890932] -> mean_test = 0.2551\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.25483685 0.25661253 0.25750852 0.2579038  0.25711309] -> mean_train = 0.2568\n",
    "Test scores: [0.25750941 0.24639282 0.25115945 0.24799389 0.25132416] -> mean_test = 0.2509\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.54430174 0.49224234 0.49570655 0.52271968 0.52896249] -> mean_train = 0.5168\n",
    "Test scores: [0.45825457 0.39281788 0.4275423  0.41115331 0.44533216] -> mean_test = 0.4270\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.44218338 0.47154214 0.46907953 0.50640186 0.52612966] -> mean_train = 0.4831\n",
    "Test scores: [0.41794719 0.40787312 0.46285865 0.4551712  0.4717947 ] -> mean_test = 0.4431\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.50729017 0.50026381 0.48247831 0.52337791 0.53190939] -> mean_train = 0.5091\n",
    "Test scores: [0.43744918 0.46668748 0.46659086 0.46733173 0.47559299] -> mean_test = 0.4627\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.51564951 0.533168   0.5462754  0.51449448 0.52771785] -> mean_train = 0.5275\n",
    "Test scores: [0.46981089 0.48904764 0.47320711 0.4360045  0.47072816] -> mean_test = 0.4678\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.31135141 0.29206503 0.25498672 0.32811158 0.31501928] -> mean_train = 0.3003\n",
    "Test scores: [0.31578124 0.265545   0.26295658 0.30517282 0.30600072] -> mean_test = 0.2911\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.3124823  0.28744464 0.28341977 0.27703655 0.28536512] -> mean_train = 0.2891\n",
    "Test scores: [0.30490637 0.26035061 0.23991877 0.27369385 0.30046343] -> mean_test = 0.2759\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.29051633 0.30135369 0.29399859 0.28739016 0.30473563] -> mean_train = 0.2956\n",
    "Test scores: [0.25262018 0.27319283 0.31489678 0.29137544 0.28354113] -> mean_test = 0.2831\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.31043962 0.31909498 0.29958588 0.31864839 0.28153108] -> mean_train = 0.3059\n",
    "Test scores: [0.32475499 0.30761267 0.28309899 0.29929982 0.25241269] -> mean_test = 0.2934\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.62287758 0.61627686 0.6203058  0.61895197 0.6068761 ] -> mean_train = 0.6171\n",
    "Test scores: [0.51206187 0.52476304 0.52843164 0.53115901 0.49411325] -> mean_test = 0.5181\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.64348381 0.65269333 0.65288184 0.64936361 0.65076979] -> mean_train = 0.6498\n",
    "Test scores: [0.55823305 0.50265354 0.52208418 0.53948546 0.52743806] -> mean_test = 0.5300\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.65881413 0.66029417 0.64909058 0.6650785  0.66054107] -> mean_train = 0.6588\n",
    "Test scores: [0.54466073 0.52675804 0.53552745 0.53019041 0.5483749 ] -> mean_test = 0.5371\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.65846428 0.67083182 0.66793144 0.63553435 0.66818127] -> mean_train = 0.6602\n",
    "Test scores: [0.55374652 0.52408791 0.53612751 0.54250362 0.53651148] -> mean_test = 0.5386"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881ee85-ead7-4da9-84b2-ffc358724079",
   "metadata": {},
   "source": [
    "<b>Univariate linear regression</b> (further testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c62b4-843f-4ca3-be17-034b4ee0ec31",
   "metadata": {},
   "source": [
    "Novos testes para uma gama de features distinta da anterior (apenas para o melhor modelo - <b>HistGradientBoostingRegressor</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38cb59ae-0a16-4f3e-9090-5e1809a5219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for HistGradientBoostingRegressor using univariate linear regression to select features...\n",
      "\n",
      "Results for 900 best features\n",
      "Train scores: [0.66688224 0.6693543  0.64699053 0.65804901 0.65496276] -> mean_train = 0.6592\n",
      "Test scores: [0.54599391 0.53878915 0.53546626 0.55122983 0.52327278] -> mean_test = 0.5390\n",
      "\n",
      "Results for 1000 best features\n",
      "Train scores: [0.6694098  0.66224539 0.66859652 0.66918313 0.67199177] -> mean_train = 0.6683\n",
      "Test scores: [0.54907084 0.55617924 0.53640704 0.54427348 0.51604045] -> mean_test = 0.5404\n",
      "\n",
      "Results for 1100 best features\n",
      "Train scores: [0.69247604 0.69628291 0.6926902  0.69139486 0.69126861] -> mean_train = 0.6928\n",
      "Test scores: [0.5784869  0.56210165 0.56201292 0.5760861  0.57289338] -> mean_test = 0.5703\n",
      "\n",
      "Results for 1200 best features\n",
      "Train scores: [0.69627107 0.69432081 0.69199877 0.69308179 0.69435136] -> mean_train = 0.6940\n",
      "Test scores: [0.56833448 0.57382256 0.57845046 0.56835063 0.5636445 ] -> mean_test = 0.5705\n",
      "\n",
      "Results for 1300 best features\n",
      "Train scores: [0.69475934 0.69202208 0.6960469  0.69555998 0.69639005] -> mean_train = 0.6950\n",
      "Test scores: [0.56968746 0.58672153 0.55414568 0.57689586 0.56750432] -> mean_test = 0.5710\n",
      "\n",
      "Results for 1400 best features\n",
      "Train scores: [0.69881584 0.69692072 0.69314296 0.69586188 0.69289755] -> mean_train = 0.6955\n",
      "Test scores: [0.55043044 0.5779404  0.57557886 0.5731831  0.57545229] -> mean_test = 0.5705\n",
      "\n",
      "Results for 1500 best features\n",
      "Train scores: [0.68757758 0.69831251 0.69299613 0.69575932 0.69099983] -> mean_train = 0.6931\n",
      "Test scores: [0.55513583 0.55758307 0.58213375 0.56612144 0.5801901 ] -> mean_test = 0.5682\n",
      "\n",
      "Results for 1600 best features\n",
      "Train scores: [0.69680396 0.67875579 0.68808888 0.6935068  0.7016316 ] -> mean_train = 0.6918\n",
      "Test scores: [0.57010867 0.58887448 0.55656807 0.57979911 0.54721794] -> mean_test = 0.5685\n",
      "\n",
      "Results for 1700 best features\n",
      "Train scores: [0.68721915 0.6983206  0.70068564 0.69672682 0.70210271] -> mean_train = 0.6970\n",
      "Test scores: [0.60723235 0.56101476 0.56193151 0.57444668 0.55663242] -> mean_test = 0.5723\n",
      "\n",
      "Results for 1800 best features\n",
      "Train scores: [0.68656108 0.69824925 0.69583443 0.67644838 0.6988139 ] -> mean_train = 0.6912\n",
      "Test scores: [0.57885629 0.56883871 0.58091668 0.57711449 0.55996856] -> mean_test = 0.5731\n",
      "\n",
      "Results for 1900 best features\n",
      "Train scores: [0.69954738 0.69798781 0.69430744 0.69749429 0.6929716 ] -> mean_train = 0.6965\n",
      "Test scores: [0.57454464 0.55854714 0.57742535 0.5581389  0.58210644] -> mean_test = 0.5702\n",
      "\n",
      "Results for 2000 best features\n",
      "Train scores: [0.69979395 0.69530248 0.70005613 0.69404283 0.6946719 ] -> mean_train = 0.6968\n",
      "Test scores: [0.56435615 0.56315425 0.56291767 0.57217159 0.57758536] -> mean_test = 0.5680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=HGBR(), method=\"univariate linear regression\", corrs=f_values, num_feats=range(900, 2001, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f6720-77e7-483d-ac3d-46d6b4555fe2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using univariate linear regression to select features...\n",
    "\n",
    "Results for 900 best features\n",
    "Train scores: [0.66688224 0.6693543  0.64699053 0.65804901 0.65496276] -> mean_train = 0.6592\n",
    "Test scores: [0.54599391 0.53878915 0.53546626 0.55122983 0.52327278] -> mean_test = 0.5390\n",
    "\n",
    "Results for 1000 best features\n",
    "Train scores: [0.6694098  0.66224539 0.66859652 0.66918313 0.67199177] -> mean_train = 0.6683\n",
    "Test scores: [0.54907084 0.55617924 0.53640704 0.54427348 0.51604045] -> mean_test = 0.5404\n",
    "\n",
    "Results for 1100 best features\n",
    "Train scores: [0.69247604 0.69628291 0.6926902  0.69139486 0.69126861] -> mean_train = 0.6928\n",
    "Test scores: [0.5784869  0.56210165 0.56201292 0.5760861  0.57289338] -> mean_test = 0.5703\n",
    "\n",
    "Results for 1200 best features\n",
    "Train scores: [0.69627107 0.69432081 0.69199877 0.69308179 0.69435136] -> mean_train = 0.6940\n",
    "Test scores: [0.56833448 0.57382256 0.57845046 0.56835063 0.5636445 ] -> mean_test = 0.5705\n",
    "\n",
    "Results for 1300 best features\n",
    "Train scores: [0.69475934 0.69202208 0.6960469  0.69555998 0.69639005] -> mean_train = 0.6950\n",
    "Test scores: [0.56968746 0.58672153 0.55414568 0.57689586 0.56750432] -> mean_test = 0.5710\n",
    "\n",
    "Results for 1400 best features\n",
    "Train scores: [0.69881584 0.69692072 0.69314296 0.69586188 0.69289755] -> mean_train = 0.6955\n",
    "Test scores: [0.55043044 0.5779404  0.57557886 0.5731831  0.57545229] -> mean_test = 0.5705\n",
    "\n",
    "Results for 1500 best features\n",
    "Train scores: [0.68757758 0.69831251 0.69299613 0.69575932 0.69099983] -> mean_train = 0.6931\n",
    "Test scores: [0.55513583 0.55758307 0.58213375 0.56612144 0.5801901 ] -> mean_test = 0.5682\n",
    "\n",
    "Results for 1600 best features\n",
    "Train scores: [0.69680396 0.67875579 0.68808888 0.6935068  0.7016316 ] -> mean_train = 0.6918\n",
    "Test scores: [0.57010867 0.58887448 0.55656807 0.57979911 0.54721794] -> mean_test = 0.5685\n",
    "\n",
    "Results for 1700 best features\n",
    "Train scores: [0.68721915 0.6983206  0.70068564 0.69672682 0.70210271] -> mean_train = 0.6970\n",
    "Test scores: [0.60723235 0.56101476 0.56193151 0.57444668 0.55663242] -> mean_test = 0.5723\n",
    "\n",
    "Results for 1800 best features\n",
    "Train scores: [0.68656108 0.69824925 0.69583443 0.67644838 0.6988139 ] -> mean_train = 0.6912\n",
    "Test scores: [0.57885629 0.56883871 0.58091668 0.57711449 0.55996856] -> mean_test = 0.5731\n",
    "\n",
    "Results for 1900 best features\n",
    "Train scores: [0.69954738 0.69798781 0.69430744 0.69749429 0.6929716 ] -> mean_train = 0.6965\n",
    "Test scores: [0.57454464 0.55854714 0.57742535 0.5581389  0.58210644] -> mean_test = 0.5702\n",
    "\n",
    "Results for 2000 best features\n",
    "Train scores: [0.69979395 0.69530248 0.70005613 0.69404283 0.6946719 ] -> mean_train = 0.6968\n",
    "Test scores: [0.56435615 0.56315425 0.56291767 0.57217159 0.57758536] -> mean_test = 0.5680"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c676af-3da6-4f61-a5ee-9b0524960631",
   "metadata": {},
   "source": [
    "Utilizando os <b>ANOVA f-values</b> como método de seleção de features obtivemos um score máximo de <b>0.5731</b> para a combinação <b>HistGradientBoostingRegressor / 1800 features</b>. Todavia, tal como havia acontecido nos casos anteriores, selecionámos a combinação <b>HistGradientBoostingRegressor / 1300 features </b> por se encontrar numa região mais estável no espaço de procura do número de features ótimo. Neste caso, o score obtido foi <b>0.5710</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212759d7-d4a7-41cd-a8a1-87a3c1ce4479",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc819be-5e0c-4259-b4f9-a9def391667b",
   "metadata": {},
   "source": [
    "<b>Mutual information regression</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bf73db1-01af-41de-a9f2-481dd3aa1e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.29933053 0.30549307 0.30197076 0.30446767 0.29626695] -> mean_train = 0.3015\n",
      "Test scores: [0.2959669  0.2691783  0.28315959 0.27444436 0.30818651] -> mean_test = 0.2862\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.39009861 0.39224099 0.39230819 0.3884802  0.38664143] -> mean_train = 0.3900\n",
      "Test scores: [0.34586822 0.34771363 0.35038695 0.36931395 0.37310897] -> mean_test = 0.3573\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.4271809  0.42857239 0.42821025 0.4340767  0.42882269] -> mean_train = 0.4294\n",
      "Test scores: [0.39660344 0.23434375 0.38580482 0.36781109 0.39394364] -> mean_test = 0.3557\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.45024162 0.44818107 0.44927905 0.44205742 0.45097461] -> mean_train = 0.4481\n",
      "Test scores: [0.38582873 0.3408515  0.34684105 0.4190393  0.38900584] -> mean_test = 0.3763\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for KNeighborsRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.66938194 0.6692286  0.67205625 0.67092688 0.67394699] -> mean_train = 0.6711\n",
      "Test scores: [0.49851846 0.50919087 0.50141949 0.50967624 0.48322933] -> mean_test = 0.5004\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.6649939  0.66388582 0.6675673  0.66380483 0.66774893] -> mean_train = 0.6656\n",
      "Test scores: [0.49177363 0.49484785 0.48735343 0.48916829 0.48379032] -> mean_test = 0.4894\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.66257682 0.65881848 0.65683579 0.65848209 0.6576441 ] -> mean_train = 0.6589\n",
      "Test scores: [0.48440107 0.44303405 0.47002927 0.48236651 0.50191799] -> mean_test = 0.4763\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.64859161 0.65853628 0.65476492 0.64637203 0.64708879] -> mean_train = 0.6511\n",
      "Test scores: [0.46616296 0.43867683 0.46643825 0.4858647  0.48901911] -> mean_test = 0.4692\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for RandomForestRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.89444151 0.89337992 0.89547431 0.89845373 0.89603736] -> mean_train = 0.8956\n",
      "Test scores: [0.53502458 0.55360583 0.54909641 0.53530799 0.54899091] -> mean_test = 0.5444\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.89585105 0.8940862  0.89247588 0.89726787 0.89673408] -> mean_train = 0.8953\n",
      "Test scores: [0.54289553 0.55422491 0.54656744 0.5286691  0.53471027] -> mean_test = 0.5414\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.89460238 0.89840983 0.89471388 0.89379372 0.89348131] -> mean_train = 0.8950\n",
      "Test scores: [0.53805615 0.49215636 0.53282304 0.54405425 0.55358532] -> mean_test = 0.5321\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.89466953 0.89382278 0.89359465 0.89711647 0.89608051] -> mean_train = 0.8951\n",
      "Test scores: [0.50978071 0.53141708 0.53141627 0.51194323 0.53676421] -> mean_test = 0.5243\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for SVR using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.21831226 0.22384925 0.22468885 0.22106031 0.23286098] -> mean_train = 0.2242\n",
      "Test scores: [0.22227113 0.22504403 0.22066862 0.22561754 0.20318227] -> mean_test = 0.2194\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.27662049 0.27005039 0.27946139 0.27833096 0.28038266] -> mean_train = 0.2770\n",
      "Test scores: [0.26810613 0.28251338 0.26700299 0.26206192 0.27327793] -> mean_test = 0.2706\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.26095284 0.2599437  0.2742461  0.27089909 0.26437299] -> mean_train = 0.2661\n",
      "Test scores: [0.2656998  0.27016543 0.24706366 0.24770026 0.26133609] -> mean_test = 0.2584\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.25518322 0.26270685 0.25606052 0.25377655 0.25957403] -> mean_train = 0.2575\n",
      "Test scores: [0.24989192 0.23992727 0.24558835 0.26371241 0.25509985] -> mean_test = 0.2508\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for MLPRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.4987827  0.52403325 0.48887852 0.49507846 0.49171286] -> mean_train = 0.4997\n",
      "Test scores: [0.46916664 0.47291492 0.50145108 0.4597296  0.47345257] -> mean_test = 0.4753\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.53748188 0.52034604 0.48873221 0.49153429 0.51736356] -> mean_train = 0.5111\n",
      "Test scores: [0.47288314 0.49475383 0.43479143 0.46580252 0.48696947] -> mean_test = 0.4710\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.52394406 0.50311842 0.51250483 0.48896357 0.50551634] -> mean_train = 0.5068\n",
      "Test scores: [0.48286718 0.48485679 0.46718476 0.44797404 0.46836286] -> mean_test = 0.4702\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.49514453 0.49211496 0.49850836 0.49249767 0.48718663] -> mean_train = 0.4931\n",
      "Test scores: [0.44881383 0.46495059 0.46009689 0.46278661 0.4584256 ] -> mean_test = 0.4590\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for AdaBoostRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.30779509 0.27707164 0.29471665 0.32587769 0.31276764] -> mean_train = 0.3036\n",
      "Test scores: [0.29247165 0.2671752  0.29446766 0.31134919 0.29826194] -> mean_test = 0.2927\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.28359559 0.32371424 0.31099812 0.29702389 0.28263655] -> mean_train = 0.2996\n",
      "Test scores: [0.29590716 0.29494945 0.29787745 0.27476386 0.28179445] -> mean_test = 0.2891\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.27976414 0.32424724 0.31334374 0.28116491 0.3159436 ] -> mean_train = 0.3029\n",
      "Test scores: [0.27701969 0.29591232 0.31300413 0.27438443 0.30041012] -> mean_test = 0.2921\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.29247856 0.29151977 0.29933653 0.28316984 0.2901339 ] -> mean_train = 0.2913\n",
      "Test scores: [0.25972989 0.27607238 0.293455   0.2808207  0.28542952] -> mean_test = 0.2791\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.68981372 0.69006714 0.6844912  0.69081417 0.69452469] -> mean_train = 0.6899\n",
      "Test scores: [0.58052739 0.57938755 0.60418372 0.58680193 0.57019993] -> mean_test = 0.5842\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.69877871 0.69744662 0.69532888 0.70010964 0.69522936] -> mean_train = 0.6974\n",
      "Test scores: [0.58736675 0.58846537 0.60117214 0.56251592 0.58267537] -> mean_test = 0.5844\n",
      "\n",
      "Results for 600 best features\n",
      "Train scores: [0.69906142 0.70169151 0.70439615 0.69289322 0.70444951] -> mean_train = 0.7005\n",
      "Test scores: [0.59873747 0.59653477 0.56286187 0.58374117 0.57587304] -> mean_test = 0.5835\n",
      "\n",
      "Results for 800 best features\n",
      "Train scores: [0.70322891 0.69916378 0.70634854 0.70964569 0.70509382] -> mean_train = 0.7047\n",
      "Test scores: [0.58508506 0.60112711 0.57402897 0.56497576 0.5867018 ] -> mean_test = 0.5824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, Model in enumerate([LR, KNR, RFR, SVR, MLPR, ADA, HGBR]):\n",
    "    test_corr_models(model=Model(), method=\"mutual information regression\", corrs=mutual_info)\n",
    "    if i < 6:\n",
    "        print(\"----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0f8a3-6be2-4da7-8ad5-047f1e0d89f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for LinearRegression using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.29933053 0.30549307 0.30197076 0.30446767 0.29626695] -> mean_train = 0.3015\n",
    "Test scores: [0.2959669  0.2691783  0.28315959 0.27444436 0.30818651] -> mean_test = 0.2862\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.39009861 0.39224099 0.39230819 0.3884802  0.38664143] -> mean_train = 0.3900\n",
    "Test scores: [0.34586822 0.34771363 0.35038695 0.36931395 0.37310897] -> mean_test = 0.3573\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.4271809  0.42857239 0.42821025 0.4340767  0.42882269] -> mean_train = 0.4294\n",
    "Test scores: [0.39660344 0.23434375 0.38580482 0.36781109 0.39394364] -> mean_test = 0.3557\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.45024162 0.44818107 0.44927905 0.44205742 0.45097461] -> mean_train = 0.4481\n",
    "Test scores: [0.38582873 0.3408515  0.34684105 0.4190393  0.38900584] -> mean_test = 0.3763\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for KNeighborsRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.66938194 0.6692286  0.67205625 0.67092688 0.67394699] -> mean_train = 0.6711\n",
    "Test scores: [0.49851846 0.50919087 0.50141949 0.50967624 0.48322933] -> mean_test = 0.5004\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.6649939  0.66388582 0.6675673  0.66380483 0.66774893] -> mean_train = 0.6656\n",
    "Test scores: [0.49177363 0.49484785 0.48735343 0.48916829 0.48379032] -> mean_test = 0.4894\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.66257682 0.65881848 0.65683579 0.65848209 0.6576441 ] -> mean_train = 0.6589\n",
    "Test scores: [0.48440107 0.44303405 0.47002927 0.48236651 0.50191799] -> mean_test = 0.4763\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.64859161 0.65853628 0.65476492 0.64637203 0.64708879] -> mean_train = 0.6511\n",
    "Test scores: [0.46616296 0.43867683 0.46643825 0.4858647  0.48901911] -> mean_test = 0.4692\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for RandomForestRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.89444151 0.89337992 0.89547431 0.89845373 0.89603736] -> mean_train = 0.8956\n",
    "Test scores: [0.53502458 0.55360583 0.54909641 0.53530799 0.54899091] -> mean_test = 0.5444\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.89585105 0.8940862  0.89247588 0.89726787 0.89673408] -> mean_train = 0.8953\n",
    "Test scores: [0.54289553 0.55422491 0.54656744 0.5286691  0.53471027] -> mean_test = 0.5414\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.89460238 0.89840983 0.89471388 0.89379372 0.89348131] -> mean_train = 0.8950\n",
    "Test scores: [0.53805615 0.49215636 0.53282304 0.54405425 0.55358532] -> mean_test = 0.5321\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.89466953 0.89382278 0.89359465 0.89711647 0.89608051] -> mean_train = 0.8951\n",
    "Test scores: [0.50978071 0.53141708 0.53141627 0.51194323 0.53676421] -> mean_test = 0.5243\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for SVR using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.21831226 0.22384925 0.22468885 0.22106031 0.23286098] -> mean_train = 0.2242\n",
    "Test scores: [0.22227113 0.22504403 0.22066862 0.22561754 0.20318227] -> mean_test = 0.2194\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.27662049 0.27005039 0.27946139 0.27833096 0.28038266] -> mean_train = 0.2770\n",
    "Test scores: [0.26810613 0.28251338 0.26700299 0.26206192 0.27327793] -> mean_test = 0.2706\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.26095284 0.2599437  0.2742461  0.27089909 0.26437299] -> mean_train = 0.2661\n",
    "Test scores: [0.2656998  0.27016543 0.24706366 0.24770026 0.26133609] -> mean_test = 0.2584\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.25518322 0.26270685 0.25606052 0.25377655 0.25957403] -> mean_train = 0.2575\n",
    "Test scores: [0.24989192 0.23992727 0.24558835 0.26371241 0.25509985] -> mean_test = 0.2508\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for MLPRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.4987827  0.52403325 0.48887852 0.49507846 0.49171286] -> mean_train = 0.4997\n",
    "Test scores: [0.46916664 0.47291492 0.50145108 0.4597296  0.47345257] -> mean_test = 0.4753\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.53748188 0.52034604 0.48873221 0.49153429 0.51736356] -> mean_train = 0.5111\n",
    "Test scores: [0.47288314 0.49475383 0.43479143 0.46580252 0.48696947] -> mean_test = 0.4710\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.52394406 0.50311842 0.51250483 0.48896357 0.50551634] -> mean_train = 0.5068\n",
    "Test scores: [0.48286718 0.48485679 0.46718476 0.44797404 0.46836286] -> mean_test = 0.4702\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.49514453 0.49211496 0.49850836 0.49249767 0.48718663] -> mean_train = 0.4931\n",
    "Test scores: [0.44881383 0.46495059 0.46009689 0.46278661 0.4584256 ] -> mean_test = 0.4590\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for AdaBoostRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.30779509 0.27707164 0.29471665 0.32587769 0.31276764] -> mean_train = 0.3036\n",
    "Test scores: [0.29247165 0.2671752  0.29446766 0.31134919 0.29826194] -> mean_test = 0.2927\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.28359559 0.32371424 0.31099812 0.29702389 0.28263655] -> mean_train = 0.2996\n",
    "Test scores: [0.29590716 0.29494945 0.29787745 0.27476386 0.28179445] -> mean_test = 0.2891\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.27976414 0.32424724 0.31334374 0.28116491 0.3159436 ] -> mean_train = 0.3029\n",
    "Test scores: [0.27701969 0.29591232 0.31300413 0.27438443 0.30041012] -> mean_test = 0.2921\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.29247856 0.29151977 0.29933653 0.28316984 0.2901339 ] -> mean_train = 0.2913\n",
    "Test scores: [0.25972989 0.27607238 0.293455   0.2808207  0.28542952] -> mean_test = 0.2791\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.68981372 0.69006714 0.6844912  0.69081417 0.69452469] -> mean_train = 0.6899\n",
    "Test scores: [0.58052739 0.57938755 0.60418372 0.58680193 0.57019993] -> mean_test = 0.5842\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.69877871 0.69744662 0.69532888 0.70010964 0.69522936] -> mean_train = 0.6974\n",
    "Test scores: [0.58736675 0.58846537 0.60117214 0.56251592 0.58267537] -> mean_test = 0.5844\n",
    "\n",
    "Results for 600 best features\n",
    "Train scores: [0.69906142 0.70169151 0.70439615 0.69289322 0.70444951] -> mean_train = 0.7005\n",
    "Test scores: [0.59873747 0.59653477 0.56286187 0.58374117 0.57587304] -> mean_test = 0.5835\n",
    "\n",
    "Results for 800 best features\n",
    "Train scores: [0.70322891 0.69916378 0.70634854 0.70964569 0.70509382] -> mean_train = 0.7047\n",
    "Test scores: [0.58508506 0.60112711 0.57402897 0.56497576 0.5867018 ] -> mean_test = 0.5824"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681809a3-2831-4d4d-801b-490e0c0a5270",
   "metadata": {},
   "source": [
    "<b>Mutual information regression</b> (further testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe62b40-9818-40c4-91eb-e2c04c6a03cd",
   "metadata": {},
   "source": [
    "Obtivemos os melhores scores utilizando o modelo <b>HistGradientBoosting</b> e um número de features entre <b>200</b> e <b>400</b>. Então, efetuámos novas validações cruzadas do modelo tendo em conta números de features pertecentes a esta gama de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "29e30cd4-e1ae-4515-9304-a42f364e75e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for HistGradientBoostingRegressor using mutual information regression to select features...\n",
      "\n",
      "Results for 100 best features\n",
      "Train scores: [0.64638056 0.647755   0.65273351 0.64679615 0.64730562] -> mean_train = 0.6482\n",
      "Test scores: [0.56075003 0.54913101 0.52380878 0.56463768 0.54638954] -> mean_test = 0.5489\n",
      "\n",
      "Results for 150 best features\n",
      "Train scores: [0.68533162 0.68011919 0.68446605 0.68878994 0.68179735] -> mean_train = 0.6841\n",
      "Test scores: [0.59444313 0.58825639 0.5846732  0.56242807 0.61195944] -> mean_test = 0.5884\n",
      "\n",
      "Results for 200 best features\n",
      "Train scores: [0.69143393 0.68617854 0.68891249 0.689917   0.69075993] -> mean_train = 0.6894\n",
      "Test scores: [0.58727969 0.59127946 0.58798012 0.58635699 0.58367   ] -> mean_test = 0.5873\n",
      "\n",
      "Results for 250 best features\n",
      "Train scores: [0.68964904 0.69257095 0.69232035 0.69044551 0.69519141] -> mean_train = 0.6920\n",
      "Test scores: [0.5855083  0.5921357  0.58939877 0.59280559 0.57684508] -> mean_test = 0.5873\n",
      "\n",
      "Results for 300 best features\n",
      "Train scores: [0.69317032 0.69305788 0.6969709  0.69497039 0.69406247] -> mean_train = 0.6944\n",
      "Test scores: [0.59697292 0.58954455 0.57880944 0.58565545 0.58374544] -> mean_test = 0.5869\n",
      "\n",
      "Results for 350 best features\n",
      "Train scores: [0.69772839 0.69377324 0.70152373 0.69195493 0.69701042] -> mean_train = 0.6964\n",
      "Test scores: [0.58113254 0.60130415 0.57293537 0.5932389  0.58947037] -> mean_test = 0.5876\n",
      "\n",
      "Results for 400 best features\n",
      "Train scores: [0.69333979 0.6969914  0.69768763 0.699293   0.70044102] -> mean_train = 0.6976\n",
      "Test scores: [0.60967112 0.58794547 0.58419745 0.58313238 0.56278805] -> mean_test = 0.5855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corr_models(model=HGBR(), method=\"mutual information regression\", corrs=mutual_info, num_feats=range(100, 401, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d608a49-6cbd-4050-8e4a-9aa923a2decf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using mutual information regression to select features...\n",
    "\n",
    "Results for 100 best features\n",
    "Train scores: [0.64638056 0.647755   0.65273351 0.64679615 0.64730562] -> mean_train = 0.6482\n",
    "Test scores: [0.56075003 0.54913101 0.52380878 0.56463768 0.54638954] -> mean_test = 0.5489\n",
    "\n",
    "Results for 150 best features\n",
    "Train scores: [0.68533162 0.68011919 0.68446605 0.68878994 0.68179735] -> mean_train = 0.6841\n",
    "Test scores: [0.59444313 0.58825639 0.5846732  0.56242807 0.61195944] -> mean_test = 0.5884\n",
    "\n",
    "Results for 200 best features\n",
    "Train scores: [0.69143393 0.68617854 0.68891249 0.689917   0.69075993] -> mean_train = 0.6894\n",
    "Test scores: [0.58727969 0.59127946 0.58798012 0.58635699 0.58367   ] -> mean_test = 0.5873\n",
    "\n",
    "Results for 250 best features\n",
    "Train scores: [0.68964904 0.69257095 0.69232035 0.69044551 0.69519141] -> mean_train = 0.6920\n",
    "Test scores: [0.5855083  0.5921357  0.58939877 0.59280559 0.57684508] -> mean_test = 0.5873\n",
    "\n",
    "Results for 300 best features\n",
    "Train scores: [0.69317032 0.69305788 0.6969709  0.69497039 0.69406247] -> mean_train = 0.6944\n",
    "Test scores: [0.59697292 0.58954455 0.57880944 0.58565545 0.58374544] -> mean_test = 0.5869\n",
    "\n",
    "Results for 350 best features\n",
    "Train scores: [0.69772839 0.69377324 0.70152373 0.69195493 0.69701042] -> mean_train = 0.6964\n",
    "Test scores: [0.58113254 0.60130415 0.57293537 0.5932389  0.58947037] -> mean_test = 0.5876\n",
    "\n",
    "Results for 400 best features\n",
    "Train scores: [0.69333979 0.6969914  0.69768763 0.699293   0.70044102] -> mean_train = 0.6976\n",
    "Test scores: [0.60967112 0.58794547 0.58419745 0.58313238 0.56278805] -> mean_test = 0.5855"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d8280-8048-4111-8095-0e9eea5d85d7",
   "metadata": {},
   "source": [
    "Utilizando a <b>informação mútua</b> como método de seleção de features obtivemos um score máximo de <b>0.5884</b> para a combinação <b>HistGradientBoostingRegressor / 150 features</b>. No entanto, tal como se sucedeu em todos os casos anteriores, selecionámos a combinação <b>HistGradientBoostingRegressor / 200 features </b> por se encontrar numa região mais estável no espaço de procura do número de features ótimo. Neste caso, o score obtido foi <b>0.5873</b>, o melhor resultado até ao momento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b442145-4863-4def-a02f-9b21e9e779e8",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ed228-585d-49d0-9a08-a1ff5b767044",
   "metadata": {},
   "source": [
    "<b>SelectFromModel</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b858e-b3c2-46a2-8bc9-491e59e5ecf9",
   "metadata": {},
   "source": [
    "De seguida, de modo a testar outro método de seleção de features, utilizámos a classe <b>SelectFromModel</b> do <b>sklearn</b>. A seleção de features é realizada tendo por base o modelo <b>RandomForestRegressor</b> já que, a par do modelo <b>LinearRegression</b>, é o único que apresenta o atributo <b>feature_importances_</b> (<b>coef_</b> no caso do modelo <b>LinearRegression</b>), necessário para a definição de quais features manter e eliminar. As features selecionadas são depois partilhadas na definição do dataset que alimenta os restantes modelos de machine learning (<b>LR</b>, <b>KNR</b>, <b>SVR</b>, <b>MLPR</b>, <b>ADA</b>, <b>HGBR</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b0d066a-b075-48f2-b362-32e56bcbe079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8171c51",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cv_select_from_model(models: list, cv=5):\n",
    "    \"\"\"\n",
    "    Cross-validates models using features outputed by sklearn's SelectFromModel using a Random Forest\n",
    "    Regressor as estimator. Returns the computed feature mask for further use.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models: list\n",
    "        A list object containing uninitialized sklearn models\n",
    "    cv: int (default=5)\n",
    "        Number of folds used in cross-validation\n",
    "    \"\"\"\n",
    "    # select best features according to RFR feature importances\n",
    "    # features whose absolute importance value is greater or equal to the mean importance are kept\n",
    "    selector = SelectFromModel(estimator=RFR())\n",
    "    selector.fit(X_train_sc, y_train)\n",
    "    feature_mask = selector.get_support()\n",
    "    # new dataframe containing the features selected by SelectFromModel\n",
    "    X_train_new = X_train_sc.iloc[:, feature_mask]\n",
    "    # iterate through models and cross-validate\n",
    "    for Model in models:\n",
    "        InitModel = Model()\n",
    "        print(f\"Getting results for {InitModel.__class__.__name__} using 'SelectFromModel' to select features...\\n\")\n",
    "        # cross-validate\n",
    "        result = cross_validate(estimator=InitModel,\n",
    "                                X=X_train_new,\n",
    "                                y=y_train,\n",
    "                                cv=KFold(n_splits=cv, shuffle=True),\n",
    "                                return_train_score=True)\n",
    "        # print cross-validation results\n",
    "        mean_train = np.sum(result[\"train_score\"]) / cv\n",
    "        mean_test = np.sum(result[\"test_score\"]) / cv\n",
    "        print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "        print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")\n",
    "    return feature_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f6d1fc3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for LinearRegression using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.47917286 0.4787124  0.47911779 0.47851584 0.47531577] -> mean_train = 0.4782\n",
      "Test scores: [0.3846648  0.41275611 0.3885643  0.38054965 0.4225524 ] -> mean_test = 0.3978\n",
      "\n",
      "Getting results for KNeighborsRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.64117131 0.64691899 0.65368522 0.64261927 0.65363452] -> mean_train = 0.6476\n",
      "Test scores: [0.48092228 0.4558046  0.45069206 0.48195009 0.43438383] -> mean_test = 0.4608\n",
      "\n",
      "Getting results for RandomForestRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.89198975 0.8930869  0.89418728 0.89629146 0.89215876] -> mean_train = 0.8935\n",
      "Test scores: [0.53534368 0.5273811  0.49640657 0.51720304 0.52155594] -> mean_test = 0.5196\n",
      "\n",
      "Getting results for SVR using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.2441218  0.23882408 0.2410639  0.24465293 0.24739255] -> mean_train = 0.2432\n",
      "Test scores: [0.23128662 0.24998816 0.24070777 0.22920134 0.23454579] -> mean_test = 0.2371\n",
      "\n",
      "Getting results for MLPRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.42067463 0.42944524 0.51796859 0.41438029 0.42415684] -> mean_train = 0.4413\n",
      "Test scores: [0.40686397 0.38491727 0.48272257 0.40023052 0.36919241] -> mean_test = 0.4088\n",
      "\n",
      "Getting results for AdaBoostRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.28959696 0.30083703 0.29143091 0.2909287  0.28061531] -> mean_train = 0.2907\n",
      "Test scores: [0.25596531 0.29722519 0.29148558 0.27467346 0.2703121 ] -> mean_test = 0.2779\n",
      "\n",
      "Getting results for HistGradientBoostingRegressor using 'SelectFromModel' to select features...\n",
      "\n",
      "Train scores: [0.68981507 0.69744861 0.70596076 0.71203651 0.70741611] -> mean_train = 0.7025\n",
      "Test scores: [0.58028429 0.57268925 0.57793106 0.56851494 0.57161777] -> mean_test = 0.5742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_mask = cv_select_from_model(models=[LR, KNR, RFR, SVR, MLPR, ADA, HGBR])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96970d-bbab-4d24-8956-519423c2a053",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Getting results for LinearRegression using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.47917286 0.4787124  0.47911779 0.47851584 0.47531577] -> mean_train = 0.4782\n",
    "Test scores: [0.3846648  0.41275611 0.3885643  0.38054965 0.4225524 ] -> mean_test = 0.3978\n",
    "\n",
    "Getting results for KNeighborsRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.64117131 0.64691899 0.65368522 0.64261927 0.65363452] -> mean_train = 0.6476\n",
    "Test scores: [0.48092228 0.4558046  0.45069206 0.48195009 0.43438383] -> mean_test = 0.4608\n",
    "\n",
    "Getting results for RandomForestRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.89198975 0.8930869  0.89418728 0.89629146 0.89215876] -> mean_train = 0.8935\n",
    "Test scores: [0.53534368 0.5273811  0.49640657 0.51720304 0.52155594] -> mean_test = 0.5196\n",
    "\n",
    "Getting results for SVR using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.2441218  0.23882408 0.2410639  0.24465293 0.24739255] -> mean_train = 0.2432\n",
    "Test scores: [0.23128662 0.24998816 0.24070777 0.22920134 0.23454579] -> mean_test = 0.2371\n",
    "\n",
    "Getting results for MLPRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.42067463 0.42944524 0.51796859 0.41438029 0.42415684] -> mean_train = 0.4413\n",
    "Test scores: [0.40686397 0.38491727 0.48272257 0.40023052 0.36919241] -> mean_test = 0.4088\n",
    "\n",
    "Getting results for AdaBoostRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.28959696 0.30083703 0.29143091 0.2909287  0.28061531] -> mean_train = 0.2907\n",
    "Test scores: [0.25596531 0.29722519 0.29148558 0.27467346 0.2703121 ] -> mean_test = 0.2779\n",
    "\n",
    "Getting results for HistGradientBoostingRegressor using 'SelectFromModel' to select features...\n",
    "\n",
    "Train scores: [0.68981507 0.69744861 0.70596076 0.71203651 0.70741611] -> mean_train = 0.7025\n",
    "Test scores: [0.58028429 0.57268925 0.57793106 0.56851494 0.57161777] -> mean_test = 0.5742"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cb32b-2944-4f19-af17-6474856d60ce",
   "metadata": {},
   "source": [
    "Os resultados sugerem que o melhor modelo é o <b>HistGradientBoostingRegressor</b> com um score de <b>0.5742</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa6aa4-461c-4552-8179-4b77aaded534",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8a5a8-9432-4e62-b43a-0935fcf819f3",
   "metadata": {},
   "source": [
    "<b>Pearson + Spearman + mutual information</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na tentativa de melhorar ligeiramente o nosso melhor modelo (combinação <b>HistGradientBoostingRegressor</b> / <b>200 features</b> utilizando a <b>informação mútua</b> como método de seleção de features), decidimos combinar as melhores features selecionadas a partir de cada método de seleção (com exceção dos <b>ANOVA f-values</b>). Para isso, definimos um lower bound de <b>150</b> features e um upper bound de <b>350</b> features, selecionámos as melhores features tendo em conta cada método de seleção e combinámo-las através da disjunção dos nomes associados às mesma. Finalmente, efetuámos novas validações cruzadas 5-fold a partir dos datasets resultantes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating HistGradientBoostingRegressor using 305 (150 comb) features...\n",
      "Train scores: [0.68301761 0.69117031 0.68361854 0.69151876 0.68589539] -> mean_train = 0.6870\n",
      "Test scores: [0.60715197 0.56753502 0.59320281 0.57107169 0.5921822 ] -> mean_test = 0.5862\n",
      "\n",
      "Cross-validating HistGradientBoostingRegressor using 404 (200 comb) features...\n",
      "Train scores: [0.6932829  0.68857836 0.69084999 0.69144631 0.6913527 ] -> mean_train = 0.6911\n",
      "Test scores: [0.58061507 0.58997917 0.59100267 0.5860717  0.58747708] -> mean_test = 0.5870\n",
      "\n",
      "Cross-validating HistGradientBoostingRegressor using 498 (250 comb) features...\n",
      "Train scores: [0.69726495 0.69041586 0.69251149 0.69384081 0.69802487] -> mean_train = 0.6944\n",
      "Test scores: [0.57633606 0.60185842 0.59790227 0.58521013 0.57564917] -> mean_test = 0.5874\n",
      "\n",
      "Cross-validating HistGradientBoostingRegressor using 588 (300 comb) features...\n",
      "Train scores: [0.69776227 0.69850622 0.69715715 0.69354673 0.6991712 ] -> mean_train = 0.6972\n",
      "Test scores: [0.58759311 0.57259427 0.57885996 0.60668513 0.58010628] -> mean_test = 0.5852\n",
      "\n",
      "Cross-validating HistGradientBoostingRegressor using 678 (350 comb) features...\n",
      "Train scores: [0.69871638 0.69956833 0.69968343 0.69848404 0.70071811] -> mean_train = 0.6994\n",
      "Test scores: [0.58591725 0.5735554  0.58815685 0.59272155 0.57522353] -> mean_test = 0.5831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num in [150, 200, 250, 300, 350]:\n",
    "    best_pearson = list(get_k_best_corrs(num, pearson_corrs).keys())\n",
    "    best_spearman = list(get_k_best_corrs(num, spearman_corrs).keys())\n",
    "    best_mutual_info = list(get_k_best_corrs(num, mutual_info).keys())\n",
    "    best_feats = list(set(best_pearson + best_spearman + best_mutual_info))\n",
    "    print(f\"Cross-validating HistGradientBoostingRegressor using {len(best_feats)} ({num} comb) features...\")\n",
    "    x_train_psmi = X_train_sc[best_feats]\n",
    "    result = cross_validate(estimator=HGBR(),\n",
    "                            X=x_train_psmi,\n",
    "                            y=y_train,\n",
    "                            cv=KFold(n_splits=5, shuffle=True),\n",
    "                            return_train_score=True)\n",
    "    mean_train = np.sum(result[\"train_score\"]) / 5\n",
    "    mean_test = np.sum(result[\"test_score\"]) / 5\n",
    "    print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "    print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(AFTER UPDATING CV)\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 305 (150 comb) features...\n",
    "Train scores: [0.68301761 0.69117031 0.68361854 0.69151876 0.68589539] -> mean_train = 0.6870\n",
    "Test scores: [0.60715197 0.56753502 0.59320281 0.57107169 0.5921822 ] -> mean_test = 0.5862\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 404 (200 comb) features...\n",
    "Train scores: [0.6932829  0.68857836 0.69084999 0.69144631 0.6913527 ] -> mean_train = 0.6911\n",
    "Test scores: [0.58061507 0.58997917 0.59100267 0.5860717  0.58747708] -> mean_test = 0.5870\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 498 (250 comb) features...\n",
    "Train scores: [0.69726495 0.69041586 0.69251149 0.69384081 0.69802487] -> mean_train = 0.6944\n",
    "Test scores: [0.57633606 0.60185842 0.59790227 0.58521013 0.57564917] -> mean_test = 0.5874\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 588 (300 comb) features...\n",
    "Train scores: [0.69776227 0.69850622 0.69715715 0.69354673 0.6991712 ] -> mean_train = 0.6972\n",
    "Test scores: [0.58759311 0.57259427 0.57885996 0.60668513 0.58010628] -> mean_test = 0.5852\n",
    "\n",
    "Cross-validating HistGradientBoostingRegressor using 678 (350 comb) features...\n",
    "Train scores: [0.69871638 0.69956833 0.69968343 0.69848404 0.70071811] -> mean_train = 0.6994\n",
    "Test scores: [0.58591725 0.5735554  0.58815685 0.59272155 0.57522353] -> mean_test = 0.5831"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Os resultados sugerem que o número ótimo de features (tendo em consideração o espaço de procura estabelecido) é <b>250</b> para cada método de seleção. Após disjunção dos nomes das features resultantes da seleção por cada um dos métodos, obtivemos um total de <b>498</b> features e um score médio de teste na validação cruzada 5-fold de <b>0.5874</b>."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "58d8963c",
   "metadata": {},
   "source": [
    "### Optimize hyperparameters of the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# best number of features considering the combination of methods (from {200, 250, 300, 350, 400})\n",
    "best_k = 250\n",
    "best_pearson = list(get_k_best_corrs(best_k, pearson_corrs).keys())\n",
    "best_spearman = list(get_k_best_corrs(best_k, spearman_corrs).keys())\n",
    "best_mutual_info = list(get_k_best_corrs(best_k, mutual_info).keys())\n",
    "\n",
    "best_features_psmi = list(set(best_pearson + best_spearman + best_mutual_info))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tendo em consideração os melhores modelos para cada método de seleção de features (<b>Pearson</b>, <b>Spearman</b>, <b>ANOVA f-values</b>, <b>informação mútua</b>, <b>SelectFromModel</b> e combinação <b>Pearson + Spearman + informação mútua</b>), procedemos à otimização dos seus hiperparâmetros. Invariavelmente, o melhor modelo foi o <b>HistGradientBoostingRegressor</b>. Consequentemente, apenas definimos um espaço de procura para a otimização de hiperparâmetros para este modelo. Considerámos os seguintes hiperparâmetros: <b>learning_rate</b>, <b>max_iter</b>, <b>max_leaf_nodes</b>, <b>min_samples_leaf</b> e <b>warm_start</b>. De modo a efetuar a procura dos mesmos, recorremos à classe <b>RandomizedSearchCV</b> do <b>sklearn</b>. Não é utilizada uma procura exaustiva (por exemplo, utilizando a classe <b>GridSearchCV</b> do <b>sklearn</b>), já que utilizando a grelha de hiperparâmetros definida em baixo seriam treinados <b>2500</b> modelos (<b>500</b> combinações de hiperparâmetros * <b>5 folds</b> na validação cruzada) para cada método de seleção de features, tornando a complexidade temporal do problema bastante elevada."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93c2b041",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f4eeb9e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "HYPER = {\"learning_rate\": [0.05, 0.1],\n",
    "         \"max_iter\": np.arange(100, 301, 50),\n",
    "         \"max_leaf_nodes\": np.arange(31, 64, 8),\n",
    "         \"min_samples_leaf\": np.arange(16, 33, 4),\n",
    "         \"warm_start\": [True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef53bf7-e4b6-47b7-9256-75d069b2b6bb",
   "metadata": {},
   "source": [
    "<b>Pearson, Spearman, univariate linear regression and mutual information regression</b>\n",
    "<br>(hyperparameter optimization using the above methods to select features to train the models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76344fba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(models:list, methods:list, corrs:list, num_feats:list, cv=5):\n",
    "    results = []\n",
    "    for mo, me, co, nf in zip(models, methods, corrs, num_feats):\n",
    "        InitModel = mo()\n",
    "        print(f\"Optimizing {InitModel.__class__.__name__} using {me} to select features ({nf})...\")\n",
    "        print(\"----------\")\n",
    "        x_train_gs = X_train_sc.loc[:, get_k_best_corrs(nf, co).keys()]\n",
    "        gs = RandomizedSearchCV(estimator=InitModel,\n",
    "                                param_distributions=HYPER,\n",
    "                                n_iter=40,\n",
    "                                cv=KFold(n_splits=cv, shuffle=True),\n",
    "                                verbose=3)\n",
    "        gs.fit(x_train_gs, y_train)\n",
    "        results.append(gs.best_params_)\n",
    "        print(\"----------\")\n",
    "        print(f\"Optimal hyperparameters: {gs.best_params_}\")\n",
    "        print(f\"Best score: {gs.best_score_}\\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cbba3e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-36-4d2cd6ae2957>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mmodels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mHGBR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mHGBR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mHGBR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mHGBR\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mmethods\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"Pearson correlation\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"Spearman correlation\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"univariate linear regression\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"mutual information regression\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mcorrs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mpearson_corrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspearman_corrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf_values\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmutual_info\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mnum_feats\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m1200\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1200\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1300\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m200\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'f_values' is not defined"
     ]
    }
   ],
   "source": [
    "models = [HGBR, HGBR, HGBR, HGBR]\n",
    "methods = [\"Pearson correlation\", \"Spearman correlation\", \"univariate linear regression\", \"mutual information regression\"]\n",
    "corrs = [pearson_corrs, spearman_corrs, f_values, mutual_info]\n",
    "num_feats = [1200, 1200, 1300, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9186a6ea-e3de-48e4-a4a9-7331eec3fda6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-37-db0232c62d72>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mbest_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgrid_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethods\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcorrs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_feats\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "best_params = grid_search(models, methods, corrs, num_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f9a05-5570-4b1e-9861-2ea49af97e20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Optimizing HistGradientBoostingRegressor using Pearson correlation to select features (1200)...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.574 total time=  13.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.574 total time=  13.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.562 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  17.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  12.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.571 total time=  17.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.580 total time=  14.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.556 total time=  14.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  13.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.578 total time=  15.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.572 total time=  17.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.578 total time=  17.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.561 total time=  12.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  14.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  14.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.555 total time=  12.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.564 total time=  12.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.544 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.555 total time=  12.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  12.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.576 total time=  13.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.576 total time=  15.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.558 total time=  13.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.576 total time=  14.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.585 total time=  14.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.573 total time=  21.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.578 total time=  21.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.562 total time=  23.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.578 total time=  19.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  22.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.573 total time=  13.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.581 total time=  15.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.558 total time=  17.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  16.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  17.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.576 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.580 total time=  15.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.558 total time=  15.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.582 total time=  16.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.580 total time=  17.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  15.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  18.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.561 total time=  14.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  13.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  16.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.577 total time=  19.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  13.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.552 total time=  11.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.577 total time=  11.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.583 total time=  15.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  12.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.572 total time=  12.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.555 total time=  11.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.576 total time=  16.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.581 total time=  15.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.570 total time=  16.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  16.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.556 total time=  16.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  16.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.581 total time=  16.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.574 total time=  14.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.573 total time=  15.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.562 total time=  15.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.581 total time=  13.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.579 total time=  13.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  28.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.582 total time=  23.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.562 total time=  22.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.585 total time=  25.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.586 total time=  34.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.578 total time=  22.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.577 total time=  21.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.567 total time=  24.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  26.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.587 total time=  25.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.576 total time=  24.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  27.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.566 total time=  27.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  22.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.585 total time=  30.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.576 total time=  19.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.580 total time=  19.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.559 total time=  19.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.575 total time=  19.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  18.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.572 total time=  16.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  15.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.564 total time=  14.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.578 total time=  15.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.579 total time=  12.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  21.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.582 total time=  23.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.562 total time=  27.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  27.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  23.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.573 total time=  13.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  10.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.560 total time=  13.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  11.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.584 total time=  15.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.571 total time=  15.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.558 total time=  16.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.581 total time=  14.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  13.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  10.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.573 total time=  21.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.549 total time=  11.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.574 total time=  11.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.578 total time=  18.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.569 total time=  12.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.575 total time=  13.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.560 total time=  14.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.577 total time=  12.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.580 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  26.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  27.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.567 total time=  26.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.582 total time=  31.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.582 total time=  29.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.576 total time=  14.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.573 total time=  15.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.560 total time=  14.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.578 total time=  12.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.582 total time=  14.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.573 total time=  20.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.580 total time=  23.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.556 total time=  19.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  33.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.582 total time=  31.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.578 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.577 total time=  12.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.562 total time=  14.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.580 total time=  13.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.580 total time=  15.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.569 total time=  11.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  16.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.559 total time=  18.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  15.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.581 total time=  14.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  16.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.569 total time=  16.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.556 total time=  16.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.571 total time=  17.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.579 total time=  16.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.578 total time=  33.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.580 total time=  30.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.562 total time=  30.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  41.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.591 total time=  45.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.569 total time=  19.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.574 total time=  19.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.555 total time=  18.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.585 total time=  15.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  20.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.576 total time=  16.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  13.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.563 total time=  15.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.576 total time=  14.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.580 total time=  13.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.569 total time=  17.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.574 total time=  17.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.556 total time=  17.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.573 total time=  17.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.581 total time=  16.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  19.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  15.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.559 total time=  12.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.579 total time=  15.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.580 total time=  21.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  12.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  15.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.561 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.565 total time=  10.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.577 total time=  11.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.572 total time=  14.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.579 total time=  13.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.555 total time=  12.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.575 total time=  13.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.577 total time=  18.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  21.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.582 total time=  21.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  21.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  21.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  21.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.574 total time=  20.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  18.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.561 total time=  18.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.580 total time=  15.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  21.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.576 total time=  16.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.577 total time=  17.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.557 total time=  19.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  16.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.582 total time=  20.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.574 total time=  15.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.578 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.562 total time=  14.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  18.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.579 total time=  15.2s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 20, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
    "Best score: 0.5801549654262863\n",
    "\n",
    "Optimizing HistGradientBoostingRegressor using Spearman correlation to select features (1200)...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.537 total time=  14.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.546 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.531 total time=  11.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.535 total time=  16.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.551 total time=  17.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.533 total time=  13.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.545 total time=  13.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.533 total time=  15.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.540 total time=  12.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.555 total time=  13.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.534 total time=  12.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.545 total time=  13.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.534 total time=  13.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.543 total time=  11.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.550 total time=  13.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.529 total time=  11.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.541 total time=  10.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.535 total time=  12.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.535 total time=  12.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.554 total time=  13.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.536 total time=  14.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.557 total time=  16.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.536 total time=  17.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.539 total time=  10.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.552 total time=  17.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.527 total time=  14.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.538 total time=  14.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.529 total time=  14.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.534 total time=  14.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.550 total time=  16.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.544 total time=  25.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  22.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.538 total time=  29.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.542 total time=  25.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.561 total time=  28.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.539 total time=  26.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.548 total time=  21.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.534 total time=  17.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.538 total time=  19.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.562 total time=  25.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.519 total time=  12.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.531 total time=  12.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.523 total time=  12.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.532 total time=  12.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.543 total time=  12.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.539 total time=  22.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  24.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.542 total time=  26.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.544 total time=  21.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.558 total time=  23.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.540 total time=  21.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.552 total time=  22.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.544 total time=  23.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.547 total time=  22.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.558 total time=  23.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.542 total time=  27.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.554 total time=  26.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.542 total time=  28.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.543 total time=  31.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.563 total time=  31.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.542 total time=  28.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.554 total time=  30.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.544 total time=  25.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.546 total time=  27.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.562 total time=  32.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.535 total time=  17.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.544 total time=  17.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.535 total time=  16.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.537 total time=  17.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.553 total time=  17.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.534 total time=  15.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.553 total time=  13.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.534 total time=  13.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.544 total time=  18.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.556 total time=  14.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.539 total time=  16.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.546 total time=  11.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.534 total time=  18.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.545 total time=  16.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.550 total time=  15.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.521 total time=  12.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.534 total time=  12.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.521 total time=  12.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.526 total time=  12.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.539 total time=  12.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.539 total time=  25.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.548 total time=  27.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.541 total time=  26.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.542 total time=  21.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.559 total time=  25.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.536 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.550 total time=  17.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.533 total time=  13.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.535 total time=  15.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.555 total time=  19.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.539 total time=  22.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.555 total time=  25.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.538 total time=  24.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.548 total time=  27.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.562 total time=  22.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.544 total time=  26.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.555 total time=  22.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.541 total time=  22.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.542 total time=  19.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.556 total time=  23.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.538 total time=  15.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.545 total time=  12.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.540 total time=  19.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.538 total time=  11.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.553 total time=  16.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.537 total time=  18.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.545 total time=  12.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.541 total time=  14.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.541 total time=  12.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.558 total time=  13.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.544 total time=  30.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.550 total time=  25.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.545 total time=  39.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.549 total time=  35.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.560 total time=  29.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.539 total time=  18.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.547 total time=  15.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.538 total time=  15.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.543 total time=  17.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.555 total time=  12.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.529 total time=  13.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.541 total time=  11.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.536 total time=  15.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.541 total time=  13.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=True;, score=0.550 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.545 total time=  19.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.549 total time=  16.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.535 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.543 total time=  18.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.553 total time=  16.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.542 total time=  27.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.545 total time=  19.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.537 total time=  26.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.544 total time=  22.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.556 total time=  27.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.522 total time=  18.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.534 total time=  19.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.522 total time=  12.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.528 total time=  12.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.543 total time=  12.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.543 total time=  28.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.552 total time=  21.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.544 total time=  30.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.550 total time=  29.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.560 total time=  22.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.542 total time=  25.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.557 total time=  29.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.541 total time=  23.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.545 total time=  24.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.563 total time=  25.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.543 total time=  22.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  22.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.542 total time=  21.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.548 total time=  27.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.558 total time=  29.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.544 total time=  28.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.553 total time=  29.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.542 total time=  29.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.542 total time=  25.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.554 total time=  23.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.543 total time=  26.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.556 total time=  22.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.537 total time=  20.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.548 total time=  27.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.560 total time=  25.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.536 total time=  16.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.545 total time=  13.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.531 total time=  15.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.543 total time=  18.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.555 total time=  14.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.539 total time=  28.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.555 total time=  42.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.542 total time=  36.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.544 total time=  23.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.560 total time=  28.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.531 total time=  18.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.541 total time=  12.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.530 total time=  11.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.534 total time=  11.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.554 total time=  11.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.539 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.539 total time=  16.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.530 total time=  17.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.538 total time=  17.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  14.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.536 total time=  12.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.548 total time=  14.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.529 total time=  18.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.531 total time=  10.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.553 total time=  12.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.540 total time=  21.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.548 total time=  24.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.538 total time=  24.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.538 total time=  20.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.558 total time=  21.4s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Best score: 0.5498209725885485\n",
    "\n",
    "Optimizing HistGradientBoostingRegressor using univariate linear regression to select features (1300)...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.591 total time=  27.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  28.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  27.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.557 total time=  27.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.574 total time=  24.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.587 total time=  16.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.576 total time=  14.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.572 total time=  12.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.555 total time=  14.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.574 total time=  16.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  25.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.580 total time=  27.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.582 total time=  27.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.564 total time=  27.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  28.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.594 total time=  16.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.585 total time=  16.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  20.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.556 total time=  21.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.570 total time=  17.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  14.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.583 total time=  17.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  17.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.552 total time=  22.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.571 total time=  15.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.581 total time=  20.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  18.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.555 total time=  15.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.567 total time=  19.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.591 total time=  23.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.587 total time=  33.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.582 total time=  29.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.562 total time=  23.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.577 total time=  28.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.594 total time=  32.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.580 total time=  32.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.581 total time=  27.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.562 total time=  26.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  28.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.592 total time=  28.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  35.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.579 total time=  23.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.562 total time=  25.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.574 total time=  31.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  27.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.581 total time=  26.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  36.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.562 total time=  30.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.577 total time=  30.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  14.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.576 total time=  17.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.580 total time=  20.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.558 total time=  17.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.570 total time=  22.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.588 total time=  14.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  17.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  16.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.554 total time=  16.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.570 total time=  13.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  17.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.576 total time=  13.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.579 total time=  17.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.553 total time=  11.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.571 total time=  18.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  23.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.582 total time=  24.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.577 total time=  21.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.559 total time=  21.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.572 total time=  21.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  19.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  19.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  19.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.554 total time=  19.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.573 total time=  19.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.588 total time=  13.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.581 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.576 total time=  11.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  15.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.571 total time=  12.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  21.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  21.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.580 total time=  21.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.556 total time=  22.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  21.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  18.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.576 total time=  13.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.574 total time=  12.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.559 total time=  18.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.570 total time=  15.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  21.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.575 total time=  20.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.572 total time=  17.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.555 total time=  15.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.564 total time=  15.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  19.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.582 total time=  17.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.578 total time=  15.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.556 total time=  20.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  15.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.585 total time=  17.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.577 total time=  15.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.576 total time=  13.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.554 total time=  17.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.572 total time=  16.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  18.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.573 total time=  18.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.568 total time=  18.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.553 total time=  18.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.570 total time=  18.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.591 total time=  16.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.577 total time=  21.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.570 total time=  17.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.554 total time=  15.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.577 total time=  18.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  12.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.571 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.579 total time=  16.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.560 total time=  13.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.565 total time=  14.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  19.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.581 total time=  18.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.579 total time=  31.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.558 total time=  13.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=16, warm_start=False;, score=0.572 total time=  19.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  18.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.589 total time=  18.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.573 total time=  19.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.553 total time=  14.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  18.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  15.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.573 total time=  14.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.571 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.556 total time=  13.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.567 total time=  17.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  31.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.587 total time=  29.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.583 total time=  34.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.558 total time=  30.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.573 total time=  31.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.589 total time=  14.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.578 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  18.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.559 total time=  18.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  12.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.588 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  17.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.573 total time=  14.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.555 total time=  16.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  16.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.589 total time=  22.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.577 total time=  17.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.573 total time=  25.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.554 total time=  22.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.571 total time=  14.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.590 total time=  12.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  15.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  19.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.560 total time=  18.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.574 total time=  19.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.579 total time=  15.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  15.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.565 total time=  15.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.541 total time=  15.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.567 total time=  15.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.576 total time=  17.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.574 total time=  12.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.555 total time=  17.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  15.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.586 total time=  15.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  14.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  14.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.558 total time=  17.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.568 total time=  13.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  16.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.574 total time=  18.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  15.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.555 total time=  18.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  18.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.590 total time=  15.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.579 total time=  20.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  19.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.553 total time=  18.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.568 total time=  16.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  14.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  13.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  18.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.554 total time=  13.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.572 total time=  15.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.594 total time=  27.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  37.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.587 total time=  37.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.565 total time=  32.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  34.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.585 total time=  22.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.587 total time=  18.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.577 total time=  18.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.558 total time=  17.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.572 total time=  17.1s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Best score: 0.5819442316084732\n",
    "\n",
    "Optimizing HistGradientBoostingRegressor using mutual information regression to select features (200)...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.602 total time=  10.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.588 total time=   9.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.602 total time=  10.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  10.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.577 total time=   9.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.596 total time=   5.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.583 total time=   5.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.594 total time=   5.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.587 total time=   5.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.563 total time=   5.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.604 total time=   5.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.596 total time=   7.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.604 total time=   8.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.600 total time=   9.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.575 total time=   9.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.605 total time=   7.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.584 total time=   7.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.608 total time=   7.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.594 total time=   7.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.573 total time=   7.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.601 total time=  10.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  10.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.600 total time=  10.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  11.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.571 total time=  10.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.599 total time=   5.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.585 total time=   5.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.595 total time=   5.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.590 total time=   5.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.571 total time=   5.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.610 total time=  18.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.600 total time=  19.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.610 total time=  16.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.602 total time=  16.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.580 total time=  15.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.613 total time=  14.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.596 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.610 total time=  14.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.598 total time=  14.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  14.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.616 total time=  12.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.577 total time=   4.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.599 total time=   6.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.591 total time=  10.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.572 total time=   6.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.611 total time=   8.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.597 total time=  10.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.603 total time=   8.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.600 total time=   9.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.581 total time=  10.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.613 total time=  10.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  12.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.608 total time=  11.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.601 total time=  12.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=True;, score=0.577 total time=  11.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.600 total time=   9.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.589 total time=   9.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.598 total time=   9.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.590 total time=   9.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.576 total time=   9.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.587 total time=   6.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.572 total time=   6.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.585 total time=   6.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.581 total time=   6.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.561 total time=   6.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.614 total time=  14.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  13.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.612 total time=  16.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.603 total time=  19.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.588 total time=  21.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.612 total time=  12.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  12.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.606 total time=  12.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.596 total time=  12.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  12.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.616 total time=  20.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.601 total time=  26.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.615 total time=  19.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.604 total time=  18.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.583 total time=  21.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.612 total time=   8.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  11.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.607 total time=   9.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.596 total time=   9.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.581 total time=   9.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.609 total time=   7.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.593 total time=   8.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.605 total time=   9.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.600 total time=   9.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.570 total time=   9.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.605 total time=   7.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.594 total time=   8.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.598 total time=   7.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.591 total time=   7.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.574 total time=   7.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.613 total time=   9.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  10.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.611 total time=  11.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.601 total time=   9.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.576 total time=   7.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.616 total time=  14.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.592 total time=  12.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.611 total time=  17.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  18.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.577 total time=  11.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.602 total time=  10.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.595 total time=  15.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.606 total time=  14.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.606 total time=  18.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  18.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.610 total time=  13.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.595 total time=  13.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.607 total time=  13.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.603 total time=  13.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.579 total time=  13.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.612 total time=   8.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.598 total time=   8.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.607 total time=   7.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.597 total time=   8.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.581 total time=   8.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.604 total time=   7.1s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.591 total time=   9.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.605 total time=  10.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.593 total time=   7.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.581 total time=   9.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.605 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  11.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.604 total time=  11.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.599 total time=  11.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.573 total time=  11.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.617 total time=  19.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.601 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.611 total time=  21.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.598 total time=  19.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  20.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.620 total time=  24.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.602 total time=  24.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.610 total time=  15.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.603 total time=  17.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.582 total time=  16.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.603 total time=   7.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.588 total time=   7.9s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.599 total time=   7.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.584 total time=   5.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.575 total time=   7.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.618 total time=  18.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.596 total time=  18.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.613 total time=  18.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.608 total time=  19.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  20.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.610 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.600 total time=  14.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.608 total time=   9.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.604 total time=   8.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.581 total time=   9.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.622 total time=  21.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.599 total time=  15.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.615 total time=  23.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.599 total time=  15.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.584 total time=  21.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.604 total time=   9.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.588 total time=   9.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.601 total time=   9.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.594 total time=   9.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.575 total time=   9.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.607 total time=  12.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.590 total time=  11.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.606 total time=  11.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  12.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  15.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.578 total time=   5.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.567 total time=   6.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.576 total time=   5.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.573 total time=   6.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.552 total time=   8.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.610 total time=   9.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  10.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.610 total time=   8.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.591 total time=  10.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.579 total time=   9.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.608 total time=   6.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.589 total time=   8.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.600 total time=   7.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.592 total time=   7.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.566 total time=   8.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.598 total time=  11.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.592 total time=  10.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.600 total time=  13.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.592 total time=  12.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.573 total time=  12.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.616 total time=  18.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  15.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.608 total time=  16.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.600 total time=  17.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  17.9s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.603 total time=  10.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  11.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.601 total time=  10.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.594 total time=  10.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.570 total time=  11.2s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
    "Best score: 0.6039044275109269"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be6d07-34ed-4628-8de1-d48f3cc47d26",
   "metadata": {},
   "source": [
    "Os hiperparâmetros ótimos para cada modelo foram, então, guardados numa variável <b>best_params</b> de modo a realizar nova validação cruzada de cada um dos modelos (nesta ocasião, treinados com hiperparâmetros otimizados)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4189769-b6e7-4bf0-b137-861926c44d1c",
   "metadata": {},
   "source": [
    "<b>SelectFromModel</b>\n",
    "<br>(hyperparameter optmization using SelectFromModel to select the best features to train the models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "33a9874a-cd63-4ce6-a19b-38509293f096",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing HistGradientBoostingRegressor using SelectFromModel to select features...\n",
      "----------\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  27.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  28.7s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.567 total time=  28.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.574 total time=  29.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.595 total time=  29.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  14.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  18.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  16.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.563 total time=  20.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  13.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  18.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  16.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  13.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.560 total time=  15.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.589 total time=  14.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  13.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  13.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.559 total time=  12.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.563 total time=  13.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.590 total time=  13.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  15.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  16.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.561 total time=  15.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.566 total time=  16.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  17.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  24.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  24.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.564 total time=  24.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  24.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.592 total time=  23.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  22.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.581 total time=  23.2s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.565 total time=  24.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.569 total time=  28.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.586 total time=  21.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.592 total time=  26.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.583 total time=  26.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.565 total time=  27.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.572 total time=  28.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  26.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.578 total time=  16.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.573 total time=  16.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.551 total time=  16.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  29.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.589 total time=  25.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  18.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  15.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  16.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  22.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.595 total time=  16.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.583 total time=  22.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.582 total time=  22.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.565 total time=  22.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.570 total time=  22.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.591 total time=  21.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  32.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  31.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.566 total time=  26.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  34.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.596 total time=  28.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.584 total time=  14.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  19.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.561 total time=  17.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.569 total time=  17.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  18.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.580 total time=  17.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.582 total time=  19.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.561 total time=  16.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  17.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.590 total time=  19.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  21.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.579 total time=  21.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.559 total time=  21.3s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  21.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.593 total time=  22.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  14.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  16.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.561 total time=  15.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  17.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  14.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.590 total time=  33.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  27.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.566 total time=  29.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.573 total time=  31.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.599 total time=  34.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  20.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.577 total time=  18.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  17.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.569 total time=  15.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.592 total time=  21.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.581 total time=  13.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  16.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  12.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.567 total time=  16.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.587 total time=  14.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.579 total time=  19.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  21.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.564 total time=  14.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  13.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  15.3s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.585 total time=  22.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  23.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.561 total time=  26.3s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.572 total time=  27.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  27.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.592 total time=  28.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.582 total time=  29.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.566 total time=  28.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.569 total time=  30.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.595 total time=  29.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  17.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.581 total time=  16.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.553 total time=  16.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.563 total time=  17.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.593 total time=  15.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  19.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.565 total time=  28.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  24.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.596 total time=  26.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.587 total time=  24.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  23.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.563 total time=  26.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  24.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.599 total time=  23.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  31.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  30.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.565 total time=  31.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.573 total time=  25.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.598 total time=  36.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.577 total time=  18.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  14.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.562 total time=  17.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  17.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  20.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.587 total time=  29.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.585 total time=  22.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.563 total time=  25.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  28.9s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.592 total time=  29.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  24.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  29.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.568 total time=  30.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.572 total time=  25.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.593 total time=  25.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  22.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  26.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.566 total time=  29.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.569 total time=  23.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  24.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  19.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.575 total time=  16.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.561 total time=  18.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  19.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  15.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.572 total time=  12.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  13.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.547 total time=  13.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  14.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  15.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.586 total time=  29.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  27.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  31.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  29.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  28.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  14.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.564 total time=  15.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.550 total time=  14.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.557 total time=  14.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  15.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  19.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  17.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.565 total time=  19.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.569 total time=  17.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.597 total time=  17.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.591 total time=  30.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.585 total time=  23.2s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.565 total time=  33.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  27.3s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  33.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.582 total time=  22.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  29.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  24.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.597 total time=  30.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.581 total time=  19.2s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  18.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.559 total time=  18.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.566 total time=  17.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.583 total time=  18.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.580 total time=  18.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.578 total time=  17.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.565 total time=  15.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.566 total time=  14.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.589 total time=  14.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  16.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  12.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.561 total time=  15.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.566 total time=  14.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  16.2s\n",
      "----------\n",
      "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 55, 'max_iter': 200, 'learning_rate': 0.05}\n",
      "Best score: 0.5836554527166748\n"
     ]
    }
   ],
   "source": [
    "print(f\"Optimizing HistGradientBoostingRegressor using SelectFromModel to select features...\")\n",
    "print(\"----------\")\n",
    "x_train_sfm = X_train_sc.iloc[:, feature_mask]\n",
    "gs_sfm = RandomizedSearchCV(estimator=HGBR(),\n",
    "                            param_distributions=HYPER,\n",
    "                            n_iter=40,\n",
    "                            cv=KFold(n_splits=5, shuffle=True),\n",
    "                            verbose=3)\n",
    "gs_sfm.fit(x_train_sfm, y_train)\n",
    "print(\"----------\")\n",
    "print(f\"Optimal hyperparameters: {gs_sfm.best_params_}\")\n",
    "print(f\"Best score: {gs_sfm.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4dd60e-843a-4053-aba0-a280bc37e805",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Optimizing HistGradientBoostingRegressor using SelectFromModel to select features...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  27.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.585 total time=  28.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.567 total time=  28.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.574 total time=  29.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.595 total time=  29.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  14.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  18.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  16.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.563 total time=  20.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  13.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  18.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  16.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  13.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.560 total time=  15.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.589 total time=  14.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  13.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.582 total time=  13.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.559 total time=  12.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.563 total time=  13.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=False;, score=0.590 total time=  13.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  15.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  16.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.561 total time=  15.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.566 total time=  16.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  17.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.584 total time=  24.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  24.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.564 total time=  24.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  24.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.592 total time=  23.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.583 total time=  22.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.581 total time=  23.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.565 total time=  24.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.569 total time=  28.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.586 total time=  21.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.592 total time=  26.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.583 total time=  26.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.565 total time=  27.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.572 total time=  28.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  26.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.578 total time=  16.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.573 total time=  16.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.551 total time=  16.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.566 total time=  29.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=28, warm_start=False;, score=0.589 total time=  25.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  18.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  15.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  16.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  22.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.595 total time=  16.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.583 total time=  22.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.582 total time=  22.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.565 total time=  22.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.570 total time=  22.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.591 total time=  21.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  32.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  31.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.566 total time=  26.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  34.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.596 total time=  28.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.584 total time=  14.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.580 total time=  19.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.561 total time=  17.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.569 total time=  17.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  18.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.580 total time=  17.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.582 total time=  19.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.561 total time=  16.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  17.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.590 total time=  19.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  21.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.579 total time=  21.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.559 total time=  21.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  21.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.593 total time=  22.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.586 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  16.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.561 total time=  15.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  17.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  14.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.590 total time=  33.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  27.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.566 total time=  29.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.573 total time=  31.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.599 total time=  34.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  20.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.577 total time=  18.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  17.7s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.569 total time=  15.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.592 total time=  21.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.581 total time=  13.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  16.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.567 total time=  16.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.587 total time=  14.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.579 total time=  19.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.573 total time=  21.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.564 total time=  14.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.563 total time=  13.7s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  15.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.585 total time=  22.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.581 total time=  23.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.561 total time=  26.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.572 total time=  27.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  27.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.592 total time=  28.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.582 total time=  29.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.566 total time=  28.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.569 total time=  30.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.595 total time=  29.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  17.0s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.581 total time=  16.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.553 total time=  16.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.563 total time=  17.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.593 total time=  15.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  19.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.565 total time=  28.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  24.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.596 total time=  26.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.587 total time=  24.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  23.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.563 total time=  26.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  24.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.599 total time=  23.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  31.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  30.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.565 total time=  31.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.573 total time=  25.2s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=32, warm_start=False;, score=0.598 total time=  36.1s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.577 total time=  18.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.583 total time=  14.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.562 total time=  17.5s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  17.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  20.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.587 total time=  29.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.585 total time=  22.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.563 total time=  25.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  28.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.592 total time=  29.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  24.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  29.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.568 total time=  30.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.572 total time=  25.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.593 total time=  25.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  22.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  26.6s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.566 total time=  29.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.569 total time=  23.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  24.8s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  19.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.575 total time=  16.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.561 total time=  18.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.567 total time=  19.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  15.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.572 total time=  12.8s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.571 total time=  13.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.547 total time=  13.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.554 total time=  14.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=16, warm_start=True;, score=0.578 total time=  15.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.586 total time=  29.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  27.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  31.1s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.570 total time=  29.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  28.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.572 total time=  14.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.564 total time=  15.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.550 total time=  14.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.557 total time=  14.5s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  19.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  17.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.565 total time=  19.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.569 total time=  17.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.597 total time=  17.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.591 total time=  30.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.585 total time=  23.2s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.565 total time=  33.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  27.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  33.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.582 total time=  22.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  29.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.569 total time=  24.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.597 total time=  30.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.581 total time=  19.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.575 total time=  18.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.559 total time=  18.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.566 total time=  17.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.583 total time=  18.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.580 total time=  18.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.578 total time=  17.4s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.565 total time=  15.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.566 total time=  14.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.589 total time=  14.0s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  16.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.575 total time=  12.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.561 total time=  15.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.566 total time=  14.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  16.2s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 55, 'max_iter': 200, 'learning_rate': 0.05}\n",
    "Best score: 0.5836554527166748"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972f740-8107-4c50-b221-f558b9319eae",
   "metadata": {},
   "source": [
    "<b>Pearson + Spearman + mutual information</b>\n",
    "<br>(hyperparameter optmization using a combination of feature selection methods to select the best features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0b88c56-e926-4a48-967d-a7f010abfe03",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing HistGradientBoostingRegressor using a combination of feature selection methods...\n",
      "----------\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.596 total time= 1.0min\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.587 total time= 1.4min\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.602 total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.608 total time= 1.0min\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.608 total time=  54.6s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.587 total time=  28.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.585 total time=  28.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  28.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  28.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.593 total time=  28.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.576 total time=  19.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.573 total time=  19.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.578 total time=  19.2s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.586 total time=  19.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  19.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.586 total time=  17.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.584 total time=  20.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.590 total time=  22.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.599 total time=  23.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.596 total time=  20.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.588 total time=  30.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.585 total time=  30.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.594 total time=  30.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.596 total time=  30.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.596 total time=  30.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.587 total time=  28.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.584 total time=  27.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  30.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.598 total time=  22.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.598 total time=  27.3s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.579 total time=  22.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.582 total time=  22.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  22.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  22.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  22.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  42.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.587 total time=  40.4s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  36.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.598 total time=  42.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.603 total time=  41.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  52.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.588 total time=  44.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.599 total time=  47.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.602 total time=  53.2s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.604 total time= 1.0min\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.591 total time=  36.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.586 total time=  36.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.596 total time=  35.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.596 total time=  36.3s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.597 total time=  35.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  26.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.581 total time=  26.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.592 total time=  27.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  27.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.598 total time=  27.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.587 total time=  21.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.591 total time=  21.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.593 total time=  19.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.595 total time=  21.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  14.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.585 total time=  23.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.589 total time=  23.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  26.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  20.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=55, min_samples_leaf=24, warm_start=True;, score=0.600 total time=  27.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  21.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  19.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  25.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.590 total time=  18.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.597 total time=  25.4s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.579 total time=  23.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.583 total time=  23.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  23.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  23.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  23.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  21.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.585 total time=  27.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.591 total time=  28.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.597 total time=  22.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.592 total time=  20.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.590 total time=  23.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.588 total time=  31.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.594 total time=  30.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.598 total time=  28.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.598 total time=  27.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.590 total time=  26.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.587 total time=  22.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  22.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.595 total time=  25.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.598 total time=  20.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.591 total time=  30.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.592 total time=  25.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  45.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.600 total time=  23.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=47, min_samples_leaf=24, warm_start=True;, score=0.598 total time=  22.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.589 total time=  22.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  28.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.591 total time=  27.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.599 total time=  21.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.595 total time=  17.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  34.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  21.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.590 total time=  19.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.596 total time=  23.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.599 total time=  25.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  21.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.585 total time=  27.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.592 total time=  25.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.596 total time=  29.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.598 total time=  24.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.589 total time=  21.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.583 total time=  20.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.584 total time=  21.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  21.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=32, warm_start=True;, score=0.595 total time=  21.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.586 total time=  18.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  27.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.595 total time=  29.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.597 total time=  22.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.603 total time=  25.6s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  21.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.579 total time=  12.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.594 total time=  28.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.594 total time=  18.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=False;, score=0.590 total time=  19.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.587 total time=  29.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.589 total time=  29.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  29.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.595 total time=  29.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  29.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  23.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.591 total time=  26.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.596 total time=  28.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.595 total time=  18.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=28, warm_start=False;, score=0.602 total time=  26.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  30.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  23.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.589 total time=  19.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.596 total time=  27.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=20, warm_start=False;, score=0.597 total time=  30.8s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.588 total time=  30.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.583 total time=  29.7s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.594 total time=  29.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.597 total time=  29.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=32, warm_start=False;, score=0.593 total time=  30.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  50.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.591 total time=  54.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.595 total time=  54.4s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.610 total time=  59.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.603 total time=  50.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.593 total time=  38.9s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.587 total time=  49.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.598 total time=  43.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.604 total time=  39.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.601 total time=  53.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.586 total time=  18.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.590 total time=  27.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.592 total time=  28.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.597 total time=  23.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.597 total time=  21.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  51.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.593 total time=  53.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.602 total time=  45.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.605 total time=  48.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.599 total time=  38.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.584 total time=  26.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  22.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.591 total time=  28.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.596 total time=  31.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=20, warm_start=True;, score=0.595 total time=  21.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  27.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.589 total time=  21.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.597 total time=  27.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.600 total time=  21.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=47, min_samples_leaf=32, warm_start=False;, score=0.600 total time=  29.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.582 total time=  15.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.583 total time=  15.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.589 total time=  14.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.595 total time=  14.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.591 total time=  14.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  19.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.581 total time=  19.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.588 total time=  19.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.598 total time=  19.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=39, min_samples_leaf=16, warm_start=False;, score=0.595 total time=  19.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  30.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.585 total time=  30.5s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.591 total time=  30.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.598 total time=  30.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  30.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.593 total time=  45.3s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.586 total time=  39.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.600 total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.602 total time=  50.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=28, warm_start=True;, score=0.604 total time=  43.9s\n",
      "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.582 total time=  27.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.589 total time=  27.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  27.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  27.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  27.9s\n",
      "----------\n",
      "Optimal hyperparameters: {'warm_start': True, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
      "Best score: 0.600136158051844\n"
     ]
    }
   ],
   "source": [
    "print(f\"Optimizing HistGradientBoostingRegressor using a combination of feature selection methods...\")\n",
    "print(\"----------\")\n",
    "x_train_psmi = X_train_sc[best_features_psmi]\n",
    "gs_psmi = RandomizedSearchCV(estimator=HGBR(),\n",
    "                             param_distributions=HYPER,\n",
    "                             n_iter=40,\n",
    "                             cv=KFold(n_splits=5, shuffle=True),\n",
    "                             verbose=3)\n",
    "gs_psmi.fit(x_train_psmi, y_train)\n",
    "print(\"----------\")\n",
    "print(f\"Optimal hyperparameters: {gs_psmi.best_params_}\")\n",
    "print(f\"Best score: {gs_psmi.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dc6c1-ff66-4952-a11f-9ebac423757b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Optimizing HistGradientBoostingRegressor using a combination of feature selection methods...\n",
    "\n",
    "----------\n",
    "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.605 total time=  23.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.593 total time=  19.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.607 total time=  20.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.598 total time=  18.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.580 total time=  18.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.607 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.590 total time=  12.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.602 total time=  12.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.602 total time=  11.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  11.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.612 total time=  21.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.597 total time=  27.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.605 total time=  20.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.603 total time=  24.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=24, warm_start=False;, score=0.578 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.608 total time=  20.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  20.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.607 total time=  20.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.600 total time=  17.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.577 total time=  16.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.599 total time=   8.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.590 total time=   9.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.595 total time=   8.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.598 total time=  11.3s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.574 total time=   9.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.603 total time=  15.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.588 total time=  15.5s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.603 total time=  15.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.593 total time=  16.7s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=False;, score=0.575 total time=  17.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.601 total time=   8.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.589 total time=   9.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.597 total time=   8.4s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.596 total time=  12.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=31, min_samples_leaf=24, warm_start=True;, score=0.574 total time=  10.9s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.603 total time=  11.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.587 total time=  10.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.601 total time=   8.8s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  10.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.571 total time=  11.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.598 total time=  13.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.600 total time=  22.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.599 total time=  23.9s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.603 total time=  18.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=False;, score=0.576 total time=  19.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.607 total time=   9.6s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.582 total time=   7.6s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.596 total time=   9.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.597 total time=   9.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=31, min_samples_leaf=28, warm_start=True;, score=0.581 total time=   9.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.590 total time=  10.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.577 total time=  10.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.593 total time=  10.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.586 total time=  10.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.566 total time=  10.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.604 total time=  15.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  16.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.606 total time=  24.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.593 total time=  16.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=16, warm_start=True;, score=0.579 total time=  20.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.607 total time=  19.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  18.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.601 total time=  15.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.598 total time=  20.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=39, min_samples_leaf=20, warm_start=True;, score=0.576 total time=  19.2s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.605 total time=  11.9s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.588 total time=  11.5s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.599 total time=  11.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.596 total time=  11.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=55, min_samples_leaf=16, warm_start=True;, score=0.577 total time=  11.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  10.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.577 total time=  10.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.596 total time=  10.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.591 total time=  10.3s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=16, warm_start=False;, score=0.559 total time=  10.6s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.598 total time=  11.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.583 total time=  11.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.596 total time=  11.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.587 total time=  11.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=20, warm_start=False;, score=0.570 total time=  11.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.590 total time=   8.3s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.584 total time=   8.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.596 total time=   8.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.591 total time=   9.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=31, min_samples_leaf=28, warm_start=False;, score=0.569 total time=  10.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.589 total time=  10.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  10.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  13.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.587 total time=  10.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.566 total time=  10.7s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.609 total time=  15.5s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  18.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.602 total time=  22.0s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.596 total time=  18.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.583 total time=  19.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.600 total time=  10.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.581 total time=   8.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.598 total time=  10.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.591 total time=  11.6s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=31, min_samples_leaf=32, warm_start=False;, score=0.566 total time=   8.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  10.3s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.578 total time=  10.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.596 total time=  10.3s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.586 total time=  10.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.566 total time=  10.2s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.606 total time=  18.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.594 total time=  17.3s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.605 total time=  16.8s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.602 total time=  19.0s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=47, min_samples_leaf=16, warm_start=False;, score=0.576 total time=  24.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.596 total time=  14.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.577 total time=  10.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.594 total time=  16.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.591 total time=   9.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20, warm_start=False;, score=0.565 total time=   9.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.611 total time=  18.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  19.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.603 total time=  13.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.601 total time=  12.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=47, min_samples_leaf=24, warm_start=False;, score=0.576 total time=  13.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.603 total time=  17.2s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.589 total time=  21.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.599 total time=  11.1s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.597 total time=  12.4s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=28, warm_start=True;, score=0.575 total time=  11.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.608 total time=  13.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.588 total time=  10.1s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.599 total time=  12.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.592 total time=   8.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=300, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.575 total time=  13.5s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.602 total time=  11.6s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.580 total time=  13.9s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.594 total time=  12.4s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  12.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=False;, score=0.568 total time=  12.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.594 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.582 total time=  11.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.596 total time=  11.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.592 total time=  11.9s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=55, min_samples_leaf=28, warm_start=False;, score=0.568 total time=  13.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.609 total time=  25.2s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.597 total time=  25.0s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.602 total time=  18.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.596 total time=  20.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=63, min_samples_leaf=16, warm_start=False;, score=0.584 total time=  24.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.608 total time=  19.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.593 total time=  11.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.598 total time=  15.0s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.594 total time=  14.0s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=32, warm_start=True;, score=0.578 total time=  12.1s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.605 total time=  12.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.589 total time=  12.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.601 total time=  13.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.593 total time=  13.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.576 total time=  13.5s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.603 total time=  10.5s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.594 total time=  12.7s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.596 total time=  11.9s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.594 total time=   9.8s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=100, max_leaf_nodes=63, min_samples_leaf=16, warm_start=True;, score=0.573 total time=   9.3s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.603 total time=  11.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.592 total time=  13.2s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.601 total time=  13.3s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.594 total time=   9.9s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=63, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  12.7s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.607 total time=  11.7s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.592 total time=  12.0s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.595 total time=  13.6s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.590 total time=   9.5s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=200, max_leaf_nodes=55, min_samples_leaf=24, warm_start=False;, score=0.576 total time=  13.0s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.610 total time=  24.1s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.592 total time=  18.7s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.601 total time=  16.5s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.605 total time=  21.6s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=55, min_samples_leaf=28, warm_start=True;, score=0.580 total time=  21.3s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.603 total time=  15.7s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.591 total time=  15.8s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.600 total time=  15.6s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.597 total time=  15.4s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=250, max_leaf_nodes=31, min_samples_leaf=20, warm_start=True;, score=0.571 total time=  15.4s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.602 total time=  15.0s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.590 total time=  15.4s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.602 total time=  15.7s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.591 total time=  16.1s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=200, max_leaf_nodes=39, min_samples_leaf=32, warm_start=True;, score=0.581 total time=  15.6s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.604 total time=  11.4s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.588 total time=   9.8s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.598 total time=   8.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.601 total time=  12.1s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=150, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.575 total time=  10.4s\n",
    "[CV 1/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.603 total time=  10.8s\n",
    "[CV 2/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.590 total time=  12.3s\n",
    "[CV 3/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.599 total time=  11.2s\n",
    "[CV 4/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.594 total time=  12.2s\n",
    "[CV 5/5] END learning_rate=0.1, max_iter=250, max_leaf_nodes=39, min_samples_leaf=24, warm_start=True;, score=0.577 total time=   9.8s\n",
    "[CV 1/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.607 total time=  20.9s\n",
    "[CV 2/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.593 total time=  17.1s\n",
    "[CV 3/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.603 total time=  23.2s\n",
    "[CV 4/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.597 total time=  15.8s\n",
    "[CV 5/5] END learning_rate=0.05, max_iter=300, max_leaf_nodes=47, min_samples_leaf=20, warm_start=True;, score=0.579 total time=  16.7s\n",
    "\n",
    "----------\n",
    "Optimal hyperparameters: {'warm_start': False, 'min_samples_leaf': 24, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Best score: 0.5990082671786074"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a050d6e-23c5-433c-b31d-c8525071ec60",
   "metadata": {},
   "source": [
    "Os hiperparâmetros ótimos referentes aos modelos obtidos pelos restantes métodos de seleção de features serão futuramente acessados através do atributo <b>best_params_</b> de objetos da classe <b>RandomizedSearchCV</b> (<b>gs_sfm.best_params_</b> e <b>gs_psmi.best_params_</b>)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78576f",
   "metadata": {},
   "source": [
    "### Cross-validate best models (with optimized hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d73b7-45c9-4b93-83de-225b313d0e86",
   "metadata": {},
   "source": [
    "Procedemos, então, a uma validação cruzada 10-fold dos melhores modelos obtidos através de cada um dos métodos de seleção de features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a6081-a6df-4d98-8e6d-92a41fc35ce6",
   "metadata": {},
   "source": [
    "<b>Pearson, Spearman, univariate linear regression and mutual information regression</b>\n",
    "<br>(cross-validation of the best models with optimized hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f3d9df1f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# only cross-validates HistGradientBoostingRegressor, as it was invariably the best model\n",
    "def cv_best(models, params: list, methods: list, corrs: list, num_feats: list, cv=10):\n",
    "    for mo, pr, me, co, nf in zip(models, params, methods, corrs, num_feats):\n",
    "        InitModel = mo()\n",
    "        print(f\"Cross-validating ({cv}-fold) {InitModel.__class__.__name__} using {me} ({nf} features)...\")\n",
    "        print(f\"Optimized hyperparameters: {pr}\")\n",
    "        x_train = X_train_sc.loc[:,get_k_best_corrs(nf, co).keys()]\n",
    "        result = cross_validate(estimator=InitModel.set_params(**pr),\n",
    "                                X=x_train,\n",
    "                                y=y_train,\n",
    "                                cv=KFold(n_splits=cv, shuffle=True),\n",
    "                                return_train_score=True)\n",
    "        mean_train = np.sum(result[\"train_score\"]) / cv\n",
    "        mean_test = np.sum(result[\"test_score\"]) / cv\n",
    "        print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "        print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e8281b35",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating (10-fold) HistGradientBoostingRegressor using Pearson correlation (1200 features)...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 20, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
      "Train scores: [0.73233652 0.73407498 0.73019125 0.74800317 0.73221829 0.71548573\n",
      " 0.75295105 0.74165818 0.73646702 0.7178306 ] -> mean_train = 0.7341\n",
      "Test scores: [0.56623301 0.60612089 0.57279343 0.57305721 0.56753691 0.60907319\n",
      " 0.59046368 0.57254022 0.61033073 0.58555759] -> mean_test = 0.5854\n",
      "\n",
      "Cross-validating (10-fold) HistGradientBoostingRegressor using Spearman correlation (1200 features)...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
      "Train scores: [0.7046133  0.72345338 0.68532331 0.74236339 0.72630959 0.69784186\n",
      " 0.68999517 0.73570951 0.72595013 0.71897368] -> mean_train = 0.7151\n",
      "Test scores: [0.53102774 0.55152941 0.55988561 0.55823386 0.5664989  0.55229307\n",
      " 0.58424717 0.56240558 0.52764792 0.54849861] -> mean_test = 0.5542\n",
      "\n",
      "Cross-validating (10-fold) HistGradientBoostingRegressor using univariate linear regression (1300 features)...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
      "Train scores: [0.75582173 0.7276507  0.76533005 0.72540476 0.73508961 0.73966701\n",
      " 0.74035541 0.73509884 0.73865676 0.76293388] -> mean_train = 0.7426\n",
      "Test scores: [0.59155216 0.5764809  0.60739257 0.5594956  0.59567879 0.59699155\n",
      " 0.58574327 0.59043057 0.58562394 0.58767947] -> mean_test = 0.5877\n",
      "\n",
      "Cross-validating (10-fold) HistGradientBoostingRegressor using mutual information regression (200 features)...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
      "Train scores: [0.76875166 0.73104154 0.75049263 0.76938016 0.76481907 0.75684443\n",
      " 0.73644814 0.74662982 0.76163698 0.78642204] -> mean_train = 0.7572\n",
      "Test scores: [0.60509896 0.6142814  0.60063617 0.63996885 0.62272178 0.59556783\n",
      " 0.60761713 0.59120005 0.59343065 0.58970676] -> mean_test = 0.6060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all variables defined above (models, best_params, methods, corrs, num_feats)\n",
    "cv_best(models, best_params, methods, corrs, num_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22262248-1303-47d2-ae67-bc9134a62771",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Cross-validating (10-fold) HistGradientBoostingRegressor using Pearson correlation (1200 features)...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 20, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
    "Train scores: [0.73233652 0.73407498 0.73019125 0.74800317 0.73221829 0.71548573\n",
    " 0.75295105 0.74165818 0.73646702 0.7178306 ] -> mean_train = 0.7341\n",
    "Test scores: [0.56623301 0.60612089 0.57279343 0.57305721 0.56753691 0.60907319\n",
    " 0.59046368 0.57254022 0.61033073 0.58555759] -> mean_test = 0.5854\n",
    "\n",
    "Cross-validating (10-fold) HistGradientBoostingRegressor using Spearman correlation (1200 features)...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Train scores: [0.7046133  0.72345338 0.68532331 0.74236339 0.72630959 0.69784186\n",
    " 0.68999517 0.73570951 0.72595013 0.71897368] -> mean_train = 0.7151\n",
    "Test scores: [0.53102774 0.55152941 0.55988561 0.55823386 0.5664989  0.55229307\n",
    " 0.58424717 0.56240558 0.52764792 0.54849861] -> mean_test = 0.5542\n",
    "\n",
    "Cross-validating (10-fold) HistGradientBoostingRegressor using univariate linear regression (1300 features)...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 28, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Train scores: [0.75582173 0.7276507  0.76533005 0.72540476 0.73508961 0.73966701\n",
    " 0.74035541 0.73509884 0.73865676 0.76293388] -> mean_train = 0.7426\n",
    "Test scores: [0.59155216 0.5764809  0.60739257 0.5594956  0.59567879 0.59699155\n",
    " 0.58574327 0.59043057 0.58562394 0.58767947] -> mean_test = 0.5877\n",
    "\n",
    "Cross-validating (10-fold) HistGradientBoostingRegressor using mutual information regression (200 features)...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
    "Train scores: [0.76875166 0.73104154 0.75049263 0.76938016 0.76481907 0.75684443\n",
    " 0.73644814 0.74662982 0.76163698 0.78642204] -> mean_train = 0.7572\n",
    "Test scores: [0.60509896 0.6142814  0.60063617 0.63996885 0.62272178 0.59556783\n",
    " 0.60761713 0.59120005 0.59343065 0.58970676] -> mean_test = 0.6060"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695b43f-643c-4d8b-970d-07261b01c51f",
   "metadata": {},
   "source": [
    "Os resultados da validação cruzada demonstram que o melhor score foi obtido utilizando a <b>informação mútua</b> como método de seleção de features (<b>0.6060</b>). O modelo respetivo será, então comparado com os modelos obtidos a partir dos métodos de seleção de features <b>SelectFromModel</b> e <b>Pearson + Spearman + mutual information</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d3a0c-c3b5-4b8f-b634-2017b325da91",
   "metadata": {},
   "source": [
    "<b>SelectFromModel</b>\n",
    "<br>(cross-validation of the best model with optimized hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f685b26d-2c39-42f4-bf57-d9c211140ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating (10-fold) HistGradientBoostingRegressor using SelectFromModel to select features...\n",
      "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 55, 'max_iter': 200, 'learning_rate': 0.05}\n",
      "Train scores: [0.72930953 0.72559338 0.72952691 0.73186194 0.73014827 0.7371733\n",
      " 0.71938107 0.72341578 0.75435627 0.76341954] -> mean_train = 0.7344\n",
      "Test scores: [0.57799925 0.62441839 0.60640188 0.57680143 0.60326652 0.59459631\n",
      " 0.60107882 0.56927381 0.58052564 0.54540325] -> mean_test = 0.5880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross-validating (10-fold) HistGradientBoostingRegressor using SelectFromModel to select features...\")\n",
    "print(f\"Optimized hyperparameters: {gs_sfm.best_params_}\")\n",
    "x_train_sfm = X_train_sc.iloc[:, feature_mask]\n",
    "result = cross_validate(estimator=HGBR(**gs_sfm.best_params_),\n",
    "                        X=x_train_sfm,\n",
    "                        y=y_train,\n",
    "                        cv=KFold(n_splits=10, shuffle=True),\n",
    "                        return_train_score=True)\n",
    "mean_train = np.sum(result[\"train_score\"]) / 10\n",
    "mean_test = np.sum(result[\"test_score\"]) / 10\n",
    "print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb3980-bc0e-484f-a292-90886e05e97c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Cross-validating (10-fold) HistGradientBoostingRegressor using SelectFromModel to select features...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 32, 'max_leaf_nodes': 55, 'max_iter': 200, 'learning_rate': 0.05}\n",
    "Train scores: [0.72930953 0.72559338 0.72952691 0.73186194 0.73014827 0.7371733\n",
    " 0.71938107 0.72341578 0.75435627 0.76341954] -> mean_train = 0.7344\n",
    "Test scores: [0.57799925 0.62441839 0.60640188 0.57680143 0.60326652 0.59459631\n",
    " 0.60107882 0.56927381 0.58052564 0.54540325] -> mean_test = 0.5880"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba12b6-b1d5-4fb3-8ba8-5052acc92014",
   "metadata": {},
   "source": [
    "O score obtido na validação cruzada foi de <b>0.5880</b>. Sendo assim, o melhor modelo até ao momento é o obtido através da seleção de features pela <b>informação mútua</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3dd86-518a-424c-9b3c-7dc45c8e529f",
   "metadata": {},
   "source": [
    "<b>Pearson + Spearman + mutual information</b>\n",
    "<br>(cross-validation of the best model with optimized hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4716ec1-3f24-416c-9efe-1bafa8fa691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating (10-fold) HistGradientBoostingRegressor using a combination of feature selection methods...\n",
      "Optimized hyperparameters: {'warm_start': True, 'min_samples_leaf': 32, 'max_leaf_nodes': 63, 'max_iter': 300, 'learning_rate': 0.05}\n",
      "Train scores: [0.75380586 0.74244005 0.74206205 0.74833658 0.74580747 0.75685111\n",
      " 0.74250112 0.74689319 0.75487387 0.74426017] -> mean_train = 0.7478\n",
      "Test scores: [0.58764092 0.59907974 0.62072532 0.62004219 0.60299351 0.60183481\n",
      " 0.60394989 0.59682932 0.58152845 0.59126593] -> mean_test = 0.6006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross-validating (10-fold) HistGradientBoostingRegressor using a combination of feature selection methods...\")\n",
    "print(f\"Optimized hyperparameters: {gs_psmi.best_params_}\")\n",
    "x_train_psmi = X_train_sc[best_features_psmi]\n",
    "result = cross_validate(estimator=HGBR(**gs_psmi.best_params_),\n",
    "                        X=x_train_psmi,\n",
    "                        y=y_train,\n",
    "                        cv=KFold(n_splits=10, shuffle=True),\n",
    "                        return_train_score=True)\n",
    "mean_train = np.sum(result[\"train_score\"]) / 10\n",
    "mean_test = np.sum(result[\"test_score\"]) / 10\n",
    "print(f\"Train scores: {result['train_score']} -> {mean_train = :.4f}\")\n",
    "print(f\"Test scores: {result['test_score']} -> {mean_test = :.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76691a74-ba12-42e5-9264-e36a86476437",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Cross-validating (10-fold) HistGradientBoostingRegressor using a combination of feature selection methods...\n",
    "Optimized hyperparameters: {'warm_start': False, 'min_samples_leaf': 24, 'max_leaf_nodes': 63, 'max_iter': 250, 'learning_rate': 0.05}\n",
    "Train scores: [0.73414891 0.75532122 0.76818821 0.76678538 0.74952505 0.77140543\n",
    " 0.74788207 0.7446634  0.73644775 0.73045008] -> mean_train = 0.7505\n",
    "Test scores: [0.61389366 0.6229216  0.59246623 0.6059233  0.58573252 0.6024856\n",
    " 0.59056188 0.62128784 0.58690858 0.59315414] -> mean_test = 0.6015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d8256-b663-4db0-95f0-e15a5e7e57ae",
   "metadata": {},
   "source": [
    "Finalmente, obteve-se um score médio de <b>0.6015</b> na validaçao cruzada referente ao modelo obtido pela combinação de métodos de seleção de features <b>Pearson + Spearman + mutual information</b>. Verificamos, então, que o melhor modelo se trata do obtido através da seleção de features pela <b>informação mútua</b>, sendo utilizado para efetuar previsões acerca dos dados de teste (sequências de aminoácidos sem label associada)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b7a3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use best model to predict labels in test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "594e7ed7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_dataset_with_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-63-32118d22649f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# não correr! dados em 'data_test.csv'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mtest\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"test.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtest_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_dataset_with_features\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data_test.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'get_dataset_with_features' is not defined"
     ]
    }
   ],
   "source": [
    "# não correr! dados em 'data_test.csv'\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_data = get_dataset_with_features(test)\n",
    "test_data.to_csv(\"data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a208d268",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa7958dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# split features and label\n",
    "X_test = test_data.iloc[:, 2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45fec257-488b-4fd2-a036-d49fae6ac00e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      SeqLength       A      R      N      D      C      E      Q      G    H  \\\n0           221   9.955  1.357  8.597  6.787  1.810  3.620  5.882  8.597  0.0   \n1           221   9.955  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n2           220  10.000  1.364  8.636  6.818  1.818  3.182  5.909  8.636  0.0   \n3           221   9.955  1.357  8.597  6.787  2.262  3.167  5.882  8.597  0.0   \n4           221   9.955  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n...         ...     ...    ...    ...    ...    ...    ...    ...    ...  ...   \n2408        221   9.502  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n2409        221   9.502  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n2410        221   9.502  1.357  9.050  6.787  1.810  3.167  5.882  8.597  0.0   \n2411        221   9.502  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n2412        221   9.502  1.357  8.597  6.787  1.810  3.167  5.882  8.597  0.0   \n\n      ...  MoreauBrotoAuto_Mutability22  MoreauBrotoAuto_Mutability23  \\\n0     ...                        -0.021                        -0.025   \n1     ...                        -0.023                        -0.027   \n2     ...                        -0.025                        -0.029   \n3     ...                        -0.022                        -0.026   \n4     ...                        -0.023                        -0.027   \n...   ...                           ...                           ...   \n2408  ...                        -0.023                        -0.027   \n2409  ...                        -0.014                        -0.018   \n2410  ...                        -0.029                        -0.033   \n2411  ...                        -0.017                        -0.021   \n2412  ...                        -0.011                        -0.015   \n\n      MoreauBrotoAuto_Mutability24  MoreauBrotoAuto_Mutability25  \\\n0                           -0.032                        -0.023   \n1                           -0.034                        -0.025   \n2                           -0.035                        -0.027   \n3                           -0.033                        -0.024   \n4                           -0.034                        -0.025   \n...                            ...                           ...   \n2408                        -0.034                        -0.025   \n2409                        -0.025                        -0.016   \n2410                        -0.040                        -0.031   \n2411                        -0.027                        -0.019   \n2412                        -0.021                        -0.013   \n\n      MoreauBrotoAuto_Mutability26  MoreauBrotoAuto_Mutability27  \\\n0                           -0.019                        -0.016   \n1                           -0.021                        -0.018   \n2                           -0.023                        -0.020   \n3                           -0.020                        -0.017   \n4                           -0.021                        -0.018   \n...                            ...                           ...   \n2408                        -0.021                        -0.018   \n2409                        -0.012                        -0.009   \n2410                        -0.028                        -0.024   \n2411                        -0.015                        -0.012   \n2412                        -0.009                        -0.006   \n\n      MoreauBrotoAuto_Mutability28  MoreauBrotoAuto_Mutability29  \\\n0                           -0.019                        -0.026   \n1                           -0.021                        -0.028   \n2                           -0.023                        -0.030   \n3                           -0.020                        -0.027   \n4                           -0.021                        -0.028   \n...                            ...                           ...   \n2408                        -0.021                        -0.028   \n2409                        -0.012                        -0.019   \n2410                        -0.028                        -0.035   \n2411                        -0.015                        -0.022   \n2412                        -0.009                        -0.016   \n\n      MoreauBrotoAuto_Mutability30  pH  \n0                           -0.021   8  \n1                           -0.023   8  \n2                           -0.025   8  \n3                           -0.022   8  \n4                           -0.023   8  \n...                            ...  ..  \n2408                        -0.023   8  \n2409                        -0.014   8  \n2410                        -0.029   8  \n2411                        -0.017   8  \n2412                        -0.010   8  \n\n[2413 rows x 9298 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SeqLength</th>\n      <th>A</th>\n      <th>R</th>\n      <th>N</th>\n      <th>D</th>\n      <th>C</th>\n      <th>E</th>\n      <th>Q</th>\n      <th>G</th>\n      <th>H</th>\n      <th>...</th>\n      <th>MoreauBrotoAuto_Mutability22</th>\n      <th>MoreauBrotoAuto_Mutability23</th>\n      <th>MoreauBrotoAuto_Mutability24</th>\n      <th>MoreauBrotoAuto_Mutability25</th>\n      <th>MoreauBrotoAuto_Mutability26</th>\n      <th>MoreauBrotoAuto_Mutability27</th>\n      <th>MoreauBrotoAuto_Mutability28</th>\n      <th>MoreauBrotoAuto_Mutability29</th>\n      <th>MoreauBrotoAuto_Mutability30</th>\n      <th>pH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>221</td>\n      <td>9.955</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.620</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.021</td>\n      <td>-0.025</td>\n      <td>-0.032</td>\n      <td>-0.023</td>\n      <td>-0.019</td>\n      <td>-0.016</td>\n      <td>-0.019</td>\n      <td>-0.026</td>\n      <td>-0.021</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>221</td>\n      <td>9.955</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.023</td>\n      <td>-0.027</td>\n      <td>-0.034</td>\n      <td>-0.025</td>\n      <td>-0.021</td>\n      <td>-0.018</td>\n      <td>-0.021</td>\n      <td>-0.028</td>\n      <td>-0.023</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>220</td>\n      <td>10.000</td>\n      <td>1.364</td>\n      <td>8.636</td>\n      <td>6.818</td>\n      <td>1.818</td>\n      <td>3.182</td>\n      <td>5.909</td>\n      <td>8.636</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.025</td>\n      <td>-0.029</td>\n      <td>-0.035</td>\n      <td>-0.027</td>\n      <td>-0.023</td>\n      <td>-0.020</td>\n      <td>-0.023</td>\n      <td>-0.030</td>\n      <td>-0.025</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>221</td>\n      <td>9.955</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>2.262</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.022</td>\n      <td>-0.026</td>\n      <td>-0.033</td>\n      <td>-0.024</td>\n      <td>-0.020</td>\n      <td>-0.017</td>\n      <td>-0.020</td>\n      <td>-0.027</td>\n      <td>-0.022</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>221</td>\n      <td>9.955</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.023</td>\n      <td>-0.027</td>\n      <td>-0.034</td>\n      <td>-0.025</td>\n      <td>-0.021</td>\n      <td>-0.018</td>\n      <td>-0.021</td>\n      <td>-0.028</td>\n      <td>-0.023</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2408</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.023</td>\n      <td>-0.027</td>\n      <td>-0.034</td>\n      <td>-0.025</td>\n      <td>-0.021</td>\n      <td>-0.018</td>\n      <td>-0.021</td>\n      <td>-0.028</td>\n      <td>-0.023</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2409</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.014</td>\n      <td>-0.018</td>\n      <td>-0.025</td>\n      <td>-0.016</td>\n      <td>-0.012</td>\n      <td>-0.009</td>\n      <td>-0.012</td>\n      <td>-0.019</td>\n      <td>-0.014</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2410</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>9.050</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.029</td>\n      <td>-0.033</td>\n      <td>-0.040</td>\n      <td>-0.031</td>\n      <td>-0.028</td>\n      <td>-0.024</td>\n      <td>-0.028</td>\n      <td>-0.035</td>\n      <td>-0.029</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2411</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.017</td>\n      <td>-0.021</td>\n      <td>-0.027</td>\n      <td>-0.019</td>\n      <td>-0.015</td>\n      <td>-0.012</td>\n      <td>-0.015</td>\n      <td>-0.022</td>\n      <td>-0.017</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2412</th>\n      <td>221</td>\n      <td>9.502</td>\n      <td>1.357</td>\n      <td>8.597</td>\n      <td>6.787</td>\n      <td>1.810</td>\n      <td>3.167</td>\n      <td>5.882</td>\n      <td>8.597</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-0.011</td>\n      <td>-0.015</td>\n      <td>-0.021</td>\n      <td>-0.013</td>\n      <td>-0.009</td>\n      <td>-0.006</td>\n      <td>-0.009</td>\n      <td>-0.016</td>\n      <td>-0.010</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>2413 rows × 9298 columns</p>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3a66853",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# scale X_test\n",
    "X_test_arr = preprocessing.MinMaxScaler().fit_transform(X_test)\n",
    "X_test_sc = pd.DataFrame(data=X_test_arr, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7b56157",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get beat_features according to previous results\n",
    "best_features = get_k_best_corrs(200, mutual_info).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df7e19a9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# reduce datasets to the best features\n",
    "X_train_sc_best = X_train_sc.loc[:, best_features]\n",
    "X_test_sc_best = X_test_sc.loc[:, best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "6be7ea8c-c233-4115-8d5d-f1db724e5d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingRegressor(learning_rate=0.05, max_iter=300,\n",
       "                              max_leaf_nodes=63, min_samples_leaf=32)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit best model overall (best combination of model / method of feature selection / number of features / hyperparameters)\n",
    "estimator = HGBR\n",
    "params = best_params[3]\n",
    "model = estimator(**params)\n",
    "model.fit(X_train_sc_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b6edaa75-216b-42a3-a5cb-02232635ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pd.Series(model.predict(X_test_sc_best), name=\"tm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "2ca20fbb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get predictions and create csv file\n",
    "predictions = pd.concat([test_data[\"seq_id\"], y_preds], axis=1)\n",
    "predictions.to_csv(\"novozymes_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3efdff-c481-4447-9355-577d9d9350e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Passando agora para a sub-área do Machine Learning, o Deep Learning permite tratar dados mais extensos com maior facilidade e precisão (em muitos casos).\n",
    "\n",
    "Visto que o código desenvolvido anteriormente é bastante extenso e demorado, vamos primeiro definir os blocos de código essenciais de correr antes de efetuar a análise por Deep Learning (de forma a poder começar a análise *de novo* a partir daqui)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data_train.csv\")\n",
    "\n",
    "train = train[(train[\"pH\"]<14) & (train[\"pH\"]>0)]\n",
    "y_train = train[\"tm\"]\n",
    "y_train = y_train[(np.abs(stats.zscore(y_train)) < 3)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tendo definido as features com a maior importância, e que permitiram efetuar previsões com precisão relativamente elevada, vamos utilizar os mesmos (gerados através do método da Informação Mútua) para prosseguir com a análise utilizando 'Deep Learning'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#X_train_sc_best.to_csv(\"x_train_mi.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "x_train_mi = pd.read_csv(\"x_train_psmi.csv\").iloc[:,1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "        OxidizedMEC           VMT  _PolarizabilityD3075           TVK  \\\ncount  28403.000000  28403.000000          28403.000000  28403.000000   \nmean       0.011967      0.019282              0.753314      0.003948   \nstd        0.019489      0.080000              0.076846      0.019061   \nmin        0.000000      0.000000              0.000000      0.000000   \n25%        0.005078      0.000000              0.716411      0.000000   \n50%        0.008499      0.000000              0.766375      0.000000   \n75%        0.014543      0.000000              0.799425      0.000000   \nmax        1.000000      1.000000              1.000000      1.000000   \n\n       MoreauBrotoAuto_Hydrophobicity11           KKL            TH  \\\ncount                      28403.000000  28403.000000  28403.000000   \nmean                           0.292995      0.017712      0.033465   \nstd                            0.056540      0.043839      0.062418   \nmin                            0.000000      0.000000      0.000000   \n25%                            0.254690      0.000000      0.000000   \n50%                            0.288600      0.000000      0.000000   \n75%                            0.325397      0.000000      0.053097   \nmax                            1.000000      1.000000      1.000000   \n\n                 VK  _PolarityD2001            SN  ...            EK  \\\ncount  28403.000000    28403.000000  28403.000000  ...  28403.000000   \nmean       0.083762        0.038799      0.054557  ...      0.067315   \nstd        0.092876        0.055728      0.068581  ...      0.062111   \nmin        0.000000        0.000000      0.000000  ...      0.000000   \n25%        0.000000        0.010179      0.000000  ...      0.022196   \n50%        0.069672        0.020096      0.039095  ...      0.059579   \n75%        0.122951        0.044338      0.088477  ...      0.098131   \nmax        1.000000        1.000000      1.000000  ...      1.000000   \n\n                 LI  _NormalizedVDWVD1001           MLV  _SecondaryStrD1050  \\\ncount  28403.000000          28403.000000  28403.000000        28403.000000   \nmean       0.107193              0.036351      0.014865            0.635295   \nstd        0.095415              0.042654      0.055992            0.067452   \nmin        0.000000              0.000000      0.000000            0.000000   \n25%        0.028571              0.011002      0.000000            0.599930   \n50%        0.098901              0.021478      0.000000            0.637655   \n75%        0.156044              0.046157      0.000000            0.676793   \nmax        1.000000              1.000000      1.000000            1.000000   \n\n                 VA            KR  _PolarizabilityD3025           HKE  \\\ncount  28403.000000  28403.000000          28403.000000  28403.000000   \nmean       0.107986      0.086051              0.224909      0.009250   \nstd        0.096550      0.094041              0.055826      0.037566   \nmin        0.000000      0.000000              0.000000      0.000000   \n25%        0.038000      0.000000              0.190607      0.000000   \n50%        0.092000      0.067568              0.222560      0.000000   \n75%        0.150000      0.128378              0.256052      0.000000   \nmax        1.000000      1.000000              1.000000      1.000000   \n\n                KHP  \ncount  28403.000000  \nmean       0.020491  \nstd        0.081423  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        1.000000  \n\n[8 rows x 496 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OxidizedMEC</th>\n      <th>VMT</th>\n      <th>_PolarizabilityD3075</th>\n      <th>TVK</th>\n      <th>MoreauBrotoAuto_Hydrophobicity11</th>\n      <th>KKL</th>\n      <th>TH</th>\n      <th>VK</th>\n      <th>_PolarityD2001</th>\n      <th>SN</th>\n      <th>...</th>\n      <th>EK</th>\n      <th>LI</th>\n      <th>_NormalizedVDWVD1001</th>\n      <th>MLV</th>\n      <th>_SecondaryStrD1050</th>\n      <th>VA</th>\n      <th>KR</th>\n      <th>_PolarizabilityD3025</th>\n      <th>HKE</th>\n      <th>KHP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>...</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n      <td>28403.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.011967</td>\n      <td>0.019282</td>\n      <td>0.753314</td>\n      <td>0.003948</td>\n      <td>0.292995</td>\n      <td>0.017712</td>\n      <td>0.033465</td>\n      <td>0.083762</td>\n      <td>0.038799</td>\n      <td>0.054557</td>\n      <td>...</td>\n      <td>0.067315</td>\n      <td>0.107193</td>\n      <td>0.036351</td>\n      <td>0.014865</td>\n      <td>0.635295</td>\n      <td>0.107986</td>\n      <td>0.086051</td>\n      <td>0.224909</td>\n      <td>0.009250</td>\n      <td>0.020491</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.019489</td>\n      <td>0.080000</td>\n      <td>0.076846</td>\n      <td>0.019061</td>\n      <td>0.056540</td>\n      <td>0.043839</td>\n      <td>0.062418</td>\n      <td>0.092876</td>\n      <td>0.055728</td>\n      <td>0.068581</td>\n      <td>...</td>\n      <td>0.062111</td>\n      <td>0.095415</td>\n      <td>0.042654</td>\n      <td>0.055992</td>\n      <td>0.067452</td>\n      <td>0.096550</td>\n      <td>0.094041</td>\n      <td>0.055826</td>\n      <td>0.037566</td>\n      <td>0.081423</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.005078</td>\n      <td>0.000000</td>\n      <td>0.716411</td>\n      <td>0.000000</td>\n      <td>0.254690</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.010179</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.022196</td>\n      <td>0.028571</td>\n      <td>0.011002</td>\n      <td>0.000000</td>\n      <td>0.599930</td>\n      <td>0.038000</td>\n      <td>0.000000</td>\n      <td>0.190607</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.008499</td>\n      <td>0.000000</td>\n      <td>0.766375</td>\n      <td>0.000000</td>\n      <td>0.288600</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.069672</td>\n      <td>0.020096</td>\n      <td>0.039095</td>\n      <td>...</td>\n      <td>0.059579</td>\n      <td>0.098901</td>\n      <td>0.021478</td>\n      <td>0.000000</td>\n      <td>0.637655</td>\n      <td>0.092000</td>\n      <td>0.067568</td>\n      <td>0.222560</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.014543</td>\n      <td>0.000000</td>\n      <td>0.799425</td>\n      <td>0.000000</td>\n      <td>0.325397</td>\n      <td>0.000000</td>\n      <td>0.053097</td>\n      <td>0.122951</td>\n      <td>0.044338</td>\n      <td>0.088477</td>\n      <td>...</td>\n      <td>0.098131</td>\n      <td>0.156044</td>\n      <td>0.046157</td>\n      <td>0.000000</td>\n      <td>0.676793</td>\n      <td>0.150000</td>\n      <td>0.128378</td>\n      <td>0.256052</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 496 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mi.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0        48.4\n1        48.4\n2        49.0\n3        55.6\n4        48.4\n         ... \n28691    51.8\n28692    37.2\n28693    64.6\n28694    50.7\n28695    37.6\nName: tm, Length: 28403, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Em primeiro lugar, vamos criar uma rede neuronal constituída por camadas densas (o tipo de rede mais simples e utilizada) para poder efetuar previsões relativamente aos valores de termostabilidade."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "#!pip install scikeras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visto que este tipo de redes (assim como outros) apresenta vários hiperparâmetros que podem ser otimizados para obter um modelo que permite uma previsão mais precisa, vamos criar uma função (chamada *create_model()*) que permite a adição de um número variável de camadas, cada uma com valores variáveis de nodos (e outros parâmetros que vão ser discutidos de seguida). A cada camada densa é adicionado também uma regularização dropout (para evitar sobreajustamentos), e por fim, a rede é compilada com a selecção de um dos otimizadores mais utilizados (selecionado através da função auxiliar *_choose_optimizer()*).\n",
    "\n",
    "Os seguintes blocos de código foram inspirados no código apresentado no seguinte site: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "#GRID SEARCH FUNC\n",
    "\n",
    "def _choose_optimizer(optimizer, learning_rate, momentum):\n",
    "    if optimizer == \"sgd\":\n",
    "        return SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        return RMSprop(learning_rate=learning_rate, momentum=momentum)\n",
    "    elif optimizer == \"adagrad\":\n",
    "        return Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adadelta\":\n",
    "        return Adadelta(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adam\":\n",
    "        return Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adamax\":\n",
    "        return Adamax(learning_rate=learning_rate)\n",
    "    elif optimizer == \"nadam\":\n",
    "        return Nadam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized optimizer\")\n",
    "\n",
    "\n",
    "def create_model(first_input, layers, neurons, dropout_rate, weight_constraint, learning_rate, momentum, activation, init_mode='uniform', optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    for ix in range(layers):\n",
    "        if ix == 0:\n",
    "            model.add(Dense(neurons[ix],\n",
    "                            activation=activation,\n",
    "                            input_shape=first_input,\n",
    "                            kernel_initializer=init_mode,\n",
    "                            kernel_constraint=MaxNorm(weight_constraint)))\n",
    "        elif ix != layers-1:\n",
    "            model.add(Dense(neurons[ix],\n",
    "                            activation=activation,\n",
    "                            kernel_initializer=init_mode,\n",
    "                            kernel_constraint=MaxNorm(weight_constraint)))\n",
    "        else:\n",
    "            model.add(Dense(1,\n",
    "                            activation=activation,\n",
    "                            kernel_initializer=init_mode))\n",
    "\n",
    "        if ix != layers-1:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "\n",
    "    opt = _choose_optimizer(optimizer.lower(), learning_rate, momentum)\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=opt, metrics=[\"mse\"])\n",
    "    return model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#Parameter values to optimize:\n",
    "neurons = [grid + (1,) for grid in itertools.product(*[[20,50,100]]*3)]\n",
    "dropout_rate = np.linspace(0.0, 0.5, 6)\n",
    "weight_constraint = np.linspace(0.5, 5, 10) #Max norm value each weight parameter can be\n",
    "learning_rate = np.linspace(0.005, 0.5, 100)\n",
    "momentum = np.linspace(0.0, 0.9, 4) #9\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "#For computational purposes, all layers will have the same  weight_constraint and dropout_rate values\n",
    "\n",
    "param_dist = dict(model__neurons=neurons,\n",
    "                  model__dropout_rate=dropout_rate,\n",
    "                  model__weight_constraint=weight_constraint,\n",
    "                  model__learning_rate=learning_rate,\n",
    "                  model__momentum=momentum,\n",
    "                  model__optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving best parameters for a 4 layered fully-connected network (n_iter=50, cv=5):\n",
      "|\n",
      "Best score: 0.370032506271634\n",
      "Best parameters: {'model__weight_constraint': 2.5, 'model__optimizer': 'Adadelta', 'model__neurons': (100, 100, 50, 1), 'model__momentum': 0.9, 'model__learning_rate': 0.465, 'model__dropout_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "param_dist[\"model__neurons\"] = [grid + (1,) for grid in itertools.product(*[[20,50,100]]*3)]\n",
    "\n",
    "print(f\"Retrieving best parameters for a 4 layered fully-connected network (n_iter=50, cv=5):\\n|\")\n",
    "model = KerasRegressor(model=create_model, epochs=100, batch_size=10, verbose=0,\n",
    "                   first_input=[x_train_mi.shape[1]],\n",
    "                   layers=4,\n",
    "                   activation=\"relu\")\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, n_jobs=-1, cv=5)\n",
    "grid.fit(x_train_mi, y_train)\n",
    "print(f\"Best score: {grid.best_score_}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving best parameters for a 6 layered fully-connected network (n_iter=50, cv=5):\n",
      "|\n",
      "(20, 50, 50, 20, 100, 1)\n",
      "Best score: -0.010840052742769002\n",
      "Best parameters: {'model__weight_constraint': 0.5, 'model__optimizer': 'Adagrad', 'model__neurons': (20, 50, 50, 20, 100, 1), 'model__momentum': 0.3, 'model__learning_rate': 0.255, 'model__dropout_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "param_dist[\"model__neurons\"] = [grid + (1,) for grid in itertools.product(*[[20,50,100]]*5)]\n",
    "\n",
    "print(f\"Retrieving best parameters for a 6 layered fully-connected network (n_iter=50, cv=5):\\n|\")\n",
    "model = KerasRegressor(model=create_model, epochs=100, batch_size=10, verbose=0,\n",
    "                   first_input=[x_train_mi.shape[1]],\n",
    "                   layers=6,\n",
    "                   activation=\"relu\")\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=1, n_jobs=-1, cv=5)\n",
    "grid.fit(x_train_mi, y_train)\n",
    "print(f\"Best score: {grid.best_score_}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving best parameters for a 8 layered fully-connected network (n_iter=50, cv=5):\n",
      "|\n",
      "Best score: -0.009267656321677187\n",
      "Best parameters: {'model__weight_constraint': 3.5, 'model__optimizer': 'Adamax', 'model__neurons': (20, 50, 100, 20, 100, 20, 20, 1), 'model__momentum': 0.0, 'model__learning_rate': 0.17, 'model__dropout_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "param_dist[\"model__neurons\"] = [grid + (1,) for grid in itertools.product(*[[20,50,100]]*7)]\n",
    "\n",
    "print(f\"Retrieving best parameters for a 8 layered fully-connected network (n_iter=50, cv=5):\\n|\")\n",
    "model = KerasRegressor(model=create_model, epochs=100, batch_size=10, verbose=0,\n",
    "                   first_input=[x_train_mi.shape[1]],\n",
    "                   layers=8,\n",
    "                   activation=\"relu\")\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=1, n_jobs=-1, cv=5)\n",
    "grid.fit(x_train_mi, y_train)\n",
    "print(f\"Best score: {grid.best_score_}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def _get_grid():\n",
    "    pass\n",
    "\n",
    "def dense_net_optimizer(layers:int,\n",
    "                        neurons:list,\n",
    "                        dropout_rates:list,\n",
    "                        weight_constraints:list,\n",
    "                        activations:list,\n",
    "                        optimizer:str,\n",
    "                        init_mode=['uniform'],\n",
    "                        randomized=True):\n",
    "    \"\"\"\n",
    "    :param layers:\n",
    "    :param neurons:\n",
    "    :param dropout_rates:\n",
    "    :param weight_constraints:\n",
    "    :param activations:\n",
    "    :param optimizers:\n",
    "    :param init_mode:\n",
    "    :param randomized:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    layers_param_grid = _get_grid(neurons, dropout_rates, weight_constraints, activations)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Neste ficheiro, iremos explorar a possibilidade de aplicar a estratégia do 'one-hot encoding' para as dadas sequências proteicas. Esta é a representação preferida pelos modelos baseados em redes convolucionais (ou CNNs), que iremos testar."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5476b304-d449-4355-9c66-18d8743459c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bdb13-5edb-4292-9aad-adf1aee7ecab",
   "metadata": {},
   "source": [
    "#### Read data and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Começamos com o mesmo preprocessamento efetuado no trabalho principal."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b070987-b0c2-49c3-a19b-5c9a0907a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Files/train.csv\")\n",
    "updates = pd.read_csv(\"Files/train_updates_20220929.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f3326a6-7696-4187-a15c-557127c8aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = updates[\"pH\"].isna()\n",
    "to_delete = updates.loc[mask,:]\n",
    "to_change = updates.loc[-mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b47301c-6ce8-4800-afad-b03f4b1103ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[to_change.index, [\"pH\", \"tm\"]] = updates.loc[to_change.index, [\"pH\", \"tm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aaf85c0-97a2-46e4-a74f-c5bf57564c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cut = train.drop(to_delete.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6cd5b35-37ea-4e61-bdda-ce4e71ba6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = train_cut[train_cut.isna().any(axis=1)].index\n",
    "train_cut.drop(index=idxs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d5a9252-b67f-499a-9c40-728dfcb4554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cut.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b61fabf6-ad58-4cdb-90bc-5891ae223f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = train_cut[(train_cut[\"pH\"] >= 1) & (train_cut[\"pH\"] <= 14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1667c6a3-735a-465d-adfa-65ed4e7c3ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       seq_id                                   protein_sequence   pH  \\\n0          25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...  7.0   \n1          28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...  7.0   \n2          29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...  7.0   \n3          30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...  5.5   \n4          33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...  7.0   \n...       ...                                                ...  ...   \n25482   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n25483   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n25484   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n25485   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n25486   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n\n                             data_source    tm  \n0      doi.org/10.1038/s41592-020-0801-4  48.4  \n1      doi.org/10.1038/s41592-020-0801-4  48.4  \n2      doi.org/10.1038/s41592-020-0801-4  49.0  \n3      doi.org/10.1038/s41592-020-0801-4  55.6  \n4      doi.org/10.1038/s41592-020-0801-4  48.4  \n...                                  ...   ...  \n25482  doi.org/10.1038/s41592-020-0801-4  51.8  \n25483  doi.org/10.1038/s41592-020-0801-4  37.2  \n25484  doi.org/10.1038/s41592-020-0801-4  64.6  \n25485  doi.org/10.1038/s41592-020-0801-4  50.7  \n25486  doi.org/10.1038/s41592-020-0801-4  37.6  \n\n[25487 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_id</th>\n      <th>protein_sequence</th>\n      <th>pH</th>\n      <th>data_source</th>\n      <th>tm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n      <td>7.0</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>48.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28</td>\n      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n      <td>7.0</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>48.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n      <td>7.0</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n      <td>5.5</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>55.6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33</td>\n      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n      <td>7.0</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>48.4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25482</th>\n      <td>31385</td>\n      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n      <td>7.0</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>51.8</td>\n    </tr>\n    <tr>\n      <th>25483</th>\n      <td>31386</td>\n      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n      <td>7.0</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>37.2</td>\n    </tr>\n    <tr>\n      <th>25484</th>\n      <td>31387</td>\n      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n      <td>7.0</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>64.6</td>\n    </tr>\n    <tr>\n      <th>25485</th>\n      <td>31388</td>\n      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n      <td>7.0</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>50.7</td>\n    </tr>\n    <tr>\n      <th>25486</th>\n      <td>31389</td>\n      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n      <td>7.0</td>\n      <td>doi.org/10.1038/s41592-020-0801-4</td>\n      <td>37.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>25487 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Add sequence size column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visto que esta técnica requer que todas as sequências sejam do mesmo tamanho (uma vez que gera novas matrizes de informação com cada filtro que percorre cada representação de sequência), vamos adicionar uma coluna ao dataset que indica o tamanho de cada sequência."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "size = data_train[\"protein_sequence\"].apply(lambda x: len(x), 0)\n",
    "data_train[\"sequence_size\"] = size.astype(\"float64\")\n",
    "\n",
    "#print(type(data_train[\"pH\"][0]))\n",
    "#print(type(data_train[\"sequence_size\"][0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "561ed8fb-3546-494e-ba0a-d7f73ec6a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.loc[:, [\"seq_id\", \"protein_sequence\", \"sequence_size\", \"pH\", \"tm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5383c93c-cf7e-4e5f-98e4-d1cc484f9ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       sequence_size            pH            tm\ncount   25487.000000  25487.000000  25487.000000\nmean      461.254561      6.903579     51.436933\nstd       422.439420      0.752407     12.190382\nmin         5.000000      1.990000      0.000000\n25%       219.000000      7.000000     43.650000\n50%       359.000000      7.000000     48.700000\n75%       547.000000      7.000000     54.500000\nmax      8798.000000     11.000000    130.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence_size</th>\n      <th>pH</th>\n      <th>tm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>25487.000000</td>\n      <td>25487.000000</td>\n      <td>25487.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>461.254561</td>\n      <td>6.903579</td>\n      <td>51.436933</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>422.439420</td>\n      <td>0.752407</td>\n      <td>12.190382</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.000000</td>\n      <td>1.990000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>219.000000</td>\n      <td>7.000000</td>\n      <td>43.650000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>359.000000</td>\n      <td>7.000000</td>\n      <td>48.700000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>547.000000</td>\n      <td>7.000000</td>\n      <td>54.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>8798.000000</td>\n      <td>11.000000</td>\n      <td>130.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe().loc[:,(\"sequence_size\", \"pH\", \"tm\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Observamos nesta tabela de resumo que a sequência com o maior tamanho tem 8798 resíduos, sendo um outlier, pelo que estender cada sequência a esse tamanho e aplicar a técnica de 'one-hot encoding' iria requerer imenso poder computacional. Desta forma, prosseguimos com a remoção dos outliers em relação ao tamanho das sequências."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Remove 'sequence_size' upper bound outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "1728.5479600038577"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub = np.mean(size) + np.std(size)*3\n",
    "ub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "       seq_id                                   protein_sequence  \\\n0          25  AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...   \n1          28  AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...   \n2          29  AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...   \n3          30  AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...   \n4          33  AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...   \n...       ...                                                ...   \n25482   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...   \n25483   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...   \n25484   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...   \n25485   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...   \n25486   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...   \n\n       sequence_size   pH    tm  \n0              501.0  7.0  48.4  \n1              313.0  7.0  48.4  \n2              109.0  7.0  49.0  \n3              329.0  5.5  55.6  \n4              278.0  7.0  48.4  \n...              ...  ...   ...  \n25482          549.0  7.0  51.8  \n25483          469.0  7.0  37.2  \n25484          128.0  7.0  64.6  \n25485          593.0  7.0  50.7  \n25486          537.0  7.0  37.6  \n\n[25031 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_id</th>\n      <th>protein_sequence</th>\n      <th>sequence_size</th>\n      <th>pH</th>\n      <th>tm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>AAPDEITTAWPVNVGPLNPHLYTPNQMFAQSMVYEPLVKYQADGSV...</td>\n      <td>501.0</td>\n      <td>7.0</td>\n      <td>48.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28</td>\n      <td>AARRFSGPRNQRQQGGGDPGLMHGKTVLITGANSGLGRATAAELLR...</td>\n      <td>313.0</td>\n      <td>7.0</td>\n      <td>48.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29</td>\n      <td>AASSPEADFVKKTISSHKIVIFSKSYCPYCKKAKSVFRELDQVPYV...</td>\n      <td>109.0</td>\n      <td>7.0</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>AATFAYSQSQKRSSSSPGGGSNHGWNNWGKAAALASTTPLVHVASV...</td>\n      <td>329.0</td>\n      <td>5.5</td>\n      <td>55.6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33</td>\n      <td>AAVLVTFIGGLYFITHHKKEESETLQSQKVTGNGLPPKPEERWRYI...</td>\n      <td>278.0</td>\n      <td>7.0</td>\n      <td>48.4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25482</th>\n      <td>31385</td>\n      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n      <td>549.0</td>\n      <td>7.0</td>\n      <td>51.8</td>\n    </tr>\n    <tr>\n      <th>25483</th>\n      <td>31386</td>\n      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n      <td>469.0</td>\n      <td>7.0</td>\n      <td>37.2</td>\n    </tr>\n    <tr>\n      <th>25484</th>\n      <td>31387</td>\n      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n      <td>128.0</td>\n      <td>7.0</td>\n      <td>64.6</td>\n    </tr>\n    <tr>\n      <th>25485</th>\n      <td>31388</td>\n      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n      <td>593.0</td>\n      <td>7.0</td>\n      <td>50.7</td>\n    </tr>\n    <tr>\n      <th>25486</th>\n      <td>31389</td>\n      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n      <td>537.0</td>\n      <td>7.0</td>\n      <td>37.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>25031 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_short = data_train[data_train[\"sequence_size\"] < ub]\n",
    "\n",
    "\n",
    "data_train_short"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Dependent variable split\n",
    "\n",
    "y_train = data_train_short.loc[:,\"ph\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Foram removidas 456 amostras (25487 - 25031) que tinham um tamanho de sequência superior à média + 3 vezes o desvio padrão (que consideramos como outlier)\n",
    "\n",
    "Desta forma, ficamos com um tamanho máximo de sequência igual a:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "1728.0"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data_train_short[\"sequence_size\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "6e12a487-0177-4118-9f16-f4a33b5f58be",
   "metadata": {},
   "source": [
    "#### Extend sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos agora estender as sequências restantes para terem todas o tamanho igual a 1728 resíduos. Vamos adicionar o símbolo \"-\" ao final de cada sequência de menor tamanho até atingirem o tamanho máximo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92ff0710-7ead-4fc2-8c6b-edef5ee845d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1728"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(max(data_train_short[\"protein_sequence\"], key=len))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81775f4d-76f9-4f4f-95d5-e6ba11eba1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in data_train_short.iterrows():\n",
    "    seq = row[\"protein_sequence\"]\n",
    "    while len(seq) < max_len:\n",
    "        seq += \"-\"\n",
    "    data_train.iloc[i, 1] = seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea7f3f-5e42-44f7-8af6-d89fcdfdb7ed",
   "metadata": {},
   "source": [
    "#### One-hot encode sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e008b4-c73b-4548-aba2-56a9183a9894",
   "metadata": {},
   "source": [
    "#### Consumo de RAM:\n",
    "num_sequences = 25031\n",
    "<br>max_len = 1728\n",
    "<br>alphabet_len = 21 characters\n",
    "<br>cell_size = 64 bits (int64)\n",
    "<br>total_bits = num_sequences * max_len * alphabet_len * cell_cize = 58132795392 bits\n",
    "<br><b>total_gb = 6.77 Gb</b>\n",
    "<br><b>prev_total_gb = 37.67 Gb</b> (Sem remoção de outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com esta remoção de outliers, foi possível poupar **30.9 Gb de RAM**. Contudo, continua a ser um valor elevado, pelo que não é aconselhável a correr o código do seguimento, onde iremos criar um dataset com a nova representação"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ffb296b-37e0-405b-957e-93d149128010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(seq):\n",
    "    alphabet = \"ACDEFGHIKLMNPQRSTVWY-\"\n",
    "    one_hot = {}\n",
    "    for i, l1 in enumerate(seq):\n",
    "        for l2 in alphabet:\n",
    "            one_hot[f\"{l2}{i}\"] = int(l1 == l2)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be67378-c199-4ce1-a083-e8acb37f2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN !!!\n",
    "one_hot = [one_hot_encoding(seq) for seq in data_train[\"protein_sequence\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07840a1-917e-449b-a3d4-936685ed782c",
   "metadata": {},
   "source": [
    "#### Create new pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e7fd8a4-38e0-4eb5-9018-2f40df939fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_one_hot = pd.DataFrame.from_records(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98da00-31fb-4f38-bb4e-ca6776f62b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pode-se posteriormente utilizar este novo dataset para efetuar as seguintes análises de Deep Learning. Serve como representação de uma possível metodologia que tem demonstrado bons resultados, mas por uma questão de limitações computacionais, não iremos prosseguir com a análise utilizando este dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "De forma semelhante ao que se fez com as redes de camadas densas, para aplicar redes convolucionais, vamos criar funções para compilar as redes de acordo com os hiperparâmetros selecionados. Desta forma, será possível efetuar uma otimização dos valores dos mesmos para encontrar o melhor conjunto de valores (que neste caso não vai ser possível averiguar)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Dense, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _choose_optimizer(optimizer, learning_rate, momentum):\n",
    "    if optimizer == \"sgd\":\n",
    "        return SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        return RMSprop(learning_rate=learning_rate, momentum=momentum)\n",
    "    elif optimizer == \"adagrad\":\n",
    "        return Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adadelta\":\n",
    "        return Adadelta(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adam\":\n",
    "        return Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adamax\":\n",
    "        return Adamax(learning_rate=learning_rate)\n",
    "    elif optimizer == \"nadam\":\n",
    "        return Nadam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized optimizer\")\n",
    "\n",
    "\n",
    "def create_model(input_shape, kernels, filters, kernel_size, activation, max_len, neurons, weight_constraint, dropout_rate, learning_rate, momentum, init_mode='uniform', optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    for ix in range(kernels):\n",
    "        if ix == 0:\n",
    "            model.add(Conv1D(filters,\n",
    "                             kernel_size[ix],\n",
    "                             activation=activation,\n",
    "                             input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Conv1D(filters,\n",
    "                             kernel_size[ix],\n",
    "                             activation=activation))\n",
    "\n",
    "        model.add(MaxPooling1D(pool_size= max_len - kernel_size[ix] + 1))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    #Only 1 Dense layer at the end, for simplicity purposes\n",
    "    model.add(Dense(neurons,\n",
    "                    activation=activation,\n",
    "                    kernel_initializer=init_mode,\n",
    "                    kernel_constraint=MaxNorm(weight_constraint)))\n",
    "\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1,\n",
    "                    activation=activation,\n",
    "                    kernel_initializer=init_mode))\n",
    "\n",
    "    opt = _choose_optimizer(optimizer.lower(), learning_rate, momentum)\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=opt, metrics=[\"mse\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Parameter values to optimize:\n",
    "kernels = [4,6,8]\n",
    "filters = np.linspace(20, 200, 10)\n",
    "kernel_size = np.linspace(5, 20, 4)\n",
    "learning_rate = np.linspace(0.005, 0.5, 100)\n",
    "momentum = np.linspace(0.0, 0.9, 4)\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "#(for second-to-last Dense layer)\n",
    "neurons = [20,50,100]\n",
    "dropout_rate = np.linspace(0.0, 0.5, 6)\n",
    "weight_constraint = np.linspace(0.5, 5, 10) #Max norm value each weight parameter can be\n",
    "\n",
    "#For computational purposes, all layers will have the same  weight_constraint and dropout_rate values\n",
    "\n",
    "param_dist = dict(model__filters=filters,\n",
    "                  model__kernel_size=kernel_size,\n",
    "                  model__neurons=neurons,\n",
    "                  model__dropout_rate=dropout_rate,\n",
    "                  model__weight_constraint=weight_constraint,\n",
    "                  model__learning_rate=learning_rate,\n",
    "                  model__momentum=momentum,\n",
    "                  model__optimizer=optimizer)\n",
    "\n",
    "for ix in [4,6,8]:\n",
    "    print(f\"Retrieving best parameters for a {ix} layered convolutional neural network (n_iter=50, cv=5):\\n|\")\n",
    "    model = KerasRegressor(model=create_model, epochs=100, batch_size=10, verbose=0,\n",
    "                       input_shape=[data_train_one_hot.shape[1]],\n",
    "                       kernels=ix,\n",
    "                       max_len=max_len,\n",
    "                       activation=\"relu\")\n",
    "\n",
    "    grid = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, n_jobs=-1, cv=5)\n",
    "    grid.fit(data_train_one_hot, y_train)\n",
    "    print(f\"Best score: {grid.best_score_}\")\n",
    "    print(f\"Best parameters: {grid.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
